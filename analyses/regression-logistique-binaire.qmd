# Régression logistique binaire {#sec-regression-logistique-binaire}

Dans le chapitre précédent (@sec-regression-lineaire), nous avons abordé la régression linéaire pour les variables continues. Pour analyser une variable catégorielle, il est nécessaire d'avoir recours à d'autres types de modèles. Les modèles linéaires généralisés (*generalized linear models* ou *GLM* en anglais) sont une généralisation de la régression linéaire grâce à l'utilisation d'une fonction de **lien** utilisée pour transformer la variable à expliquer et pouvoir ainsi retomber sur un modèle linéaire classique. Il existe de multiples fonctions de lien correspondant à tout autant de modèles. Par exemple, on pourra utiliser un modèle de Poisson pour une variable entière positive ou un modèle d'incidence.

Pour une variable binaire (c'est-à-dire du type <q>oui / non</q> ou <q>vrai / faux</q>), les modèles les plus courants utilisent les fonctions de lien *probit* ou *logit*, cette dernière fonction correspondent à la **régression logistique binaire** (modèle *logit*). Comme pour la régression linéaire, les variables explicatives peuvent être continues et/ou catégorielles.

## Préparation des données

Dans ce chapitre, nous allons encore une fois utiliser les données de l'enquête *Histoire de vie*, fournies avec l'extension `{questionr}`.

```{r}
#| warning: false
data(hdv2003, package = "questionr")
d <- hdv2003
```

À titre d'exemple, nous allons étudier l'effet de l'âge, du sexe, du niveau d'étude, de la pratique religieuse et du nombre moyen d'heures passées à regarder la télévision par jour sur la probabilité de pratiquer un sport.

En premier lieu, il importe de vérifier, par exemple avec `labelled::look_for()`, que notre variable d'intérêt (ici *sport*) est correctement codée, c'est-à-dire que la première modalité correspondent à la référence (soit ne pas avoir vécu l'évènement d'intérêt) et que la seconde modalité corresponde au fait d'avoir vécu l'évènement.

```{r}
library(labelled)
d |> look_for("sport")
```

Dans notre exemple, la modalité <q>Non</q> est déjà la première modalité. Il n'y a donc pas besoin de modifier notre variable.

Il faut également la présence éventuelle de données manquantes (`NA`)[^regression-logistique-binaire-1]. Les observations concernées seront tout simplement exclues du modèle lors de son calcul. Ce n'est pas notre cas ici.

[^regression-logistique-binaire-1]: Pour visualiser le nombre de données manquantes (`NA`) de l'ensemble des variables d'un tableau, on pourra avoir recours à `questionr::freq.na()`.

::: callout-tip
Alternativement, on pourra aussi coder notre variable à expliquer sous forme booléenne (`FALSE` / `TRUE`) ou numériquement en `0`/`1`.

Il est possible d'indiquer un facteur à plus de deux modalités. Dans une telle situation, **R** considérera que tous les modalités, sauf la modalité de référence, est une réalisation de la variable d'intérêt. Cela serait correct, par exemple, si notre variable sport était codée ainsi : <q>Non</q>, <q>Oui, de temps en temps</q>, <q>Oui, régulièrement</q>. Cependant, afin d'éviter tout risque d'erreur ou de mauvaise interprétation, il est vivement conseillé de recoder au préalable sa variable d'intérêt en un facteur à deux modalités.
:::

La notion de **modalité de référence** s'applique également aux variables explicatives catégorielles. En effet, dans un modèle, tous les coefficients sont calculés par rapport à la modalité de référence (cf. @sec-regression-lineaire-variable-explicative-categorielle). Il importe donc de choisir une modalité de référence qui fasse sens afin de faciliter l'interprétation. Par ailleurs, ce choix doit dépendre de la manière dont on souhaite présenter les résultats (le *data storytelling* est essentiel). De manière générale on évitera de choisir comme référence une modalité peu représentée dans l'échantillon ou bien une modalité correspondant à une situation atypique.

Prenons l'exemple de la variable *sexe*. Souhaite-t-on connaitre l'effet d'être une femme par rapport au fait d'être un homme ou bien l'effet d'être un homme par rapport au fait d'être une femme ? Si l'on opte pour le second, alors notre modalité de référence sera le sexe féminin. Comme est codée cette variable ?

```{r}
d |> look_for("sexe")
```

La modalité <q>Femme</q> s'avère ne pas être la première modalité. Nous devons appliquer la fonction `forcats::fct_relevel()` ou la fonction `stats::relevel()` :

```{r}
#| message: false
library(tidyverse)
d <- d |> 
  mutate(sexe = sexe |> fct_relevel("Femme"))
```

```{r}
d |> guideR::proportion(sexe)
```

::: important
**Données labellisées**

Si l'on utilise des données labellisées (voir @sec-etiquettes-valeurs), nos variables catégorielles seront stockées sous la forme d'un vecteur numérique avec des étiquettes. Il sera donc nécessaire de convertir ces variables en facteurs, tout simplement avec `labelled::to_factor()` ou `labelled::unlabelled()`.
:::

Les variables *age* et *heures.tv* sont des variables quantitatives. Il importe de vérifier qu'elles sont bien enregistrées en tant que variables numériques. En effet, il arrive parfois que dans le fichier source les variables quantitatives soient renseignées sous forme de valeur textuelle et non sous forme numérique.

```{r}
d |> look_for("age", "heures")
```

Nos deux variables sont bien renseignées sous forme numérique (respectivement des entiers et des nombres décimaux).

Cependant, l'effet de l'âge est rarement linéaire. Un exemple trivial est par exemple le fait d'occuper un emploi qui sera moins fréquent aux jeunes âges et aux âges élevés. Dès lors, on pourra transformer la variable *age* en groupe d'âges (et donc en variable catégorielle) avec la fonction `cut()` (cf. @sec-cut) :

```{r}
d <- d |> 
  mutate(
    groupe_ages = age |>
      cut(
        c(18, 25, 45, 65, 99),
        right = FALSE,
        include.lowest = TRUE,
        labels = c("18-24 ans", "25-44 ans",
                   "45-64 ans", "65 ans et plus")
      )
  )
d |> guideR::proportion(groupe_ages)
```

Jetons maintenant un œil à la variable *nivetud* :

```{r}
d |> guideR::proportion(nivetud)
```

En premier lieu, cette variable est détaillée en pas moins de huit modalités dont certaines sont peu représentées (seulement 39 individus soit 2 % n'ont jamais fait d'études par exemple). Afin d'améliorer notre modèle logistique, il peut être pertinent de regrouper certaines modalités (cf. @sec-modifier-modalites) :

```{r}
d <- d |> 
  mutate(
    etudes = nivetud |> 
      fct_recode(
      "Primaire" = "N'a jamais fait d'etudes",
      "Primaire" = "A arrete ses etudes, avant la derniere annee d'etudes primaires",
      "Primaire" = "Derniere annee d'etudes primaires",
      "Secondaire" = "1er cycle",
      "Secondaire" = "2eme cycle",
      "Technique / Professionnel" = "Enseignement technique ou professionnel court",
      "Technique / Professionnel" = "Enseignement technique ou professionnel long",
      "Supérieur" = "Enseignement superieur y compris technique superieur"
    )    
  )
d |> guideR::proportion(etudes)
```

Notre variable comporte également 112 individus avec une valeur manquante. Si nous conservons cette valeur manquante, ces 112 individus seront, par défaut, exclus de l'analyse. Ces valeurs manquantes n'étant pas négligeable (5,6 %), nous pouvons également faire le choix de considérer ces valeurs manquantes comme une modalité supplémentaire. Auquel cas, nous utiliserons la fonction `forcats::fct_na_value_to_level()`  :

```{r}
d$etudes <- d$etudes |> 
  fct_na_value_to_level("Non documenté")
d |> guideR::proportion(etudes)
```

Enfin, pour améliorer les différentes sorties (tableaux et figures), nous allons ajouter des étiquettes de variables (cf. @sec-etiquettes-variables) avec `labelled::set_variable_labels()`.

```{r}
d <- d |> 
  set_variable_labels(
    sport = "Pratique un sport ?",
    sexe = "Sexe",
    groupe_ages = "Groupe d'âges",
    etudes = "Niveau d'études",
    relig = "Rapport à la religion",
    heures.tv = "Heures de télévision / jour"
  )
```

::: callout-note
## Code récapitulatif (préparation des données)

```{r}
data(hdv2003, package = "questionr")
d <-
  hdv2003 |> 
  mutate(
    sexe = sexe |> fct_relevel("Femme"),
    groupe_ages = age |>
      cut(
        c(18, 25, 45, 65, 99),
        right = FALSE,
        include.lowest = TRUE,
        labels = c("18-24 ans", "25-44 ans",
                   "45-64 ans", "65 ans et plus")
      ),
    etudes = nivetud |> 
      fct_recode(
        "Primaire" = "N'a jamais fait d'etudes",
        "Primaire" = "A arrete ses etudes, avant la derniere annee d'etudes primaires",
        "Primaire" = "Derniere annee d'etudes primaires",
        "Secondaire" = "1er cycle",
        "Secondaire" = "2eme cycle",
        "Technique / Professionnel" = "Enseignement technique ou professionnel court",
        "Technique / Professionnel" = "Enseignement technique ou professionnel long",
        "Supérieur" = "Enseignement superieur y compris technique superieur"
    ) |> 
    fct_na_value_to_level("Non documenté")  
  ) |> 
  set_variable_labels(
    sport = "Pratique un sport ?",
    sexe = "Sexe",
    groupe_ages = "Groupe d'âges",
    etudes = "Niveau d'études",
    relig = "Rapport à la religion",
    heures.tv = "Heures de télévision / jour"
  )
```
:::

## Statistiques descriptives

Avant toute analyse multivariable, il est toujours bon de procéder à une analyse descriptive bivariée simple, tout simplement avec `gtsummary::tbl_summary()`. Dans le cas présent, il est préférable d'afficher les pourcentages en ligne qui permettent ainsi de comparer de suite la proportion de personnes faisant du sport entre les différentes catégories.

Ajoutons quelques tests de comparaison avec `gtsummary::add_p()`. Petite astuce : `gtsummary::modify_spanning_header()` permet de rajouter un en-tête sur plusieurs colonnes.

```{r}
#| message: false
library(gtsummary)
theme_gtsummary_language("fr", decimal.mark = ",", big.mark = " ")
```

```{r}
#| label: tbl-analyse-bivariee
#| tbl-cap: Pratique d'un sport selon différentes variables explicatives (analyse bivariée)
d |> 
  tbl_summary(
    by = sport,
    include = c(sexe, groupe_ages, etudes, relig, heures.tv),
    percent = "row"
  ) |>
  add_overall(last = TRUE) |> 
  add_p() |> 
  bold_labels() |> 
  modify_spanning_header(
    all_stat_cols(stat_0 = FALSE) ~ "**Pratique un sport ?**"
  )
```

::: callout-tip
## Comparer visuellement une proportion entre sous-groupes

Depuis sa version 0.2.0, `{guideR}`, le package compagnon de *guide-R*, propose une fonction `guideR::plot_proportions()` qui permet de comparer facilement les proportions selon plusieurs sous-groupes, en affichant également les intervalles de confiance et les p-valeurs (test de Fisher par défaut).

```{r}
#| fig-height: 6
#| fig-width: 6
d |> 
  guideR::plot_proportions(
    sport == "Oui",
    by = c(sexe, groupe_ages, etudes, relig),
    fill = "lightblue",
    flip = TRUE
  )
```
:::

## Calcul de la régression logistique binaire

La spécification d'une régression logistique se fait avec `stats::glm()` et est très similaire à celle d'une régression linéaire simple (cf. @sec-regression-lineaire-multivariee) : on indique la variable à expliquer suivie d'un tilde (`~`) puis des variables explicatives séparées par un plus (`+`)[^regression-logistique-binaire-2]. Il faut indiquer à `glm()` la famille du modèle souhaité : on indiquera simplement `family = binomial` pour un modèle *logit*[^regression-logistique-binaire-3].

[^regression-logistique-binaire-2]: Il est possible de spécifier des modèles plus complexes, notamment avec des effets d'interaction, qui seront aborder plus loin (cf. @sec-interactions).

[^regression-logistique-binaire-3]: Pour un modèle *probit*, on indiquera `family = binomial("probit")`.

```{r}
mod <- glm(
  sport ~ sexe + groupe_ages + etudes + relig + heures.tv,
  family = binomial,
  data = d
)
```

Pour afficher les résultats du modèle, le plus simple est d'avoir recours à `gtsummary::tbl_regression()`.

```{r}
#| label: tbl-regression-logistique
#| tbl-cap: Facteurs associés à la pratique d'un sport (régression logistique binaire)
mod |> 
  tbl_regression(intercept = TRUE) |> 
  bold_labels()
```

## Interpréter les coefficients {#sec-interpreter-coefficients-regression-logistique}

L'*intercept* traduit la situation à la référence (i.e. toutes les variables catégorielles à leur modalité de référence et les variables continues à 0), après transformation selon la fonction de lien (i.e. après la transformation *logit*).

Illustrons cela. Supposons donc une personne de sexe féminin, âgée entre 18 et 24 ans, de niveau d'étude primaire, pratiquante régulière et ne regardant pas la télévision (situation de référence). Seul l'*intercept* s'applique dans le modèle, et donc le modèle prédit que sa probabilité de faire du sport est de $-0,80$ selon l'échelle *logit*. Retraduisons cela en probabilité classique avec la fonction *logit inverse*.

```{r}
logit_inverse <- binomial("logit") |> purrr::pluck("linkinv")
logit_inverse(-0.80)
```

Selon le modèle, la probabilité que cette personne fasse du sport est donc de $31\%$.

Prenons maintenant une personne identique mais de sexe masculin. Nous devons donc considérer, en plus de l'*intercept*, le coefficient associé à la modalité <q>Homme</q>. Sa probabilité de faire du sport est donc :

```{r}
logit_inverse(-0.80 + 0.44)
```

Le coefficient associé à <q>Homme</q> est donc un modificateur par rapport à la situation de référence.

Enfin, considérons que cette dernière personne regarde également la télévision 2 heures en moyenne par jour. Nous devons alors considérer le coefficient associé à la variable *heures.tv* et, comme il s'agit d'une variable continue, multiplier ce coefficient par 2, car le coefficient représente le changement pour un incrément de 1 unité.

```{r}
logit_inverse(-0.80 + 0.44 + 2 * -0.12)
```

Il est crucial de bien comprendre comment dans quels cas et comment chaque coefficient est utilisé par le modèle.

Le package `{breakdown}` permet de mieux visualiser notre dernier exemple.

```{r}
individu3 <- d[1, ]
individu3$sexe[1] <- "Homme"
individu3$groupe_ages[1] <- "18-24 ans"
individu3$etudes[1] <- "Primaire"
individu3$relig[1] <- "Pratiquant regulier"
individu3$heures.tv[1] <- 2
```

```{r}
#| label: breakdown-individu3
#| fig-cap: Décomposition de la probabilité de faire du sport de l'individu 3
#| message: false
library(breakDown)
logit <- function(x) exp(x) / (1 + exp(x))
plot(
  broken(mod, individu3, predict.function = betas),
  trans = logit
) +
  scale_y_continuous(
    labels = scales::label_percent(),
    breaks = 0:5/5,
    limits = c(0, 1)
  )
```

## La notion d'*odds ratio*

L'un des intérêts de la régression logistique *logit* réside dans le fait que l'exponentiel des coefficients correspond à des *odds ratio* ou rapport des côtes en français.

::: callout-tip
Pour comprendre la notion de côte (*odd* en anglais), on peut se référer aux paris sportifs. Par exemple, lorsque les trois quarts des parieurs parient que le cheval A va remporter la course, on dit alors que ce cheval à une côte de trois contre un (trois personnes parient qu'il va gagner contre une personne qu'il va perdre). Prenons un autre cheval : si les deux tiers pensent que le cheval B va perdre (donc un tiers pense qu'il va gagner), on dira alors que sa côte est de un contre deux (une personne pense qu'il va gagner contre deux qu'il va perdre).

Si l'on connait la proportion ou probabilité *p* d'avoir vécu ou de vivre un évènement donné (ici gagner la course), la côte (l'*odd*) s'obtient avec la formule suivante : $p/(1-p)$. La côte du cheval A est bien $0,75/(1-0,75)=0,75/0,25=3$ est celle du cheval B $(1/3)/(2/3)=1/2=0,5$.

Pour comparer deux côtes (par exemple pour savoir si le cheval A a une probabilité plus élevée de remporter la course que le cheval B, selon les parieurs), on calculera tout simplement le rapport des côtes ou *odds ratio* (OR) : $OR_{A/B}=Odds_{A}/Odds_{B}=3/0,5=6$.

Ce calcul peut se faire facilement dans **R** avec la fonction `questionr::odds.ratio()`.

```{r}
questionr::odds.ratio(.75, 1/3)
```

L'*odds ratio* est donc égal à 1 si les deux côtes sont identiques, est supérieur à 1 si le cheval A une probabilité supérieure à celle du cheval B, et inférieur à 1 si c'est probabilité est inférieure.

On le voit, par construction, l'*odds ratio* de B par rapport à A est l'inverse de celui de A par rapport à B : $OR_{B/A}=1/OR_{A/B}$.
:::

Pour afficher les *odds ratio* il suffit d'indiquer `exponentiate = TRUE` à `gtsummary::tbl_regression()`.

```{r}
#| label: tbl-regression-logistique-OR
#| tbl-cap: Facteurs associés à la pratique d'un sport (*odds ratios*)
mod |> 
  tbl_regression(exponentiate = TRUE) |> 
  bold_labels()
```

Pour une représentation visuelle, graphique en forêt ou *forest plot* en anglais, on aura tout simplement recours à `ggstats::ggcoef_model()`.

```{r}
#| label: fig-forest-plot-regression-logistique
#| fig-cap: Facteurs associés à la pratique d'un sport (*forest plot*)
mod |> 
  ggstats::ggcoef_model(exponentiate = TRUE)
```

On pourra alternativement préférer `ggstats::ggcoef_table()`[^regression-logistique-binaire-4] qui affiche un tableau des coefficients à la droite du *forest plot*.

[^regression-logistique-binaire-4]: `ggstats::ggcoef_table()` est disponible à partir de la version 0.4.0 de `{ggstats}`.

```{r}
#| label: fig-ggcoef_table-regression-logistique
#| fig-cap: Facteurs associés à la pratique d'un sport (*forest plot* avec table des coefficients)
mod |> 
  ggstats::ggcoef_table(exponentiate = TRUE)
```

::: callout-note
Lorsque l'on réalise un *forest plot* de coefficients exponentialisés tels que des *odds ratios*, une bonne pratique consiste à utiliser une échelle logarithmique. En effet, l'inverse d'un *odds ratio* de 2 est 0,5. Avec une échelle logarithmique, la distance entre 0,5 et 1 est égale à celle entre 1 et 2. Sur la figure précédente, vous pourrez noter que `ggstats::ggcoef_model()` applique automatiquement une échelle logarithmique lorsque `exponentiate = TRUE`.

Quelques références : [Forest Plots: Linear or Logarithmic Scale?](https://doi.org/10.1016/j.jadohealth.2017.07.025) ou encore [Graphing Ratio Measures on Forest Plot](https://doi.org/10.1016/j.jacc.2017.10.098).
:::

::: callout-caution
En rédigeant les résultats de la régression, il faudra être vigilant à ne pas confondre les *odds ratios* avec des *prevalence ratios*. Avec un *odds ratio* de 1,55, il serait tentant d'écrire que <q>les hommes ont une probabilité 55% supérieure de pratique un sport que les femmes</q> (toutes choses égales par ailleurs). Une telle formulation correspond à un *prevalence ratio* (rapport des prévalences en français) ou *risk ratio* (rapport des risques), à savoir diviser la probabilité de faire du sport des hommes par celle des femmes, $p_{hommes}/p_{femmes}$. Or, cela ne correspond pas à la formule de l'*odds ratio*, à savoir $(p_{hommes}/(1-p_{hommes}))/(p_{femmes}/(1-p_{femmes}))$.

Lorsque le phénomène étudié est rare et donc que les probabilités sont faibles (inférieures à quelques pour-cents), alors il est vrai que les *odds ratio* sont approximativement égaux aux *prevalence ratios*. Mais ceci n'est plus du tout vrai pour des phénomènes plus fréquents.
:::

## Afficher les écarts-types plutôt que les intervalles de confiance

La manière de présenter les résultats d'un modèle de régression varie selon les disciplines, les champs thématiques et les revues. Si en sociologie et épidémiologie on aurait plutôt tendance à afficher les *odds ratio* avec leur intervalle de confiance, il est fréquent en économétrie de présenter plutôt les coefficients bruts et leurs écarts-types (*standard deviation* ou *sd* en anglais). De même, plutôt que d'ajouter une colonne avec les p valeurs, un usage consiste à afficher des étoiles de significativité à la droite des coefficients significatifs.

Pour cela, on pourra personnaliser le tableau produit avec `gtsummary::tbl_regression()`, notamment avec `gtsummary::add_significance_stars()` pour l'ajout des étoiles de significativité, ainsi que `gtsummary::modify_column_hide()` et `gtsummary::modify_column_unhide()` pour afficher / masquer les colonnes du tableau produit[^regression-logistique-binaire-5].

[^regression-logistique-binaire-5]: La liste des colonnes disponibles peut être obtenues avec `mod |> tbl_regression() |> purrr::pluck("table_body") |> colnames()`.

```{r}
#| label: tbl-regression-presentation_econometrique
#| tbl-cap: Présentation économétrique des facteurs associés à la pratique d'un sport
mod |> 
  tbl_regression() |> 
  add_significance_stars() |> 
  modify_column_hide(c("ci", "p.value")) |> 
  modify_column_unhide("std.error") |> 
  bold_labels()
```

Les économistes pourraient préférer le package `{modelsummary}` à `{gtsummary}`. Ces deux packages ont un objectif similaire (la production de tableaux statistiques) mais abordent cet objectif avec des approches différentes. Il faut noter que `modelsummary::modelsummary()` n'affiche pas les modalités de référence, ni les étiquettes de variable.

```{r}
#| label: tbl-modelsummary
#| tbl-cap: Présentation des facteurs associés à la pratique d'un sport avec modelsummary()
mod |> modelsummary::modelsummary(stars = TRUE)
```

La fonction `modelsummary::modelplot()` permet d'afficher un graphique des coefficients.

```{r}
#| label: fig-modelplot
#| fig-cap: Facteurs associés à la pratique d'un sport avec modelplot()
mod |> modelsummary::modelplot()
```

**ATTENTION :** si l'on affiche les *odds ratio* avec `exponentiate = TRUE`, `modelsummary::modelplot()` conserve par défaut une échelle linéaire. On sera donc vigilant à appliquer `ggplot2::scale_x_log10()` manuellement pour utiliser une échelle logarithmique.

```{r}
#| label: fig-modelplot-or
#| fig-cap: Odds Ratios associés à la pratique d'un sport avec modelplot()
mod |>
  modelsummary::modelplot(exponentiate = TRUE) +
  ggplot2::scale_x_log10()
```

## Afficher toutes les comparaisons (*pairwise contrasts*)

Dans le tableau des résultats (@tbl-regression-logistique-OR), pour les variables catégorielles, il importe de bien garder en mémoire que chaque *odds ratio* doit se comparer à la valeur de référence. Ainsi, les *odds ratios* affichés pour chaque classe d'âges correspondent à une comparaison avec la classe d'âges de références, les 18-24 ans. La p-valeur associée nous indique quant à elle si cet *odds ratio* est significativement de 1, donc si cette classe d'âges données se comporte différemment de celle de référence.

Mais cela ne nous dit nullement si les 65 ans et plus diffèrent des 45-64 ans. Il est tout à fait possible de recalculer l'*odds ratio* correspondant en rapport les *odds ratio* à la référence : $OR_{65+/45-64}=OR_{65+/18-24}/OR_{45-64/18-24}$.

Le package `{emmeans}` et sa fonction `emmeans::emmeans()` permettent de recalculer toutes les combinaisons d'*odds ratio* (on parle alors de *pairwise contrasts*) ainsi que leur intervalle de confiance et la p-valeur correspondante.

On peut ajouter facilement[^regression-logistique-binaire-6] cela au tableau produit avec `gtsummary::tbl_regression()` en ajoutant l'option `add_pairwise_contrasts = TRUE`.

[^regression-logistique-binaire-6]: Cela nécessite néanmoins au minimum la version 1.11.0 du package `{broom.helpers}` et la version 1.6.3 de `{gtsummary}`.

```{r}
#| label: tbl-regression-logistique-pairwise
#| tbl-cap: Facteurs associés à la pratique d'un sport (*pairwise contrasts*)
mod |> 
  tbl_regression(
    exponentiate = TRUE,
    add_pairwise_contrasts = TRUE
  ) |> 
  bold_labels()
```

De même, on peur visualiser les coefficients avec la même option dans `ggstats::ggcoef_model()`[^regression-logistique-binaire-7]. On peut d'ailleurs choisir les variables concernées avec l'argument `pairwise_variables`.

[^regression-logistique-binaire-7]: Cela nécessite néanmoins au minimum la version 1.11.0 du package `{broom.helpers}` et la version 0.2.0 de `{ggstats}`.

```{r}
#| label: fig-forest-plot-regression-logistique-pairwise
#| fig-cap: Facteurs associés à la pratique d'un sport (*pairwise contrasts*)
mod |> 
  ggstats::ggcoef_model(
    exponentiate = TRUE,
    add_pairwise_contrasts = TRUE,
    pairwise_variables = c("groupe_ages", "etudes")
  )
```

## Identifier les variables ayant un effet significatif {#sec-reg-log-anova}

Pour les variables catégorielles à trois modalités ou plus, les p-valeurs associées aux *odds ratios* nous indique si un *odd ratio* est significativement différent de 1, par rapport à la modalité de référence. Mais cela n'indique pas si globalement une variable a un effet significatif sur le modèle. Pour tester l'effet global d'une variable, on peut avoir recours à la fonction `car::Anova()`. Cette dernière va tour à tour supprimer chaque variable du modèle et réaliser une analyse de variance (ANOVA) pour voir si la variance change significativement.

```{r}
car::Anova(mod)
```

Ainsi, dans le cas présent, la suppression de la variable *relig* ne modifie significativement pas le modèle, indiquant l'absence d'effet de cette variable.

Si l'on a recours à `gtsummary::tbl_regression()`, on peut facilement ajouter les p-valeurs globales avec `gtsummary::add_global_p()`[^regression-logistique-binaire-8].

[^regression-logistique-binaire-8]: Si l'on veut conserver les p-valeurs individuelles associées à chaque *odds ratio*, on ajoutera l'option `keep = TRUE`.

```{r}
#| label: tbl-regression-logistique-global-p
#| tbl-cap: Ajout des p-valeurs globales
mod |>
  tbl_regression(exponentiate = TRUE) |>
  bold_labels() |> 
  add_global_p()
```

::: callout-note
Concernant le test réalisé dans le cadre d'une Anova, il existe trois tests différents que l'on présente comme le type 1, le type 2 et le type 3 (ou I, II et III). Pour une explication sur ces différents types, on pourra se référer (en anglais) à <https://mcfromnz.wordpress.com/2011/03/02/anova-type-iiiiii-ss-explained/> ou encore <http://md.psych.bio.uni-goettingen.de/mv/unit/lm_cat/lm_cat_unbal_ss_explained.html>.

Le type I n'est pas recommandé dans le cas présent car il dépend de l'ordre dans lequel les différentes variables sont testées.

Lorsqu'il n'y a pas d'interaction dans un modèle, le type II serait à privilégier car plus puissant (nous aborderons les interactions dans un prochain chapitre, cf. @sec-interactions).

En présence d'interactions, il est conseillé d'avoir plutôt recours au type III. Cependant, en toute rigueur, pour utiliser le type III, il faut que les variables catégorielles soient codées en utilisant un contrastes dont la somme est nulle (un contraste de type somme ou polynomial). Or, par défaut, les variables catégorielles sont codées avec un contraste de type <q>traitement</q> (nous aborderons les différents types de contrastes plus tard, cf. @sec-contrastes).

Par défaut, `car::Anova()` utilise le type II et `gtsummary::add_global_p()` le type III. Dans les deux cas, il est possible de préciser le type de test avec `type = "II"` ou `type = "III"`.

Dans le cas de notre exemple, un modèle simple sans interaction, le type de test ne change pas les résultats.
:::

## Régressions logistiques univariables {#sec-regressions-logistiques-univariables}

Les usages varient selon les disciplines et les revues scientifiques, mais il n'est pas rare de présenter, avant le modèle logistique multivariable, une succession de modèles logistiques univariables (i.e. avec une seule variable explicative à la fois) afin de présenter les *odds ratios* et leur intervalle de confiance et p-valeur associés avant l'ajustement multiniveau.

Afin d'éviter le code fastidieux consistant à réaliser chaque modèle un par un (par exemple `glm(sport ~ sexe, family = binomial, data = d)`) puis à en fusionner les résultats, on pourra tirer partie de `gtsummary::tbl_uvregression()` qui permet de réaliser toutes ces régressions individuelles en une fois et de les présenter dans un tableau synthétique.

```{r}
#| label: tbl-uregression
#| tbl-cap: Régressions logistiques univariables
d |>
  tbl_uvregression(
    y = sport,
    include = c(sexe, groupe_ages, etudes, relig, heures.tv),
    method = glm,
    method.args = list(family = binomial),
    exponentiate = TRUE
  ) |> 
  bold_labels()
```

## Présenter l'ensemble des résultats dans un même tableau

La fonction `gtsummary::tbl_merge()` permet de fusionner plusieurs tableaux (en tenant compte du nom des variables) et donc de présenter les différents résultats de l'analyse descriptive, univariable et multivariable dans un seul et même tableau.

```{r}
#| label: tbl-merge-regression-logistique
#| tbl-cap: tableau synthétique de l'analyse
tbl_desc <-
  d |> 
  tbl_summary(
    by = sport,
    include = c(sexe, groupe_ages, etudes, relig, heures.tv),
    statistic = all_categorical() ~ "{p}% ({n}/{N})",
    percent = "row",
    digits = all_categorical() ~ c(1, 0, 0)
  ) |> 
  modify_column_hide("stat_1") |> 
  modify_header("stat_2" ~ "**Pratique d'un sport**")

tbl_uni <-
  d |>
  tbl_uvregression(
    y = sport,
    include = c(sexe, groupe_ages, etudes, relig, heures.tv),
    method = glm,
    method.args = list(family = binomial),
    exponentiate = TRUE
  ) |> 
  modify_column_hide("stat_n")

tbl_multi <-
  mod |> 
  tbl_regression(exponentiate = TRUE)

list(tbl_desc, tbl_uni, tbl_multi) |> 
  tbl_merge(
    tab_spanner = c(
      NA,
      "**Régressions univariables**",
      "**Régression multivariable**"
    )
  ) |> 
  bold_labels()
```

:::: {.content-visible when-format="html"}
Le [diaporama ci-dessous](ressources/flipbook-regression-logistique.html) vous permet de visualiser chaque étape du code correspondant au graphique précédent.

::: {.column-page-right .ratio .ratio-16x9}
<iframe src="ressources/flipbook-regression-logistique.html">

</iframe>
:::
::::

::: {.content-visible unless-format="html"}
Pour visualiser chaque étape du code, vous pouvez consulter le diaporama suivant : <https://larmarange.github.io/guide-R/analyses/ressources/flipbook-regression-logistique.html>
:::

## webin-R

La régression logistique est présentée sur YouTube dans le [webin-R #06](https://youtu.be/-bdMv2aAqUY) (*régression logistique (partie 1)*) et le le [webin-R #07](https://youtu.be/BUo9i7XTLYQ) (*régression logistique (partie 2)*).

{{< video https://youtu.be/-bdMv2aAqUY >}}

{{< video https://youtu.be/BUo9i7XTLYQ >}}
