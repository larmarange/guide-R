[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "guide-R",
    "section": "",
    "text": "Préface\nCe guide porte sur l’analyse de données d’enquêtes avec le logiciel R, un logiciel libre de statistiques et de traitement de données. Les exemples présentés ici relèvent principalement du champs des sciences sociales quantitatives et des sciences de la santé. Ils peuvent néanmoins s’appliquer à d’autre champs disciplinaires. Comme tout ouvrage, ce guide ne peut être exhaustif.\nCe guide présente comment réaliser des analyses statistiques et diverses opérations courantes (comme la manipulation de données ou la production de graphiques) avec R. Il ne s’agit pas d’un cours de statistiques : les différents chapitres présupposent donc que vous avez déjà une connaissance des différentes techniques présentées. Si vous souhaitez des précisions théoriques / méthodologiques à propos d’un certain type d’analyses, nous vous conseillons d’utiliser votre moteur de recherche préféré. En effet, on trouve sur internet de très nombreux supports de cours (sans compter les nombreux ouvrages spécialisés disponibles en librairie).\nDe même, il ne s’agit pas d’une introduction ou d’un guide pour les utilisatrices et utilisateurs débutant·es. Si vous découvrez R, nous vous conseillons la lecture de l’Introduction à R et au tidyverse de Julien Barnier (https://juba.github.io/tidyverse/). Néanmoins, quelques rappels sur les bases du langage sont fournis dans la section Bases du langage. Une bonne compréhension de ces dernières, bien qu’un peu ardue de prime abord, permet de comprendre le sens des commandes que l’on utilise et de pleinement exploiter la puissance que R offre en matière de manipulation de données.\nR disposent de nombreuses extensions ou packages (plus de 16 000) et il existe souvent plusieurs manières de procéder pour arriver au même résultat. En particulier, en matière de manipulation de données, on oppose1 souvent base R qui repose sur les fonctions disponibles en standard dans R, la majorité étant fournies dans les packages {base}, {utils} ou encore {stats}, qui sont toujours chargés par défaut, et le tidyverse qui est une collection de packages comprenant, entre autres, dplyr, tibble, tidyr, forcats ou encore ggplot2. Il y a un débat ouvert, parfois passionné, sur le fait de privilégier l’une ou l’autre approche, et les avantages et inconvénients de chacune dépendent de nombreux facteurs, comme la lisibilité du code ou bien les performances en temps de calcul. Dans ce guide, nous avons adopté un point de vue pragmatique et utiliserons, le plus souvent mais pas exclusivement, les fonctions du tidyverse, de même que nous avons privilégié d’autres packages, comme gtsummary ou ggstats par exemple pour la statistique descriptive. Cela ne signifie pas, pour chaque point abordé, qu’il s’agit de l’unique manière de procéder. Dans certains cas, il s’agit simplement de préférences personnelles.\nBien qu’il en reprenne de nombreux contenus, ce guide ne se substitue pas au site analyse-R. Il s’agit plutôt d’une version complémentaire qui a vocation à être plus structurée et parfois plus sélective dans les contenus présentés.\nEn complément, on pourra également se référer aux webin-R, une série de vidéos avec partage d’écran, librement accessibles sur YouTube : https://www.youtube.com/c/webinR.\nCette version du guide a utilisé R version 4.4.1 (2024-06-14 ucrt). Ce document est généré avec quarto et le code source est disponible sur GitHub. Pour toute suggestion ou correction, vous pouvez ouvrir un ticket GitHub. Pour d’autres questions, vous pouvez utiliser les forums de discussion disponibles en bas de chaque page sur la version web du guide. Ce document est régulièrement mis à jour. La dernière version est consultable sur https://larmarange.github.io/guide-R/.",
    "crumbs": [
      "Préface"
    ]
  },
  {
    "objectID": "index.html#préface",
    "href": "index.html#préface",
    "title": "guide-R",
    "section": "",
    "text": "Guide en cours d’écriture\n\n\n\nCe guide est encore incomplet. Le plan prévu est visible à cette adresse : https://github.com/larmarange/guide-R/issues/12.\nEn attendant, nous vous conseillons de compléter votre lecture par le site analyse-R.\n\n\n\n\n\n\n1 Une comparaison des deux syntaxes est illustrée par une vignette dédiée de dplyr.",
    "crumbs": [
      "Préface"
    ]
  },
  {
    "objectID": "index.html#remerciements",
    "href": "index.html#remerciements",
    "title": "guide-R",
    "section": "Remerciements",
    "text": "Remerciements\nCe document a bénéficié de différents apports provenant notamment de l’Introduction à R et de l’Introduction à R et au tidyverse de Julien Barnier et d’analyse-R : introduction à l’analyse d’enquêtes avec R et RStudio. Certains chapitres se sont appuyés sur l’ouvrage de référence R for data science par Hadley Wickham, Mine Çetinkaya-Rundel et Garret Grolemund, ou encore sur les notes de cours d’Ewan Gallic.\nMerci donc à Julien Barnier, Julien Biaudet, François Briatte, Milan Bouchet-Valat, Mine Çetinkaya-Rundel, Ewen Gallic, Frédérique Giraud, Joël Gombin, Garret Grolemund, Mayeul Kauffmann, Christophe Lalanne, Nicolas Robette et Hadley Wickham.",
    "crumbs": [
      "Préface"
    ]
  },
  {
    "objectID": "index.html#licence",
    "href": "index.html#licence",
    "title": "guide-R",
    "section": "Licence",
    "text": "Licence\nCe document est mis à disposition selon les termes de la Licence Creative Commons Attribution - Pas d’Utilisation Commerciale - Partage dans les Mêmes Conditions 4.0 International.",
    "crumbs": [
      "Préface"
    ]
  },
  {
    "objectID": "bases/packages.html",
    "href": "bases/packages.html",
    "title": "1  Packages",
    "section": "",
    "text": "1.1 Installation (CRAN)\nL’installation d’une extension se fait par la fonction install.packages(), à qui on fournit le nom de l’extension. Par exemple, si on souhaite installer l’extension gtsummary :\ninstall.packages(\"gtsummary\")\nSous RStudio, on pourra également cliquer sur Install dans l’onglet Packages du quadrant inférieur droit.\nAlternativement, on pourra avoir recours au package remotes et à sa fonction remotes::install_cran() :\nremotes::install_cran(\"gtsummary\")",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Packages</span>"
    ]
  },
  {
    "objectID": "bases/packages.html#installation-cran",
    "href": "bases/packages.html#installation-cran",
    "title": "1  Packages",
    "section": "",
    "text": "Note\n\n\n\nLe package remotes n’est pas disponible par défaut sous R et devra donc être installé classiquement avec install.packages(\"remotes\"). À la différence de install.packages(), remotes::install_cran() vérifie si le package est déjà installé et, si oui, si la version installée est déjà la dernière version, avant de procéder à une installation complète si et seulement si cela est nécessaire.",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Packages</span>"
    ]
  },
  {
    "objectID": "bases/packages.html#chargement",
    "href": "bases/packages.html#chargement",
    "title": "1  Packages",
    "section": "\n1.2 Chargement",
    "text": "1.2 Chargement\nUne fois un package installé (c’est-à-dire que ses fichiers ont été téléchargés et copiés sur votre ordinateur), ses fonctions et objets ne sont pas directement accessibles. Pour pouvoir les utiliser, il faut, à chaque session de travail, charger le package en mémoire avec la fonction library() ou la fonction require() :\n\nlibrary(gtsummary)\n\nÀ partir de là, on peut utiliser les fonctions de l’extension, consulter leur page d’aide en ligne, accéder aux jeux de données qu’elle contient, etc.\nAlternativement, pour accéder à un objet ou une fonction d’un package sans avoir à le charger en mémoire, on pourra avoir recours à l’opérateur ::. Ainsi, l’écriture p::f() signifie la fonction f() du package p. Cette écriture sera notamment utilisée tout au long de ce guide pour indiquer à quel package appartient telle fonction : remotes::install_cran() indique que la fonction install_cran() provient du packages remotes.\n\n\n\n\n\n\nImportant\n\n\n\nIl est important de bien comprendre la différence entre install.packages() et library(). La première va chercher un package sur internet et l’installe en local sur le disque dur de l’ordinateur. On n’a besoin d’effectuer cette opération qu’une seule fois. La seconde lit les informations de l’extension sur le disque dur et les met à disposition de R. On a besoin de l’exécuter à chaque début de session ou de script.",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Packages</span>"
    ]
  },
  {
    "objectID": "bases/packages.html#mise-à-jour",
    "href": "bases/packages.html#mise-à-jour",
    "title": "1  Packages",
    "section": "\n1.3 Mise à jour",
    "text": "1.3 Mise à jour\nPour mettre à jour l’ensemble des packages installés, il suffit d’exécuter la fonction update.packages() :\n\nupdate.packages()\n\nSous RStudio, on pourra alternativement cliquer sur Update dans l’onglet Packages du quadrant inférieur droit.\nSi on souhaite désinstaller une extension précédemment installée, on peut utiliser la fonction remove.packages() :\n\nremove.packages(\"gtsummary\")\n\n\n\n\n\n\n\nInstaller / Mettre à jour les packages utilisés par un projet\n\n\n\nAprès une mise à jour majeure de R, il est souvent nécessaire de réinstaller tous les packages utilisés. De même, on peut parfois souhaiter mettre à jour uniquement les packages utilisés par un projet donné sans avoir à mettre à jour tous les autres packages présents sur son PC.\nUne astuce consiste à avoir recours à la fonction renv::dependencies() qui examine le code du projet courant pour identifier les packages utilisés, puis à passer cette liste de packages à remotes::install_cran() qui installera les packages manquants ou pour lesquels une mise à jour est disponible.\nIl vous suffit d’exécuter la commande ci-dessous :\n\nrenv::dependencies() |&gt; \n  purrr::pluck(\"Package\") |&gt;\n  unique() |&gt; \n  remotes::install_cran()",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Packages</span>"
    ]
  },
  {
    "objectID": "bases/packages.html#installation-depuis-github",
    "href": "bases/packages.html#installation-depuis-github",
    "title": "1  Packages",
    "section": "\n1.4 Installation depuis GitHub",
    "text": "1.4 Installation depuis GitHub\nCertains packages ne sont pas disponibles sur CRAN mais seulement sur GitHub, une plateforme de développement informatique. Il s’agit le plus souvent de packages qui ne sont pas encore suffisamment matures pour être diffusés sur CRAN (sachant que des vérifications strictes sont effectués avant qu’un package ne soit référencés sur CRAN).\nDans d’autres cas de figure, la dernière version stable d’un package est disponible sur CRAN tandis que la version en cours de développement est, elle, disponible sur GitHub. Il faut être vigilant avec les versions de développement. Parfois, elle corrige un bug ou introduit une nouvelle fonctionnalité qui n’est pas encore dans la version stable. Mais les versions de développement peuvent aussi contenir de nouveaux bugs ou des fonctionnalités instables.\n\n\n\n\n\n\nSous Windows\n\n\n\nPour les utilisatrices et utilisateurs sous Windows, il faut être conscient que le code source d’un package doit être compilé afin de pouvoir être utilisé. CRAN fournit une version des packages déjà compilée pour Windows ce qui facilite l’installation.\nPar contre, lorsque l’on installe un package depuis GitHub, R ne récupère que le code source et il est donc nécessaire de compiler localement le package. Pour cela, il est nécessaire que soit installé sur le PC un outil complémentaire appelé RTools. Il est téléchargeable à l’adresse https://cran.r-project.org/bin/windows/Rtools/.\n\n\nLe code source du package labelled est disponible sur GitHub à l’adresse https://github.com/larmarange/labelled. Pour installer la version de développement de labelled,on aura recours à la fonction remotes::install_github() à laquelle on passera la partie située à droite de https://github.com/ dans l’URL du package, à savoir :\n\nremotes::install_github(\"larmarange/labelled\")",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Packages</span>"
    ]
  },
  {
    "objectID": "bases/packages.html#le-tidyverse",
    "href": "bases/packages.html#le-tidyverse",
    "title": "1  Packages",
    "section": "\n1.5 Le tidyverse",
    "text": "1.5 Le tidyverse\nLe terme tidyverse est une contraction de tidy (qu’on pourrait traduire par bien rangé) et de universe. Il s’agit en fait d’une collection de packages conçus pour travailler ensemble et basés sur une philosophie commune.\nIls abordent un très grand nombre d’opérations courantes dans R (la liste n’est pas exhaustive) :\n\nvisualisation (ggplot2)\nmanipulation des tableaux de données (dplyr, tidyr)\nimport/export de données (readr, readxl, haven)\nmanipulation de variables (forcats, stringr, lubridate)\nprogrammation (purrr, magrittr, glue)\n\nUn des objectifs de ces extensions est de fournir des fonctions avec une syntaxe cohérente, qui fonctionnent bien ensemble, et qui retournent des résultats prévisibles. Elles sont en grande partie issues du travail d’Hadley Wickham, qui travaille désormais pour RStudio.\ntidyverse est également le nom d’une extension générique qui permets d’installer en une seule commande l’ensemble des packages constituant le tidyverse :\n\ninstall.packages(\"tidyverse\")\n\nLorsque l’on charge le package tidyverse avec library(), cela charge également en mémoire les principaux packages du tidyverse1.\n1 Si on a besoin d’un autre package du tidyverse comme lubridate, il faudra donc le charger individuellement.\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\n\n\n\nFigure 1.1: Packages chargés avec library(tidyverse)",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Packages</span>"
    ]
  },
  {
    "objectID": "bases/packages.html#packages-utilisés-sur-guide-r",
    "href": "bases/packages.html#packages-utilisés-sur-guide-r",
    "title": "1  Packages",
    "section": "\n1.6 Packages utilisés sur guide-R",
    "text": "1.6 Packages utilisés sur guide-R\nVoici la liste complète des packages utilisés sur guide-R ainsi qu’une commande permettant de tous les installer.\n\n\n\n\n\ninstall.packages(\"remotes\")\nc(\"ade4\", \"AER\", \"breakDown\", \"broom\", \"broom.helpers\", \"bstfun\", \n\"car\", \"cluster\", \"DHARMa\", \"dplyr\", \"effects\", \"explor\", \"factoextra\", \n\"FactoMineR\", \"fastcluster\", \"fastDummies\", \"forcats\", \"gapminder\", \n\"GDAtools\", \"GGally\", \"ggeffects\", \"ggplot2\", \"ggstats\", \"gtsummary\", \n\"khroma\", \"knitr\", \"labelled\", \"logbin\", \"magrittr\", \"marginaleffects\", \n\"margins\", \"MASS\", \"modelsummary\", \"nnet\", \"nycflights13\", \"ordinal\", \n\"paletteer\", \"patchwork\", \"performance\", \"pscl\", \"purrr\", \"questionr\", \n\"RColorBrewer\", \"readr\", \"renv\", \"rmarkdown\", \"scales\", \"see\", \n\"sjstats\", \"srvyr\", \"survey\", \"svrepmisc\", \"svyVGAM\", \"tibble\", \n\"tidyr\", \"tidyverse\", \"VGAM\", \"WeightedCluster\") |&gt;\nremotes::install_cran()\n\n\n\n\n\nFigure 1.1: Packages chargés avec library(tidyverse)",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Packages</span>"
    ]
  },
  {
    "objectID": "bases/vecteurs.html",
    "href": "bases/vecteurs.html",
    "title": "2  Vecteurs",
    "section": "",
    "text": "2.1 Types et classes\nDans R, il existe plusieurs types fondamentaux de vecteurs et, en particulier, :\nEn plus de ces types de base, il existe de nombreux autres types de vecteurs utilisés pour représenter toutes sortes de données, comme les facteurs (voir Chapitre 9) ou les dates (voir Chapitre 34).\nLa fonction class() renvoie la nature d’un vecteur tandis que la fonction typeof() indique la manière dont un vecteur est stocké de manière interne par R.",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Vecteurs</span>"
    ]
  },
  {
    "objectID": "bases/vecteurs.html#types-et-classes",
    "href": "bases/vecteurs.html#types-et-classes",
    "title": "2  Vecteurs",
    "section": "",
    "text": "les nombres réels (c’est-à-dire les nombres décimaux1), par exemple 5.23 ;\nles nombres entiers, que l’on saisi en ajoutant le suffixe L2, par exemple 4L ;\nles chaînes de caractères (qui correspondent à du texte), que l’on saisit avec des guillemets doubles (\") ou simples ('), par exemple \"abc\" ;\nles valeurs logiques ou valeurs booléennes, à savoir vrai ou faux, que l’on représente avec les mots TRUE et FALSE (en majuscules3).\n\n1 Pour rappel, R étant anglophone, le caractère utilisé pour indiqué les chiffres après la virgule est le point (.).2 R utilise 32 bits pour représenter des nombres entiers, ce qui correspond en informatique à des entiers longs ou long integers en anglais, d’où la lettre L utilisée pour indiquer un nombre entier.3 On peut également utiliser les raccourcis T et F. Cependant, pour une meilleure lisibilité du code, il est préférable d’utiliser les versions longues TRUE et FALSE.\n\n\n\n\n\n\n\n\n\n\nx\nclass(x)\ntypeof(x)\n\n\n\n3L\ninteger\ninteger\n\n\n5.3\nnumeric\ndouble\n\n\nTRUE\nlogical\nlogical\n\n\n\"abc\"\ncharacter\ncharacter\n\n\nfactor(\"a\")\nfactor\ninteger\n\n\nas.Date(\"2020-01-01\")\nDate\ndouble\n\n\n\n\n\nTable 2.1: Le type et la classe des principaux types de vecteurs\n\n\n\n\n\n\n\n\nAstuce\n\n\n\nPour un vecteur numérique, le type est \"double\" car R utilise une double précision pour stocker en mémoire les nombres réels.\nEn interne, les facteurs sont représentés par un nombre entier auquel est attaché une étiquette, c’est pourquoi typeof() renvoie \"integer\".\nQuand aux dates, elles sont stockées en interne sous la forme d’un nombre réel représentant le nombre de jours depuis le 1er janvier 1970, d’où le fait que typeof() renvoie \"double\".",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Vecteurs</span>"
    ]
  },
  {
    "objectID": "bases/vecteurs.html#création-dun-vecteur",
    "href": "bases/vecteurs.html#création-dun-vecteur",
    "title": "2  Vecteurs",
    "section": "\n2.2 Création d’un vecteur",
    "text": "2.2 Création d’un vecteur\nPour créer un vecteur, on utilisera la fonction c() en lui passant la liste des valeurs à combiner4.\n4 La lettre c est un raccourci du mot anglais combine, puisque cette fonction permet de combiner des valeurs individuelles dans un vecteur unique.\ntaille &lt;- c(1.88, 1.65, 1.92, 1.76, NA, 1.72)\ntaille\n\n[1] 1.88 1.65 1.92 1.76   NA 1.72\n\nsexe &lt;- c(\"h\", \"f\", \"h\", \"f\", \"f\", \"f\")\nsexe\n\n[1] \"h\" \"f\" \"h\" \"f\" \"f\" \"f\"\n\nurbain &lt;- c(TRUE, TRUE, FALSE, FALSE, FALSE, TRUE)\nurbain\n\n[1]  TRUE  TRUE FALSE FALSE FALSE  TRUE\n\n\nNous l’avons vu, toutes les valeurs d’un vecteur doivent obligatoirement être du même type. Dès lors, si on essaie de combiner des valeurs de différents types, R essaiera de les convertir au mieux. Par exemple :\n\nx &lt;- c(2L, 3.14, \"a\")\nx\n\n[1] \"2\"    \"3.14\" \"a\"   \n\nclass(x)\n\n[1] \"character\"\n\n\nDans le cas présent, toutes les valeurs ont été converties en chaînes de caractères.\nDans certaines situations, on peut avoir besoin de créer un vecteur d’une certaine longueur mais dont toutes les valeurs sont identiques. Cela se réalise facilement avec rep() à qui on indiquera la valeur à répéter puis le nombre de répétitions :\n\nrep(2, 10)\n\n [1] 2 2 2 2 2 2 2 2 2 2\n\n\nOn peut aussi lui indiquer plusieurs valeurs qui seront alors répétées en boucle :\n\nrep(c(\"a\", \"b\"), 3)\n\n[1] \"a\" \"b\" \"a\" \"b\" \"a\" \"b\"\n\n\nDans d’autres situations, on peut avoir besoin de créer un vecteur contenant une suite de valeurs, ce qui se réalise aisément avec seq() à qui on précisera les arguments from (point de départ), to (point d’arrivée) et by (pas). Quelques exemples valent mieux qu’un long discours :\n\nseq(1, 10)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nseq(5, 17, by = 2)\n\n[1]  5  7  9 11 13 15 17\n\nseq(10, 0)\n\n [1] 10  9  8  7  6  5  4  3  2  1  0\n\nseq(100, 10, by = -10)\n\n [1] 100  90  80  70  60  50  40  30  20  10\n\nseq(1.23, 5.67, by = 0.33) \n\n [1] 1.23 1.56 1.89 2.22 2.55 2.88 3.21 3.54 3.87 4.20 4.53 4.86 5.19 5.52\n\n\nL’opérateur : est un raccourci de la fonction seq() pour créer une suite de nombres entiers. Il s’utilise ainsi :\n\n1:5\n\n[1] 1 2 3 4 5\n\n24:32\n\n[1] 24 25 26 27 28 29 30 31 32\n\n55:43\n\n [1] 55 54 53 52 51 50 49 48 47 46 45 44 43",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Vecteurs</span>"
    ]
  },
  {
    "objectID": "bases/vecteurs.html#longueur-dun-vecteur",
    "href": "bases/vecteurs.html#longueur-dun-vecteur",
    "title": "2  Vecteurs",
    "section": "\n2.3 Longueur d’un vecteur",
    "text": "2.3 Longueur d’un vecteur\nLa longueur d’un vecteur correspond au nombre de valeurs qui le composent. Elle s’obtient avec length() :\n\nlength(taille)\n\n[1] 6\n\nlength(c(\"a\", \"b\"))\n\n[1] 2\n\n\nLa longueur d’un vecteur vide (NULL) est zéro.\n\nlength(NULL)\n\n[1] 0",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Vecteurs</span>"
    ]
  },
  {
    "objectID": "bases/vecteurs.html#combiner-des-vecteurs",
    "href": "bases/vecteurs.html#combiner-des-vecteurs",
    "title": "2  Vecteurs",
    "section": "\n2.4 Combiner des vecteurs",
    "text": "2.4 Combiner des vecteurs\nPour combiner des vecteurs, rien de plus simple. Il suffit d’utiliser c() ! Les valeurs des différents vecteurs seront mises bout à bout pour créer un unique vecteur.\n\nx &lt;- c(2, 1, 3, 4)\nlength(x)\n\n[1] 4\n\ny &lt;- c(9, 1, 2, 6, 3, 0)\nlength(y)\n\n[1] 6\n\nz &lt;- c(x, y)\nz\n\n [1] 2 1 3 4 9 1 2 6 3 0\n\nlength(z)\n\n[1] 10",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Vecteurs</span>"
    ]
  },
  {
    "objectID": "bases/vecteurs.html#vecteurs-nommés",
    "href": "bases/vecteurs.html#vecteurs-nommés",
    "title": "2  Vecteurs",
    "section": "\n2.5 Vecteurs nommés",
    "text": "2.5 Vecteurs nommés\nLes différentes valeurs d’un vecteur peuvent être nommées. Une première manière de nommer les éléments d’un vecteur est de le faire à sa création :\n\nsexe &lt;- c(\n  Michel = \"h\", Anne = \"f\", \n  Dominique = NA, Jean = \"h\", \n  Claude = NA, Marie = \"f\"\n)\n\nLorsqu’on affiche le vecteur, la présentation change quelque peu.\n\nsexe\n\n   Michel      Anne Dominique      Jean    Claude     Marie \n      \"h\"       \"f\"        NA       \"h\"        NA       \"f\" \n\n\nLa liste des noms s’obtient avec names().\n\nnames(sexe)\n\n[1] \"Michel\"    \"Anne\"      \"Dominique\" \"Jean\"      \"Claude\"    \"Marie\"    \n\n\nPour ajouter ou modifier les noms d’un vecteur, on doit attribuer un nouveau vecteur de noms :\n\nnames(sexe) &lt;- c(\"Michael\", \"Anna\", \"Dom\", \"John\", \"Alex\", \"Mary\")\nsexe\n\nMichael    Anna     Dom    John    Alex    Mary \n    \"h\"     \"f\"      NA     \"h\"      NA     \"f\" \n\n\nPour supprimer tous les noms, il y a la fonction unname() :\n\nanonyme &lt;- unname(sexe)\nanonyme\n\n[1] \"h\" \"f\" NA  \"h\" NA  \"f\"",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Vecteurs</span>"
    ]
  },
  {
    "objectID": "bases/vecteurs.html#indexation-par-position",
    "href": "bases/vecteurs.html#indexation-par-position",
    "title": "2  Vecteurs",
    "section": "\n2.6 Indexation par position",
    "text": "2.6 Indexation par position\nL’indexation est l’une des fonctionnalités les plus puissantes mais aussi les plus difficiles à maîtriser de R. Il s’agit d’opérations permettant de sélectionner des sous-ensembles de valeurs en fonction de différents critères. Il existe trois types d’indexation : (i) l’indexation par position, (ii) l’indexation par nom et (iii) l’indexation par condition. Le principe est toujours le même : on indique entre crochets5 ([]) ce qu’on souhaite garder ou non.\n5 Pour rappel, les crochets s’obtiennent sur un clavier français de type PC en appuyant sur la touche Alt Gr et la touche ( ou ).Commençons par l’indexation par position encore appelée indexation directe. Ce mode le plus simple d’indexation consiste à indiquer la position des éléments à conserver.\nReprenons notre vecteur taille :\n\ntaille\n\n[1] 1.88 1.65 1.92 1.76   NA 1.72\n\n\nSi on souhaite le premier élément du vecteur, on peut faire :\n\ntaille[1]\n\n[1] 1.88\n\n\nSi on souhaite les trois premiers éléments ou les éléments 2, 5 et 6 :\n\ntaille[1:3]\n\n[1] 1.88 1.65 1.92\n\ntaille[c(2, 5, 6)]\n\n[1] 1.65   NA 1.72\n\n\nSi on veut le dernier élément :\n\ntaille[length(taille)]\n\n[1] 1.72\n\n\nIl est tout à fait possible de sélectionner les valeurs dans le désordre :\n\ntaille[c(5, 1, 4, 3)]\n\n[1]   NA 1.88 1.76 1.92\n\n\nDans le cadre de l’indexation par position, il est également possible de spécifier des nombres négatifs, auquel cas cela signifiera toutes les valeurs sauf celles-là. Par exemple :\n\ntaille[c(-1, -5)]\n\n[1] 1.65 1.92 1.76 1.72\n\n\nÀ noter, si on indique une position au-delà de la longueur du vecteur, R renverra NA. Par exemple :\n\ntaille[23:25]\n\n[1] NA NA NA",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Vecteurs</span>"
    ]
  },
  {
    "objectID": "bases/vecteurs.html#indexation-par-nom",
    "href": "bases/vecteurs.html#indexation-par-nom",
    "title": "2  Vecteurs",
    "section": "\n2.7 Indexation par nom",
    "text": "2.7 Indexation par nom\nLorsqu’un vecteur est nommé, il est dès lors possible d’accéder à ses valeurs à partir de leur nom. Il s’agit de l’indexation par nom.\n\nsexe[\"Anna\"]\n\nAnna \n \"f\" \n\nsexe[c(\"Mary\", \"Michael\", \"John\")]\n\n   Mary Michael    John \n    \"f\"     \"h\"     \"h\" \n\n\nPar contre il n’est pas possible d’utiliser l’opérateur - comme pour l’indexation directe. Pour exclure un élément en fonction de son nom, on doit utiliser une autre forme d’indexation, l’indexation par condition, expliquée dans la section suivante. On peut ainsi faire…\n\nsexe[names(sexe) != \"Dom\"]\n\n… pour sélectionner tous les éléments sauf celui qui s’appelle Dom.",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Vecteurs</span>"
    ]
  },
  {
    "objectID": "bases/vecteurs.html#indexation-par-condition",
    "href": "bases/vecteurs.html#indexation-par-condition",
    "title": "2  Vecteurs",
    "section": "\n2.8 Indexation par condition",
    "text": "2.8 Indexation par condition\nL’indexation par condition consiste à fournir un vecteur logique indiquant si chaque élément doit être inclus (si TRUE) ou exclu (si FALSE). Par exemple :\n\nsexe\n\nMichael    Anna     Dom    John    Alex    Mary \n    \"h\"     \"f\"      NA     \"h\"      NA     \"f\" \n\nsexe[c(TRUE, FALSE, FALSE, TRUE, FALSE, FALSE)]\n\nMichael    John \n    \"h\"     \"h\" \n\n\nÉcrire manuellement une telle condition n’est pas très pratique à l’usage. Mais supposons que nous ayons également à notre disposition les deux vecteurs suivants, également de longueur 6.\n\nurbain &lt;- c(TRUE, TRUE, FALSE, FALSE, FALSE, TRUE)\npoids &lt;- c(80, 63, 75, 87, 82, 67)\n\nLe vecteur urbain est un vecteur logique. On peut directement l’utiliser pour avoir le sexe des enquêtés habitant en milieu urbain :\n\nsexe[urbain]\n\nMichael    Anna    Mary \n    \"h\"     \"f\"     \"f\" \n\n\nSupposons qu’on souhaite maintenant avoir la taille des individus pesant 80 kilogrammes ou plus. Nous pouvons effectuer une comparaison à l’aide des opérateurs de comparaison suivants :\n\n\n\n\nOpérateur de comparaison\nSignification\n\n\n\n==\négal à\n\n\n%in%\nappartient à\n\n\n!=\ndifférent de\n\n\n&gt;\nstrictement supérieur à\n\n\n&lt;\nstrictement inférieur à\n\n\n&gt;=\nsupérieur ou égal à\n\n\n&lt;=\ninférieur ou égal à\n\n\n\n\n\nTable 2.2: Opérateurs de comparaison\n\n\nVoyons tout de suite un exemple :\n\npoids &gt;= 80\n\n[1]  TRUE FALSE FALSE  TRUE  TRUE FALSE\n\n\nQue s’est-il passé ? Nous avons fourni à R une condition et il nous a renvoyé un vecteur logique avec autant d’éléments qu’il y a d’observations et dont la valeur est TRUE si la condition est remplie et FALSE dans les autres cas. Nous pouvons alors utiliser ce vecteur logique pour obtenir la taille des participants pesant 80 kilogrammes ou plus :\n\ntaille[poids &gt;= 80]\n\n[1] 1.88 1.76   NA\n\n\nOn peut combiner ou modifier des conditions à l’aide des opérateurs logiques habituels :\n\n\n\n\nOpérateur logique\nSignification\n\n\n\n&\net logique\n\n\n|\nou logique\n\n\n!\nnégation logique\n\n\n\n\n\nTable 2.3: Opérateurs logiques\n\n\nSupposons que je veuille identifier les personnes pesant 80 kilogrammes ou plus et vivant en milieu urbain :\n\npoids &gt;= 80 & urbain\n\n[1]  TRUE FALSE FALSE FALSE FALSE FALSE\n\n\nLes résultats sont différents si je souhaite isoler les personnes pesant 80 kilogrammes ou plus ou vivant milieu urbain :\n\npoids &gt;= 80 | urbain\n\n[1]  TRUE  TRUE FALSE  TRUE  TRUE  TRUE\n\n\n\n\n\n\n\n\nComparaison et valeur manquante\n\n\n\nUne remarque importante : quand l’un des termes d’une condition comporte une valeur manquante (NA), le résultat de cette condition n’est pas toujours TRUE ou FALSE, il peut aussi être à son tour une valeur manquante.\n\ntaille\n\n[1] 1.88 1.65 1.92 1.76   NA 1.72\n\ntaille &gt; 1.8\n\n[1]  TRUE FALSE  TRUE FALSE    NA FALSE\n\n\nOn voit que le test NA &gt; 1.8 ne renvoie ni vrai ni faux, mais NA.\nUne autre conséquence importante de ce comportement est qu’on ne peut pas utiliser l’opérateur l’expression == NA pour tester la présence de valeurs manquantes. On utilisera à la place la fonction ad hoc is.na() :\n\nis.na(taille &gt; 1.8)\n\n[1] FALSE FALSE FALSE FALSE  TRUE FALSE\n\n\nPour compliquer encore un peu le tout, lorsqu’on utilise une condition pour l’indexation, si la condition renvoie NA, R ne sélectionne pas l’élément mais retourne quand même la valeur NA. Ceci a donc des conséquences sur le résultat d’une indexation par comparaison.\nPar exemple si je cherche à connaître le poids des personnes mesurant 1,80 mètre ou plus :\n\ntaille\n\n[1] 1.88 1.65 1.92 1.76   NA 1.72\n\npoids\n\n[1] 80 63 75 87 82 67\n\npoids[taille &gt; 1.8]\n\n[1] 80 75 NA\n\n\nLes éléments pour lesquels la taille n’est pas connue ont été transformés en NA, ce qui n’influera pas le calcul d’une moyenne. Par contre, lorsqu’on utilisera assignation et indexation ensemble, cela peut créer des problèmes. Il est donc préférable lorsqu’on a des valeurs manquantes de les exclure ainsi :\n\npoids[taille &gt; 1.8 & !is.na(taille)]\n\n[1] 80 75",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Vecteurs</span>"
    ]
  },
  {
    "objectID": "bases/vecteurs.html#assignation-par-indexation",
    "href": "bases/vecteurs.html#assignation-par-indexation",
    "title": "2  Vecteurs",
    "section": "\n2.9 Assignation par indexation",
    "text": "2.9 Assignation par indexation\nL’indexation peut être combinée avec l’assignation (opérateur &lt;-) pour modifier seulement certaines parties d’un vecteur. Ceci fonctionne pour les différents types d’indexation évoqués précédemment.\n\nv &lt;- 1:5\nv\n\n[1] 1 2 3 4 5\n\nv[1] &lt;- 3\nv\n\n[1] 3 2 3 4 5\n\nsexe[\"Alex\"] &lt;- \"non-binaire\"\nsexe\n\n      Michael          Anna           Dom          John          Alex \n          \"h\"           \"f\"            NA           \"h\" \"non-binaire\" \n         Mary \n          \"f\" \n\n\nEnfin on peut modifier plusieurs éléments d’un seul coup soit en fournissant un vecteur, soit en profitant du mécanisme de recyclage. Les deux commandes suivantes sont ainsi rigoureusement équivalentes :\n\nsexe[c(1,3,4)] &lt;- c(\"Homme\", \"Homme\", \"Homme\")\nsexe[c(1,3,4)] &lt;- \"Homme\"\n\nL’assignation par indexation peut aussi être utilisée pour ajouter une ou plusieurs valeurs à un vecteur :\n\nlength(sexe)\n\n[1] 6\n\nsexe[7] &lt;- \"f\"\nsexe\n\n      Michael          Anna           Dom          John          Alex \n      \"Homme\"           \"f\"       \"Homme\"       \"Homme\" \"non-binaire\" \n         Mary               \n          \"f\"           \"f\" \n\nlength(sexe)\n\n[1] 7",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Vecteurs</span>"
    ]
  },
  {
    "objectID": "bases/vecteurs.html#en-résumé",
    "href": "bases/vecteurs.html#en-résumé",
    "title": "2  Vecteurs",
    "section": "\n2.10 En résumé",
    "text": "2.10 En résumé\n\nUn vecteur est un objet unidimensionnel contenant une liste de valeurs qui sont toutes du même type (entières, numériques, textuelles ou logiques).\nLa fonction class() permet de connaître le type du vecteur et la fonction length() sa longueur, c’est-à-dire son nombre d’éléments.\nLa fonction c() sert à créer et à combiner des vecteurs.\nLes valeurs manquantes sont représentées avec NA.\nUn vecteur peut être nommé, c’est-à-dire qu’un nom textuel a été associé à chaque élément. Cela peut se faire lors de sa création ou avec la fonction names().\nL’indexation consiste à extraire certains éléments d’un vecteur. Pour cela, on indique ce qu’on souhaite extraire entre crochets ([]) juste après le nom du vecteur. Le type d’indexation dépend du type d’information transmise.\nS’il s’agit de nombres entiers, c’est l’indexation par position : les nombres représentent la position dans le vecteur des éléments qu’on souhaite extraire. Un nombre négatif s’interprète comme tous les éléments sauf celui-là.\nSi on indique des chaînes de caractères, c’est l’indexation par nom : on indique le nom des éléments qu’on souhaite extraire. Cette forme d’indexation ne fonctionne que si le vecteur est nommé.\nSi on transmet des valeurs logiques, le plus souvent sous la forme d’une condition, c’est l’indexation par condition : TRUE indique les éléments à extraire et FALSE les éléments à exclure. Il faut être vigilant aux valeurs manquantes (NA) dans ce cas précis.\nEnfin, il est possible de ne modifier que certains éléments d’un vecteur en ayant recours à la fois à l’indexation ([]) et à l’assignation (&lt;-).",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Vecteurs</span>"
    ]
  },
  {
    "objectID": "bases/vecteurs.html#webin-r",
    "href": "bases/vecteurs.html#webin-r",
    "title": "2  Vecteurs",
    "section": "\n2.11 webin-R",
    "text": "2.11 webin-R\nOn pourra également se référer au webin-R #02 (les bases du langage R) sur YouTube.",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Vecteurs</span>"
    ]
  },
  {
    "objectID": "bases/listes.html",
    "href": "bases/listes.html",
    "title": "3  Listes",
    "section": "",
    "text": "3.1 Propriétés et création\nUne liste se crée tout simplement avec la fonction list() :\nl1 &lt;- list(1:5, \"abc\")\nl1\n\n[[1]]\n[1] 1 2 3 4 5\n\n[[2]]\n[1] \"abc\"\nUne liste est un ensemble d’objets, quels qu’ils soient, chaque élément d’une liste pouvant avoir ses propres dimensions. Dans notre exemple précédent, nous avons créé une liste l1 composée de deux éléments : un vecteur d’entiers de longueur 5 et un vecteur textuel de longueur 1. La longueur d’une liste correspond aux nombres d’éléments qu’elle contient et s’obtient avec length() :\nlength(l1)\n\n[1] 2\nComme les vecteurs, une liste peut être nommée et les noms des éléments d’une liste sont accessibles avec names() :\nl2 &lt;- list(\n  minuscules = letters, \n  majuscules = LETTERS, \n  mois = month.name\n)\nl2\n\n$minuscules\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\n$majuscules\n [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n[20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\n\n$mois\n [1] \"January\"   \"February\"  \"March\"     \"April\"     \"May\"       \"June\"     \n [7] \"July\"      \"August\"    \"September\" \"October\"   \"November\"  \"December\" \n\nlength(l2)\n\n[1] 3\n\nnames(l2)\n\n[1] \"minuscules\" \"majuscules\" \"mois\"\nQue se passe-t-il maintenant si on effectue la commande suivante ?\nl &lt;- list(l1, l2)\nÀ votre avis, quelle est la longueur de cette nouvelle liste l ? 5 ?\nlength(l)\n\n[1] 2\nEh bien non ! Elle est de longueur 2 car nous avons créé une liste composée de deux éléments qui sont eux-mêmes des listes. Cela est plus lisible si on fait appel à la fonction str() qui permet de visualiser la structure d’un objet.\nstr(l)\n\nList of 2\n $ :List of 2\n  ..$ : int [1:5] 1 2 3 4 5\n  ..$ : chr \"abc\"\n $ :List of 3\n  ..$ minuscules: chr [1:26] \"a\" \"b\" \"c\" \"d\" ...\n  ..$ majuscules: chr [1:26] \"A\" \"B\" \"C\" \"D\" ...\n  ..$ mois      : chr [1:12] \"January\" \"February\" \"March\" \"April\" ...\nUne liste peut contenir tous types d’objets, y compris d’autres listes. Pour combiner les éléments d’une liste, il faut utiliser la fonction append() :\nl &lt;- append(l1, l2)\nlength(l)\n\n[1] 5\n\nstr(l)\n\nList of 5\n $           : int [1:5] 1 2 3 4 5\n $           : chr \"abc\"\n $ minuscules: chr [1:26] \"a\" \"b\" \"c\" \"d\" ...\n $ majuscules: chr [1:26] \"A\" \"B\" \"C\" \"D\" ...\n $ mois      : chr [1:12] \"January\" \"February\" \"March\" \"April\" ...",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Listes</span>"
    ]
  },
  {
    "objectID": "bases/listes.html#propriétés-et-création",
    "href": "bases/listes.html#propriétés-et-création",
    "title": "3  Listes",
    "section": "",
    "text": "Note\n\n\n\nOn peut noter en passant qu’une liste peut tout à fait n’être que partiellement nommée.",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Listes</span>"
    ]
  },
  {
    "objectID": "bases/listes.html#indexation",
    "href": "bases/listes.html#indexation",
    "title": "3  Listes",
    "section": "\n3.2 Indexation",
    "text": "3.2 Indexation\nLes crochets simples ([]) fonctionnent comme pour les vecteurs. On peut utiliser à la fois l’indexation par position, l’indexation par nom et l’indexation par condition.\n\nl\n\n[[1]]\n[1] 1 2 3 4 5\n\n[[2]]\n[1] \"abc\"\n\n$minuscules\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\n$majuscules\n [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n[20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\n\n$mois\n [1] \"January\"   \"February\"  \"March\"     \"April\"     \"May\"       \"June\"     \n [7] \"July\"      \"August\"    \"September\" \"October\"   \"November\"  \"December\" \n\nl[c(1,3,4)]\n\n[[1]]\n[1] 1 2 3 4 5\n\n$minuscules\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\n$majuscules\n [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n[20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\n\nl[c(\"majuscules\", \"minuscules\")]\n\n$majuscules\n [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n[20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\n\n$minuscules\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\nl[c(TRUE, TRUE, FALSE, FALSE, TRUE)]\n\n[[1]]\n[1] 1 2 3 4 5\n\n[[2]]\n[1] \"abc\"\n\n$mois\n [1] \"January\"   \"February\"  \"March\"     \"April\"     \"May\"       \"June\"     \n [7] \"July\"      \"August\"    \"September\" \"October\"   \"November\"  \"December\" \n\n\nMême si on extrait un seul élément, l’extraction obtenue avec les crochets simples renvoie toujours une liste, ici composée d’un seul élément :\n\nstr(l[1])\n\nList of 1\n $ : int [1:5] 1 2 3 4 5\n\n\nSupposons que je souhaite calculer la moyenne des valeurs du premier élément de ma liste. Essayons la commande suivante :\n\nmean(l[1])\n\nWarning in mean.default(l[1]): l'argument n'est ni numérique, ni logique :\nrenvoi de NA\n\n\n[1] NA\n\n\nNous obtenons un message d’erreur. En effet, R ne sait pas calculer une moyenne à partir d’une liste. Ce qu’il lui faut, c’est un vecteur de valeurs numériques. Autrement dit, ce que nous cherchons à obtenir c’est le contenu même du premier élément de notre liste et non une liste à un seul élément.\nC’est ici que les doubles crochets ([[]]) vont rentrer en jeu. Pour ces derniers, nous pourrons utiliser l’indexation par position ou l’indexation par nom, mais pas l’indexation par condition. De plus, le critère qu’on indiquera doit indiquer un et un seul élément de notre liste. Au lieu de renvoyer une liste à un élément, les doubles crochets vont renvoyer l’élément désigné.\n\nstr(l[1])\n\nList of 1\n $ : int [1:5] 1 2 3 4 5\n\nstr(l[[1]])\n\n int [1:5] 1 2 3 4 5\n\n\nMaintenant, nous pouvons calculer notre moyenne :\n\nmean(l[[1]])\n\n[1] 3\n\n\nNous pouvons aussi utiliser l’indexation par nom.\n\nl[[\"mois\"]]\n\n [1] \"January\"   \"February\"  \"March\"     \"April\"     \"May\"       \"June\"     \n [7] \"July\"      \"August\"    \"September\" \"October\"   \"November\"  \"December\" \n\n\nMais il faut avouer que cette écriture avec doubles crochets et guillemets est un peu lourde. Heureusement, un nouvel acteur entre en scène : le symbole dollar ($). C’est un raccourci des doubles crochets pour l’indexation par nom qu’on utilise ainsi :\n\nl$mois\n\n [1] \"January\"   \"February\"  \"March\"     \"April\"     \"May\"       \"June\"     \n [7] \"July\"      \"August\"    \"September\" \"October\"   \"November\"  \"December\" \n\n\nLes écritures l$mois et l[[\"mois\"]] sont équivalentes. Attention ! Cela ne fonctionne que pour l’indexation par nom.\n\nl$1\n\n\nError: unexpected numeric constant in \"l$1\"\n\nL’assignation par indexation fonctionne également avec les doubles crochets ou le signe dollar :\n\nl[[2]] &lt;- list(c(\"un\", \"vecteur\", \"textuel\"))\nl$mois &lt;- c(\"Janvier\", \"Février\", \"Mars\")\nl\n\n[[1]]\n[1] 1 2 3 4 5\n\n[[2]]\n[[2]][[1]]\n[1] \"un\"      \"vecteur\" \"textuel\"\n\n\n$minuscules\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\n$majuscules\n [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n[20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\n\n$mois\n[1] \"Janvier\" \"Février\" \"Mars\"",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Listes</span>"
    ]
  },
  {
    "objectID": "bases/listes.html#en-résumé",
    "href": "bases/listes.html#en-résumé",
    "title": "3  Listes",
    "section": "\n3.3 En résumé",
    "text": "3.3 En résumé\n\nLes listes sont des objets unidimensionnels pouvant contenir tout type d’objet, y compris d’autres listes.\nElles ont une longueur qu’on obtient avec length().\nOn crée une liste avec list() et on peut fusionner des listes avec append().\nTout comme les vecteurs, les listes peuvent être nommées et les noms des éléments s’obtiennent avec base::names().\nLes crochets simples ([]) permettent de sélectionner les éléments d’une liste, en utilisant l’indexation par position, l’indexation par nom ou l’indexation par condition. Cela renvoie toujours une autre liste.\nLes doubles crochets ([[]]) renvoient directement le contenu d’un élément de la liste qu’on aura sélectionné par position ou par nom.\nLe symbole $ est un raccourci pour facilement sélectionner un élément par son nom, liste$nom étant équivalent à liste[[\"nom\"]].",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Listes</span>"
    ]
  },
  {
    "objectID": "bases/listes.html#webin-r",
    "href": "bases/listes.html#webin-r",
    "title": "3  Listes",
    "section": "\n3.4 webin-R",
    "text": "3.4 webin-R\nOn pourra également se référer au webin-R #02 (les bases du langage R) sur YouTube.",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Listes</span>"
    ]
  },
  {
    "objectID": "bases/tableaux_donnees.html",
    "href": "bases/tableaux_donnees.html",
    "title": "4  Tableaux de données",
    "section": "",
    "text": "4.1 Propriétés et création\nDans R, les tableaux de données sont tout simplement des listes (voir Chapitre 3) avec quelques propriétés spécifiques :\nDès lors, un tableau de données correspond aux fichiers de données qu’on a l’habitude de manipuler dans d’autres logiciels de statistiques comme SPSS ou Stata. Les variables sont organisées en colonnes et les observations en lignes.\nOn peut créer un tableau de données avec la fonction data.frame() :\ndf &lt;- data.frame(\n  sexe =  c(\"f\", \"f\", \"h\", \"h\"), \n  age = c(52, 31, 29, 35), \n  blond = c(FALSE, TRUE, TRUE, FALSE)\n)\ndf\n\n  sexe age blond\n1    f  52 FALSE\n2    f  31  TRUE\n3    h  29  TRUE\n4    h  35 FALSE\n\nstr(df)\n\n'data.frame':   4 obs. of  3 variables:\n $ sexe : chr  \"f\" \"f\" \"h\" \"h\"\n $ age  : num  52 31 29 35\n $ blond: logi  FALSE TRUE TRUE FALSE\nUn tableau de données étant une liste, la fonction length() renverra le nombre d’éléments de la liste, donc dans le cas présent le nombre de variables, et names() leurs noms :\nlength(df)\n\n[1] 3\n\nnames(df)\n\n[1] \"sexe\"  \"age\"   \"blond\"\nComme tous les éléments d’un tableau de données ont la même longueur, cet objet peut être vu comme bidimensionnel. Les fonctions nrow(), ncol() et dim() donnent respectivement le nombre de lignes, le nombre de colonnes et les dimensions de notre tableau.\nnrow(df)\n\n[1] 4\n\nncol(df)\n\n[1] 3\n\ndim(df)\n\n[1] 4 3\nDe plus, tout comme les colonnes ont un nom, il est aussi possible de nommer les lignes avec row.names() :\nrow.names(df) &lt;- c(\"Anna\", \"Mary-Ann\", \"Michael\", \"John\")\ndf\n\n         sexe age blond\nAnna        f  52 FALSE\nMary-Ann    f  31  TRUE\nMichael     h  29  TRUE\nJohn        h  35 FALSE",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tableaux de données</span>"
    ]
  },
  {
    "objectID": "bases/tableaux_donnees.html#propriétés-et-création",
    "href": "bases/tableaux_donnees.html#propriétés-et-création",
    "title": "4  Tableaux de données",
    "section": "",
    "text": "les tableaux de données ne peuvent contenir que des vecteurs ;\ntous les vecteurs d’un tableau de données ont la même longueur ;\ntous les éléments d’un tableau de données sont nommés et ont chacun un nom unique.",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tableaux de données</span>"
    ]
  },
  {
    "objectID": "bases/tableaux_donnees.html#indexation",
    "href": "bases/tableaux_donnees.html#indexation",
    "title": "4  Tableaux de données",
    "section": "\n4.2 Indexation",
    "text": "4.2 Indexation\nLes tableaux de données étant des listes, nous pouvons donc utiliser les crochets simples ([]), les crochets doubles ([[]]) et le symbole dollar ($) pour extraire des parties de notre tableau, de la même manière que pour n’importe quelle liste.\n\ndf[1]\n\n         sexe\nAnna        f\nMary-Ann    f\nMichael     h\nJohn        h\n\ndf[[1]]\n\n[1] \"f\" \"f\" \"h\" \"h\"\n\ndf$sexe\n\n[1] \"f\" \"f\" \"h\" \"h\"\n\n\nCependant, un tableau de données étant un objet bidimensionnel, il est également possible d’extraire des données sur deux dimensions, à savoir un premier critère portant sur les lignes et un second portant sur les colonnes. Pour cela, nous utiliserons les crochets simples ([]) en séparant nos deux critères par une virgule (,).\nUn premier exemple :\n\ndf\n\n         sexe age blond\nAnna        f  52 FALSE\nMary-Ann    f  31  TRUE\nMichael     h  29  TRUE\nJohn        h  35 FALSE\n\ndf[3, 2]\n\n[1] 29\n\n\nCette première commande indique que nous souhaitons la troisième ligne de la seconde colonne, autrement dit l’âge de Michael. Le même résultat peut être obtenu avec l’indexation par nom, l’indexation par condition, ou un mélange de tout ça.\n\ndf[\"Michael\", \"age\"]\n\n[1] 29\n\ndf[c(F, F, T, F), c(F, T, F)]\n\n[1] 29\n\ndf[3, \"age\"]\n\n[1] 29\n\ndf[\"Michael\", 2]\n\n[1] 29\n\n\nIl est également possible de préciser un seul critère. Par exemple, si je souhaite les deux premières observations, ou les variables sexe et blond :\n\ndf[1:2,]\n\n         sexe age blond\nAnna        f  52 FALSE\nMary-Ann    f  31  TRUE\n\ndf[,c(\"sexe\", \"blond\")]\n\n         sexe blond\nAnna        f FALSE\nMary-Ann    f  TRUE\nMichael     h  TRUE\nJohn        h FALSE\n\n\nIl a suffi de laisser un espace vide avant ou après la virgule.\n\n\n\n\n\n\nAvertissement\n\n\n\nATTENTION ! Il est cependant impératif de laisser la virgule pour indiquer à R qu’on souhaite effectuer une indexation à deux dimensions. Si on oublie la virgule, cela nous ramène au mode de fonctionnement des listes. Et le résultat n’est pas forcément le même :\n\ndf[2, ]\n\n         sexe age blond\nMary-Ann    f  31  TRUE\n\ndf[, 2]\n\n[1] 52 31 29 35\n\ndf[2]\n\n         age\nAnna      52\nMary-Ann  31\nMichael   29\nJohn      35\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAu passage, on pourra noter quelques subtilités sur le résultat renvoyé.\n\nstr(df[2, ])\n\n'data.frame':   1 obs. of  3 variables:\n $ sexe : chr \"f\"\n $ age  : num 31\n $ blond: logi TRUE\n\nstr(df[, 2])\n\n num [1:4] 52 31 29 35\n\nstr(df[2])\n\n'data.frame':   4 obs. of  1 variable:\n $ age: num  52 31 29 35\n\nstr(df[[2]])\n\n num [1:4] 52 31 29 35\n\n\ndf[2, ] signifie qu’on veut toutes les variables pour le second individu. Le résultat est un tableau de données à une ligne et trois colonnes. df[2] correspond au mode d’extraction des listes et renvoie donc une liste à un élément, en l’occurrence un tableau de données à quatre observations et une variable. df[[2]] quant à lui renvoie le contenu de cette variable, soit un vecteur numérique de longueur quatre. Reste df[, 2] qui renvoie toutes les observations pour la seconde colonne. Or l’indexation bidimensionnelle a un fonctionnement un peu particulier : par défaut elle renvoie un tableau de données mais s’il y a une seule variable dans l’extraction, c’est un vecteur qui est renvoyé. Pour plus de détails, on pourra consulter l’entrée d’aide help(\"[.data.frame\").",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tableaux de données</span>"
    ]
  },
  {
    "objectID": "bases/tableaux_donnees.html#sec-afficher-donnees",
    "href": "bases/tableaux_donnees.html#sec-afficher-donnees",
    "title": "4  Tableaux de données",
    "section": "\n4.3 Afficher les données",
    "text": "4.3 Afficher les données\nPrenons un tableau de données un peu plus conséquent, en l’occurrence le jeu de données ?questionr::hdv2003 disponible dans l’extension questionr et correspondant à un extrait de l’enquête Histoire de vie réalisée par l’INSEE en 2003. Il contient 2000 individus et 20 variables.\n\nlibrary(questionr)\ndata(hdv2003)\n\nSi on demande d’afficher l’objet hdv2003 dans la console (résultat non reproduit ici), R va afficher l’ensemble du contenu de hdv2003 à l’écran ce qui, sur un tableau de cette taille, ne sera pas très lisible. Pour une exploration visuelle, le plus simple est souvent d’utiliser la visionneuse intégrée à RStudio et qu’on peut appeler avec la fonction View().\n\nView(hdv2003)\n\n\n\n\n\n\nFigure 4.1: Interface View() de R RStudio\n\n\nLes fonctions head() et tail(), qui marchent également sur les vecteurs, permettent d’afficher seulement les premières (respectivement les dernières) lignes d’un tableau de données :\n\nhead(hdv2003)\n\n  id age  sexe                                              nivetud    poids\n1  1  28 Femme Enseignement superieur y compris technique superieur 2634.398\n2  2  23 Femme                                                 &lt;NA&gt; 9738.396\n3  3  59 Homme                    Derniere annee d'etudes primaires 3994.102\n4  4  34 Homme Enseignement superieur y compris technique superieur 5731.662\n5  5  71 Femme                    Derniere annee d'etudes primaires 4329.094\n6  6  35 Femme        Enseignement technique ou professionnel court 8674.699\n                  occup     qualif freres.soeurs clso\n1 Exerce une profession    Employe             8  Oui\n2       Etudiant, eleve       &lt;NA&gt;             2  Oui\n3 Exerce une profession Technicien             2  Non\n4 Exerce une profession Technicien             1  Non\n5              Retraite    Employe             0  Oui\n6 Exerce une profession    Employe             5  Non\n                        relig                     trav.imp    trav.satisf\n1 Ni croyance ni appartenance                Peu important Insatisfaction\n2 Ni croyance ni appartenance                         &lt;NA&gt;           &lt;NA&gt;\n3 Ni croyance ni appartenance Aussi important que le reste      Equilibre\n4  Appartenance sans pratique Moins important que le reste   Satisfaction\n5         Pratiquant regulier                         &lt;NA&gt;           &lt;NA&gt;\n6 Ni croyance ni appartenance            Le plus important      Equilibre\n  hard.rock lecture.bd peche.chasse cuisine bricol cinema sport heures.tv\n1       Non        Non          Non     Oui    Non    Non   Non         0\n2       Non        Non          Non     Non    Non    Oui   Oui         1\n3       Non        Non          Non     Non    Non    Non   Oui         0\n4       Non        Non          Non     Oui    Oui    Oui   Oui         2\n5       Non        Non          Non     Non    Non    Non   Non         3\n6       Non        Non          Non     Non    Non    Oui   Oui         2\n\ntail(hdv2003, 2)\n\n       id age  sexe                                       nivetud     poids\n1999 1999  24 Femme Enseignement technique ou professionnel court 13740.810\n2000 2000  66 Femme  Enseignement technique ou professionnel long  7709.513\n                     occup  qualif freres.soeurs clso\n1999 Exerce une profession Employe             2  Non\n2000              Au foyer Employe             3  Non\n                          relig                     trav.imp trav.satisf\n1999 Appartenance sans pratique Moins important que le reste   Equilibre\n2000 Appartenance sans pratique                         &lt;NA&gt;        &lt;NA&gt;\n     hard.rock lecture.bd peche.chasse cuisine bricol cinema sport heures.tv\n1999       Non        Non          Non     Non    Non    Oui   Non       0.3\n2000       Non        Oui          Non     Oui    Non    Non   Non       0.0\n\n\nL’extension dplyr propose une fonction dplyr::glimpse() (ce qui signifie aperçu en anglais) qui permet de visualiser rapidement et de manière condensée le contenu d’un tableau de données.\n\nlibrary(dplyr)\nglimpse(hdv2003)\n\nRows: 2,000\nColumns: 20\n$ id            &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ age           &lt;int&gt; 28, 23, 59, 34, 71, 35, 60, 47, 20, 28, 65, 47, 63, 67, …\n$ sexe          &lt;fct&gt; Femme, Femme, Homme, Homme, Femme, Femme, Femme, Homme, …\n$ nivetud       &lt;fct&gt; \"Enseignement superieur y compris technique superieur\", …\n$ poids         &lt;dbl&gt; 2634.3982, 9738.3958, 3994.1025, 5731.6615, 4329.0940, 8…\n$ occup         &lt;fct&gt; \"Exerce une profession\", \"Etudiant, eleve\", \"Exerce une …\n$ qualif        &lt;fct&gt; Employe, NA, Technicien, Technicien, Employe, Employe, O…\n$ freres.soeurs &lt;int&gt; 8, 2, 2, 1, 0, 5, 1, 5, 4, 2, 3, 4, 1, 5, 2, 3, 4, 0, 2,…\n$ clso          &lt;fct&gt; Oui, Oui, Non, Non, Oui, Non, Oui, Non, Oui, Non, Oui, O…\n$ relig         &lt;fct&gt; Ni croyance ni appartenance, Ni croyance ni appartenance…\n$ trav.imp      &lt;fct&gt; Peu important, NA, Aussi important que le reste, Moins i…\n$ trav.satisf   &lt;fct&gt; Insatisfaction, NA, Equilibre, Satisfaction, NA, Equilib…\n$ hard.rock     &lt;fct&gt; Non, Non, Non, Non, Non, Non, Non, Non, Non, Non, Non, N…\n$ lecture.bd    &lt;fct&gt; Non, Non, Non, Non, Non, Non, Non, Non, Non, Non, Non, N…\n$ peche.chasse  &lt;fct&gt; Non, Non, Non, Non, Non, Non, Oui, Oui, Non, Non, Non, N…\n$ cuisine       &lt;fct&gt; Oui, Non, Non, Oui, Non, Non, Oui, Oui, Non, Non, Oui, N…\n$ bricol        &lt;fct&gt; Non, Non, Non, Oui, Non, Non, Non, Oui, Non, Non, Oui, O…\n$ cinema        &lt;fct&gt; Non, Oui, Non, Oui, Non, Oui, Non, Non, Oui, Oui, Oui, N…\n$ sport         &lt;fct&gt; Non, Oui, Oui, Oui, Non, Oui, Non, Non, Non, Oui, Non, O…\n$ heures.tv     &lt;dbl&gt; 0.0, 1.0, 0.0, 2.0, 3.0, 2.0, 2.9, 1.0, 2.0, 2.0, 1.0, 0…\n\n\nL’extension labelled propose une fonction labelled::look_for() qui permet de lister les différentes variables d’un fichier de données :\n\nlibrary(labelled)\nlook_for(hdv2003)\n\n pos variable      label col_type missing values                              \n 1   id            —     int      0                                           \n 2   age           —     int      0                                           \n 3   sexe          —     fct      0       Homme                               \n                                          Femme                               \n 4   nivetud       —     fct      112     N'a jamais fait d'etudes            \n                                          A arrete ses etudes, avant la derni~\n                                          Derniere annee d'etudes primaires   \n                                          1er cycle                           \n                                          2eme cycle                          \n                                          Enseignement technique ou professio~\n                                          Enseignement technique ou professio~\n                                          Enseignement superieur y compris te~\n 5   poids         —     dbl      0                                           \n 6   occup         —     fct      0       Exerce une profession               \n                                          Chomeur                             \n                                          Etudiant, eleve                     \n                                          Retraite                            \n                                          Retire des affaires                 \n                                          Au foyer                            \n                                          Autre inactif                       \n 7   qualif        —     fct      347     Ouvrier specialise                  \n                                          Ouvrier qualifie                    \n                                          Technicien                          \n                                          Profession intermediaire            \n                                          Cadre                               \n                                          Employe                             \n                                          Autre                               \n 8   freres.soeurs —     int      0                                           \n 9   clso          —     fct      0       Oui                                 \n                                          Non                                 \n                                          Ne sait pas                         \n 10  relig         —     fct      0       Pratiquant regulier                 \n                                          Pratiquant occasionnel              \n                                          Appartenance sans pratique          \n                                          Ni croyance ni appartenance         \n                                          Rejet                               \n                                          NSP ou NVPR                         \n 11  trav.imp      —     fct      952     Le plus important                   \n                                          Aussi important que le reste        \n                                          Moins important que le reste        \n                                          Peu important                       \n 12  trav.satisf   —     fct      952     Satisfaction                        \n                                          Insatisfaction                      \n                                          Equilibre                           \n 13  hard.rock     —     fct      0       Non                                 \n                                          Oui                                 \n 14  lecture.bd    —     fct      0       Non                                 \n                                          Oui                                 \n 15  peche.chasse  —     fct      0       Non                                 \n                                          Oui                                 \n 16  cuisine       —     fct      0       Non                                 \n                                          Oui                                 \n 17  bricol        —     fct      0       Non                                 \n                                          Oui                                 \n 18  cinema        —     fct      0       Non                                 \n                                          Oui                                 \n 19  sport         —     fct      0       Non                                 \n                                          Oui                                 \n 20  heures.tv     —     dbl      5                                           \n\n\nLorsqu’on a un gros tableau de données avec de nombreuses variables, il peut être difficile de retrouver la ou les variables d’intérêt. Il est possible d’indiquer à labelled::look_for() un mot-clé pour limiter la recherche. Par exemple :\n\nlook_for(hdv2003, \"trav\")\n\n pos variable    label col_type missing values                      \n 11  trav.imp    —     fct      952     Le plus important           \n                                        Aussi important que le reste\n                                        Moins important que le reste\n                                        Peu important               \n 12  trav.satisf —     fct      952     Satisfaction                \n                                        Insatisfaction              \n                                        Equilibre                   \n\n\nIl est à noter que si la recherche n’est pas sensible à la casse (i.e. aux majuscules et aux minuscules), elle est sensible aux accents.\nLa méthode summary() qui fonctionne sur tout type d’objet permet d’avoir quelques statistiques de base sur les différentes variables de notre tableau, les statistiques affichées dépendant du type de variable.\n\nsummary(hdv2003)\n\n       id              age           sexe     \n Min.   :   1.0   Min.   :18.00   Homme: 899  \n 1st Qu.: 500.8   1st Qu.:35.00   Femme:1101  \n Median :1000.5   Median :48.00               \n Mean   :1000.5   Mean   :48.16               \n 3rd Qu.:1500.2   3rd Qu.:60.00               \n Max.   :2000.0   Max.   :97.00               \n                                              \n                                                 nivetud        poids         \n Enseignement technique ou professionnel court       :463   Min.   :   78.08  \n Enseignement superieur y compris technique superieur:441   1st Qu.: 2221.82  \n Derniere annee d'etudes primaires                   :341   Median : 4631.19  \n 1er cycle                                           :204   Mean   : 5535.61  \n 2eme cycle                                          :183   3rd Qu.: 7626.53  \n (Other)                                             :256   Max.   :31092.14  \n NA's                                                :112                     \n                   occup                           qualif    freres.soeurs   \n Exerce une profession:1049   Employe                 :594   Min.   : 0.000  \n Chomeur              : 134   Ouvrier qualifie        :292   1st Qu.: 1.000  \n Etudiant, eleve      :  94   Cadre                   :260   Median : 2.000  \n Retraite             : 392   Ouvrier specialise      :203   Mean   : 3.283  \n Retire des affaires  :  77   Profession intermediaire:160   3rd Qu.: 5.000  \n Au foyer             : 171   (Other)                 :144   Max.   :22.000  \n Autre inactif        :  83   NA's                    :347                   \n          clso                              relig    \n Oui        : 936   Pratiquant regulier        :266  \n Non        :1037   Pratiquant occasionnel     :442  \n Ne sait pas:  27   Appartenance sans pratique :760  \n                    Ni croyance ni appartenance:399  \n                    Rejet                      : 93  \n                    NSP ou NVPR                : 40  \n                                                     \n                         trav.imp           trav.satisf  hard.rock  lecture.bd\n Le plus important           : 29   Satisfaction  :480   Non:1986   Non:1953  \n Aussi important que le reste:259   Insatisfaction:117   Oui:  14   Oui:  47  \n Moins important que le reste:708   Equilibre     :451                        \n Peu important               : 52   NA's          :952                        \n NA's                        :952                                             \n                                                                              \n                                                                              \n peche.chasse cuisine    bricol     cinema     sport        heures.tv     \n Non:1776     Non:1119   Non:1147   Non:1174   Non:1277   Min.   : 0.000  \n Oui: 224     Oui: 881   Oui: 853   Oui: 826   Oui: 723   1st Qu.: 1.000  \n                                                          Median : 2.000  \n                                                          Mean   : 2.247  \n                                                          3rd Qu.: 3.000  \n                                                          Max.   :12.000  \n                                                          NA's   :5       \n\n\nOn peut également appliquer summary() à une variable particulière.\n\nsummary(hdv2003$sexe)\n\nHomme Femme \n  899  1101 \n\nsummary(hdv2003$age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  18.00   35.00   48.00   48.16   60.00   97.00",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tableaux de données</span>"
    ]
  },
  {
    "objectID": "bases/tableaux_donnees.html#en-résumé",
    "href": "bases/tableaux_donnees.html#en-résumé",
    "title": "4  Tableaux de données",
    "section": "\n4.4 En résumé",
    "text": "4.4 En résumé\n\nLes tableaux de données sont des listes avec des propriétés particulières :\n\ntous les éléments sont des vecteurs ;\ntous les vecteurs ont la même longueur ;\ntous les vecteurs ont un nom et ce nom est unique.\n\n\nOn peut créer un tableau de données avec data.frame().\nLes tableaux de données correspondent aux fichiers de données qu’on utilise usuellement dans d’autres logiciels de statistiques : les variables sont représentées en colonnes et les observations en lignes.\nCe sont des objets bidimensionnels : ncol() renvoie le nombre de colonnes et nrow() le nombre de lignes.\nLes doubles crochets ([[]]) et le symbole dollar ($) fonctionnent comme pour les listes et permettent d’accéder aux variables.\nIl est possible d’utiliser des coordonnées bidimensionnelles avec les crochets simples ([]) en indiquant un critère sur les lignes puis un critère sur les colonnes, séparés par une virgule (,).",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tableaux de données</span>"
    ]
  },
  {
    "objectID": "bases/tableaux_donnees.html#webin-r",
    "href": "bases/tableaux_donnees.html#webin-r",
    "title": "4  Tableaux de données",
    "section": "\n4.5 webin-R",
    "text": "4.5 webin-R\nOn pourra également se référer au webin-R #02 (les bases du langage R) sur YouTube.\n\n\n\n\nFigure 4.1: Interface View() de R RStudio",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tableaux de données</span>"
    ]
  },
  {
    "objectID": "bases/tibbles.html",
    "href": "bases/tibbles.html",
    "title": "5  Tibbles",
    "section": "",
    "text": "5.1 Le concept de tidy data\nLe tidyverse est en partie fondé sur le concept de tidy data, développé à l’origine par Hadley Wickham dans un article de 2014 du Journal of Statistical Software.\nIl s’agit d’un modèle d’organisation des données qui vise à faciliter le travail souvent long et fastidieux de nettoyage et de préparation préalable à la mise en oeuvre de méthodes d’analyse.\nLes principes d’un jeu de données tidy sont les suivants :\nUn chapitre dédié à tidyr (voir Chapitre 36) présente comment définir et rendre des données tidy avec ce package.\nLes extensions du tidyverse, notamment ggplot2 et dplyr, sont prévues pour fonctionner avec des données tidy.",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Tibbles</span>"
    ]
  },
  {
    "objectID": "bases/tibbles.html#sec-tidy-data",
    "href": "bases/tibbles.html#sec-tidy-data",
    "title": "5  Tibbles",
    "section": "",
    "text": "chaque variable est une colonne\nchaque observation est une ligne\nchaque type d’observation est dans une table différente",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Tibbles</span>"
    ]
  },
  {
    "objectID": "bases/tibbles.html#tibbles",
    "href": "bases/tibbles.html#tibbles",
    "title": "5  Tibbles",
    "section": "\n5.2 tibbles : des tableaux de données améliorés",
    "text": "5.2 tibbles : des tableaux de données améliorés\nUne autre particularité du tidyverse est que ces extensions travaillent avec des tableaux de données au format tibble::tibble(), qui est une évolution plus moderne du classique data.frame de R de base.\nCe format est fourni est géré par l’extension du même nom (tibble), qui fait partie du cœur du tidyverse. La plupart des fonctions des extensions du tidyverse acceptent des data.frames en entrée, mais retournent un tibble.\nContrairement aux data frames, les tibbles :\n\nn’ont pas de noms de lignes (rownames)\nautorisent des noms de colonnes invalides pour les data frames (espaces, caractères spéciaux, nombres…) 1\n\ns’affichent plus intelligemment que les data frames : seules les premières lignes sont affichées, ainsi que quelques informations supplémentaires utiles (dimensions, types des colonnes…)\nne font pas de partial matching sur les noms de colonnes 2\n\naffichent un avertissement si on essaie d’accéder à une colonne qui n’existe pas\n\n1 Quand on veut utiliser des noms de ce type, on doit les entourer avec des backticks (`)2 Dans R base, si une table d contient une colonne qualif, d$qual retournera cette colonne.Pour autant, les tibbles restent compatibles avec les data frames.\nIl est possible de créer un tibble manuellement avec tibble::tibble().\n\n\n\n\nlibrary(tidyverse)\ntibble(\n  x = c(1.2345, 12.345, 123.45, 1234.5, 12345),\n  y = c(\"a\", \"b\", \"c\", \"d\", \"e\")\n)\n\n# A tibble: 5 × 2\n         x y    \n     &lt;dbl&gt; &lt;chr&gt;\n1     1.23 a    \n2    12.3  b    \n3   123.   c    \n4  1234.   d    \n5 12345    e    \n\n\nOn peut ainsi facilement convertir un data frame en tibble avec tibble::as_tibble() :\n\nd &lt;- as_tibble(mtcars)\nd\n\n# A tibble: 32 × 11\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8  24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9  22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10  19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# ℹ 22 more rows\n\n\nD’ailleurs, quand on regarde la classe d’un tibble, on peut s’apercevoir qu’un tibble hérite de la classe data.frame mais possède en plus la classe tbl_df. Cela traduit bien le fait que les tibbles restent des data frames.\n\nclass(d)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nSi le data frame d’origine a des rownames, on peut d’abord les convertir en colonnes avec tibble::rownames_to_column() :\n\nd &lt;- as_tibble(rownames_to_column(mtcars))\nd\n\n# A tibble: 32 × 12\n   rowname       mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Mazda RX4    21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2 Mazda RX4 …  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3 Datsun 710   22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4 Hornet 4 D…  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5 Hornet Spo…  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6 Valiant      18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7 Duster 360   14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8 Merc 240D    24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9 Merc 230     22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10 Merc 280     19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# ℹ 22 more rows\n\n\nÀ l’inverse, on peut à tout moment convertir un tibble en data frame avec tibble::as.data.frame() :\n\nas.data.frame(d)\n\n               rowname  mpg cyl  disp  hp drat    wt  qsec vs am gear carb\n1            Mazda RX4 21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\n2        Mazda RX4 Wag 21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\n3           Datsun 710 22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\n4       Hornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\n5    Hornet Sportabout 18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\n6              Valiant 18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\n7           Duster 360 14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\n8            Merc 240D 24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\n9             Merc 230 22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\n10            Merc 280 19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\n11           Merc 280C 17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\n12          Merc 450SE 16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\n13          Merc 450SL 17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\n14         Merc 450SLC 15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\n15  Cadillac Fleetwood 10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\n16 Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\n17   Chrysler Imperial 14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\n18            Fiat 128 32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\n19         Honda Civic 30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\n20      Toyota Corolla 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\n21       Toyota Corona 21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\n22    Dodge Challenger 15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\n23         AMC Javelin 15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\n24          Camaro Z28 13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\n25    Pontiac Firebird 19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\n26           Fiat X1-9 27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\n27       Porsche 914-2 26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\n28        Lotus Europa 30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\n29      Ford Pantera L 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\n30        Ferrari Dino 19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\n31       Maserati Bora 15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\n32          Volvo 142E 21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n\nLà encore, on peut convertir la colonne rowname en “vrais” rownames avec tibble::column_to_rownames() :\n\ncolumn_to_rownames(as.data.frame(d))\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n\n\n\n\n\n\n\nNote\n\n\n\nLes deux fonctions tibble::column_to_rownames() et tibble::rownames_to_column() acceptent un argument supplémentaire var qui permet d’indiquer un nom de colonne autre que le nom rowname utilisé par défaut pour créer ou identifier la colonne contenant les noms de lignes.",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Tibbles</span>"
    ]
  },
  {
    "objectID": "bases/tibbles.html#données-et-tableaux-imbriqués",
    "href": "bases/tibbles.html#données-et-tableaux-imbriqués",
    "title": "5  Tibbles",
    "section": "\n5.3 Données et tableaux imbriqués",
    "text": "5.3 Données et tableaux imbriqués\nUne des particularités des tibbles est qu’ils acceptent, à la différence des data frames, des colonnes composées de listes et, par extension, d’autres tibbles (qui sont des listes)  !\n\nd &lt;- tibble(\n  g = c(1, 2, 3),\n  data = list(\n    tibble(x = 1, y = 2),\n    tibble(x = 4:5, y = 6:7),\n    tibble(x = 10)\n  )\n)\nd\n\n# A tibble: 3 × 2\n      g data            \n  &lt;dbl&gt; &lt;list&gt;          \n1     1 &lt;tibble [1 × 2]&gt;\n2     2 &lt;tibble [2 × 2]&gt;\n3     3 &lt;tibble [1 × 1]&gt;\n\nd$data[[2]]\n\n# A tibble: 2 × 2\n      x     y\n  &lt;int&gt; &lt;int&gt;\n1     4     6\n2     5     7\n\n\nCette fonctionnalité, combinée avec les fonctions de tidyr et de purrr, s’avère très puissante pour réaliser des opérations multiples en peu de ligne de code.\nDans l’exemple ci-dessous, nous réalisons des régressions linéaires par sous-groupe et les présentons dans un même tableau. Pour le moment, le code présenté doit vous sembler complexe et un peu obscur. Pas de panique : tout cela sera clarifié dans les différents chapitres de ce guide. Ce qu’il y a à retenir pour le moment, c’est la possibilité de stocker, dans les colonnes d’un tibble, différent types de données, y compris des sous-tableaux, des résultats de modèles et même des tableaux mis en forme.\n\nreg &lt;-\n  iris |&gt; \n  group_by(Species) |&gt; \n  nest() |&gt; \n  mutate(\n    model = map(\n      data, \n      ~ lm(Sepal.Length ~ Petal.Length + Petal.Width, data = .)\n    ),\n    tbl = map(model, gtsummary::tbl_regression)\n  )\nreg\n\n# A tibble: 3 × 4\n# Groups:   Species [3]\n  Species    data              model  tbl       \n  &lt;fct&gt;      &lt;list&gt;            &lt;list&gt; &lt;list&gt;    \n1 setosa     &lt;tibble [50 × 4]&gt; &lt;lm&gt;   &lt;tbl_rgrs&gt;\n2 versicolor &lt;tibble [50 × 4]&gt; &lt;lm&gt;   &lt;tbl_rgrs&gt;\n3 virginica  &lt;tibble [50 × 4]&gt; &lt;lm&gt;   &lt;tbl_rgrs&gt;\n\ngtsummary::tbl_merge(\n  reg$tbl,\n  tab_spanner = paste0(\"**\", reg$Species, \"**\")\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\n\nsetosa\n\n\n\nversicolor\n\n\n\nvirginica\n\n\n\nBeta\n\n95% CI\n1\n\np-value\nBeta\n\n95% CI\n1\n\np-value\nBeta\n\n95% CI\n1\n\np-value\n\n\n\n\nPetal.Length\n0.40\n-0.20, 0.99\n0.2\n0.93\n0.59, 1.3\n&lt;0.001\n1.0\n0.81, 1.2\n&lt;0.001\n\n\nPetal.Width\n0.71\n-0.27, 1.7\n0.2\n-0.32\n-1.1, 0.49\n0.4\n0.01\n-0.35, 0.37\n&gt;0.9\n\n\n\n\n1\nCI = Confidence Interval",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Tibbles</span>"
    ]
  },
  {
    "objectID": "bases/attributs.html",
    "href": "bases/attributs.html",
    "title": "6  Attributs",
    "section": "",
    "text": "Les objets R peuvent avoir des attributs qui correspondent en quelque sorte à des métadonnées associées à l’objet en question. Techniquement, un attribut peut être tout type d’objet R (un vecteur, une liste, une fonction…).\nParmi les attributs les plus courants, on retrouve notamment :\n\n\nclass : la classe de l’objet\n\nlenghth : sa longueur\n\nnames : les noms donnés aux éléments de l’objet\n\nlevels : pour les facteurs, les étiquettes des différents niveaux\n\nlabel : une étiquette de variable\n\nLa fonction attributes() permet de lister tous les attributs associés à un objet.\n\nattributes(iris)\n\n$names\n[1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  \"Species\"     \n\n$class\n[1] \"data.frame\"\n\n$row.names\n  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n [91]  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n[109] 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n[127] 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n[145] 145 146 147 148 149 150\n\n\nPour accéder à un attribut spécifique, on aura recours à attr() en spécifiant à la fois l’objet considéré et le nom de l’attribut souhaité.\n\niris |&gt; attr(\"names\")\n\n[1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  \"Species\"     \n\n\nPour les attributs les plus courants de R, il faut noter qu’il existe le plus souvent des fonctions spécifiques, comme class(), names() ou row.names().\n\nclass(iris)\n\n[1] \"data.frame\"\n\nnames(iris)\n\n[1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  \"Species\"     \n\n\nLa fonction attr(), associée à l’opérateur d’assignation (&lt;-) permet également de définir ses propres attributs.\n\nattr(iris, \"perso\") &lt;- \"Des notes personnelles\"\nattributes(iris)\n\n$names\n[1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  \"Species\"     \n\n$class\n[1] \"data.frame\"\n\n$row.names\n  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n [91]  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n[109] 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n[127] 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n[145] 145 146 147 148 149 150\n\n$perso\n[1] \"Des notes personnelles\"\n\nattr(iris, \"perso\")\n\n[1] \"Des notes personnelles\"",
    "crumbs": [
      "**Bases du langage**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Attributs</span>"
    ]
  },
  {
    "objectID": "manipulation/pipe.html",
    "href": "manipulation/pipe.html",
    "title": "7  Le pipe",
    "section": "",
    "text": "7.1 Le pipe natif de R : |&gt;\nDepuis la version 4.1, R a introduit ce que l’on nomme un pipe (tuyau en anglais), un nouvel opérateur noté |&gt;.\nLe principe de cet opérateur est de passer l’élément situé à sa gauche comme premier argument de la fonction située à sa droite. Ainsi, l’écriture x |&gt; f() est équivalente à f(x) et l’écriture x |&gt; f(y) à f(x, y).\nParfois, on souhaite passer l’objet x à un autre endroit de la fonction f() que le premier argument. Depuis la version 4.2, R a introduit l’opérateur _,que l’on nomme un placeholder, pour indiquer où passer l’objet de gauche. Ainsi, x |&gt; f(y, a = _) devient équivalent à f(y, a = x). ATTENTION : le placeholder doit impérativement être transmis à un argument nommé !\nTout cela semble encore un peu abstrait ? Reprenons notre exemple précédent et réécrivons le code avec le pipe.\nv |&gt; \n  mean() |&gt; \n  round(digits = 1) |&gt; \n  format(decimal.mark = \",\") |&gt; \n  paste0(\"La moyenne est de \", m = _, \".\") |&gt; \n  message()\n\nLa moyenne est de 6,7.\nLe code n’est-il pas plus lisible ?\nLe diaporama ci-dessous vous permet de visualiser chaque étape du code.",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Le pipe</span>"
    ]
  },
  {
    "objectID": "manipulation/pipe.html#le-pipe-du-tidyverse",
    "href": "manipulation/pipe.html#le-pipe-du-tidyverse",
    "title": "7  Le pipe",
    "section": "\n7.2 Le pipe du tidyverse : %>%\n",
    "text": "7.2 Le pipe du tidyverse : %&gt;%\n\nCe n’est qu’à partir de la version 4.1 sortie en 2021 que R a proposé de manière native un pipe, en l’occurence l’opérateur |&gt;.\nEn cela, R s’est notamment inspiré d’un opérateur similaire introduit dès 2014 dans le tidyverse. Le pipe du tidyverse fonctionne de manière similaire. Il est implémenté dans le package magrittr qui doit donc être chargé en mémoire. Le pipe est également disponible lorsque l’on effectue library(tidyverse).\nCet opérateur s’écrit %&gt;% et il dispose lui aussi d’un placeholder qui est le .. La syntaxe du placeholder est un peu plus souple puisqu’il peut être passé à tout type d’argument, y compris un argument sans nom. Si l’on reprend notre exemple précédent.\n\nlibrary(magrittr)\nv %&gt;% \n  mean() %&gt;%\n  round(digits = 1) %&gt;%\n  format(decimal.mark = \",\") %&gt;%\n  paste0(\"La moyenne est de \", ., \".\") %&gt;%\n  message()\n\nLa moyenne est de 6,7.",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Le pipe</span>"
    ]
  },
  {
    "objectID": "manipulation/pipe.html#vaut-il-mieux-utiliser-ou",
    "href": "manipulation/pipe.html#vaut-il-mieux-utiliser-ou",
    "title": "7  Le pipe",
    "section": "\n7.3 Vaut-il mieux utiliser |> ou %>% ?",
    "text": "7.3 Vaut-il mieux utiliser |&gt; ou %&gt;% ?\n\nBonne question. Si vous utilisez une version récente de R (≥ 4.2), il est préférable d’avoir recours au pipe natif de R dans la mesure où il est plus efficient en termes de temps de calcul car il fait partie intégrante du langage. Dans ce guide, nous privilégions d’ailleurs l’utilisation de |&gt;.\nSi votre code nécessite de fonctionner avec différentes versions de R, par exemple dans le cadre d’un package, il est alors préférable, pour le moment, d’utiliser celui fourni par magrittr (%&gt;%).",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Le pipe</span>"
    ]
  },
  {
    "objectID": "manipulation/pipe.html#sec-pluck-chuck",
    "href": "manipulation/pipe.html#sec-pluck-chuck",
    "title": "7  Le pipe",
    "section": "\n7.4 Accéder à un élément avec purrr::pluck() et purrr::chuck()\n",
    "text": "7.4 Accéder à un élément avec purrr::pluck() et purrr::chuck()\n\nIl est fréquent d’avoir besoin d’accéder à un élément précis d’une liste, d’un tableau ou d’un vecteur, ce que l’on fait d’ordinaire avec la syntaxe [[]] ou $ pour les listes ou [] pour les vecteurs. Cependant, cette syntaxe se combine souvent mal avec un enchaînement d’opérations utilisant le pipe.\nLe package purrr, chargé par défaut avec library(tidyverse), fournit une fonction purrr::pluck() qui, est l’équivalent de [[]], et qui permet de récupérer un élément par son nom ou sa position. Ainsi, si l’on considère le tableau de données iris, pluck(iris, \"Petal.Witdh\") est équivalent à iris$Petal.Width. Voyons un exemple d’utilisation dans le cadre d’un enchaînement d’opérations.\n\niris |&gt; \n  purrr::pluck(\"Petal.Width\") |&gt; \n  mean()\n\n[1] 1.199333\n\n\nCette écriture est équivalente à :\n\nmean(iris$Petal.Width)\n\n[1] 1.199333\n\n\npurrr::pluck() fonctionne également sur des vecteurs (et dans ce cas opère comme []).\n\nv &lt;- c(\"a\", \"b\", \"c\", \"d\")\nv |&gt; purrr::pluck(2)\n\n[1] \"b\"\n\nv[2]\n\n[1] \"b\"\n\n\nOn peut également, dans un même appel à purrr::pluck(), enchaîner plusieurs niveaux. Les trois syntaxes ci-après sont ainsi équivalents :\n\niris |&gt; \n  purrr::pluck(\"Sepal.Width\", 3)\n\n[1] 3.2\n\niris |&gt; \n  purrr::pluck(\"Sepal.Width\") |&gt; \n  purrr::pluck(3)\n\n[1] 3.2\n\niris[[\"Sepal.Width\"]][3]\n\n[1] 3.2\n\n\nSi l’on demande un élément qui n’existe pas, purrr:pluck() renverra l’élement vide (NULL). Si l’on souhaite plutôt que cela génère une erreur, on aura alors recours à purrr::chuck().\n\niris |&gt; purrr::pluck(\"inconnu\")\n\nNULL\n\niris |&gt; purrr::chuck(\"inconnu\")\n\nError in `purrr::chuck()`:\n! Can't find name `inconnu` in vector.\n\nv |&gt; purrr::pluck(10)\n\nNULL\n\nv |&gt; purrr::chuck(10)\n\nError in `purrr::chuck()`:\n! Index 1 exceeds the length of plucked object (10 &gt; 4).",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Le pipe</span>"
    ]
  },
  {
    "objectID": "manipulation/dplyr.html",
    "href": "manipulation/dplyr.html",
    "title": "8  dplyr",
    "section": "",
    "text": "8.1 Opérations sur les lignes",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>`dplyr`</span>"
    ]
  },
  {
    "objectID": "manipulation/dplyr.html#opérations-sur-les-lignes",
    "href": "manipulation/dplyr.html#opérations-sur-les-lignes",
    "title": "8  dplyr",
    "section": "",
    "text": "8.1.1 filter()\ndplyr::filter() sélectionne des lignes d’un tableau de données selon une condition. On lui passe en paramètre un test, et seules les lignes pour lesquelles ce test renvoi TRUE (vrai) sont conservées2.\n2 Si le test renvoie faux (FALSE) ou une valeur manquante (NA), les lignes correspondantes ne seront donc pas sélectionnées.Par exemple, si on veut sélectionner les vols du mois de janvier, on peut filtrer sur la variable month de la manière suivante :\n\nfilter(flights, month == 1)\n\n# A tibble: 27,004 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 26,994 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nCela peut s’écrire plus simplement avec un pipe :\n\nflights |&gt; filter(month == 1)\n\n# A tibble: 27,004 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 26,994 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nSi l’on veut uniquement les vols avec un retard au départ (variable dep_delay) compris entre 10 et 15 minutes :\n\nflights |&gt; \n  filter(dep_delay &gt;= 10 & dep_delay &lt;= 15)\n\n# A tibble: 14,919 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      611            600        11      945            931\n 2  2013     1     1      623            610        13      920            915\n 3  2013     1     1      743            730        13     1107           1100\n 4  2013     1     1      743            730        13     1059           1056\n 5  2013     1     1      851            840        11     1215           1206\n 6  2013     1     1      912            900        12     1241           1220\n 7  2013     1     1      914            900        14     1058           1043\n 8  2013     1     1      920            905        15     1039           1025\n 9  2013     1     1     1011           1001        10     1133           1128\n10  2013     1     1     1112           1100        12     1440           1438\n# ℹ 14,909 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nSi l’on passe plusieurs arguments à dplyr::filter(), celui-ci rajoute automatiquement une condition ET. La ligne ci-dessus peut donc également être écrite de la manière suivante, avec le même résultat :\n\nflights |&gt; \n  filter(dep_delay &gt;= 10, dep_delay &lt;= 15)\n\nEnfin, on peut également placer des fonctions dans les tests, qui nous permettent par exemple de sélectionner les vols avec la plus grande distance :\n\nflights |&gt; \n  filter(distance == max(distance))\n\n# A tibble: 342 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      857            900        -3     1516           1530\n 2  2013     1     2      909            900         9     1525           1530\n 3  2013     1     3      914            900        14     1504           1530\n 4  2013     1     4      900            900         0     1516           1530\n 5  2013     1     5      858            900        -2     1519           1530\n 6  2013     1     6     1019            900        79     1558           1530\n 7  2013     1     7     1042            900       102     1620           1530\n 8  2013     1     8      901            900         1     1504           1530\n 9  2013     1     9      641            900      1301     1242           1530\n10  2013     1    10      859            900        -1     1449           1530\n# ℹ 332 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\n\n\n\n\n\nÉvaluation contextuelle\n\n\n\nIl est important de noter que dplyr procède à une évaluation contextuelle des expressions qui lui sont passées. Ainsi, on peut indiquer directement le nom d’une variable et dplyr l’interprétera dans le contexte du tableau de données, c’est-à-dire regardera s’il existe une colonne portant ce nom dans le tableau.\nDans l’expression flights |&gt; filter(month == 1), month est interprété comme la colonne month du tableau flights, à savoir flights$month.\nIl est également possible d’indiquer des objets extérieurs au tableau :\n\nm &lt;- 2\nflights |&gt; \n  filter(month == m)\n\n# A tibble: 24,951 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     2     1      456            500        -4      652            648\n 2  2013     2     1      520            525        -5      816            820\n 3  2013     2     1      527            530        -3      837            829\n 4  2013     2     1      532            540        -8     1007           1017\n 5  2013     2     1      540            540         0      859            850\n 6  2013     2     1      552            600        -8      714            715\n 7  2013     2     1      552            600        -8      919            910\n 8  2013     2     1      552            600        -8      655            709\n 9  2013     2     1      553            600        -7      833            815\n10  2013     2     1      553            600        -7      821            825\n# ℹ 24,941 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nCela fonctionne car il n’y a pas de colonne m dans flights. Dès lors, dplyr regarde s’il existe un objet m dans l’environnement de travail.\nPar contre, si une colonne existe dans le tableau, elle aura priorité sur les objets du même nom dans l’environnement. Dans l’exemple ci-dessous, le résultat obtenu n’est pas celui voulu. Il est interprété comme sélectionner toutes les lignes où la colonne mois est égale à elle-même et donc cela sélectionne toutes les lignes du tableau.\n\nmonth &lt;- 3\nflights |&gt; \n  filter(month == month)\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nAfin de distinguer ce qui correspond à une colonne du tableau et à un objet de l’environnement, on pourra avoir recours à .data et .env (voir help(\".env\", package = \"rlang\")).\n\nmonth &lt;- 3\nflights |&gt; \n  filter(.data$month == .env$month)\n\n# A tibble: 28,834 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     3     1        4           2159       125      318             56\n 2  2013     3     1       50           2358        52      526            438\n 3  2013     3     1      117           2245       152      223           2354\n 4  2013     3     1      454            500        -6      633            648\n 5  2013     3     1      505            515       -10      746            810\n 6  2013     3     1      521            530        -9      813            827\n 7  2013     3     1      537            540        -3      856            850\n 8  2013     3     1      541            545        -4     1014           1023\n 9  2013     3     1      549            600       -11      639            703\n10  2013     3     1      550            600       -10      747            801\n# ℹ 28,824 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\n\n\n8.1.2 slice()\nLe verbe dplyr::slice() sélectionne des lignes du tableau selon leur position. On lui passe un chiffre ou un vecteur de chiffres.\nSi l’on souhaite sélectionner la 345e ligne du tableau airports :\n\nairports |&gt; \n  slice(345)\n\n# A tibble: 1 × 8\n  faa   name                lat   lon   alt    tz dst   tzone            \n  &lt;chr&gt; &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;            \n1 CYF   Chefornak Airport  60.1 -164.    40    -9 A     America/Anchorage\n\n\nSi l’on veut sélectionner les 5 premières lignes :\n\nairports |&gt; \n  slice(1:5)\n\n# A tibble: 5 × 8\n  faa   name                            lat   lon   alt    tz dst   tzone       \n  &lt;chr&gt; &lt;chr&gt;                         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;       \n1 04G   Lansdowne Airport              41.1 -80.6  1044    -5 A     America/New…\n2 06A   Moton Field Municipal Airport  32.5 -85.7   264    -6 A     America/Chi…\n3 06C   Schaumburg Regional            42.0 -88.1   801    -6 A     America/Chi…\n4 06N   Randall Airport                41.4 -74.4   523    -5 A     America/New…\n5 09J   Jekyll Island Airport          31.1 -81.4    11    -5 A     America/New…\n\n\n\n8.1.3 arrange()\ndplyr::arrange() réordonne les lignes d’un tableau selon une ou plusieurs colonnes.\nAinsi, si l’on veut trier le tableau flights selon le retard au départ, dans l’ordre croissant :\n\nflights |&gt; \n  arrange(dep_delay)\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013    12     7     2040           2123       -43       40           2352\n 2  2013     2     3     2022           2055       -33     2240           2338\n 3  2013    11    10     1408           1440       -32     1549           1559\n 4  2013     1    11     1900           1930       -30     2233           2243\n 5  2013     1    29     1703           1730       -27     1947           1957\n 6  2013     8     9      729            755       -26     1002            955\n 7  2013    10    23     1907           1932       -25     2143           2143\n 8  2013     3    30     2030           2055       -25     2213           2250\n 9  2013     3     2     1431           1455       -24     1601           1631\n10  2013     5     5      934            958       -24     1225           1309\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nOn peut trier selon plusieurs colonnes. Par exemple selon le mois, puis selon le retard au départ :\n\nflights |&gt; \n  arrange(month, dep_delay)\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1    11     1900           1930       -30     2233           2243\n 2  2013     1    29     1703           1730       -27     1947           1957\n 3  2013     1    12     1354           1416       -22     1606           1650\n 4  2013     1    21     2137           2159       -22     2232           2316\n 5  2013     1    20      704            725       -21     1025           1035\n 6  2013     1    12     2050           2110       -20     2310           2355\n 7  2013     1    12     2134           2154       -20        4             50\n 8  2013     1    14     2050           2110       -20     2329           2355\n 9  2013     1     4     2140           2159       -19     2241           2316\n10  2013     1    11     1947           2005       -18     2209           2230\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nSi l’on veut trier selon une colonne par ordre décroissant, on lui applique la fonction dplyr::desc() :\n\nflights |&gt; \n  arrange(desc(dep_delay))\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     9      641            900      1301     1242           1530\n 2  2013     6    15     1432           1935      1137     1607           2120\n 3  2013     1    10     1121           1635      1126     1239           1810\n 4  2013     9    20     1139           1845      1014     1457           2210\n 5  2013     7    22      845           1600      1005     1044           1815\n 6  2013     4    10     1100           1900       960     1342           2211\n 7  2013     3    17     2321            810       911      135           1020\n 8  2013     6    27      959           1900       899     1236           2226\n 9  2013     7    22     2257            759       898      121           1026\n10  2013    12     5      756           1700       896     1058           2020\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nCombiné avec dplyr::slice(), dplyr::arrange() permet par exemple de sélectionner les trois vols ayant eu le plus de retard :\n\nflights |&gt; \n  arrange(desc(dep_delay)) |&gt; \n  slice(1:3)\n\n# A tibble: 3 × 19\n   year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n1  2013     1     9      641            900      1301     1242           1530\n2  2013     6    15     1432           1935      1137     1607           2120\n3  2013     1    10     1121           1635      1126     1239           1810\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\n8.1.4 slice_sample()\ndplyr::slice_sample() permet de sélectionner aléatoirement un nombre de lignes ou une fraction des lignes d’un tableau. Ainsi si l’on veut choisir 5 lignes au hasard dans le tableau airports :\n\nairports |&gt; \n  slice_sample(n = 5)\n\n# A tibble: 5 × 8\n  faa   name                       lat    lon   alt    tz dst   tzone           \n  &lt;chr&gt; &lt;chr&gt;                    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;           \n1 ECG   Elizabeth City Cgas Rgnl  36.3  -76.2    12    -5 A     America/New_York\n2 MQB   Macomb Municipal Airport  40.5  -90.7   707    -6 U     America/Chicago \n3 GSO   Piedmont Triad            36.1  -79.9   925    -5 A     America/New_York\n4 BFI   Boeing Fld King Co Intl   47.5 -122.     21    -8 A     America/Los_Ang…\n5 LIH   Lihue                     22.0 -159.    153   -10 N     Pacific/Honolulu\n\n\nSi l’on veut tirer au hasard 10% des lignes de flights :\n\nflights |&gt; \n  slice_sample(prop = .1)\n\n# A tibble: 33,677 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013    12     9     2233           2100        93     2326           2206\n 2  2013     5    10      752            755        -3     1035           1045\n 3  2013     4     2     1022           1015         7     1211           1205\n 4  2013     4     2      955           1000        -5     1052           1112\n 5  2013     6    26     1404           1359         5     1632           1632\n 6  2013     2    20     2140           2130        10     2258           2255\n 7  2013     6    24     1114           1115        -1     1351           1400\n 8  2013     2    25     1122           1130        -8     1426           1446\n 9  2013     7    18     2202           2142        20     2326           2259\n10  2013    12     2     1822           1800        22     2105           2037\n# ℹ 33,667 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nCes fonctions sont utiles notamment pour faire de l’“échantillonnage” en tirant au hasard un certain nombre d’observations du tableau.\n\n8.1.5 distinct()\ndplyr::distinct() filtre les lignes du tableau pour ne conserver que les lignes distinctes, en supprimant toutes les lignes en double.\n\nflights |&gt;\n  select(day, month) |&gt;\n  distinct()\n\n# A tibble: 365 × 2\n     day month\n   &lt;int&gt; &lt;int&gt;\n 1     1     1\n 2     2     1\n 3     3     1\n 4     4     1\n 5     5     1\n 6     6     1\n 7     7     1\n 8     8     1\n 9     9     1\n10    10     1\n# ℹ 355 more rows\n\n\nOn peut lui spécifier une liste de variables : dans ce cas, pour toutes les observations ayant des valeurs identiques pour les variables en question, dplyr::distinct() ne conservera que la première d’entre elles.\n\nflights |&gt;\n  distinct(month, day)\n\n# A tibble: 365 × 2\n   month   day\n   &lt;int&gt; &lt;int&gt;\n 1     1     1\n 2     1     2\n 3     1     3\n 4     1     4\n 5     1     5\n 6     1     6\n 7     1     7\n 8     1     8\n 9     1     9\n10     1    10\n# ℹ 355 more rows\n\n\nL’option .keep_all permet, dans l’opération précédente, de conserver l’ensemble des colonnes du tableau :\n\nflights |&gt;\n  distinct(month, day, .keep_all = TRUE) \n\n# A tibble: 365 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     2       42           2359        43      518            442\n 3  2013     1     3       32           2359        33      504            442\n 4  2013     1     4       25           2359        26      505            442\n 5  2013     1     5       14           2359        15      503            445\n 6  2013     1     6       16           2359        17      451            442\n 7  2013     1     7       49           2359        50      531            444\n 8  2013     1     8      454            500        -6      625            648\n 9  2013     1     9        2           2359         3      432            444\n10  2013     1    10        3           2359         4      426            437\n# ℹ 355 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>`dplyr`</span>"
    ]
  },
  {
    "objectID": "manipulation/dplyr.html#opérations-sur-les-colonnes",
    "href": "manipulation/dplyr.html#opérations-sur-les-colonnes",
    "title": "8  dplyr",
    "section": "\n8.2 Opérations sur les colonnes",
    "text": "8.2 Opérations sur les colonnes\n\n8.2.1 select()\ndplyr::select() permet de sélectionner des colonnes d’un tableau de données. Ainsi, si l’on veut extraire les colonnes lat et lon du tableau airports :\n\nairports |&gt; \n  select(lat, lon)\n\n# A tibble: 1,458 × 2\n     lat    lon\n   &lt;dbl&gt;  &lt;dbl&gt;\n 1  41.1  -80.6\n 2  32.5  -85.7\n 3  42.0  -88.1\n 4  41.4  -74.4\n 5  31.1  -81.4\n 6  36.4  -82.2\n 7  41.5  -84.5\n 8  42.9  -76.8\n 9  39.8  -76.6\n10  48.1 -123. \n# ℹ 1,448 more rows\n\n\nSi on fait précéder le nom d’un -, la colonne est éliminée plutôt que sélectionnée :\n\nairports |&gt; \n  select(-lat, -lon)\n\n# A tibble: 1,458 × 6\n   faa   name                             alt    tz dst   tzone              \n   &lt;chr&gt; &lt;chr&gt;                          &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;              \n 1 04G   Lansdowne Airport               1044    -5 A     America/New_York   \n 2 06A   Moton Field Municipal Airport    264    -6 A     America/Chicago    \n 3 06C   Schaumburg Regional              801    -6 A     America/Chicago    \n 4 06N   Randall Airport                  523    -5 A     America/New_York   \n 5 09J   Jekyll Island Airport             11    -5 A     America/New_York   \n 6 0A9   Elizabethton Municipal Airport  1593    -5 A     America/New_York   \n 7 0G6   Williams County Airport          730    -5 A     America/New_York   \n 8 0G7   Finger Lakes Regional Airport    492    -5 A     America/New_York   \n 9 0P2   Shoestring Aviation Airfield    1000    -5 U     America/New_York   \n10 0S9   Jefferson County Intl            108    -8 A     America/Los_Angeles\n# ℹ 1,448 more rows\n\n\ndplyr::select() comprend toute une série de fonctions facilitant la sélection de multiples colonnes. Par exemple, dplyr::starts_with(), dplyr::ends_width(), dplyr::contains() ou dplyr::matches() permettent d’exprimer des conditions sur les noms de variables :\n\nflights |&gt; \n  select(starts_with(\"dep_\"))\n\n# A tibble: 336,776 × 2\n   dep_time dep_delay\n      &lt;int&gt;     &lt;dbl&gt;\n 1      517         2\n 2      533         4\n 3      542         2\n 4      544        -1\n 5      554        -6\n 6      554        -4\n 7      555        -5\n 8      557        -3\n 9      557        -3\n10      558        -2\n# ℹ 336,766 more rows\n\n\nLa syntaxe colonne1:colonne2 permet de sélectionner toutes les colonnes situées entre colonne1 et colonne2 incluses3 :\n3 À noter que cette opération est un peu plus “fragile” que les autres, car si l’ordre des colonnes change elle peut renvoyer un résultat différent.\nflights |&gt; \n  select(year:day)\n\n# A tibble: 336,776 × 3\n    year month   day\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1  2013     1     1\n 2  2013     1     1\n 3  2013     1     1\n 4  2013     1     1\n 5  2013     1     1\n 6  2013     1     1\n 7  2013     1     1\n 8  2013     1     1\n 9  2013     1     1\n10  2013     1     1\n# ℹ 336,766 more rows\n\n\ndplyr::all_of() et dplyr::any_of() permettent de fournir une liste de variables à extraire sous forme de vecteur textuel. Alors que dplyr::all_of() renverra une erreur si une variable n’est pas trouvée dans le tableau de départ, dplyr::any_of() sera moins stricte.\n\nflights |&gt; \n  select(all_of(c(\"year\", \"month\", \"day\")))\n\n# A tibble: 336,776 × 3\n    year month   day\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1  2013     1     1\n 2  2013     1     1\n 3  2013     1     1\n 4  2013     1     1\n 5  2013     1     1\n 6  2013     1     1\n 7  2013     1     1\n 8  2013     1     1\n 9  2013     1     1\n10  2013     1     1\n# ℹ 336,766 more rows\n\n\n\nflights |&gt; \n  select(all_of(c(\"century\", \"year\", \"month\", \"day\")))\n\nError in `select()`:\nℹ In argument: `all_of(c(\"century\", \"year\", \"month\", \"day\"))`.\nCaused by error in `all_of()`:\n! Can't subset elements that don't exist.\n✖ Element `century` doesn't exist.\n\n\nErreur : Can't subset columns that don't exist. \nx Column `century` doesn't exist.\n\nflights |&gt; \n  select(any_of(c(\"century\", \"year\", \"month\", \"day\")))\n\n# A tibble: 336,776 × 3\n    year month   day\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1  2013     1     1\n 2  2013     1     1\n 3  2013     1     1\n 4  2013     1     1\n 5  2013     1     1\n 6  2013     1     1\n 7  2013     1     1\n 8  2013     1     1\n 9  2013     1     1\n10  2013     1     1\n# ℹ 336,766 more rows\n\n\ndplyr::where() permets de sélectionner des variables à partir d’une fonction qui renvoie une valeur logique. Par exemple, pour sélectionner seulement les variables textuelles :\n\nflights |&gt; \n  select(where(is.character))\n\n# A tibble: 336,776 × 4\n   carrier tailnum origin dest \n   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;\n 1 UA      N14228  EWR    IAH  \n 2 UA      N24211  LGA    IAH  \n 3 AA      N619AA  JFK    MIA  \n 4 B6      N804JB  JFK    BQN  \n 5 DL      N668DN  LGA    ATL  \n 6 UA      N39463  EWR    ORD  \n 7 B6      N516JB  EWR    FLL  \n 8 EV      N829AS  LGA    IAD  \n 9 B6      N593JB  JFK    MCO  \n10 AA      N3ALAA  LGA    ORD  \n# ℹ 336,766 more rows\n\n\ndplyr::select() peut être utilisée pour réordonner les colonnes d’une table en utilisant la fonction dplyr::everything(), qui sélectionne l’ensemble des colonnes non encore sélectionnées. Ainsi, si l’on souhaite faire passer la colonne name en première position de la table airports, on peut faire :\n\nairports |&gt; \n  select(name, everything())\n\n# A tibble: 1,458 × 8\n   name                           faa     lat    lon   alt    tz dst   tzone    \n   &lt;chr&gt;                          &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    \n 1 Lansdowne Airport              04G    41.1  -80.6  1044    -5 A     America/…\n 2 Moton Field Municipal Airport  06A    32.5  -85.7   264    -6 A     America/…\n 3 Schaumburg Regional            06C    42.0  -88.1   801    -6 A     America/…\n 4 Randall Airport                06N    41.4  -74.4   523    -5 A     America/…\n 5 Jekyll Island Airport          09J    31.1  -81.4    11    -5 A     America/…\n 6 Elizabethton Municipal Airport 0A9    36.4  -82.2  1593    -5 A     America/…\n 7 Williams County Airport        0G6    41.5  -84.5   730    -5 A     America/…\n 8 Finger Lakes Regional Airport  0G7    42.9  -76.8   492    -5 A     America/…\n 9 Shoestring Aviation Airfield   0P2    39.8  -76.6  1000    -5 U     America/…\n10 Jefferson County Intl          0S9    48.1 -123.    108    -8 A     America/…\n# ℹ 1,448 more rows\n\n\n\n8.2.2 relocate()\nPour réordonner des colonnes, on pourra aussi avoir recours à dplyr::relocate() en indiquant les premières variables. Il n’est pas nécessaire d’ajouter everything() car avec dplyr::relocate() toutes les variables sont conservées.\n\nairports |&gt; \n  relocate(lon, lat, name)\n\n# A tibble: 1,458 × 8\n      lon   lat name                           faa     alt    tz dst   tzone    \n    &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                          &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    \n 1  -80.6  41.1 Lansdowne Airport              04G    1044    -5 A     America/…\n 2  -85.7  32.5 Moton Field Municipal Airport  06A     264    -6 A     America/…\n 3  -88.1  42.0 Schaumburg Regional            06C     801    -6 A     America/…\n 4  -74.4  41.4 Randall Airport                06N     523    -5 A     America/…\n 5  -81.4  31.1 Jekyll Island Airport          09J      11    -5 A     America/…\n 6  -82.2  36.4 Elizabethton Municipal Airport 0A9    1593    -5 A     America/…\n 7  -84.5  41.5 Williams County Airport        0G6     730    -5 A     America/…\n 8  -76.8  42.9 Finger Lakes Regional Airport  0G7     492    -5 A     America/…\n 9  -76.6  39.8 Shoestring Aviation Airfield   0P2    1000    -5 U     America/…\n10 -123.   48.1 Jefferson County Intl          0S9     108    -8 A     America/…\n# ℹ 1,448 more rows\n\n\n\n8.2.3 rename()\nUne variante de dplyr::select() est dplyr::rename()4, qui permet de renommer facilement des colonnes. On l’utilise en lui passant des paramètres de la forme nouveau_nom = ancien_nom. Ainsi, si on veut renommer les colonnes lon et lat de airports en longitude et latitude :\n4 Il est également possible de renommer des colonnes directement avec select(), avec la même syntaxe que pour rename().\nairports |&gt; \n  rename(longitude = lon, latitude = lat)\n\n# A tibble: 1,458 × 8\n   faa   name                         latitude longitude   alt    tz dst   tzone\n   &lt;chr&gt; &lt;chr&gt;                           &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n 1 04G   Lansdowne Airport                41.1     -80.6  1044    -5 A     Amer…\n 2 06A   Moton Field Municipal Airpo…     32.5     -85.7   264    -6 A     Amer…\n 3 06C   Schaumburg Regional              42.0     -88.1   801    -6 A     Amer…\n 4 06N   Randall Airport                  41.4     -74.4   523    -5 A     Amer…\n 5 09J   Jekyll Island Airport            31.1     -81.4    11    -5 A     Amer…\n 6 0A9   Elizabethton Municipal Airp…     36.4     -82.2  1593    -5 A     Amer…\n 7 0G6   Williams County Airport          41.5     -84.5   730    -5 A     Amer…\n 8 0G7   Finger Lakes Regional Airpo…     42.9     -76.8   492    -5 A     Amer…\n 9 0P2   Shoestring Aviation Airfield     39.8     -76.6  1000    -5 U     Amer…\n10 0S9   Jefferson County Intl            48.1    -123.    108    -8 A     Amer…\n# ℹ 1,448 more rows\n\n\nSi les noms de colonnes comportent des espaces ou des caractères spéciaux, on peut les entourer de guillemets (\") ou de quotes inverses (`) :\n\nflights |&gt; \n  rename(\n    \"retard départ\" = dep_delay,\n    \"retard arrivée\" = arr_delay\n  ) |&gt; \n  select(`retard départ`, `retard arrivée`)\n\n# A tibble: 336,776 × 2\n   `retard départ` `retard arrivée`\n             &lt;dbl&gt;            &lt;dbl&gt;\n 1               2               11\n 2               4               20\n 3               2               33\n 4              -1              -18\n 5              -6              -25\n 6              -4               12\n 7              -5               19\n 8              -3              -14\n 9              -3               -8\n10              -2                8\n# ℹ 336,766 more rows\n\n\n\n8.2.4 rename_with()\nLa fonction dplyr::rename_with() permets de renommer plusieurs colonnes d’un coup en transmettant une fonction, par exemple toupper() qui passe tous les caractères en majuscule.\n\nairports |&gt; \n  rename_with(toupper)\n\n# A tibble: 1,458 × 8\n   FAA   NAME                             LAT    LON   ALT    TZ DST   TZONE    \n   &lt;chr&gt; &lt;chr&gt;                          &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    \n 1 04G   Lansdowne Airport               41.1  -80.6  1044    -5 A     America/…\n 2 06A   Moton Field Municipal Airport   32.5  -85.7   264    -6 A     America/…\n 3 06C   Schaumburg Regional             42.0  -88.1   801    -6 A     America/…\n 4 06N   Randall Airport                 41.4  -74.4   523    -5 A     America/…\n 5 09J   Jekyll Island Airport           31.1  -81.4    11    -5 A     America/…\n 6 0A9   Elizabethton Municipal Airport  36.4  -82.2  1593    -5 A     America/…\n 7 0G6   Williams County Airport         41.5  -84.5   730    -5 A     America/…\n 8 0G7   Finger Lakes Regional Airport   42.9  -76.8   492    -5 A     America/…\n 9 0P2   Shoestring Aviation Airfield    39.8  -76.6  1000    -5 U     America/…\n10 0S9   Jefferson County Intl           48.1 -123.    108    -8 A     America/…\n# ℹ 1,448 more rows\n\n\nOn pourra notamment utiliser les fonctions du package snakecase et, en particulier, snakecase::to_snake_case() que je recommande pour nommer de manière consistante les variables5.\n5 Le snake case est une convention typographique en informatique consistant à écrire des ensembles de mots, généralement, en minuscules en les séparant par des tirets bas.\n8.2.5 pull()\nLa fonction dplyr::pull() permet d’accéder au contenu d’une variable. C’est un équivalent aux opérateurs $ ou [[]]. On peut lui passer un nom de variable ou bien sa position.\n\nairports |&gt; \n  pull(alt) |&gt; \n  mean()\n\n[1] 1001.416\n\n\n\n\n\n\n\n\nNote\n\n\n\ndplyr::pull() ressemble à la fonction purrr::chuck() que nous avons déjà abordée (cf. Section 7.4). Cependant, dplyr::pull() ne fonctionne que sur des tableaux de données tandis que purrr::chuck() est plus générique et peut s’appliquer à tous types de listes.\n\n\n\n8.2.6 mutate()\ndplyr::mutate() permet de créer de nouvelles colonnes dans le tableau de données, en général à partir de variables existantes.\nPar exemple, la table airports contient l’altitude de l’aéroport en pieds. Si l’on veut créer une nouvelle variable alt_m avec l’altitude en mètres, on peut faire :\n\nairports &lt;- \n  airports |&gt; \n  mutate(alt_m = alt / 3.2808)\n\nOn peut créer plusieurs nouvelles colonnes en une seule fois, et les expressions successives peuvent prendre en compte les résultats des calculs précédents. L’exemple suivant convertit d’abord la distance en kilomètres dans une variable distance_km, puis utilise cette nouvelle colonne pour calculer la vitesse en km/h.\n\nflights &lt;- \n  flights |&gt; \n  mutate(\n    distance_km = distance / 0.62137,\n    vitesse = distance_km / air_time * 60\n)",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>`dplyr`</span>"
    ]
  },
  {
    "objectID": "manipulation/dplyr.html#opérations-groupées",
    "href": "manipulation/dplyr.html#opérations-groupées",
    "title": "8  dplyr",
    "section": "\n8.3 Opérations groupées",
    "text": "8.3 Opérations groupées\n\n8.3.1 group_by()\nUn élément très important de dplyr est la fonction dplyr::group_by(). Elle permet de définir des groupes de lignes à partir des valeurs d’une ou plusieurs colonnes. Par exemple, on peut grouper les vols selon leur mois :\n\nflights |&gt; \n  group_by(month)\n\n# A tibble: 336,776 × 21\n# Groups:   month [12]\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 13 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, distance_km &lt;dbl&gt;,\n#   vitesse &lt;dbl&gt;\n\n\nPar défaut ceci ne fait rien de visible, à part l’apparition d’une mention Groups dans l’affichage du résultat. Mais à partir du moment où des groupes ont été définis, les verbes comme dplyr::slice() ou dplyr::mutate() vont en tenir compte lors de leurs opérations.\nPar exemple, si on applique dplyr::slice() à un tableau préalablement groupé, il va sélectionner les lignes aux positions indiquées pour chaque groupe. Ainsi la commande suivante affiche le premier vol de chaque mois, selon leur ordre d’apparition dans le tableau :\n\nflights |&gt; \n  group_by(month) |&gt; \n  slice(1)\n\n# A tibble: 12 × 21\n# Groups:   month [12]\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     2     1      456            500        -4      652            648\n 3  2013     3     1        4           2159       125      318             56\n 4  2013     4     1      454            500        -6      636            640\n 5  2013     5     1        9           1655       434      308           2020\n 6  2013     6     1        2           2359         3      341            350\n 7  2013     7     1        1           2029       212      236           2359\n 8  2013     8     1       12           2130       162      257             14\n 9  2013     9     1        9           2359        10      343            340\n10  2013    10     1      447            500       -13      614            648\n11  2013    11     1        5           2359         6      352            345\n12  2013    12     1       13           2359        14      446            445\n# ℹ 13 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, distance_km &lt;dbl&gt;,\n#   vitesse &lt;dbl&gt;\n\n\nIdem pour dplyr::mutate() : les opérations appliquées lors du calcul des valeurs des nouvelles colonnes sont appliquée groupe de lignes par groupe de lignes. Dans l’exemple suivant, on ajoute une nouvelle colonne qui contient le retard moyen du mois correspondant :\n\nflights |&gt; \n  group_by(month) |&gt; \n  mutate(mean_delay_month = mean(dep_delay, na.rm = TRUE))\n\n# A tibble: 336,776 × 22\n# Groups:   month [12]\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 14 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, distance_km &lt;dbl&gt;,\n#   vitesse &lt;dbl&gt;, mean_delay_month &lt;dbl&gt;\n\n\nCeci peut permettre, par exemple, de déterminer si un retard donné est supérieur ou inférieur au retard moyen du mois en cours.\ndplyr::group_by() peut aussi être utile avec dplyr::filter(), par exemple pour sélectionner les vols avec le retard au départ le plus important pour chaque mois :\n\nflights |&gt; \n  group_by(month) |&gt; \n  filter(dep_delay == max(dep_delay, na.rm = TRUE))\n\n# A tibble: 12 × 21\n# Groups:   month [12]\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     9      641            900      1301     1242           1530\n 2  2013    10    14     2042            900       702     2255           1127\n 3  2013    11     3      603           1645       798      829           1913\n 4  2013    12     5      756           1700       896     1058           2020\n 5  2013     2    10     2243            830       853      100           1106\n 6  2013     3    17     2321            810       911      135           1020\n 7  2013     4    10     1100           1900       960     1342           2211\n 8  2013     5     3     1133           2055       878     1250           2215\n 9  2013     6    15     1432           1935      1137     1607           2120\n10  2013     7    22      845           1600      1005     1044           1815\n11  2013     8     8     2334           1454       520      120           1710\n12  2013     9    20     1139           1845      1014     1457           2210\n# ℹ 13 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, distance_km &lt;dbl&gt;,\n#   vitesse &lt;dbl&gt;\n\n\n\nAttention : la clause dplyr::roup_by() marche pour les verbes déjà vus précédemment, sauf pour dplyr::arrange(), qui par défaut trie la table sans tenir compte des groupes. Pour obtenir un tri par groupe, il faut lui ajouter l’argument .by_group = TRUE.\n\nOn peut voir la différence en comparant les deux résultats suivants :\n\nflights |&gt; \n  group_by(month) |&gt; \n  arrange(desc(dep_delay))\n\n# A tibble: 336,776 × 21\n# Groups:   month [12]\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     9      641            900      1301     1242           1530\n 2  2013     6    15     1432           1935      1137     1607           2120\n 3  2013     1    10     1121           1635      1126     1239           1810\n 4  2013     9    20     1139           1845      1014     1457           2210\n 5  2013     7    22      845           1600      1005     1044           1815\n 6  2013     4    10     1100           1900       960     1342           2211\n 7  2013     3    17     2321            810       911      135           1020\n 8  2013     6    27      959           1900       899     1236           2226\n 9  2013     7    22     2257            759       898      121           1026\n10  2013    12     5      756           1700       896     1058           2020\n# ℹ 336,766 more rows\n# ℹ 13 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, distance_km &lt;dbl&gt;,\n#   vitesse &lt;dbl&gt;\n\nflights |&gt; \n  group_by(month) |&gt; \n  arrange(desc(dep_delay), .by_group = TRUE)\n\n# A tibble: 336,776 × 21\n# Groups:   month [12]\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     9      641            900      1301     1242           1530\n 2  2013     1    10     1121           1635      1126     1239           1810\n 3  2013     1     1      848           1835       853     1001           1950\n 4  2013     1    13     1809            810       599     2054           1042\n 5  2013     1    16     1622            800       502     1911           1054\n 6  2013     1    23     1551            753       478     1812           1006\n 7  2013     1    10     1525            900       385     1713           1039\n 8  2013     1     1     2343           1724       379      314           1938\n 9  2013     1     2     2131           1512       379     2340           1741\n10  2013     1     7     2021           1415       366     2332           1724\n# ℹ 336,766 more rows\n# ℹ 13 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, distance_km &lt;dbl&gt;,\n#   vitesse &lt;dbl&gt;\n\n\n\n8.3.2 summarise()\ndplyr::summarise() permet d’agréger les lignes du tableau en effectuant une opération résumée sur une ou plusieurs colonnes. Il s’agit de toutes les fonctions qui prennent en entrée un ensemble de valeurs et renvoie une valeur unique, comme la moyenne (mean()). Par exemple, si l’on souhaite connaître les retards moyens au départ et à l’arrivée pour l’ensemble des vols du tableau flights :\n\nflights |&gt; \n  summarise(\n    retard_dep = mean(dep_delay, na.rm=TRUE),\n    retard_arr = mean(arr_delay, na.rm=TRUE)\n  )\n\n# A tibble: 1 × 2\n  retard_dep retard_arr\n       &lt;dbl&gt;      &lt;dbl&gt;\n1       12.6       6.90\n\n\nCette fonction est en général utilisée avec dplyr::group_by(), puisqu’elle permet du coup d’agréger et de résumer les lignes du tableau groupe par groupe. Si l’on souhaite calculer le délai maximum, le délai minimum et le délai moyen au départ pour chaque mois, on pourra faire :\n\nflights |&gt;\n  group_by(month) |&gt;\n  summarise(\n    max_delay = max(dep_delay, na.rm=TRUE),\n    min_delay = min(dep_delay, na.rm=TRUE),\n    mean_delay = mean(dep_delay, na.rm=TRUE)\n  )\n\n# A tibble: 12 × 4\n   month max_delay min_delay mean_delay\n   &lt;int&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1     1      1301       -30      10.0 \n 2     2       853       -33      10.8 \n 3     3       911       -25      13.2 \n 4     4       960       -21      13.9 \n 5     5       878       -24      13.0 \n 6     6      1137       -21      20.8 \n 7     7      1005       -22      21.7 \n 8     8       520       -26      12.6 \n 9     9      1014       -24       6.72\n10    10       702       -25       6.24\n11    11       798       -32       5.44\n12    12       896       -43      16.6 \n\n\ndplyr::summarise() dispose d’une fonction spéciale dplyr::n(), qui retourne le nombre de lignes du groupe. Ainsi si l’on veut le nombre de vols par destination, on peut utiliser :\n\nflights |&gt;\n  group_by(dest) |&gt;\n  summarise(n = n())\n\n# A tibble: 105 × 2\n   dest      n\n   &lt;chr&gt; &lt;int&gt;\n 1 ABQ     254\n 2 ACK     265\n 3 ALB     439\n 4 ANC       8\n 5 ATL   17215\n 6 AUS    2439\n 7 AVL     275\n 8 BDL     443\n 9 BGR     375\n10 BHM     297\n# ℹ 95 more rows\n\n\ndplyr::n() peut aussi être utilisée avec dplyr::filter() et dplyr::mutate().\n\n8.3.3 count()\nÀ noter que quand l’on veut compter le nombre de lignes par groupe, on peut utiliser directement la fonction dplyr::count(). Ainsi le code suivant est identique au précédent :\n\nflights |&gt;\n  count(dest)\n\n# A tibble: 105 × 2\n   dest      n\n   &lt;chr&gt; &lt;int&gt;\n 1 ABQ     254\n 2 ACK     265\n 3 ALB     439\n 4 ANC       8\n 5 ATL   17215\n 6 AUS    2439\n 7 AVL     275\n 8 BDL     443\n 9 BGR     375\n10 BHM     297\n# ℹ 95 more rows\n\n\n\n8.3.4 Grouper selon plusieurs variables\nOn peut grouper selon plusieurs variables à la fois, il suffit de les indiquer dans la clause du dplyr::group_by() :\n\nflights |&gt;\n  group_by(month, dest) |&gt;\n  summarise(nb = n()) |&gt;\n  arrange(desc(nb))\n\n`summarise()` has grouped output by 'month'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 1,113 × 3\n# Groups:   month [12]\n   month dest     nb\n   &lt;int&gt; &lt;chr&gt; &lt;int&gt;\n 1     8 ORD    1604\n 2    10 ORD    1604\n 3     5 ORD    1582\n 4     9 ORD    1582\n 5     7 ORD    1573\n 6     6 ORD    1547\n 7     7 ATL    1511\n 8     8 ATL    1507\n 9     8 LAX    1505\n10     7 LAX    1500\n# ℹ 1,103 more rows\n\n\nOn peut également compter selon plusieurs variables :\n\nflights |&gt; \n  count(origin, dest) |&gt; \n  arrange(desc(n))\n\n# A tibble: 224 × 3\n   origin dest      n\n   &lt;chr&gt;  &lt;chr&gt; &lt;int&gt;\n 1 JFK    LAX   11262\n 2 LGA    ATL   10263\n 3 LGA    ORD    8857\n 4 JFK    SFO    8204\n 5 LGA    CLT    6168\n 6 EWR    ORD    6100\n 7 JFK    BOS    5898\n 8 LGA    MIA    5781\n 9 JFK    MCO    5464\n10 EWR    BOS    5327\n# ℹ 214 more rows\n\n\nOn peut utiliser plusieurs opérations de groupage dans le même pipeline. Ainsi, si l’on souhaite déterminer le couple origine/destination ayant le plus grand nombre de vols selon le mois de l’année, on devra procéder en deux étapes :\n\nd’abord grouper selon mois, origine et destination pour calculer le nombre de vols\npuis grouper uniquement selon le mois pour sélectionner la ligne avec la valeur maximale.\n\nAu final, on obtient le code suivant :\n\nflights |&gt;\n  group_by(month, origin, dest) |&gt;\n  summarise(nb = n()) |&gt;\n  group_by(month) |&gt;\n  filter(nb == max(nb))\n\n`summarise()` has grouped output by 'month', 'origin'. You can override using\nthe `.groups` argument.\n\n\n# A tibble: 12 × 4\n# Groups:   month [12]\n   month origin dest     nb\n   &lt;int&gt; &lt;chr&gt;  &lt;chr&gt; &lt;int&gt;\n 1     1 JFK    LAX     937\n 2     2 JFK    LAX     834\n 3     3 JFK    LAX     960\n 4     4 JFK    LAX     935\n 5     5 JFK    LAX     960\n 6     6 JFK    LAX     928\n 7     7 JFK    LAX     985\n 8     8 JFK    LAX     979\n 9     9 JFK    LAX     925\n10    10 JFK    LAX     965\n11    11 JFK    LAX     907\n12    12 JFK    LAX     947\n\n\nLorsqu’on effectue un dplyr::group_by() suivi d’un dplyr::summarise(), le tableau résultat est automatiquement dégroupé de la dernière variable de regroupement. Ainsi le tableau généré par le code suivant est groupé par month et origin6 :\n6 Comme expliqué dans le message affiché dans la console, cela peut être contrôlé avec l’argument .groups de dplyr::summarise(), dont les options sont décrites dans l’aide de la fonction.\nflights |&gt;\n  group_by(month, origin, dest) |&gt;\n  summarise(nb = n())\n\n`summarise()` has grouped output by 'month', 'origin'. You can override using\nthe `.groups` argument.\n\n\n# A tibble: 2,313 × 4\n# Groups:   month, origin [36]\n   month origin dest     nb\n   &lt;int&gt; &lt;chr&gt;  &lt;chr&gt; &lt;int&gt;\n 1     1 EWR    ALB      64\n 2     1 EWR    ATL     362\n 3     1 EWR    AUS      51\n 4     1 EWR    AVL       2\n 5     1 EWR    BDL      37\n 6     1 EWR    BNA     111\n 7     1 EWR    BOS     430\n 8     1 EWR    BQN      31\n 9     1 EWR    BTV     100\n10     1 EWR    BUF     119\n# ℹ 2,303 more rows\n\n\nCela peut permettre d’enchaîner les opérations groupées. Dans l’exemple suivant, on calcule le pourcentage des trajets pour chaque destination par rapport à tous les trajets du mois :\n\nflights |&gt;\n  group_by(month, dest) |&gt;\n  summarise(nb = n()) |&gt; \n  mutate(pourcentage = nb / sum(nb) * 100)\n\n`summarise()` has grouped output by 'month'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 1,113 × 4\n# Groups:   month [12]\n   month dest     nb pourcentage\n   &lt;int&gt; &lt;chr&gt; &lt;int&gt;       &lt;dbl&gt;\n 1     1 ALB      64     0.237  \n 2     1 ATL    1396     5.17   \n 3     1 AUS     169     0.626  \n 4     1 AVL       2     0.00741\n 5     1 BDL      37     0.137  \n 6     1 BHM      25     0.0926 \n 7     1 BNA     399     1.48   \n 8     1 BOS    1245     4.61   \n 9     1 BQN      93     0.344  \n10     1 BTV     223     0.826  \n# ℹ 1,103 more rows\n\n\nOn peut à tout moment dégrouper un tableau à l’aide de dplyr::ungroup(). Ce serait par exemple nécessaire, dans l’exemple précédent, si on voulait calculer le pourcentage sur le nombre total de vols plutôt que sur le nombre de vols par mois :\n\nflights |&gt;\n  group_by(month, dest) |&gt;\n  summarise(nb = n()) |&gt; \n  ungroup() |&gt; \n  mutate(pourcentage = nb / sum(nb) * 100)\n\n`summarise()` has grouped output by 'month'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 1,113 × 4\n   month dest     nb pourcentage\n   &lt;int&gt; &lt;chr&gt; &lt;int&gt;       &lt;dbl&gt;\n 1     1 ALB      64    0.0190  \n 2     1 ATL    1396    0.415   \n 3     1 AUS     169    0.0502  \n 4     1 AVL       2    0.000594\n 5     1 BDL      37    0.0110  \n 6     1 BHM      25    0.00742 \n 7     1 BNA     399    0.118   \n 8     1 BOS    1245    0.370   \n 9     1 BQN      93    0.0276  \n10     1 BTV     223    0.0662  \n# ℹ 1,103 more rows\n\n\nÀ noter que dplyr::count(), par contre, renvoi un tableau non groupé :\n\nflights |&gt; \n  count(month, dest)\n\n# A tibble: 1,113 × 3\n   month dest      n\n   &lt;int&gt; &lt;chr&gt; &lt;int&gt;\n 1     1 ALB      64\n 2     1 ATL    1396\n 3     1 AUS     169\n 4     1 AVL       2\n 5     1 BDL      37\n 6     1 BHM      25\n 7     1 BNA     399\n 8     1 BOS    1245\n 9     1 BQN      93\n10     1 BTV     223\n# ℹ 1,103 more rows",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>`dplyr`</span>"
    ]
  },
  {
    "objectID": "manipulation/dplyr.html#cheatsheet",
    "href": "manipulation/dplyr.html#cheatsheet",
    "title": "8  dplyr",
    "section": "\n8.4 Cheatsheet",
    "text": "8.4 Cheatsheet",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>`dplyr`</span>"
    ]
  },
  {
    "objectID": "manipulation/dplyr.html#webin-r",
    "href": "manipulation/dplyr.html#webin-r",
    "title": "8  dplyr",
    "section": "\n8.5 webin-R",
    "text": "8.5 webin-R\nOn pourra également se référer au webin-R #04 (manipuler les données avec dplyr) sur YouTube.",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>`dplyr`</span>"
    ]
  },
  {
    "objectID": "manipulation/facteurs.html",
    "href": "manipulation/facteurs.html",
    "title": "9  Facteurs et forcats",
    "section": "",
    "text": "9.1 Création d’un facteur\nLe plus simple pour créer un facteur est de partir d’un vecteur textuel et d’utiliser la fonction factor().\nx &lt;- c(\"nord\", \"sud\", \"sud\", \"est\", \"est\", \"est\")\nx |&gt; \n  factor()\n\n[1] nord sud  sud  est  est  est \nLevels: est nord sud\nPar défaut, les niveaux du facteur obtenu correspondent aux valeurs uniques du facteur textuel, triés par ordre alphabétique. Si l’on veut contrôler l’ordre des niveaux, et éventuellement indiquer un niveau absent des données, on utilisera l’argument levels de factor().\nx |&gt; \n  factor(levels = c(\"nord\", \"est\", \"sud\", \"ouest\"))\n\n[1] nord sud  sud  est  est  est \nLevels: nord est sud ouest\nSi une valeur observée dans les données n’est pas indiqué dans levels, elle sera silencieusement convertie en valeur manquante (NA).\nx |&gt; \n  factor(levels = c(\"nord\", \"sud\"))\n\n[1] nord sud  sud  &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;\nLevels: nord sud\nSi l’on veut être averti par un warning dans ce genre de situation, on pourra avoir plutôt recours à la fonction readr::parse_factor() du package readr, qui, le cas échéant, renverra un tableau avec les problèmes rencontrés.\nx |&gt; \n  readr::parse_factor(levels = c(\"nord\", \"sud\"))\n\nWarning: 3 parsing failures.\nrow col           expected actual\n  4  -- value in level set    est\n  5  -- value in level set    est\n  6  -- value in level set    est\n\n\n[1] nord sud  sud  &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;\nattr(,\"problems\")\n# A tibble: 3 × 4\n    row   col expected           actual\n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;              &lt;chr&gt; \n1     4    NA value in level set est   \n2     5    NA value in level set est   \n3     6    NA value in level set est   \nLevels: nord sud\nUne fois un facteur créé, on peut accéder à la liste de ses étiquettes avec levels().\nf &lt;- factor(x)\nlevels(f)\n\n[1] \"est\"  \"nord\" \"sud\"\nDans certaines situations (par exemple pour la réalisation d’une régression logistique ordinale), on peut avoir avoir besoin d’indiquer que les modalités du facteur sont ordonnées hiérarchiquement. Dans ce cas là, on aura simplement recours à ordered() pour créer/convertir notre facteur.\nc(\"supérieur\", \"primaire\", \"secondaire\", \"primaire\", \"supérieur\") |&gt; \n  ordered(levels = c(\"primaire\", \"secondaire\", \"supérieur\"))\n\n[1] supérieur  primaire   secondaire primaire   supérieur \nLevels: primaire &lt; secondaire &lt; supérieur\nTechniquement, les valeurs d’un facteur sont stockés de manière interne à l’aide de nombres entiers, dont la valeur représente la position de l’étiquette correspondante dans l’attribut levels. Ainsi, un facteur à n modalités sera toujours codé avec les nombre entiers allant de 1 à n.\nclass(f)\n\n[1] \"factor\"\n\ntypeof(f)\n\n[1] \"integer\"\n\nas.integer(f)\n\n[1] 2 3 3 1 1 1\n\nas.character(f)\n\n[1] \"nord\" \"sud\"  \"sud\"  \"est\"  \"est\"  \"est\"",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Facteurs et `forcats`</span>"
    ]
  },
  {
    "objectID": "manipulation/facteurs.html#changer-lordre-des-modalités",
    "href": "manipulation/facteurs.html#changer-lordre-des-modalités",
    "title": "9  Facteurs et forcats",
    "section": "\n9.2 Changer l’ordre des modalités",
    "text": "9.2 Changer l’ordre des modalités\nLe package forcats, chargé par défaut lorsque l’on exécute la commande library(tidyverse), fournie plusieurs fonctions pour manipuler des facteurs. Pour donner des exemples d’utilisation de ces différentes fonctions, nous allons utiliser le jeu de données hdv2003 du package questionr.\n\n\n\n\nlibrary(tidyverse)\ndata(\"hdv2003\", package = \"questionr\")\n\nConsidérons la variable qualif qui indique le niveau de qualification des enquêtés. On peut voir la liste des niveaux de ce facteur, et leur ordre, avec levels(), ou en effectuant un tri à plat avec la fonction questionr::freq().\n\nhdv2003$qualif |&gt; \n  levels()\n\n[1] \"Ouvrier specialise\"       \"Ouvrier qualifie\"        \n[3] \"Technicien\"               \"Profession intermediaire\"\n[5] \"Cadre\"                    \"Employe\"                 \n[7] \"Autre\"                   \n\nhdv2003$qualif |&gt; \n  questionr::freq()\n\n                           n    % val%\nOuvrier specialise       203 10.2 12.3\nOuvrier qualifie         292 14.6 17.7\nTechnicien                86  4.3  5.2\nProfession intermediaire 160  8.0  9.7\nCadre                    260 13.0 15.7\nEmploye                  594 29.7 35.9\nAutre                     58  2.9  3.5\nNA                       347 17.3   NA\n\n\nParfois, on a simplement besoin d’inverser l’ordre des facteurs, ce qui peut se faire facilement avec la fonction forcats::fct_rev(). Elle renvoie le facteur fourni en entrée en ayant inverser l’ordre des modalités (mais sans modifier l’ordre des valeurs dans le vecteur).\n\nhdv2003$qualif |&gt; \n  fct_rev() |&gt; \n  questionr::freq()\n\n                           n    % val%\nAutre                     58  2.9  3.5\nEmploye                  594 29.7 35.9\nCadre                    260 13.0 15.7\nProfession intermediaire 160  8.0  9.7\nTechnicien                86  4.3  5.2\nOuvrier qualifie         292 14.6 17.7\nOuvrier specialise       203 10.2 12.3\nNA                       347 17.3   NA\n\n\nPour plus de contrôle, on utilisera forcats::fct_relevel() où l’on indique l’ordre souhaité des modalités. On peut également seulement indiquer les premières modalités, les autres seront ajoutées à la fin sans changer leur ordre.\n\nhdv2003$qualif |&gt; \n  fct_relevel(\"Cadre\", \"Autre\", \"Technicien\", \"Employe\") |&gt; \n  questionr::freq()\n\n                           n    % val%\nCadre                    260 13.0 15.7\nAutre                     58  2.9  3.5\nTechnicien                86  4.3  5.2\nEmploye                  594 29.7 35.9\nOuvrier specialise       203 10.2 12.3\nOuvrier qualifie         292 14.6 17.7\nProfession intermediaire 160  8.0  9.7\nNA                       347 17.3   NA\n\n\nLa fonction forcats::fct_infreq() ordonne les modalités de celle la plus fréquente à celle la moins fréquente (nombre d’observations) :\n\nhdv2003$qualif |&gt; \n  fct_infreq() |&gt; \n  questionr::freq()\n\n                           n    % val%\nEmploye                  594 29.7 35.9\nOuvrier qualifie         292 14.6 17.7\nCadre                    260 13.0 15.7\nOuvrier specialise       203 10.2 12.3\nProfession intermediaire 160  8.0  9.7\nTechnicien                86  4.3  5.2\nAutre                     58  2.9  3.5\nNA                       347 17.3   NA\n\n\nPour inverser l’ordre, on combinera forcats::fct_infreq() avec forcats::fct_rev().\n\nhdv2003$qualif |&gt; \n  fct_infreq() |&gt; \n  fct_rev() |&gt; \n  questionr::freq()\n\n                           n    % val%\nAutre                     58  2.9  3.5\nTechnicien                86  4.3  5.2\nProfession intermediaire 160  8.0  9.7\nOuvrier specialise       203 10.2 12.3\nCadre                    260 13.0 15.7\nOuvrier qualifie         292 14.6 17.7\nEmploye                  594 29.7 35.9\nNA                       347 17.3   NA\n\n\nDans certains cas, on souhaite créer un facteur dont les modalités sont triées selon leur ordre d'apparition dans le jeu de données. Pour cela, on aura recours à forcats::fct_inorder().\n\nv &lt;- c(\"c\", \"a\", \"d\", \"b\", \"a\", \"c\")\nfactor(v)\n\n[1] c a d b a c\nLevels: a b c d\n\nfct_inorder(v)\n\n[1] c a d b a c\nLevels: c a d b\n\n\nLa fonction forcats::fct_reorder() permets de trier les modalités en fonction d’une autre variable. Par exemple, si je souhaite trier les modalités de la variable qualif en fonction de l’âge moyen (dans chaque modalité) :\n\nhdv2003$qualif_tri_age &lt;-\n  hdv2003$qualif |&gt; \n  fct_reorder(hdv2003$age, .fun = mean)\nhdv2003 |&gt; \n  dplyr::group_by(qualif_tri_age) |&gt; \n  dplyr::summarise(age_moyen = mean(age))\n\n# A tibble: 8 × 2\n  qualif_tri_age           age_moyen\n  &lt;fct&gt;                        &lt;dbl&gt;\n1 Technicien                    45.9\n2 Employe                       46.7\n3 Autre                         47.0\n4 Ouvrier specialise            48.9\n5 Profession intermediaire      49.1\n6 Cadre                         49.7\n7 Ouvrier qualifie              50.0\n8 &lt;NA&gt;                          47.9\n\n\n\n\n\n\n\n\nAstuce\n\n\n\nquestionr propose une interface graphique afin de faciliter les opérations de ré-ordonnancement manuel. Pour la lancer, sélectionner le menu Addins puis Levels ordering, ou exécuter la fonction questionr::iorder() en lui passant comme paramètre le facteur à réordonner.\n\nUne démonstration en vidéo de cet add-in est disponible dans le webin-R #05 (recoder des variables) sur [YouTube](https://youtu.be/CokvTbtWdwc?t=3934).",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Facteurs et `forcats`</span>"
    ]
  },
  {
    "objectID": "manipulation/facteurs.html#sec-modifier-modalites",
    "href": "manipulation/facteurs.html#sec-modifier-modalites",
    "title": "9  Facteurs et forcats",
    "section": "\n9.3 Modifier les modalités",
    "text": "9.3 Modifier les modalités\nPour modifier le nom des modalités, on pourra avoir recours à forcats::fct_recode() avec une syntaxe de la forme \"nouveau nom\" = \"ancien nom\".\n\nhdv2003$sexe |&gt; \n  questionr::freq()\n\n         n  % val%\nHomme  899 45   45\nFemme 1101 55   55\n\nhdv2003$sexe &lt;- \n  hdv2003$sexe |&gt; \n  fct_recode(f = \"Femme\", m = \"Homme\")\nhdv2003$sexe |&gt; \n  questionr::freq()\n\n     n  % val%\nm  899 45   45\nf 1101 55   55\n\n\nOn peut également fusionner des modalités ensemble en leur attribuant le même nom.\n\nhdv2003$nivetud |&gt; \n  questionr::freq()\n\n                                                                  n    % val%\nN'a jamais fait d'etudes                                         39  2.0  2.1\nA arrete ses etudes, avant la derniere annee d'etudes primaires  86  4.3  4.6\nDerniere annee d'etudes primaires                               341 17.0 18.1\n1er cycle                                                       204 10.2 10.8\n2eme cycle                                                      183  9.2  9.7\nEnseignement technique ou professionnel court                   463 23.2 24.5\nEnseignement technique ou professionnel long                    131  6.6  6.9\nEnseignement superieur y compris technique superieur            441 22.0 23.4\nNA                                                              112  5.6   NA\n\nhdv2003$instruction &lt;- \n  hdv2003$nivetud |&gt; \n  fct_recode(\n    \"primaire\" = \"N'a jamais fait d'etudes\",\n    \"primaire\" = \"A arrete ses etudes, avant la derniere annee d'etudes primaires\",\n    \"primaire\" = \"Derniere annee d'etudes primaires\",\n    \"secondaire\" = \"1er cycle\",\n    \"secondaire\" = \"2eme cycle\",\n    \"technique/professionnel\" = \"Enseignement technique ou professionnel court\",\n    \"technique/professionnel\" = \"Enseignement technique ou professionnel long\",\n    \"supérieur\" = \"Enseignement superieur y compris technique superieur\"\n  )\nhdv2003$instruction |&gt; \n  questionr::freq()\n\n                          n    % val%\nprimaire                466 23.3 24.7\nsecondaire              387 19.4 20.5\ntechnique/professionnel 594 29.7 31.5\nsupérieur               441 22.0 23.4\nNA                      112  5.6   NA\n\n\n\n\n\n\n\n\nInterface graphique\n\n\n\nLe packagequestionr propose une interface graphique facilitant le recodage des modalités d’une variable qualitative. L’objectif est de permettre à la personne qui l’utilise de saisir les nouvelles valeurs dans un formulaire, et de générer ensuite le code R correspondant au recodage indiqué.\nPour utiliser cette interface, sous RStudio vous pouvez aller dans le menu Addins (présent dans la barre d’outils principale) puis choisir Levels recoding. Sinon, vous pouvez lancer dans la console la fonction questionr::irec() en lui passant comme paramètre la variable à recoder.\n\n\n\n\n\n\n\nAstuce\n\n\n\nUne démonstration en vidéo de cet add-in est disponible dans le webin-R #05 (recoder des variables) sur [YouTube](https://youtu.be/CokvTbtWdwc?t=3387).\n\n\n\n\n\nLa fonction forcats::fct_collapse() est une variante de forcats::fct_recode() pour indiquer les fusions de modalités. La même recodification s’écrirait alors :\n\nhdv2003$instruction &lt;- \n  hdv2003$nivetud |&gt; \n  fct_collapse(\n    \"primaire\" = c(\n      \"N'a jamais fait d'etudes\",\n      \"A arrete ses etudes, avant la derniere annee d'etudes primaires\",\n      \"Derniere annee d'etudes primaires\"\n    ),\n    \"secondaire\" = c(\n      \"1er cycle\",\n      \"2eme cycle\"\n    ),\n    \"technique/professionnel\" = c(\n      \"Enseignement technique ou professionnel court\",\n      \"Enseignement technique ou professionnel long\"\n    ),\n    \"supérieur\" = \"Enseignement superieur y compris technique superieur\"\n  )\n\nPour transformer les valeurs manquantes (NA) en une modalité explicite, on pourra avoir recours à forcats::fct_na_value_to_level()1.\n1 Cette fonction s’appelait précédemment forcats::fct_explicit_na() et a été renommée depuis la version 1.0.0 de {forcats}.\nhdv2003$instruction &lt;-\n  hdv2003$instruction |&gt; \n  fct_na_value_to_level(level = \"(manquant)\")\nhdv2003$instruction |&gt; \n  questionr::freq()\n\n                          n    % val%\nprimaire                466 23.3 23.3\nsecondaire              387 19.4 19.4\ntechnique/professionnel 594 29.7 29.7\nsupérieur               441 22.0 22.0\n(manquant)              112  5.6  5.6\n\n\nPlusieurs fonctions permettent de regrouper plusieurs modalités dans une modalité autres.\nPar exemple, avec forcats::fct_other(), on pourra indiquer les modalités à garder.\n\nhdv2003$qualif |&gt; \n  questionr::freq()\n\n                           n    % val%\nOuvrier specialise       203 10.2 12.3\nOuvrier qualifie         292 14.6 17.7\nTechnicien                86  4.3  5.2\nProfession intermediaire 160  8.0  9.7\nCadre                    260 13.0 15.7\nEmploye                  594 29.7 35.9\nAutre                     58  2.9  3.5\nNA                       347 17.3   NA\n\nhdv2003$qualif |&gt; \n  fct_other(keep = c(\"Technicien\", \"Cadre\", \"Employe\")) |&gt; \n  questionr::freq()\n\n             n    % val%\nTechnicien  86  4.3  5.2\nCadre      260 13.0 15.7\nEmploye    594 29.7 35.9\nOther      713 35.6 43.1\nNA         347 17.3   NA\n\n\nLa fonction forcats::fct_lump_n() permets de ne conserver que les modalités les plus fréquentes et de regrouper les autres dans une modalité autres.\n\nhdv2003$qualif |&gt; \n  fct_lump_n(n = 4, other_level = \"Autres\") |&gt; \n  questionr::freq()\n\n                     n    % val%\nOuvrier specialise 203 10.2 12.3\nOuvrier qualifie   292 14.6 17.7\nCadre              260 13.0 15.7\nEmploye            594 29.7 35.9\nAutres             304 15.2 18.4\nNA                 347 17.3   NA\n\n\nEt forcats::fct_lump_min() celles qui ont un minimum d’observations.\n\nhdv2003$qualif |&gt; \n  fct_lump_min(min = 200, other_level = \"Autres\") |&gt; \n  questionr::freq()\n\n                     n    % val%\nOuvrier specialise 203 10.2 12.3\nOuvrier qualifie   292 14.6 17.7\nCadre              260 13.0 15.7\nEmploye            594 29.7 35.9\nAutres             304 15.2 18.4\nNA                 347 17.3   NA\n\n\nIl peut arriver qu’une des modalités d’un facteur ne soit pas représentée dans les données.\n\nv &lt;- factor(\n  c(\"a\", \"a\", \"b\", \"a\"),\n  levels = c(\"a\", \"b\", \"c\")\n)\nquestionr::freq(v)\n\n  n  % val%\na 3 75   75\nb 1 25   25\nc 0  0    0\n\n\nPour calculer certains tests statistiques ou faire tourner un modèle, ces modalités sans observation peuvent être problématiques. forcats::fct_drop() permet de supprimer les modalités qui n’apparaissent pas dans les données.\n\nv\n\n[1] a a b a\nLevels: a b c\n\nv |&gt; fct_drop()\n\n[1] a a b a\nLevels: a b\n\n\nÀ l’inverse, forcats::fct_expand() permet d’ajouter une ou plusieurs modalités à un facteur.\n\nv\n\n[1] a a b a\nLevels: a b c\n\nv |&gt; fct_expand(\"d\", \"e\")\n\n[1] a a b a\nLevels: a b c d e",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Facteurs et `forcats`</span>"
    ]
  },
  {
    "objectID": "manipulation/facteurs.html#sec-cut",
    "href": "manipulation/facteurs.html#sec-cut",
    "title": "9  Facteurs et forcats",
    "section": "\n9.4 Découper une variable numérique en classes",
    "text": "9.4 Découper une variable numérique en classes\nIl est fréquent d’avoir besoin de découper une variable numérique en une variable catégorielles (un facteur) à plusieurs modalités, par exemple pour créer des groupes d’âges à partir d’une variable age.\nOn utilise pour cela la fonction cut() qui prend, outre la variable à découper, un certain nombre d’arguments :\n\n\nbreaks indique soit le nombre de classes souhaité, soit, si on lui fournit un vecteur, les limites des classes ;\n\nlabels permet de modifier les noms de modalités attribués aux classes ;\n\ninclude.lowest et right influent sur la manière dont les valeurs situées à la frontière des classes seront inclues ou exclues ;\n\ndig.lab indique le nombre de chiffres après la virgule à conserver dans les noms de modalités.\n\nPrenons tout de suite un exemple et tentons de découper la variable age en cinq classes :\n\nhdv2003 &lt;-\n  hdv2003 |&gt; \n  mutate(groupe_ages = cut(age, 5))\nhdv2003$groupe_ages |&gt; questionr::freq()\n\n              n    % val%\n(17.9,33.8] 454 22.7 22.7\n(33.8,49.6] 628 31.4 31.4\n(49.6,65.4] 556 27.8 27.8\n(65.4,81.2] 319 16.0 16.0\n(81.2,97.1]  43  2.1  2.1\n\n\nPar défaut R nous a bien créé cinq classes d’amplitudes égales. La première classe va de 17,9 à 33,8 ans (en fait de 17 à 32), etc.\nLes frontières de classe seraient plus présentables si elles utilisaient des nombres ronds. On va donc spécifier manuellement le découpage souhaité, par tranches de 20 ans :\n\nhdv2003 &lt;-\n  hdv2003 |&gt; \n  mutate(groupe_ages = cut(age, c(18, 20, 40, 60, 80, 97)))\nhdv2003$groupe_ages |&gt; questionr::freq()\n\n          n    % val%\n(18,20]  55  2.8  2.8\n(20,40] 660 33.0 33.3\n(40,60] 780 39.0 39.3\n(60,80] 436 21.8 22.0\n(80,97]  52  2.6  2.6\nNA       17  0.9   NA\n\n\nLes symboles dans les noms attribués aux classes ont leur importance : ( signifie que la frontière de la classe est exclue, tandis que [ signifie qu’elle est incluse. Ainsi, (20,40] signifie « strictement supérieur à 20 et inférieur ou égal à 40 ».\nOn remarque que du coup, dans notre exemple précédent, la valeur minimale, 18, est exclue de notre première classe, et qu’une observation est donc absente de ce découpage. Pour résoudre ce problème on peut soit faire commencer la première classe à 17, soit utiliser l’option include.lowest=TRUE :\n\nhdv2003 &lt;-\n  hdv2003 |&gt; \n  mutate(groupe_ages = cut(\n    age, \n    c(18, 20, 40, 60, 80, 97),\n    include.lowest = TRUE\n  ))\nhdv2003$groupe_ages |&gt; questionr::freq()\n\n          n    % val%\n[18,20]  72  3.6  3.6\n(20,40] 660 33.0 33.0\n(40,60] 780 39.0 39.0\n(60,80] 436 21.8 21.8\n(80,97]  52  2.6  2.6\n\n\nOn peut également modifier le sens des intervalles avec l’option right=FALSE :\n\nhdv2003 &lt;-\n  hdv2003 |&gt; \n  mutate(groupe_ages = cut(\n    age, \n    c(18, 20, 40, 60, 80, 97),\n    include.lowest = TRUE,\n    right = FALSE\n  ))\nhdv2003$groupe_ages |&gt; questionr::freq()\n\n          n    % val%\n[18,20)  48  2.4  2.4\n[20,40) 643 32.1 32.1\n[40,60) 793 39.6 39.6\n[60,80) 454 22.7 22.7\n[80,97]  62  3.1  3.1\n\n\n\n\n\n\n\n\nInterface graphique\n\n\n\nIl n’est pas nécessaire de connaître toutes les options de cut(). Le package questionr propose là encore une interface graphique permettant de visualiser l’effet des différents paramètres et de générer le code R correspondant.\nPour utiliser cette interface, sous RStudio vous pouvez aller dans le menu Addins (présent dans la barre d’outils principale) puis choisir Numeric range dividing. Sinon, vous pouvez lancer dans la console la fonction questionr::icut() en lui passant comme paramètre la variable numérique à découper.\n Une démonstration en vidéo de cet add-in est disponible dans le webin-R #05 (recoder des variables) sur [YouTube](https://youtu.be/CokvTbtWdwc?t=2795).",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Facteurs et `forcats`</span>"
    ]
  },
  {
    "objectID": "manipulation/combiner-variables.html",
    "href": "manipulation/combiner-variables.html",
    "title": "10  Combiner plusieurs variables",
    "section": "",
    "text": "10.1 if_else()\ndplyr::if_else() prend trois arguments : un test, les valeurs à renvoyer si le test est vrai, et les valeurs à renvoyer si le test est faux.\nVoici un exemple simple :\nv &lt;- c(12, 14, 8, 16)\nif_else(v &gt; 10, \"Supérieur à 10\", \"Inférieur à 10\")\n\n[1] \"Supérieur à 10\" \"Supérieur à 10\" \"Inférieur à 10\" \"Supérieur à 10\"\nLa fonction devient plus intéressante avec des tests combinant plusieurs variables. Par exemple, imaginons qu’on souhaite créer une nouvelle variable indiquant les hommes de plus de 60 ans :\nhdv2003 &lt;- \n  hdv2003 |&gt; \n  mutate(\n    statut = if_else(\n      sexe == \"Homme\" & age &gt; 60,\n      \"Homme de plus de 60 ans\",\n      \"Autre\"\n    )\n  )\nhdv2003 |&gt; \n  pull(statut) |&gt; \n  questionr::freq()\n\n                           n    % val%\nAutre                   1778 88.9 88.9\nHomme de plus de 60 ans  222 11.1 11.1\nIl est possible d’utiliser des variables ou des combinaisons de variables au sein du dplyr::if_else(). Supposons une petite enquête menée auprès de femmes et d’hommes. Le questionnaire comportait une question de préférence posée différemment aux femmes et aux hommes et dont les réponses ont ainsi été collectées dans deux variables différentes, pref_f et pref_h, que l’on souhaite combiner en une seule variable. De même, une certaine mesure quantitative a été réalisée, mais une correction est nécessaire pour normaliser ce score (retirer 0.4 aux scores des hommes et 0.6 aux scores des femmes). Cela peut être réalisé avec le code ci-dessous.\ndf &lt;- tibble(\n  sexe = c(\"f\", \"f\", \"h\", \"h\"),\n  pref_f = c(\"a\", \"b\", NA, NA),\n  pref_h = c(NA, NA, \"c\", \"d\"),\n  mesure = c(1.2, 4.1, 3.8, 2.7)\n)\ndf\n\n# A tibble: 4 × 4\n  sexe  pref_f pref_h mesure\n  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;dbl&gt;\n1 f     a      &lt;NA&gt;      1.2\n2 f     b      &lt;NA&gt;      4.1\n3 h     &lt;NA&gt;   c         3.8\n4 h     &lt;NA&gt;   d         2.7\n\ndf &lt;- \n  df |&gt; \n  mutate(\n    pref = if_else(sexe == \"f\", pref_f, pref_h),\n    indicateur = if_else(sexe == \"h\", mesure - 0.4, mesure - 0.6)\n  )\ndf\n\n# A tibble: 4 × 6\n  sexe  pref_f pref_h mesure pref  indicateur\n  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n1 f     a      &lt;NA&gt;      1.2 a            0.6\n2 f     b      &lt;NA&gt;      4.1 b            3.5\n3 h     &lt;NA&gt;   c         3.8 c            3.4\n4 h     &lt;NA&gt;   d         2.7 d            2.3",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Combiner plusieurs variables</span>"
    ]
  },
  {
    "objectID": "manipulation/combiner-variables.html#if_else",
    "href": "manipulation/combiner-variables.html#if_else",
    "title": "10  Combiner plusieurs variables",
    "section": "",
    "text": "if_else() et ifelse()\n\n\n\nLa fonction dplyr::if_else() ressemble à la fonction ifelse() en base R. Il y a néanmoins quelques petites différences :\n\n\ndplyr::if_else() vérifie que les valeurs fournies pour true et celles pour false sont du même type et de la même classe et renvoie une erreur dans le cas contraire, là où ifelse() sera plus permissif ;\nsi un vecteur a des attributs (cf. Chapitre 6), ils seront préservés par dplyr::if_else() (et pris dans le vecteur true), ce que ne fera pas if_else() ;\n\ndplyr::if_else() propose un argument optionnel supplémentaire missing pour indiquer les valeurs à retourner lorsque le test renvoie NA.",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Combiner plusieurs variables</span>"
    ]
  },
  {
    "objectID": "manipulation/combiner-variables.html#case_when",
    "href": "manipulation/combiner-variables.html#case_when",
    "title": "10  Combiner plusieurs variables",
    "section": "\n10.2 case_when()",
    "text": "10.2 case_when()\ndplyr::case_when() est une généralisation de dplyr::if_else() qui permet d’indiquer plusieurs tests et leurs valeurs associées.\nImaginons que l’on souhaite créer une nouvelle variable permettant d’identifier les hommes de plus de 60 ans, les femmes de plus de 60 ans, et les autres. On peut utiliser la syntaxe suivante :\n\nhdv2003 &lt;-\n  hdv2003 |&gt; \n  mutate(\n    statut = case_when(\n      age &gt;= 60 & sexe == \"Homme\" ~ \"Homme, 60 et plus\",\n      age &gt;= 60 & sexe == \"Femme\" ~ \"Femme, 60 et plus\",\n      TRUE ~ \"Autre\"\n    )\n  )\nhdv2003 |&gt; \n  pull(statut) |&gt; \n  questionr::freq()\n\n                     n    % val%\nAutre             1484 74.2 74.2\nFemme, 60 et plus  278 13.9 13.9\nHomme, 60 et plus  238 11.9 11.9\n\n\ndplyr::case_when() prend en arguments une série d’instructions sous la forme condition ~ valeur. Il les exécute une par une, et dès qu’une condition est vraie, il renvoi la valeur associée.\nLa clause TRUE ~ \"Autre\" permet d’assigner une valeur à toutes les lignes pour lesquelles aucune des conditions précédentes n’est vraie.\n\n\n\n\n\n\nImportant\n\n\n\nAttention : comme les conditions sont testées l’une après l’autre et que la valeur renvoyée est celle correspondant à la première condition vraie, l’ordre de ces conditions est très important. Il faut absolument aller du plus spécifique au plus général.\nPar exemple le recodage suivant ne fonctionne pas :\n\nhdv2003 &lt;-\n  hdv2003 |&gt; \n  mutate(\n    statut = case_when(\n      sexe == \"Homme\" ~ \"Homme\",\n      age &gt;= 60 & sexe == \"Homme\" ~ \"Homme, 60 et plus\",\n      TRUE ~ \"Autre\"\n    )\n  )\nhdv2003 |&gt; \n  pull(statut) |&gt; \n  questionr::freq()\n\n         n  % val%\nAutre 1101 55   55\nHomme  899 45   45\n\n\nComme la condition sexe == \"Homme\" est plus générale que sexe == \"Homme\" & age &gt; 60, cette deuxième condition n’est jamais testée ! On n’obtiendra jamais la valeur correspondante.\nPour que ce recodage fonctionne il faut donc changer l’ordre des conditions pour aller du plus spécifique au plus général :\n\nhdv2003 &lt;-\n  hdv2003 |&gt; \n  mutate(\n    statut = case_when(\n      age &gt;= 60 & sexe == \"Homme\" ~ \"Homme, 60 et plus\",\n      sexe == \"Homme\" ~ \"Homme\",\n      TRUE ~ \"Autre\"\n    )\n  )\nhdv2003 |&gt; \n  pull(statut) |&gt; \n  questionr::freq()\n\n                     n    % val%\nAutre             1101 55.0 55.0\nHomme              661 33.1 33.1\nHomme, 60 et plus  238 11.9 11.9\n\n\nC’est pour cela que l’on peut utiliser, en toute dernière condition, la valeur TRUE pour indiquer dans tous les autres cas.",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Combiner plusieurs variables</span>"
    ]
  },
  {
    "objectID": "manipulation/combiner-variables.html#recode_if",
    "href": "manipulation/combiner-variables.html#recode_if",
    "title": "10  Combiner plusieurs variables",
    "section": "\n10.3 recode_if()",
    "text": "10.3 recode_if()\nParfois, on n’a besoin de ne modifier une variable que pour certaines observations. Prenons un petit exemple :\n\ndf &lt;- tibble(\n  pref = factor(c(\"bleu\", \"rouge\", \"autre\", \"rouge\", \"autre\")),\n  autre_details = c(NA, NA, \"bleu ciel\", NA, \"jaune\")\n)\ndf\n\n# A tibble: 5 × 2\n  pref  autre_details\n  &lt;fct&gt; &lt;chr&gt;        \n1 bleu  &lt;NA&gt;         \n2 rouge &lt;NA&gt;         \n3 autre bleu ciel    \n4 rouge &lt;NA&gt;         \n5 autre jaune        \n\n\nNous avons demandé aux enquêtés d’indiquer leur couleur préférée. Ils pouvaient répondre bleu ou rouge et avait également la possibilité de choisir autre et d’indiquer la valeur de leur choix dans un champs textuel libre.\nUne des personnes enquêtées a choisi autre et a indiqué dans le champs texte la valeur bleu ciel. Pour les besoins de l’analyse, on peut considérer que cette valeur bleu ciel pour être tout simplement recodée en bleu.\nEn syntaxe R classique, on pourra simplement faire :\n\ndf$pref[df$autre_details == \"bleu ciel\"] &lt;- \"bleu\"\n\nAvec dplyr::if_else(), on serait tenté d’écrire :\n\ndf |&gt; \n  mutate(pref = if_else(autre_details == \"bleu ciel\", \"bleu\", pref))\n\n# A tibble: 5 × 2\n  pref  autre_details\n  &lt;chr&gt; &lt;chr&gt;        \n1 &lt;NA&gt;  &lt;NA&gt;         \n2 &lt;NA&gt;  &lt;NA&gt;         \n3 bleu  bleu ciel    \n4 &lt;NA&gt;  &lt;NA&gt;         \n5 autre jaune        \n\n\nOn obtient une erreur, car dplyr::if_else() exige les valeurs fournie pour true et false soient de même type. Essayons alors :\n\ndf |&gt; \n  mutate(pref = if_else(autre_details == \"bleu ciel\", factor(\"bleu\"), pref))\n\n# A tibble: 5 × 2\n  pref  autre_details\n  &lt;fct&gt; &lt;chr&gt;        \n1 &lt;NA&gt;  &lt;NA&gt;         \n2 &lt;NA&gt;  &lt;NA&gt;         \n3 bleu  bleu ciel    \n4 &lt;NA&gt;  &lt;NA&gt;         \n5 autre jaune        \n\n\nIci nous avons un autre problème, signalé par un message d’avertissement (warning) : dplyr::if_else() ne préserve que les attributs du vecteur passé en true et non ceux passés à false. Or l’ensemble des modalités (niveaux du facteur) de la variable pref n’ont pas été définis dans factor(\"bleu\") et sont ainsi perdus, générant une perte de données (valeurs manquantes NA).\nPour obtenir le bon résultat, il faudrait inverser la condition :\n\ndf |&gt; \n  mutate(pref = if_else(\n    autre_details != \"bleu ciel\", \n    pref, \n    factor(\"bleu\")\n  ))\n\n# A tibble: 5 × 2\n  pref  autre_details\n  &lt;fct&gt; &lt;chr&gt;        \n1 &lt;NA&gt;  &lt;NA&gt;         \n2 &lt;NA&gt;  &lt;NA&gt;         \n3 bleu  bleu ciel    \n4 &lt;NA&gt;  &lt;NA&gt;         \n5 autre jaune        \n\n\nMais ce n’est toujours pas suffisant. En effet, la variable autre_details a des valeurs manquantes pour lesquelles le test autre_details != \"bleu ciel\" renvoie NA ce qui une fois encore génère des valeurs manquantes non souhaitées. Dès lors, il nous faut soit définir l’argument missing de dplyr::if_else(), soit être plus précis dans notre test.\n\ndf |&gt; \n  mutate(pref = if_else(\n    autre_details != \"bleu ciel\", \n    pref, \n    factor(\"bleu\"),\n    missing = pref\n  ))\n\n# A tibble: 5 × 2\n  pref  autre_details\n  &lt;fct&gt; &lt;chr&gt;        \n1 bleu  &lt;NA&gt;         \n2 rouge &lt;NA&gt;         \n3 bleu  bleu ciel    \n4 rouge &lt;NA&gt;         \n5 autre jaune        \n\ndf |&gt; \n  mutate(pref = if_else(\n    autre_details != \"bleu ciel\" | is.na(autre_details), \n    pref, \n    factor(\"bleu\")\n  ))\n\n# A tibble: 5 × 2\n  pref  autre_details\n  &lt;fct&gt; &lt;chr&gt;        \n1 bleu  &lt;NA&gt;         \n2 rouge &lt;NA&gt;         \n3 bleu  bleu ciel    \n4 rouge &lt;NA&gt;         \n5 autre jaune        \n\n\nBref, on peut s’en sortir avec dplyr::if_else() mais ce n’est pas forcément le plus pratique dans le cas présent. La syntaxe en base R fonctionne très bien, mais ne peut pas être intégrée à un enchaînement d’opérations utilisant le pipe.\nDans ce genre de situation, on pourra être intéressé par la fonction labelled::recode_if() disponible dans le package labelled. Elle permet de ne modifier que certaines observations d’un vecteur en fonction d’une condition. Si la condition vaut FALSE ou NA, les observations concernées restent inchangées. Voyons comment cela s’écrit :\n\ndf &lt;-\n  df |&gt; \n  mutate(\n    pref = pref |&gt; \n      labelled::recode_if(autre_details == \"bleu ciel\", \"bleu\")\n  )\ndf\n\n# A tibble: 5 × 2\n  pref  autre_details\n  &lt;fct&gt; &lt;chr&gt;        \n1 bleu  &lt;NA&gt;         \n2 rouge &lt;NA&gt;         \n3 bleu  bleu ciel    \n4 rouge &lt;NA&gt;         \n5 autre jaune        \n\n\nC’est tout de suite plus intuitif !",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Combiner plusieurs variables</span>"
    ]
  },
  {
    "objectID": "manipulation/etiquettes-variables.html",
    "href": "manipulation/etiquettes-variables.html",
    "title": "11  Étiquettes de variables",
    "section": "",
    "text": "11.1 Principe\nLes étiquettes de variable permettent de donner un nom long, plus explicite, aux différentes colonnes d’un tableau de données (ou encore directement à un vecteur autonome). Dans le champs des grandes enquêtes, il est fréquent de nommer les variables q101, q102, etc. pour refléter le numéro de la question et d’indiquer ce qu’elle représente (groupe d’âges, milieu de résidence…) avec une étiquette.\nUn usage, introduit par le package haven, et repris depuis par de nombreux autres packages dont gtsummary que nous aborderons dans de prochains chapitres, consiste à stocker les étiquettes de variables sous la forme d’un attribut1 \"label\" attaché au vecteur / à la colonne du tableau.\nLe package labelled permet de manipuler aisément ces étiquettes de variables.\nLa visionneuse de données de RStudio sait reconnaître et afficher ces étiquettes de variable lorsqu’elles existent. Prenons pour exemple le jeu de données gtsummary::trial dont les colonnes ont des étiquettes de variable. La commande View(gtsummary::trial) permet d’ouvrir la visionneuse de données de RStudio. Comme on peut le constater, une étiquette de variable est bien présente sous le nom des différentes colonnes.\nLa fonction labelled::look_for() du package labelled permet de lister l’ensemble des variables d’un tableau de données et affiche notamment les étiquettes de variable associées.\nlibrary(labelled)\ngtsummary::trial |&gt; \n  look_for()\n\n pos variable label                  col_type missing values\n 1   trt      Chemotherapy Treatment chr      0             \n 2   age      Age                    dbl      11            \n 3   marker   Marker Level (ng/mL)   dbl      10            \n 4   stage    T Stage                fct      0       T1    \n                                                      T2    \n                                                      T3    \n                                                      T4    \n 5   grade    Grade                  fct      0       I     \n                                                      II    \n                                                      III   \n 6   response Tumor Response         int      7             \n 7   death    Patient Died           int      0             \n 8   ttdeath  Months to Death/Censor dbl      0\nLa fonction labelled::look_for() permet également de rechercher des variables en tenant compte à la fois de leur nom et de leur étiquette.\ngtsummary::trial |&gt; \n  look_for(\"months\")\n\n pos variable label                  col_type missing values\n 8   ttdeath  Months to Death/Censor dbl      0",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Étiquettes de variables</span>"
    ]
  },
  {
    "objectID": "manipulation/etiquettes-variables.html#principe",
    "href": "manipulation/etiquettes-variables.html#principe",
    "title": "11  Étiquettes de variables",
    "section": "",
    "text": "1 Pour plus d’information sur les attributs, voir Chapitre 6.\n\n\n\n\n\n\nFigure 11.1: Présentation du tableau gtsummary::trial dans la visionneuse de RStudio\n\n\n\n\n\n\n\n\n\n\n\n\nAstuce\n\n\n\nComme on le voit, la fonction labelled::look_for() est tout à fait adaptée pour générer un dictionnaire de codification. Ses différentes options sont détaillées dans une vignette dédiée. Les résultats renvoyés par labelled::look_for() sont récupérables dans un tableau de données que l’on pourra ainsi manipuler à sa guise.\n\ngtsummary::trial |&gt; \n  look_for() |&gt; \n  dplyr::as_tibble()\n\n# A tibble: 8 × 7\n    pos variable label                  col_type missing levels     value_labels\n  &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                  &lt;chr&gt;      &lt;int&gt; &lt;named li&gt; &lt;named list&gt;\n1     1 trt      Chemotherapy Treatment chr            0 &lt;NULL&gt;     &lt;NULL&gt;      \n2     2 age      Age                    dbl           11 &lt;NULL&gt;     &lt;NULL&gt;      \n3     3 marker   Marker Level (ng/mL)   dbl           10 &lt;NULL&gt;     &lt;NULL&gt;      \n4     4 stage    T Stage                fct            0 &lt;chr [4]&gt;  &lt;NULL&gt;      \n5     5 grade    Grade                  fct            0 &lt;chr [3]&gt;  &lt;NULL&gt;      \n6     6 response Tumor Response         int            7 &lt;NULL&gt;     &lt;NULL&gt;      \n7     7 death    Patient Died           int            0 &lt;NULL&gt;     &lt;NULL&gt;      \n8     8 ttdeath  Months to Death/Censor dbl            0 &lt;NULL&gt;     &lt;NULL&gt;",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Étiquettes de variables</span>"
    ]
  },
  {
    "objectID": "manipulation/etiquettes-variables.html#manipulation-sur-un-vecteur-une-colonne",
    "href": "manipulation/etiquettes-variables.html#manipulation-sur-un-vecteur-une-colonne",
    "title": "11  Étiquettes de variables",
    "section": "\n11.2 Manipulation sur un vecteur / une colonne",
    "text": "11.2 Manipulation sur un vecteur / une colonne\nLa fonction labelled::var_label() permets de voir l’étiquette de variable attachée à un vecteur (renvoie NULL s’il n’y en a pas) mais également d’ajouter/modifier une étiquette.\nLe fait d’ajouter une étiquette de variable à un vecteur ne modifie en rien son type ni sa classe. On peut associer une étiquette de variable à n’importe quel type de variable, qu’elle soit numérique, textuelle, un facteur ou encore des dates.\n\nv &lt;- c(1, 5, 2, 4, 1)\nv |&gt; var_label()\n\nNULL\n\nvar_label(v) &lt;- \"Mon étiquette\"\nvar_label(v)\n\n[1] \"Mon étiquette\"\n\nstr(v)\n\n num [1:5] 1 5 2 4 1\n - attr(*, \"label\")= chr \"Mon étiquette\"\n\nvar_label(v) &lt;- \"Une autre étiquette\"\nvar_label(v)\n\n[1] \"Une autre étiquette\"\n\nstr(v)\n\n num [1:5] 1 5 2 4 1\n - attr(*, \"label\")= chr \"Une autre étiquette\"\n\n\nPour supprimer une étiquette, il suffit d’attribuer la valeur NULL.\n\nvar_label(v) &lt;- NULL\nstr(v)\n\n num [1:5] 1 5 2 4 1\n\n\nOn peut appliquer labelled::var_label() directement sur une colonne de tableau.\n\nvar_label(iris$Petal.Length) &lt;- \"Longueur du pétale\"\nvar_label(iris$Petal.Width) &lt;- \"Largeur du pétale\"\nvar_label(iris$Species) &lt;- \"Espèce\"\niris |&gt; \n  look_for()\n\n pos variable     label              col_type missing values    \n 1   Sepal.Length —                  dbl      0                 \n 2   Sepal.Width  —                  dbl      0                 \n 3   Petal.Length Longueur du pétale dbl      0                 \n 4   Petal.Width  Largeur du pétale  dbl      0                 \n 5   Species      Espèce             fct      0       setosa    \n                                                      versicolor\n                                                      virginica",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Étiquettes de variables</span>"
    ]
  },
  {
    "objectID": "manipulation/etiquettes-variables.html#manipulation-sur-un-tableau-de-données",
    "href": "manipulation/etiquettes-variables.html#manipulation-sur-un-tableau-de-données",
    "title": "11  Étiquettes de variables",
    "section": "\n11.3 Manipulation sur un tableau de données",
    "text": "11.3 Manipulation sur un tableau de données\nLa fonction labelled::set_variable_labels() permets de manipuler les étiquettes de variable d’un tableau de données avec une syntaxe du type dplyr.\n\niris &lt;- \n  iris |&gt; \n  set_variable_labels(\n    Species = NULL,\n    Sepal.Length = \"Longeur du sépale\"\n  )\niris |&gt; \n  look_for()\n\n pos variable     label              col_type missing values    \n 1   Sepal.Length Longeur du sépale  dbl      0                 \n 2   Sepal.Width  —                  dbl      0                 \n 3   Petal.Length Longueur du pétale dbl      0                 \n 4   Petal.Width  Largeur du pétale  dbl      0                 \n 5   Species      —                  fct      0       setosa    \n                                                      versicolor\n                                                      virginica",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Étiquettes de variables</span>"
    ]
  },
  {
    "objectID": "manipulation/etiquettes-variables.html#préserver-les-étiquettes",
    "href": "manipulation/etiquettes-variables.html#préserver-les-étiquettes",
    "title": "11  Étiquettes de variables",
    "section": "\n11.4 Préserver les étiquettes",
    "text": "11.4 Préserver les étiquettes\nCertaines fonctions de R ne préservent pas les attributs et risquent donc d’effacer les étiquettes de variables que l’on a définit. Un exemple est la fonction générique subset() qui permet de sélectionner certaines lignes remplissant une certaines conditions.\n\niris |&gt; \n  look_for()\n\n pos variable     label              col_type missing values    \n 1   Sepal.Length Longeur du sépale  dbl      0                 \n 2   Sepal.Width  —                  dbl      0                 \n 3   Petal.Length Longueur du pétale dbl      0                 \n 4   Petal.Width  Largeur du pétale  dbl      0                 \n 5   Species      —                  fct      0       setosa    \n                                                      versicolor\n                                                      virginica \n\niris |&gt; \n  subset(Species == \"setosa\") |&gt; \n  look_for()\n\n pos variable     label col_type missing values    \n 1   Sepal.Length —     dbl      0                 \n 2   Sepal.Width  —     dbl      0                 \n 3   Petal.Length —     dbl      0                 \n 4   Petal.Width  —     dbl      0                 \n 5   Species      —     fct      0       setosa    \n                                         versicolor\n                                         virginica \n\n\nOn pourra, dans ce cas précis, préférer la fonction dplyr::filter() qui préserve les attributs et donc les étiquettes de variables.\n\niris |&gt; \n  dplyr::filter(Species == \"setosa\") |&gt; \n  look_for()\n\n pos variable     label              col_type missing values    \n 1   Sepal.Length Longeur du sépale  dbl      0                 \n 2   Sepal.Width  —                  dbl      0                 \n 3   Petal.Length Longueur du pétale dbl      0                 \n 4   Petal.Width  Largeur du pétale  dbl      0                 \n 5   Species      —                  fct      0       setosa    \n                                                      versicolor\n                                                      virginica \n\n\nOn pourra également tirer parti de la fonction labelled::copy_labels_from() qui permet de copier les étiquettes d’un tableau à un autre.\n\niris |&gt; \n  subset(Species == \"setosa\") |&gt; \n  copy_labels_from(iris) |&gt; \n  look_for()\n\n pos variable     label              col_type missing values    \n 1   Sepal.Length Longeur du sépale  dbl      0                 \n 2   Sepal.Width  —                  dbl      0                 \n 3   Petal.Length Longueur du pétale dbl      0                 \n 4   Petal.Width  Largeur du pétale  dbl      0                 \n 5   Species      —                  fct      0       setosa    \n                                                      versicolor\n                                                      virginica \n\n\n\n\n\nFigure 11.1: Présentation du tableau gtsummary::trial dans la visionneuse de RStudio",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Étiquettes de variables</span>"
    ]
  },
  {
    "objectID": "manipulation/etiquettes-valeurs.html",
    "href": "manipulation/etiquettes-valeurs.html",
    "title": "12  Étiquettes de valeurs",
    "section": "",
    "text": "12.1 La classe haven_labelled\nAfin d’assurer une importation complète des données depuis SPSS, Stata et SAS, le package haven a introduit un nouveau type de vecteurs, la classe haven_labelled, qui permet justement de rendre compte de ces vecteurs labellisés (i.e. avec des étiquettes de valeurs). Le package labelled fournie un jeu de fonctions pour faciliter la manipulation des vecteurs labellisés.",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Étiquettes de valeurs</span>"
    ]
  },
  {
    "objectID": "manipulation/etiquettes-valeurs.html#la-classe-haven_labelled",
    "href": "manipulation/etiquettes-valeurs.html#la-classe-haven_labelled",
    "title": "12  Étiquettes de valeurs",
    "section": "",
    "text": "Important\n\n\n\nLes vecteurs labellisés sont un format intermédiaire qui permets d’importer les données telles qu’elles ont été définies dans le fichier source. Il n’est pas destiné à être utilisé pour l’analyse statistique.\nPour la réalisation de tableaux, graphiques, modèles, R attend que les variables catégorielles soit codées sous formes de facteurs, et que les variables continues soient numériques. On aura donc besoin, à un moment ou à un autre, de convertir les vecteurs labellisés en facteurs ou en variables numériques classiques.",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Étiquettes de valeurs</span>"
    ]
  },
  {
    "objectID": "manipulation/etiquettes-valeurs.html#manipulation-sur-un-vecteur-une-colonne",
    "href": "manipulation/etiquettes-valeurs.html#manipulation-sur-un-vecteur-une-colonne",
    "title": "12  Étiquettes de valeurs",
    "section": "\n12.2 Manipulation sur un vecteur / une colonne",
    "text": "12.2 Manipulation sur un vecteur / une colonne\nPour définir des étiquettes, la fonction de base est labelled::val_labels(). Il est possible de définir des étiquettes de valeurs pour des vecteurs numériques, d’entiers et textuels. On indiquera les étiquettes sous la forme étiquette = valeur. Cette fonction s’utilise de la même manière que labelled::var_label() abordée au chapitre précédent (cf. Chapitre 11). Un appel simple renvoie les étiquettes de valeur associées au vecteur, NULL s’il n’y en n’a pas. Combiner avec l’opérateur d’assignation (&lt;-), on peut ajouter/modifier les étiquettes de valeurs associées au vecteur.\n\nlibrary(labelled)\nv &lt;- c(1, 2, 1, 9)\nv\n\n[1] 1 2 1 9\n\nclass(v)\n\n[1] \"numeric\"\n\nval_labels(v)\n\nNULL\n\nval_labels(v) &lt;- c(non = 1, oui = 2)\nval_labels(v)\n\nnon oui \n  1   2 \n\nv\n\n&lt;labelled&lt;double&gt;[4]&gt;\n[1] 1 2 1 9\n\nLabels:\n value label\n     1   non\n     2   oui\n\nclass(v)\n\n[1] \"haven_labelled\" \"vctrs_vctr\"     \"double\"        \n\n\nComme on peut le voir avec cet exemple simple :\n\nl’ajout d’étiquettes de valeurs modifie la classe de l’objet (qui est maintenant un vecteur de la classe haven_labelled) ;\nl’objet obtenu est multi-classes, la classe double indiquant ici qu’il s’agit d’un vecteur numérique ;\nil n’est pas obligatoire d’associer une étiquette de valeurs à toutes les valeurs observées dans le vecteur (ici, nous n’avons pas défini d’étiquettes pour la valeur 9).\n\nLa fonction labelled::val_label() (notez l’absence d’un s à la fin du nom de la fonction) permet d’accéder / de modifier l’étiquette associée à une valeur spécifique.\n\nval_label(v, 1)\n\n[1] \"non\"\n\nval_label(v, 9)\n\nNULL\n\nval_label(v, 9) &lt;- \"(manquant)\"\nval_label(v, 2) &lt;- NULL\nv\n\n&lt;labelled&lt;double&gt;[4]&gt;\n[1] 1 2 1 9\n\nLabels:\n value      label\n     1        non\n     9 (manquant)\n\n\nPour supprimer, toutes les étiquettes de valeurs, on attribuera NULL avec labelled::val_labels().\n\nval_labels(v) &lt;- NULL\nv\n\n[1] 1 2 1 9\n\nclass(v)\n\n[1] \"numeric\"\n\n\nOn remarquera que, lorsque toutes les étiquettes de valeurs sont supprimées, la nature de l’objet change à nouveau et il redevient un simple vecteur numérique.\n\n\n\n\n\n\nMise en garde\n\n\n\nIl est essentiel de bien comprendre que l’ajout d’étiquettes de valeurs ne change pas fondamentalement la nature du vecteur. Cela ne le transforme pas en variable catégorielle. À ce stade, le vecteur n’a pas été transformé en facteur. Cela reste un vecteur numérique qui est considéré comme tel par R. On peut ainsi en calculer une moyenne, ce qui serait impossible avec un facteur.\n\nv &lt;- c(1, 2, 1, 2)\nval_labels(v) &lt;- c(non = 1, oui = 2)\nmean(v)\n\n[1] 1.5\n\nf &lt;- factor(v, levels = c(1, 2), labels = c(\"non\", \"oui\"))\nmean(f)\n\nWarning in mean.default(f): l'argument n'est ni numérique, ni logique : renvoi\nde NA\n\n\n[1] NA\n\n\n\n\nLes fonctions labelled::val_labels() et labelled::val_label() peuvent également être utilisées sur les colonnes d’un tableau.\n\ndf &lt;- dplyr::tibble(\n  x = c(1, 2, 1, 2),\n  y = c(3, 9, 9, 3)\n)\nval_labels(df$x) &lt;- c(non = 1, oui = 2)\nval_label(df$y, 9) &lt;- \"(manquant)\"\ndf\n\n# A tibble: 4 × 2\n  x         y             \n  &lt;dbl+lbl&gt; &lt;dbl+lbl&gt;     \n1 1 [non]   3             \n2 2 [oui]   9 [(manquant)]\n3 1 [non]   9 [(manquant)]\n4 2 [oui]   3             \n\n\nOn pourra noter, que si notre tableau est un tibble, les étiquettes sont rendues dans la console quand on affiche le tableau.\nLa fonction labelled::look_for() est également un bon moyen d’afficher les étiquettes de valeurs.\n\ndf |&gt; \n  look_for()\n\n pos variable label col_type missing values        \n 1   x        —     dbl+lbl  0       [1] non       \n                                     [2] oui       \n 2   y        —     dbl+lbl  0       [9] (manquant)",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Étiquettes de valeurs</span>"
    ]
  },
  {
    "objectID": "manipulation/etiquettes-valeurs.html#manipulation-sur-un-tableau-de-données",
    "href": "manipulation/etiquettes-valeurs.html#manipulation-sur-un-tableau-de-données",
    "title": "12  Étiquettes de valeurs",
    "section": "\n12.3 Manipulation sur un tableau de données",
    "text": "12.3 Manipulation sur un tableau de données\nlabelled fournie 3 fonctions directement applicables sur un tableau de données : labelled::set_value_labels(), labelled::add_value_labels() et labelled::remove_value_labels(). La première remplace l’ensemble des étiquettes de valeurs associées à une variable, la seconde ajoute des étiquettes de valeurs (et conserve celles déjà définies), la troisième supprime les étiquettes associées à certaines valeurs spécifiques (et laisse les autres inchangées).\n\ndf |&gt; \n  look_for()\n\n pos variable label col_type missing values        \n 1   x        —     dbl+lbl  0       [1] non       \n                                     [2] oui       \n 2   y        —     dbl+lbl  0       [9] (manquant)\n\ndf &lt;- df |&gt; \n  set_value_labels(\n    x = c(yes = 2),\n    y = c(\"a répondu\" = 3, \"refus de répondre\" = 9)\n  )\ndf |&gt; \n  look_for()\n\n pos variable label col_type missing values               \n 1   x        —     dbl+lbl  0       [2] yes              \n 2   y        —     dbl+lbl  0       [3] a répondu        \n                                     [9] refus de répondre\n\ndf &lt;- df |&gt; \n  add_value_labels(\n    x = c(no = 1)\n  ) |&gt; \n  remove_value_labels(\n    y = 9\n  )\ndf |&gt; \n  look_for()\n\n pos variable label col_type missing values       \n 1   x        —     dbl+lbl  0       [2] yes      \n                                     [1] no       \n 2   y        —     dbl+lbl  0       [3] a répondu",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Étiquettes de valeurs</span>"
    ]
  },
  {
    "objectID": "manipulation/etiquettes-valeurs.html#conversion",
    "href": "manipulation/etiquettes-valeurs.html#conversion",
    "title": "12  Étiquettes de valeurs",
    "section": "\n12.4 Conversion",
    "text": "12.4 Conversion\n\n12.4.1 Quand convertir les vecteurs labellisés ?\nLa classe haven_labelled permets d’ajouter des métadonnées aux variables sous la forme d’étiquettes de valeurs. Lorsque les données sont importées depuis SAS, SPSS ou Stata, cela permet notamment de conserver le codage original du fichier importé.\nMais il faut noter que ces étiquettes de valeur n’indique pas pour autant de manière systématique le type de variable (catégorielle ou continue). Les vecteurs labellisés n’ont donc pas vocation à être utilisés pour l’analyse, notamment le calcul de modèles statistiques. Ils doivent être convertis en facteurs (pour les variables catégorielles) ou en vecteurs numériques (pour les variables continues).\nLa question qui peut se poser est donc de choisir à quel moment cette conversion doit avoir lieu dans un processus d’analyse. On peut considérer deux approches principales.\n\n\n\n\n\nFigure 12.1: Deux approches possibles pour la conversion des étiquettes de valeurs\n\n\nDans l’approche A, les vecteurs labellisés sont convertis juste après l’import des données, en utilisant les fonctions labelled::unlabelled(), labelled::to_factor() ou base::unclass() qui sont présentées ci-après. Dès lors, toute la partie de nettoyage et de recodage des données se fera en utilisant les fonctions classiques de R. Si l’on n’a pas besoin de conserver le codage original, cette approche a l’avantage de s’inscrire dans le fonctionnement usuel de R.\nDans l’approche B, les vecteurs labellisés sont conservés pour l’étape de nettoyage et de recodage des données. Dans ce cas là, on pourra avoir recours aux fonctions de l’extension labelled qui facilitent la gestion des données labellisées. Cette approche est particulièrement intéressante quand (i) on veut pouvoir se référer au dictionnaire de codification fourni avec les données sources et donc on veut conserver le codage original et/ou (ii) quand les données devront faire l’objet d’un ré-export après transformation. Par contre, comme dans l’approche A, il faudra prévoir une conversion des variables labellisées au moment de l’analyse.\n\n\n\n\n\n\nAvertissement\n\n\n\nDans tous les cas, il est recommandé d’adopter l’une ou l’autre approche, mais d’éviter de mélanger les différents types de vecteur. Une organisation rigoureuse de ses données et de son code est essentielle !\n\n\n\n12.4.2 Convertir un vecteur labellisé en facteur\nIl est très facile de convertir un vecteur labellisé en facteur à l’aide la fonction labelled::to_factor() du package labelled1.\n1 On privilégiera la fonction labelled::to_factor() à la fonction haven::as_factor() de l’extension haven, la première ayant plus de possibilités et un comportement plus consistent.\nv &lt;- c(1,2,9,3,3,2,NA)\nval_labels(v) &lt;- c(\n  oui = 1, \"peut-être\" = 2, \n  non = 3, \"ne sait pas\" = 9\n)\nv\n\n&lt;labelled&lt;double&gt;[7]&gt;\n[1]  1  2  9  3  3  2 NA\n\nLabels:\n value       label\n     1         oui\n     2   peut-être\n     3         non\n     9 ne sait pas\n\nto_factor(v)\n\n[1] oui         peut-être   ne sait pas non         non         peut-être  \n[7] &lt;NA&gt;       \nLevels: oui peut-être non ne sait pas\n\n\nIl possible d’indiquer si l’on souhaite, comme étiquettes du facteur, utiliser les étiquettes de valeur (par défaut), les valeurs elles-mêmes, ou bien les étiquettes de valeurs préfixées par la valeur d’origine indiquée entre crochets.\n\nto_factor(v, 'l')\n\n[1] oui         peut-être   ne sait pas non         non         peut-être  \n[7] &lt;NA&gt;       \nLevels: oui peut-être non ne sait pas\n\nto_factor(v, 'v')\n\n[1] 1    2    9    3    3    2    &lt;NA&gt;\nLevels: 1 2 3 9\n\nto_factor(v, 'p')\n\n[1] [1] oui         [2] peut-être   [9] ne sait pas [3] non        \n[5] [3] non         [2] peut-être   &lt;NA&gt;           \nLevels: [1] oui [2] peut-être [3] non [9] ne sait pas\n\n\nPar défaut, les modalités du facteur seront triées selon l’ordre des étiquettes de valeur. Mais cela peut être modifié avec l’argument sort_levels si l’on préfère trier selon les valeurs ou selon l’ordre alphabétique des étiquettes.\n\nto_factor(v, sort_levels = 'v')\n\n[1] oui         peut-être   ne sait pas non         non         peut-être  \n[7] &lt;NA&gt;       \nLevels: oui peut-être non ne sait pas\n\nto_factor(v, sort_levels = 'l')\n\n[1] oui         peut-être   ne sait pas non         non         peut-être  \n[7] &lt;NA&gt;       \nLevels: ne sait pas non oui peut-être\n\n\n\n12.4.3 Convertir un vecteur labellisé en numérique ou en texte\nPour rappel, il existe deux types de vecteurs labellisés : des vecteurs numériques labellisés (x dans l’exemple ci-dessous) et des vecteurs textuels labellisés (y dans l’exemple ci-dessous).\n\nx &lt;- c(1, 2, 9, 3, 3, 2, NA)\nval_labels(x) &lt;- c(\n  oui = 1, \"peut-être\" = 2, \n  non = 3, \"ne sait pas\" = 9\n)\n  \ny &lt;- c(\"f\", \"f\", \"h\", \"f\")\nval_labels(y) &lt;- c(femme = \"f\", homme = \"h\")\n\nPour leur retirer leur caractère labellisé et revenir à leur classe d’origine, on peut utiliser la fonction unclass().\n\nunclass(x)\n\n[1]  1  2  9  3  3  2 NA\nattr(,\"labels\")\n        oui   peut-être         non ne sait pas \n          1           2           3           9 \n\nunclass(y)\n\n[1] \"f\" \"f\" \"h\" \"f\"\nattr(,\"labels\")\nfemme homme \n  \"f\"   \"h\" \n\n\nÀ noter que dans ce cas-là, les étiquettes sont conservées comme attributs du vecteur.\nUne alternative est d’utiliser labelled::remove_labels() qui supprimera toutes les étiquettes, y compris les étiquettes de variable. Pour conserver les étiquettes de variables et ne supprimer que les étiquettes de valeurs, on indiquera keep_var_label = TRUE.\n\nvar_label(x) &lt;- \"Etiquette de variable\"\nremove_labels(x)\n\n[1]  1  2  9  3  3  2 NA\n\nremove_labels(x, keep_var_label = TRUE)\n\n[1]  1  2  9  3  3  2 NA\nattr(,\"label\")\n[1] \"Etiquette de variable\"\n\nremove_labels(y)\n\n[1] \"f\" \"f\" \"h\" \"f\"\n\n\nDans le cas d’un vecteur numérique labellisé que l’on souhaiterait convertir en variable textuelle, on pourra utiliser labelled::to_character() à la place de labelled::to_factor() qui, comme sa grande sœur, utilisera les étiquettes de valeurs.\n\nto_character(x)\n\n[1] \"oui\"         \"peut-être\"   \"ne sait pas\" \"non\"         \"non\"        \n[6] \"peut-être\"   NA           \nattr(,\"label\")\n[1] \"Etiquette de variable\"\n\n\n\n12.4.4 Conversion conditionnelle en facteurs\nIl n’est pas toujours possible de déterminer la nature d’une variable (continue ou catégorielle) juste à partir de la présence ou l’absence d’étiquettes de valeur. En effet, on peut utiliser des étiquettes de valeur dans le cadre d’une variable continue pour indiquer certaines valeurs spécifiques.\nUne bonne pratique est de vérifier chaque variable inclue dans une analyse, une à une.\nCependant, une règle qui fonctionne dans 90% des cas est de convertir un vecteur labellisé en facteur si et seulement si toutes les valeurs observées dans le vecteur disposent d’une étiquette de valeur correspondante. C’est ce que propose la fonction labelled::unlabelled() qui peut même être appliqué à tout un tableau de données. Par défaut, elle fonctionne ainsi :\n\nles variables non labellisées restent inchangées (variables f et g dans l’exemple ci-dessous);\nsi toutes les valeurs observées d’une variable labellisées ont une étiquette, elles sont converties en facteurs (variables b et c);\nsinon, on leur applique base::unclass() (variables a, d et e).\n\n\ndf &lt;- dplyr::tibble(\n  a = c(1, 1, 2, 3),\n  b = c(1, 1, 2, 3),\n  c = c(1, 1, 2, 2),\n  d = c(\"a\", \"a\", \"b\", \"c\"),\n  e = c(1, 9, 1, 2),\n  f = 1:4,\n  g = as.Date(c(\n    \"2020-01-01\", \"2020-02-01\", \n    \"2020-03-01\", \"2020-04-01\"\n  ))\n) |&gt; \n  set_value_labels(\n    a = c(No = 1, Yes = 2),\n    b = c(No = 1, Yes = 2, DK = 3),\n    c = c(No = 1, Yes = 2, DK = 3),\n    d = c(No = \"a\", Yes = \"b\"),\n    e = c(No = 1, Yes = 2)\n  )\ndf |&gt; look_for()\n\n pos variable label col_type missing values \n 1   a        —     dbl+lbl  0       [1] No \n                                     [2] Yes\n 2   b        —     dbl+lbl  0       [1] No \n                                     [2] Yes\n                                     [3] DK \n 3   c        —     dbl+lbl  0       [1] No \n                                     [2] Yes\n                                     [3] DK \n 4   d        —     chr+lbl  0       [a] No \n                                     [b] Yes\n 5   e        —     dbl+lbl  0       [1] No \n                                     [2] Yes\n 6   f        —     int      0              \n 7   g        —     date     0              \n\nto_factor(df) |&gt; look_for()\n\n pos variable label col_type missing values\n 1   a        —     fct      0       No    \n                                     Yes   \n                                     3     \n 2   b        —     fct      0       No    \n                                     Yes   \n                                     DK    \n 3   c        —     fct      0       No    \n                                     Yes   \n                                     DK    \n 4   d        —     fct      0       No    \n                                     Yes   \n                                     c     \n 5   e        —     fct      0       No    \n                                     Yes   \n                                     9     \n 6   f        —     int      0             \n 7   g        —     date     0             \n\nunlabelled(df) |&gt; look_for()\n\n pos variable label col_type missing values\n 1   a        —     dbl      0             \n 2   b        —     fct      0       No    \n                                     Yes   \n                                     DK    \n 3   c        —     fct      0       No    \n                                     Yes   \n                                     DK    \n 4   d        —     chr      0             \n 5   e        —     dbl      0             \n 6   f        —     int      0             \n 7   g        —     date     0             \n\n\nOn peut indiquer certaines options, par exemple drop_unused_labels = TRUE pour supprimer des facteurs créés les niveaux non observées dans les données (voir la variable c).\n\nunlabelled(df, drop_unused_labels = TRUE) |&gt; \n  look_for()\n\n pos variable label col_type missing values\n 1   a        —     dbl      0             \n 2   b        —     fct      0       No    \n                                     Yes   \n                                     DK    \n 3   c        —     fct      0       No    \n                                     Yes   \n 4   d        —     chr      0             \n 5   e        —     dbl      0             \n 6   f        —     int      0             \n 7   g        —     date     0             \n\nunlabelled(df, levels = \"prefixed\") |&gt; \n  look_for()\n\n pos variable label col_type missing values \n 1   a        —     dbl      0              \n 2   b        —     fct      0       [1] No \n                                     [2] Yes\n                                     [3] DK \n 3   c        —     fct      0       [1] No \n                                     [2] Yes\n                                     [3] DK \n 4   d        —     chr      0              \n 5   e        —     dbl      0              \n 6   f        —     int      0              \n 7   g        —     date     0              \n\n\n\n\n\nFigure 12.1: Deux approches possibles pour la conversion des étiquettes de valeurs",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Étiquettes de valeurs</span>"
    ]
  },
  {
    "objectID": "manipulation/valeurs-manquantes.html",
    "href": "manipulation/valeurs-manquantes.html",
    "title": "13  Valeurs manquantes",
    "section": "",
    "text": "13.1 Valeurs manquantes étiquetées (tagged NAs)",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Valeurs manquantes</span>"
    ]
  },
  {
    "objectID": "manipulation/valeurs-manquantes.html#sec-tagged-na",
    "href": "manipulation/valeurs-manquantes.html#sec-tagged-na",
    "title": "13  Valeurs manquantes",
    "section": "",
    "text": "13.1.1 Création et test\nLes tagged NAs sont de véritables valeurs manquantes (NA) au sens de R, auxquelles a été attachées sur étiquette, une lettre unique minuscule (a-z) ou majuscule (A-Z). On peut les créer avec labelled::tagged_na().\n\nx &lt;- c(1:3, tagged_na(\"a\"), tagged_na(\"z\"), NA)\n\nPour la plupart des fonctions de R, les tagged NAs sont juste considérées comme des valeurs manquantes régulières (regular NAs). Dès lors, par défaut, elles sont justes affichées à l’écran comme n’importe quelle valeur manquante et la fonction is.na() renvoie TRUE.\n\nx\n\n[1]  1  2  3 NA NA NA\n\nis.na(x)\n\n[1] FALSE FALSE FALSE  TRUE  TRUE  TRUE\n\n\nPour afficher les étiquettes associées à ces valeurs manquantes, il faut avoir recours à labelled::na_tag(), labelled::print_tagged_na() ou encore labelled::format_tagged_na().\n\nna_tag(x)\n\n[1] NA  NA  NA  \"a\" \"z\" NA \n\nprint_tagged_na(x)\n\n[1]     1     2     3 NA(a) NA(z)    NA\n\nformat_tagged_na(x)\n\n[1] \"    1\" \"    2\" \"    3\" \"NA(a)\" \"NA(z)\" \"   NA\"\n\n\nPour tester si une certaine valeur manquante est une regular NA ou une tagged NA, on aura recours à labelled::is_regular_na() et à labelled::is_tagged_na().\n\nis.na(x)\n\n[1] FALSE FALSE FALSE  TRUE  TRUE  TRUE\n\nis_regular_na(x)\n\n[1] FALSE FALSE FALSE FALSE FALSE  TRUE\n\nis_tagged_na(x)\n\n[1] FALSE FALSE FALSE  TRUE  TRUE FALSE\n\n\nIl est possible de tester une étiquette particulière en passant un deuxième argument à labelled::is_tagged_na().\n\nis_tagged_na(x, \"a\")\n\n[1] FALSE FALSE FALSE  TRUE FALSE FALSE\n\n\n\n\n\n\n\n\nNote\n\n\n\nIl n’est possible de définir des tagged NAs seulement pour des vecteurs numériques (double). Si l’on ajoute une tagged NA à un vecteur d’entiers, ce vecteur sera converti en vecteur numérique. Si on l’ajoute à un vecteur textuel, la valeur manquante sera convertie en regular NA.\n\ny &lt;- c(\"a\", \"b\", tagged_na(\"z\"))\ny\n\n[1] \"a\" \"b\" NA \n\nis_tagged_na(y)\n\n[1] FALSE FALSE FALSE\n\nformat_tagged_na(y)\n\nError: `x` must be a double vector\n\nz &lt;- c(1L, 2L, tagged_na(\"a\"))\ntypeof(z)\n\n[1] \"double\"\n\nformat_tagged_na(z)\n\n[1] \"    1\" \"    2\" \"NA(a)\"\n\n\n\n\n\n13.1.2 Valeurs uniques, doublons et tris\nPar défaut, les fonctions classiques de R unique(), duplicated(), ordered() ou encore sort() traiteront les tagged NAs comme des valeurs manquantes tout ce qu’il y a de plus classique, et ne feront pas de différences entre des tagged NAs ayant des étiquettes différentes.\nPour traiter des tagged NAs ayant des étiquettes différentes comme des valeurs différentes, on aura recours aux fonctions labelled::unique_tagged_na(), labelled::duplicated_tagged_na(), labelled::order_tagged_na() ou encore labelled::sort_tagged_na().\n\nx &lt;- c(1, 2, tagged_na(\"a\"), 1, tagged_na(\"z\"), 2, tagged_na(\"a\"), NA)\nx |&gt; \n  print_tagged_na()\n\n[1]     1     2 NA(a)     1 NA(z)     2 NA(a)    NA\n\nx |&gt; \n  unique() |&gt; \n  print_tagged_na()\n\n[1]     1     2 NA(a)\n\nx |&gt; \n  unique_tagged_na() |&gt; \n  print_tagged_na()\n\n[1]     1     2 NA(a) NA(z)    NA\n\nx |&gt; \n  duplicated()\n\n[1] FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n\nx |&gt; \n  duplicated_tagged_na()\n\n[1] FALSE FALSE FALSE  TRUE FALSE  TRUE  TRUE FALSE\n\nx |&gt; \n  sort(na.last = TRUE) |&gt; \n  print_tagged_na()\n\n[1]     1     1     2     2 NA(a) NA(z) NA(a)    NA\n\nx |&gt; \n  sort_tagged_na()  |&gt; \n  print_tagged_na()\n\n[1]     1     1     2     2 NA(a) NA(a) NA(z)    NA\n\n\n\n13.1.3 Tagged NAs et étiquettes de valeurs\nIl est tout à fait possible d’associer une étiquette de valeurs (cf. Chapitre 12) à des tagged NAs.\n\nx &lt;- c(\n  1, 0, \n  1, tagged_na(\"r\"), \n  0, tagged_na(\"d\"), \n  tagged_na(\"z\"), NA\n)\nval_labels(x) &lt;- c(\n  no = 0, \n  yes = 1,\n  \"don't know\" = tagged_na(\"d\"),\n  refusal = tagged_na(\"r\")\n)\nx\n\n&lt;labelled&lt;double&gt;[8]&gt;\n[1]     1     0     1 NA(r)     0 NA(d) NA(z)    NA\n\nLabels:\n value      label\n     0         no\n     1        yes\n NA(d) don't know\n NA(r)    refusal\n\n\nLorsqu’un vecteur labellisé est converti en facteur avec labelled::to_factor(), les tagged NAs sont, par défaut convertis en en valeurs manquantes classiques (regular NAs). Il n’est pas possible de définir des tagged NAs pour des facteurs.\n\nx |&gt; to_factor()\n\n[1] yes  no   yes  &lt;NA&gt; no   &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;\nLevels: no yes\n\n\nL’option explicit_tagged_na de labelled::to_factor() permets de convertir les tagged NAs en modalités explicites du facteur.\n\nx |&gt; \n  to_factor(explicit_tagged_na = TRUE)\n\n[1] yes        no         yes        refusal    no         don't know NA(z)     \n[8] &lt;NA&gt;      \nLevels: no yes don't know refusal NA(z)\n\nx |&gt; \n  to_factor(\n    levels = \"prefixed\", \n    explicit_tagged_na = TRUE\n  )\n\n[1] [1] yes            [0] no             [1] yes            [NA(r)] refusal   \n[5] [0] no             [NA(d)] don't know [NA(z)] NA(z)      &lt;NA&gt;              \nLevels: [0] no [1] yes [NA(d)] don't know [NA(r)] refusal [NA(z)] NA(z)\n\n\n\n13.1.4 Conversion en user NAs\nLa fonction labelled::tagged_na_to_user_na() permets de convertir des tagged NAs en user NAs.\n\nx |&gt; \n  tagged_na_to_user_na()\n\n&lt;labelled_spss&lt;double&gt;[8]&gt;\n[1]  1  0  1  3  0  2  4 NA\nMissing range:  [2, 4]\n\nLabels:\n value      label\n     0         no\n     1        yes\n     2 don't know\n     3    refusal\n     4      NA(z)\n\nx |&gt; \n  tagged_na_to_user_na(user_na_start = 10)\n\n&lt;labelled_spss&lt;double&gt;[8]&gt;\n[1]  1  0  1 11  0 10 12 NA\nMissing range:  [10, 12]\n\nLabels:\n value      label\n     0         no\n     1        yes\n    10 don't know\n    11    refusal\n    12      NA(z)\n\n\nLa fonction labelled::tagged_na_to_regular_na() convertit les tagged NAs en valeurs manquantes classiques (regular NAs).\n\nx |&gt; \n  tagged_na_to_regular_na()\n\n&lt;labelled&lt;double&gt;[8]&gt;\n[1]  1  0  1 NA  0 NA NA NA\n\nLabels:\n value label\n     0    no\n     1   yes\n\nx |&gt; \n  tagged_na_to_regular_na() |&gt;\n  is_tagged_na()\n\n[1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Valeurs manquantes</span>"
    ]
  },
  {
    "objectID": "manipulation/valeurs-manquantes.html#sec-user-na",
    "href": "manipulation/valeurs-manquantes.html#sec-user-na",
    "title": "13  Valeurs manquantes",
    "section": "\n13.2 Valeurs manquantes définies par l’utilisateurs (user NAs)",
    "text": "13.2 Valeurs manquantes définies par l’utilisateurs (user NAs)\nLe package haven a introduit la classe haven_labelled_spss, une extension de la classe haven_labelled permettant d’indiquer des valeurs à considérer comme manquantes à la manière de SPSS.\n\n\n\n\n\n\nImportant\n\n\n\nCela revient à associer à un vecteur des attributs (cf. Chapitre 6) additionnels pour indiquer des valeurs que l’utilisateur pourrait/devrait considérer comme manquante. Cependant, il ne s’agit que de métadonnées et en interne ces valeurs ne sont pas stockées sous forme de NA mais restent des valeurs valides.\nIl convient de garder en mémoire que la très grande majorité des fonctions de R ne prendront pas en compte ces métadonnées et traiteront donc ces valeurs comme des valeurs valides. C’est donc à l’utilisateur de convertir, au besoin, ces les valeurs indiquées comme manquantes en réelles valeurs manquantes (NA).\n\n\n\n13.2.1 Création\nIl est possible d’indiquer des valeurs à considérer comme manquantes (user NAs) de deux manières :\n\nsoit en indiquant une liste de valeurs individuelles avec labelled::na_values() (on peut indiquer NULL pour supprimer les déclarations existantes) ;\nsoit en indiquant deux valeurs représentant une plage de valeurs à considérées comme manquantes avec labelled::na_range() (seront considérées comme manquantes toutes les valeurs supérieures ou égale au premier chiffre et inférieures ou égales au second chiffre1).\n\n1 On peut utiler -Inf et Inf qui représentent respectivement moins l’infini et l’infini.\nv &lt;- c(1, 2, 3, 9, 1, 3, 2, NA)\nval_labels(v) &lt;- c(\n  faible = 1, \n  fort = 3, \n  \"ne sait pas\" = 9\n)\nna_values(v) &lt;- 9\nv\n\n&lt;labelled_spss&lt;double&gt;[8]&gt;\n[1]  1  2  3  9  1  3  2 NA\nMissing values: 9\n\nLabels:\n value       label\n     1      faible\n     3        fort\n     9 ne sait pas\n\nna_values(v) &lt;- NULL\nv\n\n&lt;labelled&lt;double&gt;[8]&gt;\n[1]  1  2  3  9  1  3  2 NA\n\nLabels:\n value       label\n     1      faible\n     3        fort\n     9 ne sait pas\n\nna_range(v) &lt;- c(5, Inf)\nv\n\n&lt;labelled_spss&lt;double&gt;[8]&gt;\n[1]  1  2  3  9  1  3  2 NA\nMissing range:  [5, Inf]\n\nLabels:\n value       label\n     1      faible\n     3        fort\n     9 ne sait pas\n\n\nOn peut noter que les user NAs peuvent cohabiter avec des regular NAs ainsi qu’avec des étiquettes de valeurs (value labels, cf. Chapitre 12).\nPour manipuler les variables d’un tableau de données, on peut également avoir recours à labelled::set_na_values() et labelled::set_na_range().\n\ndf &lt;- \n  dplyr::tibble(\n    s1 = c(\"M\", \"M\", \"F\", \"F\"), \n    s2 = c(1, 1, 2, 9)\n  ) |&gt; \n  set_na_values(s2 = 9)\ndf$s2\n\n&lt;labelled_spss&lt;double&gt;[4]&gt;\n[1] 1 1 2 9\nMissing values: 9\n\ndf &lt;- \n  df |&gt; \n  set_na_values(s2 = NULL)\ndf$s2\n\n&lt;labelled&lt;double&gt;[4]&gt;\n[1] 1 1 2 9\n\n\n\n13.2.2 Tests\nLa fonction is.na() est l’une des rares fonctions de base R à reconnaître les user NAs et donc à renvoyer TRUE dans ce cas. Pour des tests plus spécifiques, on aura recours à labelled::is_user_na() et labelled::is_regular_na().\n\nv\n\n&lt;labelled_spss&lt;double&gt;[8]&gt;\n[1]  1  2  3  9  1  3  2 NA\nMissing range:  [5, Inf]\n\nLabels:\n value       label\n     1      faible\n     3        fort\n     9 ne sait pas\n\nv |&gt; is.na()\n\n[1] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE\n\nv |&gt; is_user_na()\n\n[1] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE\n\nv |&gt; is_regular_na()\n\n[1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE\n\n\n\n13.2.3 Conversion\nComme dit précédemment, pour la plupart des fonctions de R, les users NAs sont toujours des valeurs valides.\n\nx &lt;- c(1:5, 11:15)\nna_range(x) &lt;- c(10, Inf)\nx\n\n&lt;labelled_spss&lt;integer&gt;[10]&gt;\n [1]  1  2  3  4  5 11 12 13 14 15\nMissing range:  [10, Inf]\n\nmean(x)\n\n[1] 8\n\n\nOn aura alors recours à labelled::user_na_to_regular_na() pour convertir les users NAs en véritables valeurs manquantes avant de procéder à un calcul statistique.\n\nx |&gt; \n  user_na_to_na()\n\n&lt;labelled&lt;integer&gt;[10]&gt;\n [1]  1  2  3  4  5 NA NA NA NA NA\n\nx |&gt; \n  user_na_to_na() |&gt; \n  mean(na.rm = TRUE)\n\n[1] 3\n\n\nUne alternative consiste à transformer les user NAs en tagged NAs avec labelled::user_na_to_tagged_na().\n\nx |&gt; \n  user_na_to_tagged_na() |&gt; \n  print_tagged_na()\n\n'x' has been converted into a double vector.\n\n\n [1]     1     2     3     4     5 NA(a) NA(b) NA(c) NA(d) NA(e)\n\nx |&gt; \n  user_na_to_tagged_na() |&gt; \n  mean(na.rm = TRUE)\n\n'x' has been converted into a double vector.\n\n\n[1] 3\n\n\nPour supprimer les métadonnées relatives aux user NAs sans les convertir en valeurs manquantes, on aura recours à labelled::remove_user_na().\n\nx |&gt;\n  remove_user_na()\n\n&lt;labelled&lt;integer&gt;[10]&gt;\n [1]  1  2  3  4  5 11 12 13 14 15\n\nx |&gt; \n  remove_user_na() |&gt; \n  mean()\n\n[1] 8\n\n\nEnfin, lorsque l’on convertit un vecteur labellisé en facteur avec labelled::to_factor(), on pourra utiliser l’argument user_na_to_na pour indiquer si les users NAs doivent être convertis ou non en valeurs manquantes classiques (NA).\n\nx &lt;- c(1, 2, 9, 2)\nval_labels(x) &lt;- c(oui = 1, non = 2, refus = 9)\nna_values(x) &lt;- 9\nx |&gt;\n  to_factor(user_na_to_na = TRUE)\n\n[1] oui  non  &lt;NA&gt; non \nLevels: oui non\n\nx |&gt;\n  to_factor(user_na_to_na = FALSE)\n\n[1] oui   non   refus non  \nLevels: oui non refus",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Valeurs manquantes</span>"
    ]
  },
  {
    "objectID": "manipulation/import-export.html",
    "href": "manipulation/import-export.html",
    "title": "14  Import & Export de données",
    "section": "",
    "text": "14.1 Importer un fichier texte\nLes fichiers texte constituent un des formats les plus largement supportés par la majorité des logiciels statistiques. Presque tous permettent d’exporter des données dans un format texte, y compris les tableurs comme Libre Office, Open Office ou Excel.\nCependant, il existe une grande variétés de format texte, qui peuvent prendre différents noms selon les outils, tels que texte tabulé ou texte (séparateur : tabulation), CSV (pour comma-separated value, sachant que suivant les logiciels le séparateur peut être une virgule ou un point-virgule).",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Import & Export de données</span>"
    ]
  },
  {
    "objectID": "manipulation/import-export.html#importer-un-fichier-texte",
    "href": "manipulation/import-export.html#importer-un-fichier-texte",
    "title": "14  Import & Export de données",
    "section": "",
    "text": "14.1.1 Structure d’un fichier texte\nDès lors, avant d’importer un fichier texte dans R, il est indispensable de regarder comment ce dernier est structuré. Il importe de prendre note des éléments suivants :\n\nLa première ligne contient-elle le nom des variables ?\nQuel est le caractère séparateur entre les différentes variables (encore appelé séparateur de champs) ? Dans le cadre d’un fichier CSV, il aurait pu s’agir d’une virgule ou d’un point-virgule.\nQuel est le caractère utilisé pour indiquer les décimales (le séparateur décimal) ? Il s’agit en général d’un point (à l’anglo-saxonne) ou d’une virgule (à la française).\nLes valeurs textuelles sont-elles encadrées par des guillemets et, si oui, s’agit-il de guillemets simple (') ou de guillemets doubles (\") ?\nPour les variables textuelles, y a-t-il des valeurs manquantes et si oui comment sont-elles indiquées ? Par exemple, le texte NA est parfois utilisé.\n\nIl ne faut pas hésitez à ouvrir le fichier avec un éditeur de texte pour le regarder de plus près.\n\n14.1.2 Interface graphique avec RStudio\nRStudio fournit une interface graphique pour faciliter l’import d’un fichier texte. Pour cela, il suffit d’aller dans le menu File &gt; Import Dataset et de choisir l’option From CSV1. Cette option est également disponible via l’onglet Environment dans le quadrant haut-droite.\n1 L’option CSV fonctionne pour tous les fichiers de type texte, même si votre fichier a une autre extension, .txt par exemplePour la suite, nous allons utiliser ce fichier texte à titre d’exemple.\n\n\n\n\n\nFigure 14.1: Importer un fichier texte avec RStudio\n\n\nL’interface de RStudio vous présente sous Import Options les différentes options d’import disponible. La section Data Preview vous permet de voir en temps réel comment les données sont importées. La section Code Preview vous indique le code R correspondant à vos choix. Il n’y a plus qu’à le copier/coller dans un de vos scripts ou à cliquer sur Import pour l’exécuter.\nVous pourrez remarquer que RStudio fait appel à l’extension readr du tidyverse pour l’import des données via la fonction readr::read_csv().\nreadr essaie de deviner le type de chacune des colonnes, en se basant sur les premières observations. En cliquant sur le nom d’une colonne, il est possible de modifier le type de la variable importée. Il est également possible d’exclure une colonne de l’import (skip).\n\n14.1.3 Dans un script\nL’interface graphique de RStudio fournit le code d’import. On peut également l’adapter à ces besoins en consultant la page d’aide de readr::read_csv() pour plus de détails. Par exemple :\n\nlibrary(readr)\nd &lt;- read_delim(\n  \"http://larmarange.github.io/analyse-R/data/exemple_texte_tabule.txt\", \n  delim = \"\\t\", \n  quote = \"'\"\n)\n\nOn peut indiquer le chemin local vers un fichier (le plus courant) ou bien directement l’URL d’un fichier sur Internet.\nreadr propose plusieurs fonctions proches : readr::read_delim(), readr::read_csv(), readr::read_csv2() et readr::read_tsv(). Elles fonctionnent toutes de manière identique et ont les mêmes arguments. Seule différence, les valeurs par défaut de certains paramètres.\n\n\n\n\n\n\nFichiers de très grande taille\n\n\n\nSi vous travaillez sur des données de grandes dimensions, les formats texte peuvent être lents à exporter et importer. Dans ce cas là, on pourra jeter un œil au package vroom et/ou aux fonctions data.table::fread() et data.table::fwrite().\n\n\n\nDans des manuels ou des exemples en ligne, vous trouverez parfois mention des fonctions utils::read.table(), utils::read.csv(), utils::read.csv2(), utils::read.delim() ou encore utils::read.delim2(). Il s’agit des fonctions natives et historiques de R (extension {utils}) dédiées à l’import de fichiers textes. Elles sont similaires à celles de readr dans l’idée générale mais diffèrent dans leurs détails et les traitements effectués sur les données (pas de détection des dates par exemple). Pour plus d’information, vous pouvez vous référer à la page d’aide de ces fonctions.",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Import & Export de données</span>"
    ]
  },
  {
    "objectID": "manipulation/import-export.html#importer-un-fichier-excel",
    "href": "manipulation/import-export.html#importer-un-fichier-excel",
    "title": "14  Import & Export de données",
    "section": "\n14.2 Importer un fichier Excel",
    "text": "14.2 Importer un fichier Excel\nUne première approche pour importer des données Excel dans R consiste à les exporter depuis Excel dans un fichier texte (texte tabulé ou CSV) puis de suivre la procédure d’importation d’un fichier texte.\nUne feuille Excel peut également être importée directement avec l’extension readxl du tidyverse.\nLa fonction readxl::read_excel() permet d’importer à la fois des fichiers .xls (Excel 2003 et précédents) et .xlsx (Excel 2007 et suivants).\n\nlibrary(readxl)\ndonnees &lt;- read_excel(\"data/fichier.xlsx\")\n\nUne seule feuille de calculs peut être importée à la fois. On pourra préciser la feuille désirée avec sheet en indiquant soit le nom de la feuille, soit sa position (première, seconde, …).\n\ndonnees &lt;- read_excel(\"data/fichier.xlsx\", sheet = 3)\ndonnees &lt;- read_excel(\"data/fichier.xlsx\", sheet = \"mes_donnees\")\n\nOn pourra préciser avec col_names si la première ligne contient le nom des variables.\nPar défaut, readxl::read_excel() va essayer de deviner le type (numérique, textuelle, date) de chaque colonne. Au besoin, on pourra indiquer le type souhaité de chaque colonne avec col_types.\nRStudio propose également pour les fichiers Excel un assistant d’importation, similaire à celui pour les fichiers texte, permettant de faciliter l’import.",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Import & Export de données</span>"
    ]
  },
  {
    "objectID": "manipulation/import-export.html#importer-depuis-des-logiciels-de-statistique",
    "href": "manipulation/import-export.html#importer-depuis-des-logiciels-de-statistique",
    "title": "14  Import & Export de données",
    "section": "\n14.3 Importer depuis des logiciels de statistique",
    "text": "14.3 Importer depuis des logiciels de statistique\nLe package haven du tidyverse a été développé spécifiquement pour permettre l’importation de données depuis les formats des logiciels Stata, SAS et SPSS.\nIl vise à offrir une importation unifiée depuis ces trois logiciels (là où le package foreign distribué en standard avec R adopte des conventions différentes selon le logiciel source).\nAfin de ne pas perdre d’information lors de l’import, haven a introduit la notion d’étiquettes de variables (cf. Chapitre 11), une classe de vecteurs pour la gestion des étiquettes de valeurs (cf. Chapitre 12), des mécanismes pour reproduire la gestion des valeurs manquantes de ces trois logiciels (cf. Chapitre 13), mais également une gestion et un import correct des dates, dates-heures et des variables horaires (cf. le package hms).\nÀ noter que RStudio intègre également une interface graphique pour l’import des fichiers Stata, SAS et SPSS.\n\n14.3.1 SPSS\nLes fichiers générés par SPSS sont de deux types : les fichiers SPSS natifs (extension .sav) et les fichiers au format SPSS export (extension .por).\nDans les deux cas, on aura recours à la fonction haven::read_spss() :\n\nlibrary(haven)\ndonnees &lt;- read_spss(\"data/fichier.sav\", user_na = TRUE)\n\n\n\n\n\n\n\nValeurs manquantes\n\n\n\nDans SPSS, il est possible de définir des valeurs à considérées comme manquantes ou user NAs, voir Chapitre 13. Par défaut, haven::read_spss() convertir toutes ces valeurs en NA lors de l’import.\nOr, il est parfois important de garder les différentes valeurs originelles. Dans ce cas, on appellera haven::read_spss() avec l’option user_na = TRUE.\n\n\n\n14.3.2 SAS\nLes fichiers SAS se présentent en général sous deux format : format SAS export (extension .xport ou .xpt) ou format SAS natif (extension .sas7bdat).\nLes fichiers SAS natifs peuvent être importées directement avec haven::read_sas() de l’extension haven :\n\nlibrary(haven)\ndonnees &lt;- read_sas(\"data/fichier.sas7bdat\")\n\nAu besoin, on pourra préciser en deuxième argument le nom d’un fichier SAS catalogue (extension .sas7bcat) contenant les métadonnées du fichier de données.\n\nlibrary(haven)\ndonnees &lt;- read_sas(\n  \"data/fichier.sas7bdat\", \n  catalog_file = \"data/fichier.sas7bcat\"\n)\n\n\n\n\n\n\n\nNote\n\n\n\nLes fichiers au format SAS export peuvent être importés via la fonction foreign::read.xport() de l’extension foreign. Celle-ci s’utilise très simplement, en lui passant le nom du fichier en argument :\n\nlibrary(foreign)\ndonnees &lt;- read.xport(\"data/fichier.xpt\")\n\n\n\n\n14.3.3 Stata\nPour les fichiers Stata (extension .dta), on aura recours aux fonctions haven::read_dta() et haven::read_stata() de l’extension haven. Ces deux fonctions sont identiques.\n\nlibrary(haven)\ndonnees &lt;- read_dta(\"data/fichier.dta\")\n\n\n\n\n\n\n\nImportant\n\n\n\nGestion des valeurs manquantes\nDans Stata, il est possible de définir plusieurs types de valeurs manquantes, qui sont notées sous la forme .a à .z. Elles sont importées par haven sous formes de tagged NAs, cf. Chapitre 13.\n\n\n\n14.3.4 dBase\nL’Insee et d’autres producteur de données diffusent leurs fichiers au format dBase (extension .dbf). Ceux-ci sont directement lisibles dans R avec la fonction foreign::read.dbf() de l’extension foreign.\n\nlibrary(foreign)\ndonnees &lt;- read.dbf(\"data/fichier.dbf\")",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Import & Export de données</span>"
    ]
  },
  {
    "objectID": "manipulation/import-export.html#sauver-ses-données",
    "href": "manipulation/import-export.html#sauver-ses-données",
    "title": "14  Import & Export de données",
    "section": "\n14.4 Sauver ses données",
    "text": "14.4 Sauver ses données\nR dispose également de son propre format pour sauvegarder et échanger des données. On peut sauver n’importe quel objet créé avec R et il est possible de sauver plusieurs objets dans un même fichier. L’usage est d’utiliser l’extension .RData pour les fichiers de données R. La fonction à utiliser s’appelle tout simplement save().\nPar exemple, si l’on souhaite sauvegarder son tableau de données d ainsi que les objets tailles et poids dans un fichier export.RData :\n\nsave(d, tailles, poids, file = \"export.RData\")\n\nÀ tout moment, il sera toujours possible de recharger ces données en mémoire à l’aide de la fonction load() :\n\nload(\"export.RData\")\n\n\n\n\n\n\n\nMise en garde\n\n\n\nSi entre temps vous aviez modifié votre tableau d, vos modifications seront perdues. En effet, si lors du chargement de données, un objet du même nom existe en mémoire, ce dernier sera remplacé par l’objet importé.\n\n\nLa fonction save.image() est un raccourci pour sauvegarder tous les objets de la session de travail dans le fichier .RData (un fichier un peu étrange car il n’a pas de nom mais juste une extension). Lors de la fermeture de RStudio, il vous sera demandé si vous souhaitez enregistrer votre session. Si vous répondez Oui, c’est cette fonction save.image() qui sera appliquée.\n\nsave.image()\n\nUn autre mécanisme possible est le format RDS de R. La fonction saveRDS() permet de sauvegarder un et un seul objet R dans un fichier.\n\nsaveRDS(d, file = \"mes_donnees.rds\")\n\nCet objet pourra ensuite être lu avec la fonction readRDS(). Mais au lieu d’être directement chargé dans la mémoire de l’environnement de travail, l’objet lu sera retourné par la fonction readRDS() et ce sera à l’utilisateur de le sauvegarder.\n\ndonnees &lt;- readRDS(\"mes_donnees.rds\")",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Import & Export de données</span>"
    ]
  },
  {
    "objectID": "manipulation/import-export.html#export-de-tableaux-de-données",
    "href": "manipulation/import-export.html#export-de-tableaux-de-données",
    "title": "14  Import & Export de données",
    "section": "\n14.5 Export de tableaux de données",
    "text": "14.5 Export de tableaux de données\nOn peut avoir besoin d’exporter un tableau de données R vers différents formats. La plupart des fonctions d’import disposent d’un équivalent permettant l’export de données. On citera notamment :\n\n\nreadr::write_csv() et readr::write_tsv() permettent d’exporter au format CSV et texte tabulé respectivement, readr::write_delim() offrant de multiples options pour l'export au format texte ;\n\nhaven::write_sas() permet d’exporter au format SAS ;\n\n\nhaven::write_sav() au format SPSS ;\n\n\nhaven::write_dta() au format Stata ;\n\n\nforeign::write.dbf() au format dBase.\n\nL’extension readxl ne fournit pas de fonction pour exporter au format Excel. Par contre, on pourra passer par la fonction openxlsx::write.xlsx() du package openxlsx ou la fonction xlsx::write.xlsx() de l’extension xlsx. L’intérêt de openxlsx est de ne pas dépendre de Java à la différence de xlsx.\n\n\n\nFigure 14.1: Importer un fichier texte avec RStudio",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Import & Export de données</span>"
    ]
  },
  {
    "objectID": "manipulation/formater-nombre.html",
    "href": "manipulation/formater-nombre.html",
    "title": "15  Mettre en forme des nombres",
    "section": "",
    "text": "15.1 label_number()\nscales::label_number() est la fonction de base de mise en forme de nombres dans scales, une majorité des autres fonctions faisant appel à scales::label_number() et partageant les mêmes arguments.\nLe paramètre accurary permets de définir le niveau d’arrondi à utiliser. Par exemple, .1 pour afficher une seule décimale. Il est aussi possible d’indiquer un nombre qui n’est pas une puissance de 10 (par exemple .25). Si on n’indique rien (NULL), alors scales::label_number() essaiera de deviner un nombre de décimales pertinent en fonction des valeurs du vecteur de nombres à mettre en forme.\nlabel_number(accuracy = NULL)(x)\n\n[1] \"0.00\"         \"0.12\"         \"4.57\"         \"874.44\"       \"8 957 845.00\"\n\nlabel_number(accuracy = .1)(x)\n\n[1] \"0.0\"         \"0.1\"         \"4.6\"         \"874.4\"       \"8 957 845.0\"\n\nlabel_number(accuracy = .25)(x)\n\n[1] \"0.0\"         \"0.0\"         \"4.5\"         \"874.5\"       \"8 957 845.0\"\n\nlabel_number(accuracy = 10)(x)\n\n[1] \"0\"         \"0\"         \"0\"         \"870\"       \"8 957 840\"\nL’option scale permets d’indiquer un facteur multiplicatif à appliquer avant de mettre en forme. On utilisera le plus souvent les options prefix et suffix en même temps pour indiquer les unités.\nlabel_number(scale = 100, suffix = \"%\")(x) # pour cent\n\n[1] \"0%\"           \"12%\"          \"457%\"         \"87 444%\"      \"895 784 500%\"\n\nlabel_number(scale = 1000, suffix = \"\\u2030\")(x) # pour mille\n\n[1] \"2‰\"             \"123‰\"           \"4 567‰\"         \"874 440‰\"      \n[5] \"8 957 845 000‰\"\n\nlabel_number(scale = .001, suffix = \" milliers\", accuracy = .1)(x)\n\n[1] \"0.0 milliers\"     \"0.0 milliers\"     \"0.0 milliers\"     \"0.9 milliers\"    \n[5] \"8 957.8 milliers\"\nLes arguments decimal.mark et big.mark permettent de définir, respectivement, le séparateur de décimale et le séparateur de milliers. Ainsi, pour afficher des nombres à la française (virgule pour les décimales, espace pour les milliers) :\nlabel_number(decimal.mark = \",\", big.mark = \" \")(x)\n\n[1] \"0,00\"         \"0,12\"         \"4,57\"         \"874,44\"       \"8 957 845,00\"\nNote : il est possible d’utiliser small.interval et small.mark pour ajouter des séparateurs parmi les décimales.\nlabel_number(accuracy = 10^-9, small.mark = \"|\", small.interval = 3)(x)\n\n[1] \"0.002|300|000\"         \"0.123|000|000\"         \"4.567|000|000\"        \n[4] \"874.440|000|000\"       \"8 957 845.000|000|000\"\nLes options style_positive et style_negative permettent de personnaliser la manière dont les valeurs positives et négatives sont mises en forme.\ny &lt;- c(-1.2, -0.3, 0, 2.4, 7.2)\nlabel_number(style_positive = \"plus\")(y)\n\n[1] \"-1.2\" \"-0.3\" \"0.0\"  \"+2.4\" \"+7.2\"\n\nlabel_number(style_negative = \"parens\")(y)\n\n[1] \"(1.2)\" \"(0.3)\" \"0.0\"   \"2.4\"   \"7.2\"\nL’option scale_cut permet d’utiliser, entre autres, les préfixes du Système international d’unités les plus proches et arrondi chaque valeur en fonction, en ajoutant la précision correspondante. Par exemple, pour des données en grammes :\ny &lt;- c(.000004536, .01245, 2.3456, 47589.14, 789456244)\nlabel_number(scale_cut = cut_si(\"g\"), accuracy = .1)(y)\n\n[1] \"4.5 µg\"   \"12.4 mg\"  \"2.3 g\"    \"47.6 kg\"  \"789.5 Mg\"",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Mettre en forme des nombres</span>"
    ]
  },
  {
    "objectID": "manipulation/formater-nombre.html#les-autres-fonctions-de-scales",
    "href": "manipulation/formater-nombre.html#les-autres-fonctions-de-scales",
    "title": "15  Mettre en forme des nombres",
    "section": "\n15.2 Les autres fonctions de {scales}\n",
    "text": "15.2 Les autres fonctions de {scales}\n\n\n15.2.1 label_comma()\n\nscales::label_comma() (et scales::comma()) est une variante de scales::label_number() qui, par défaut, affiche les nombres à l’américaine, avec une virgule comme séparateur de milliers.\n\nlabel_comma()(x)\n\n[1] \"0.00\"         \"0.12\"         \"4.57\"         \"874.44\"       \"8,957,845.00\"\n\n\n\n15.2.2 label_percent()\n\nscales::label_percent() (et scales::percent()) est une variante de scales::label_number() qui affiche les nombres sous formes de pourcentages (les options par défaut sont scale = 100, suffix = \"%\").\n\nlabel_percent()(x)\n\n[1] \"0%\"           \"12%\"          \"457%\"         \"87 444%\"      \"895 784 500%\"\n\n\nOn peut utiliser cette fonction pour afficher des résultats en pour mille (le code Unicode du symbole ‰ étant u2030) :\n\nlabel_percent(scale = 1000, suffix = \"\\u2030\")(x)\n\n[1] \"2‰\"             \"123‰\"           \"4 567‰\"         \"874 440‰\"      \n[5] \"8 957 845 000‰\"\n\n\n\n15.2.3 label_dollar()\n\nscales::label_dollar() est adapté à l’affichage des valeurs monétaires.\n\nlabel_dollar()(x)\n\n[1] \"$0\"         \"$0\"         \"$5\"         \"$874\"       \"$8,957,845\"\n\nlabel_dollar(prefix = \"\", suffix = \" €\", accuracy = .01, big.mark = \" \")(x)\n\n[1] \"0.00 €\"         \"0.12 €\"         \"4.57 €\"         \"874.44 €\"      \n[5] \"8 957 845.00 €\"\n\n\nL’option style_negative permet d’afficher les valeurs négatives avec des parenthèses, convention utilisée dans certaines disciplines.\n\nlabel_dollar()(c(12.5, -4, 21, -56.36))\n\n[1] \"$12.50\"  \"-$4.00\"  \"$21.00\"  \"-$56.36\"\n\nlabel_dollar(style_negative = \"parens\")(c(12.5, -4, 21, -56.36))\n\n[1] \"$12.50\"   \"($4.00)\"  \"$21.00\"   \"($56.36)\"\n\n\n\n15.2.4 label_pvalue()\n\nscales::label_pvalue() est adapté pour la mise en forme de p-valeurs.\n\nlabel_pvalue()(c(0.000001, 0.023, 0.098, 0.60, 0.9998))\n\n[1] \"&lt;0.001\" \"0.023\"  \"0.098\"  \"0.600\"  \"&gt;0.999\"\n\nlabel_pvalue(accuracy = .01, add_p = TRUE)(c(0.000001, 0.023, 0.098, 0.60))\n\n[1] \"p&lt;0.01\" \"p=0.02\" \"p=0.10\" \"p=0.60\"\n\n\n\n15.2.5 label_scientific()\n\nscales::label_scientific() affiche les nombres dans un format scientifique (avec des puissances de 10).\n\nlabel_scientific(unit = \"g\")(c(.00000145, .0034, 5, 12478, 14569787))\n\n[1] \"1.45e-06\" \"3.40e-03\" \"5.00e+00\" \"1.25e+04\" \"1.46e+07\"\n\n\n\n15.2.6 label_bytes()\n\nscales::label_bytes() mets en forme des tailles exprimées en octets, utilisant au besoin des multiples de 1024.\n\nb &lt;- c(478, 1235468, 546578944897)\nlabel_bytes()(b)\n\n[1] \"478 B\"  \"1 MB\"   \"547 GB\"\n\nlabel_bytes(units = \"auto_binary\")(b)\n\n[1] \"478 iB\"  \"1 MiB\"   \"509 GiB\"\n\n\n\n15.2.7 label_ordinal()\n\nscales::label_ordinal() permets d’afficher des rangs ou nombres ordinaux. Plusieurs langues sont disponibles.\n\nlabel_ordinal()(1:5)\n\n[1] \"1st\" \"2nd\" \"3rd\" \"4th\" \"5th\"\n\nlabel_ordinal(rules = ordinal_french())(1:5)\n\n[1] \"1er\" \"2e\"  \"3e\"  \"4e\"  \"5e\" \n\nlabel_ordinal(rules = ordinal_french(gender = \"f\", plural = TRUE))(1:5)\n\n[1] \"1res\" \"2es\"  \"3es\"  \"4es\"  \"5es\" \n\n\n\n15.2.8 label_date(), label_date_short() & label_time()\n\nscales::label_date(), scales::label_date_short() et scales::label_time() peuvent être utilisées pour la mise en forme de dates.\n\nlabel_date()(as.Date(\"2020-02-14\"))\n\n[1] \"2020-02-14\"\n\nlabel_date(format = \"%d/%m/%Y\")(as.Date(\"2020-02-14\"))\n\n[1] \"14/02/2020\"\n\nlabel_date_short()(as.Date(\"2020-02-14\"))\n\n[1] \"14\\nfévr.\\n2020\"\n\n\nLa mise en forme des dates est un peu complexe. Ne pas hésiter à consulter le fichier d’aide de la fonction base::strptime() pour plus d’informations.\n\n15.2.9 label_wrap()\n\nLa fonction scales::label_wrap() est un peu différente. Elle permets d’insérer des retours à la ligne (\\n) dans des chaines de caractères. Elle tient compte des espaces pour identifier les mots et éviter ainsi des coupures au milieu d’un mot.\n\nx &lt;- \"Ceci est un texte assez long et que l'on souhaiterait afficher sur plusieurs lignes. Cependant, on souhaite éviter que des coupures apparaissent au milieu d'un mot.\"\nlabel_wrap(80)(x)\n\n[1] \"Ceci est un texte assez long et que l'on souhaiterait afficher sur plusieurs\\nlignes. Cependant, on souhaite éviter que des coupures apparaissent au milieu\\nd'un mot.\"\n\nlabel_wrap(80)(x) |&gt; message()\n\nCeci est un texte assez long et que l'on souhaiterait afficher sur plusieurs\nlignes. Cependant, on souhaite éviter que des coupures apparaissent au milieu\nd'un mot.\n\nlabel_wrap(40)(x) |&gt; message()\n\nCeci est un texte assez long et que\nl'on souhaiterait afficher sur\nplusieurs lignes. Cependant, on\nsouhaite éviter que des coupures\napparaissent au milieu d'un mot.",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Mettre en forme des nombres</span>"
    ]
  },
  {
    "objectID": "manipulation/formater-nombre.html#les-fonctions-de-formatage-de-gtsummary",
    "href": "manipulation/formater-nombre.html#les-fonctions-de-formatage-de-gtsummary",
    "title": "15  Mettre en forme des nombres",
    "section": "\n15.3 Les fonctions de formatage de {gtsummary}\n",
    "text": "15.3 Les fonctions de formatage de {gtsummary}\n\nVéritable couteau-suisse du statisticien, le package gtsummary sera largement utilisé dans les prochains chapitres pour produire des tableaux statistiques prêts à être publiés.\nCe package utilise par défaut ses propres fonctions de formatage mais, au besoin, il sera toujours possible de lui transmettre des fonctions de formatage créées avec scales.\n\n15.3.1 style_number()\n\nFonction de base, gtsummary::style_number() accepte les paramètres big.mark (séparateur de milliers), decimal.mark (séparateur de décimales) et scale (facteur d’échelle). Le nombre de décimales se précisera quant à lui avec digits où l’on indiquera le nombre de décimales souhaité.\n\nlibrary(gtsummary)\nx &lt;- c(0.123, 0.9, 1.1234, 12.345, -0.123, -0.9, -1.1234, -132.345)\nstyle_number(x, digits = 1)\n\n[1] \"0.1\"    \"0.9\"    \"1.1\"    \"12.3\"   \"-0.1\"   \"-0.9\"   \"-1.1\"   \"-132.3\"\n\n\n\n\n\n\n\n\nAstuce\n\n\n\nNous verrons dans le chapitre sur les statistiques univariées (cf. Section 18.2.1) la fonction gtsummary::theme_gtsummary_language() qui permet de fixer globalement le séparateur de milliers et celui des décimales, afin de changer les valeurs par défaut de l’ensemble des fonctions de formatage de gtsummary.\nIl est important de noter que cela n’a aucun effet sur les fonctions de formatage de scales.\n\n\n\n\n\n\n\n\nMise en garde\n\n\n\ngtsummary::style_number() est directement une fonction de formatage (comme scales::number()) et non une fonction qui génère une fonction de formatage (comme scales::label::number()).\nPour créer une fonction de formatage personnalisée, on pourra avoir recours à purrr::partial() qui permet d’appeler partiellement une fonction et qui renvoie une nouvelle fonction avec des paramètres par défaut personnalisés.\n\nfr &lt;- style_number |&gt;\n  purrr::partial(decimal.mark = \",\", digits = 1)\nfr(x)\n\n[1] \"0,1\"    \"0,9\"    \"1,1\"    \"12,3\"   \"-0,1\"   \"-0,9\"   \"-1,1\"   \"-132,3\"\n\n\n\n\n\n15.3.2 style_sigfig()\n\nVariante de gtsummary::style_number(), gstummary::style_sigfig() arrondi les valeurs transmises pour n’afficher qu’un nombre choisi de chiffres significatifs. Le nombre de décimales peut ainsi varier.\n\nstyle_sigfig(x)\n\n[1] \"0.12\"  \"0.90\"  \"1.1\"   \"12\"    \"-0.12\" \"-0.90\" \"-1.1\"  \"-132\" \n\nstyle_sigfig(x, digits = 3)\n\n[1] \"0.123\"  \"0.900\"  \"1.12\"   \"12.3\"   \"-0.123\" \"-0.900\" \"-1.12\"  \"-132\"  \n\n\n\n15.3.3 style_percent()\n\nLa fonction gtsummary::style_percent() a un fonctionnement un peu différent de celui de scales::label_percent(). Par défaut, le symbole % n’est pas affiché (mais paramétrable avec symbol = TRUE. Par défaut, une décimale est affichée pour les valeurs inférieures à 10% et aucune pour celles supérieures à 10%. Un symbole &lt; est ajouté devant les valeurs strictement positives inférieures à 0,1%.\n\nv &lt;- c(0, 0.0001, 0.005, 0.01, 0.10, 0.45356, 0.99, 1.45)\nlabel_percent(accuracy = .1)(v)\n\n[1] \"0.0%\"   \"0.0%\"   \"0.5%\"   \"1.0%\"   \"10.0%\"  \"45.4%\"  \"99.0%\"  \"145.0%\"\n\nstyle_percent(v)\n\n[1] \"0\"    \"&lt;0.1\" \"0.5\"  \"1.0\"  \"10\"   \"45\"   \"99\"   \"145\" \n\nstyle_percent(v, symbol = TRUE)\n\n[1] \"0%\"    \"&lt;0.1%\" \"0.5%\"  \"1.0%\"  \"10%\"   \"45%\"   \"99%\"   \"145%\" \n\nstyle_percent(v, digits = 1)\n\n[1] \"0\"     \"0.01\"  \"0.50\"  \"1.00\"  \"10.0\"  \"45.4\"  \"99.0\"  \"145.0\"\n\n\n\n15.3.4 style_pvalue()\n\nLa fonction gtsummary::style_pvalue() est similaire à scales::label_pvalue() mais adapte le nombre de décimales affichées,\n\np &lt;- c(0.000001, 0.023, 0.098, 0.60, 0.9998)\nlabel_pvalue()(p)\n\n[1] \"&lt;0.001\" \"0.023\"  \"0.098\"  \"0.600\"  \"&gt;0.999\"\n\nstyle_pvalue(p)\n\n[1] \"&lt;0.001\" \"0.023\"  \"0.10\"   \"0.6\"    \"&gt;0.9\"  \n\nstyle_pvalue(p, prepend_p = TRUE)\n\n[1] \"p&lt;0.001\" \"p=0.023\" \"p=0.10\"  \"p=0.6\"   \"p&gt;0.9\"  \n\n\n\n15.3.5 style_ratio()\n\nEnfin, gtsummary::style_ratio() est adaptée à l’affichage de ratios.\n\nr &lt;- c(0.123, 0.9, 1.1234, 12.345, 101.234, -0.123, -0.9, -1.1234, -12.345, -101.234)\nstyle_ratio(r)\n\n [1] \"0.12\"  \"0.90\"  \"1.12\"  \"12.3\"  \"101\"   \"-0.12\" \"-0.90\" \"-1.12\" \"-12.3\"\n[10] \"-101\"",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Mettre en forme des nombres</span>"
    ]
  },
  {
    "objectID": "manipulation/formater-nombre.html#bonus-signif_stars-de-ggstats",
    "href": "manipulation/formater-nombre.html#bonus-signif_stars-de-ggstats",
    "title": "15  Mettre en forme des nombres",
    "section": "\n15.4 Bonus : signif_stars() de {ggstats}\n",
    "text": "15.4 Bonus : signif_stars() de {ggstats}\n\nLa fonction ggstats::signif_stars() de ggstats permet d’afficher des p-valeurs sous forme d’étoiles de significativité. Par défaut, trois astérisques si p &lt; 0,001, deux si p &lt; 0,01, une si p &lt; 0,05 et un point si p &lt; 0,10. Les valeurs sont bien sur paramétrables.\n\np &lt;- c(0.5, 0.1, 0.05, 0.01, 0.001)\nggstats::signif_stars(p)\n\n[1] \"\"    \".\"   \"*\"   \"**\"  \"***\"\n\nggstats::signif_stars(p, one = .15, point = NULL)\n\n[1] \"\"    \"*\"   \"*\"   \"**\"  \"***\"",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Mettre en forme des nombres</span>"
    ]
  },
  {
    "objectID": "manipulation/formater-nombre.html#section",
    "href": "manipulation/formater-nombre.html#section",
    "title": "15  Mettre en forme des nombres",
    "section": "\n15.5 ",
    "text": "15.5",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Mettre en forme des nombres</span>"
    ]
  },
  {
    "objectID": "manipulation/couleurs.html",
    "href": "manipulation/couleurs.html",
    "title": "16  Couleurs & Palettes",
    "section": "",
    "text": "16.1 Noms de couleur\nLorsque l’on doit indiquer à R une couleur, notamment dans les fonctions graphiques, on peut mentionner certaines couleurs en toutes lettres (en anglais) comme \"red\" ou \"blue\". La liste des couleurs reconnues par R est disponible sur http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf.\nlibrary(tidyverse)\nggplot(iris) +\n  aes(x = Petal.Length) +\n  geom_histogram(colour = \"red\", fill = \"blue\")",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Couleurs & Palettes</span>"
    ]
  },
  {
    "objectID": "manipulation/couleurs.html#couleurs-rvb-et-code-hexadécimal",
    "href": "manipulation/couleurs.html#couleurs-rvb-et-code-hexadécimal",
    "title": "16  Couleurs & Palettes",
    "section": "\n16.2 Couleurs RVB et code hexadécimal",
    "text": "16.2 Couleurs RVB et code hexadécimal\nEn informatique, les couleurs sont usuellement codées en Rouge/Vert/Bleu (voir https://fr.wikipedia.org/wiki/Rouge_vert_bleu) et représentées par un code hexadécimal à 6 caractères (chiffres 0 à 9 et/ou lettres A à F), précédés du symbole #. Ce code est reconnu par R. On pourra par exemple indiquer \"#FF0000\" pour la couleur rouge ou \"#666666\" pour un gris foncé. Le code hexadécimal des différentes couleurs peut s’obtenir aisément sur internet, de nombreux sites étant consacrés aux palettes de couleurs.\n\nggplot(iris) +\n  aes(x = Petal.Length) +\n  geom_histogram(colour = \"#666666\", fill = \"#FF0000\") \n\n\n\n\n\n\n\nParfois, au lieu du code hexadécimal, les couleurs RVB sont indiquées avec trois chiffres entiers compris entre 0 et 255. La conversion en hexadécimal se fait avec la fonction grDevices::rgb().\n\nrgb(255, 0, 0, maxColorValue = 255)\n\n[1] \"#FF0000\"",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Couleurs & Palettes</span>"
    ]
  },
  {
    "objectID": "manipulation/couleurs.html#palettes-de-couleurs",
    "href": "manipulation/couleurs.html#palettes-de-couleurs",
    "title": "16  Couleurs & Palettes",
    "section": "\n16.3 Palettes de couleurs",
    "text": "16.3 Palettes de couleurs\n\n16.3.1 Color Brewer\nLe projet Color Brewer a développé des palettes cartographiques, à la fois séquentielles, divergentes et catégorielles, présentées en détail sur http://colorbrewer2.org/. Pour chaque type de palette, et en fonction du nombre de classes, est indiqué sur ce site si la palette est adaptée aux personnes souffrant de daltonisme, si elle est rendra correctement sur écran, en cas d’impression couleur et en cas d’impression en noir et blanc.\nVoici un aperçu des différentes palettes disponibles :\n\n\n\n\n\n\n\n\nL’extension {RColorBrewer} permets d’accéder à ces palettes sous R.\nSi on utilise ggplot2, les palettes Color Brewer sont directement disponibles via les fonctions ggplot2::scale_fill_brewer() et ggplot2::scale_colour_brewer().\n\n\n\n\n\n\nMise en garde\n\n\n\nLes palettes Color Brewer sont seulement implémentées pour des variables catégorielles. Il est cependant possible de les utiliser avec des variables continues en les combinant avec ggplot2::scale_fill_gradientn() ou ggplot2::scale_coulour_gradientn() (en remplaçant \"Set1\" par le nom de la palette désirée) :\n\nscale_fill_gradientn(values = RColorBrewer::brewer.pal(6, \"Set1\"))\n\n\n\n\n16.3.2 Palettes de Paul Tol\nLe physicien Paul Tol a développé plusieurs palettes de couleurs adaptées aux personnes souffrant de déficit de perception des couleurs (daltonisme). À titre personnel, il s’agit des palettes de couleurs que j’utilise le plus fréquemment.\nLe détail de ses travaux est présenté sur https://personal.sron.nl/~pault/.\nLe package khroma implémente ces palettes de couleurs proposées par Paul Tol afin de pouvoir les utilisées directement dans R et avec {ggplot}.\n\nlibrary(khroma)\nplot_scheme(colour(\"bright\")(7), colours = TRUE)\n\n\n\n\n\n\nggplot(mpg) +\n  aes(x = displ, y = hwy, colour = class) +\n  geom_point() +\n  khroma::scale_colour_bright()\n\n\n\n\n\n\n\n\nplot_scheme(colour(\"muted\")(9), colours = TRUE)\n\n\n\n\n\n\n\n\nplot_scheme(colour(\"PRGn\")(9), colours = TRUE, size = 0.9)\n\n\n\n\n\n\n\nPour la liste complète des palettes disponibles, voir https://packages.tesselle.org/khroma/articles/tol.html.\n\n16.3.3 Interface unifiée avec {paletteer}\n\nL’extension paletteer vise à proposer une interface unifiée pour l’utilisation de palettes de couleurs fournies par d’autres packages (dont khroma, mais aussi par exemple ggsci qui fournit les palettes utilisées par certaines revues scientifiques). Plus de 2 500 palettes sont ainsi disponibles.\nOn peut afficher un aperçu des principales palettes disponibles dans paletteer avec la commande suivante :\n\ngt::info_paletteer()\n\nPour afficher la liste complète des palettes discrètes et continues, on utilisera les commandes suivantes :\n\npalettes_d_names |&gt; View()\npalettes_c_names |&gt; View()\n\nLa fonction paletteer::paletteer_d() permet d’obtenir les codes hexadécimaux d’une palette discrète en précisant le nombre de couleurs attendues. Les fonctions paletteer::scale_color_paletteer_d() et paletteer::scale_fill_paletteer_d() permettront d’utiliser une palette donnée avec ggplot2.\n\nlibrary(paletteer)\npaletteer_d(\"khroma::bright\", n = 5)\n\n&lt;colors&gt;\n#4477AAFF #EE6677FF #228833FF #CCBB44FF #66CCEEFF \n\nggplot(mpg) +\n  aes(x = displ, y = hwy, colour = class) +\n  geom_point() +\n  scale_color_paletteer_d(\"khroma::bright\")\n\n\n\n\n\n\n\nL’équivalent existe pour les palettes continues, avec paletteer::paletteer_c(), paletteer::scale_color_paletteer_c() et paletteer::scale_fill_paletteer_c() .\n\npaletteer_c(\"viridis::viridis\", n = 6)\n\n&lt;colors&gt;\n#440154FF #414487FF #2A788EFF #22A884FF #7AD151FF #FDE725FF \n\nggplot(iris) +\n  aes(x = Sepal.Length, y = Sepal.Width, colour = Petal.Length) +\n  geom_point() +\n  scale_colour_paletteer_c(\"viridis::viridis\", direction = -1)",
    "crumbs": [
      "**Manipulation de données**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Couleurs & Palettes</span>"
    ]
  },
  {
    "objectID": "analyses/ggplot2.html",
    "href": "analyses/ggplot2.html",
    "title": "17  Graphiques avec ggplot2",
    "section": "",
    "text": "17.1 Ressources\nIl existe de très nombreuses ressources traitant de ggplot2.\nPour une introduction en français, on pourra se référer au chapitre Visualiser avec ggplot2 de l’Introduction à R et au tidyverse de Julien Barnier, au chapitre Introduction à ggplot2, la grammaire des graphiques du site analyse-R et adapté d’une séance de cours de François Briatte, ou encore au chapitre Graphiques du cours Logiciel R et programmation d’Ewen Gallic.\nPour les anglophones, la référence reste encore l’ouvrage ggplot2: Elegant Graphics for Data Analysis d’Hadley Wickham lui-même, dont la troisième édition est librement accessible en ligne (https://ggplot2-book.org/). D’un point de vue pratique, l’ouvrage R Graphics Cookbook: practical recipes for visualizing data de Winston Chang est une mine d’informations, ouvrage là encore librement accessible en ligne (https://r-graphics.org/).",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Graphiques avec `ggplot2`</span>"
    ]
  },
  {
    "objectID": "analyses/ggplot2.html#les-bases-de-ggplot2",
    "href": "analyses/ggplot2.html#les-bases-de-ggplot2",
    "title": "17  Graphiques avec ggplot2",
    "section": "\n17.2 Les bases de ggplot2\n",
    "text": "17.2 Les bases de ggplot2\n\nggplot2 nécessite que les données du graphique soient sous la forme d’un tableau de données (data.frame ou tibble) au format tidy, c’est-à-dire avec une ligne par observation et les différentes valeurs à représenter sous forme de variables du tableau.\n\n\n\n\n\nFigure 17.1: La grammaire des graphiques\n\n\nTous les graphiques avec ggplot2 suivent une même logique. En premier lieu, on appellera la fonction ggplot2::ggplot() en lui passant en paramètre le fichier de données.\nggplot2 nomme esthétiques les différentes propriétés visuelles d’un graphique, à savoir l’axe des x (x), celui des y (y), la couleur des lignes (colour), celle de remplissage des polygones (fill), le type de lignes (linetype), la forme des points (shape), etc. Une représentation graphique consiste donc à représenter chacune de nos variables d’intérêt selon une esthétique donnée. En second lieu, on appellera donc la fonction ggplot2::aes() pour indiquer la correspondance entre les variables de notre fichier de données et les esthétiques du graphique.\nA minima, il est nécessaire d’indiquer en troisième lieu une géométrie, autrement dit la manière dont les éléments seront représentés visuellement. À chaque géométrie corresponds une fonction commençant par geom_, par exemple ggplot2::geom_point() pour dessiner des points, ggplot2::geom_line() pour des lignes, ggplot2::geom_bar() pour des barres ou encore ggplot2::geom_area() pour des aires. Il existe de nombreuses géométries différentes1, chacune prenant en compte certaines esthétiques, certaines étant requises pour cette géométrie et d’autres optionnelles. La liste des esthétiques prises en compte par chaque géométrie est indiquée dans l’aide en ligne de cette dernière.\n1 On trouvera une liste dans la cheat sheet de ggplot2, voir Section 17.3.Voici un exemple minimal de graphique avec ggplot2 :\n\nlibrary(ggplot2)\np &lt;- \n  ggplot(iris) +\n  aes(\n    x = Petal.Length, \n    y = Petal.Width, \n    colour = Species\n  ) +\n  geom_point()\np\n\n\n\n\n\n\nFigure 17.2: Un exemple simple de nuage de points avec ggplot2\n\n\n\n\n\n\n\n\n\n\nSyntaxe additive\n\n\n\nLe développement de ggplot2 a débuté avant celui du tidyverse et la généralisation du pipe. Dès lors, on ne sera pas étonné que la syntaxe de ggplot2 n’ait pas recours à ce dernier mais repose sur une approche additive. Un graphique est dès lors initialisé avec la fonction ggplot2::ggplot() et l’on ajoutera successivement des éléments au graphique en appelant différentes fonctions et en utilisant l’opérateur +.\n\n\nIl est ensuite possible de personnaliser de nombreux éléments d’un graphique et notamment :\n\nles étiquettes ou labs (titre, axes, légendes) avec ggplot2::ggtitle(), ggplot2::xlab(), ggplot2::ylab() ou encore la fonction plus générique ggplot2::labs() ;\nles échelles (scales) des différentes esthétiques avec les fonctions commençant par scale_ ;\nle système de coordonnées avec les fonctions commençant par coord_ ;\nles facettes (facets) avec les fonctions commençant par facet_ ;\nla légende (guides) avec les fonctions commençant par guide_ ;\nle thème du graphiques (mise en forme des différents éléments) avec ggplot2::theme().\n\n\np +\n  labs(\n    x = \"Longueur du pétale\",\n    y = \"Largeur du pétale\",\n    colour = \"Espèce\"\n  ) +\n  ggtitle(\n    \"Relation entre longueur et largeur des pétales\",\n    subtitle = \"Jeu de données Iris\"\n  ) +\n  scale_x_continuous(breaks = 1:7) +\n  scale_y_continuous(\n    labels = scales::label_number(decimal.mark = \",\")\n  ) +\n  coord_equal() +\n  facet_grid(cols = vars(Species)) +\n  guides(\n    color = guide_legend(nrow = 2)\n  ) +\n  theme_light() +\n  theme(\n    legend.position = \"bottom\",\n    axis.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\nFigure 17.3: Un exemple avancé de nuage de points avec ggplot2\n\n\n\n\nLe diaporama ci-dessous vous permet de visualiser chaque étape du code.",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Graphiques avec `ggplot2`</span>"
    ]
  },
  {
    "objectID": "analyses/ggplot2.html#sec-cheatsheet-ggplot2",
    "href": "analyses/ggplot2.html#sec-cheatsheet-ggplot2",
    "title": "17  Graphiques avec ggplot2",
    "section": "\n17.3 Cheatsheet",
    "text": "17.3 Cheatsheet\n\n\n\n\n\nFigure 17.4: Cheatsheet ggplot2",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Graphiques avec `ggplot2`</span>"
    ]
  },
  {
    "objectID": "analyses/ggplot2.html#sec-esquisse",
    "href": "analyses/ggplot2.html#sec-esquisse",
    "title": "17  Graphiques avec ggplot2",
    "section": "\n17.4 Exploration visuelle avec esquisse\n",
    "text": "17.4 Exploration visuelle avec esquisse\n\nLe package esquisse propose un addin offrant une interface visuelle pour la création de graphiques ggplot2. Après installation du package, on pourra lancer esquisse directement à partir du menu addins de RStudio.\n\n\n\n\n\nFigure 17.5: Lancement d’esquisse à partir du menu Addins de RStudio\n\n\nAu lancement de l’addin, une interface permettra de choisir le tableau de données à partir duquel générer le graphique. Le plus simple est de choisir un tableau présent dans l’environnement. Mais esquisse offre aussi la possibilité d’importer des fichiers externes, voir de procéder à quelques modifications des données.\n\n\n\n\n\nFigure 17.6: Import de données au lancement d’esquisse\n\n\nLe principe général d’esquisse consiste à associer des variables à des esthétiques par glisser/déposer2. L’outil déterminera automatiquement une géométrie adaptée en fonction de la nature des variables (continues ou catégorielles). Un clic sur le nom de la géométrie en haut à gauche permet de sélectionner une autre géométrie.\n2 Si une esthétique n’est pas visible à l’écran, on pourra cliquer en haut à droite sur l’icône en forme de roue dentée afin de choisir d’afficher plus d’esthétiques.\n\n\n\n\nFigure 17.7: Choix d’une géométrie dans esquisse\n\n\nLes menus situés en bas de l’écran permettent d’ajouter/modifier des étiquettes, de modifier certaines options du graphiques, de modifier les échelles de couleurs et l’apparence du graphique, et de filtrer les observations inclues dans le graphique.\nLe menu Code permet de récupérer le code correspondant au graphique afin de pouvoir le copier/coller dans un script.\n\n\n\n\n\nFigure 17.8: Obtenir le code du graphique obtenu avec esquisse\n\n\nesquisse offre également la possibilité d’exporter le graphique obtenu dans différents formats.",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Graphiques avec `ggplot2`</span>"
    ]
  },
  {
    "objectID": "analyses/ggplot2.html#webin-r",
    "href": "analyses/ggplot2.html#webin-r",
    "title": "17  Graphiques avec ggplot2",
    "section": "\n17.5 webin-R",
    "text": "17.5 webin-R\nL’utilisation d’esquisse est présentée dans le webin-R #03 (statistiques descriptives avec gtsummary et esquisse) sur YouTube.\n\nggplot2 est abordé plus en détails dans le webin-R #08 (ggplot2 et la grammaire des graphiques) sur YouTube.",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Graphiques avec `ggplot2`</span>"
    ]
  },
  {
    "objectID": "analyses/ggplot2.html#sec-combiner-graphiques",
    "href": "analyses/ggplot2.html#sec-combiner-graphiques",
    "title": "17  Graphiques avec ggplot2",
    "section": "\n17.6 Combiner plusieurs graphiques",
    "text": "17.6 Combiner plusieurs graphiques\nPlusieurs packages proposent des fonctions pour combiner ensemble des graphiques ggplot2, comme patchwork, ggpubr, {egg} ou cowplot. Ici, nous privilégierons le package patchwork car, bien qu’il ne fasse pas partie du tidyverse, est développé et maintenant par les mêmes auteurs que ggplot2.\nCommençons par créer quelques graphiques avec ggplot2.\n\np1 &lt;- ggplot(mtcars) +\n  aes(x = wt, y = mpg) + \n  geom_point()\np2 &lt;- ggplot(mtcars) +\n  aes(x = factor(cyl)) +\n  geom_bar()\np3 &lt;- ggplot(mtcars) +\n  aes(x = factor(cyl), y = mpg) +\n  geom_violin() +\n  theme(axis.title = element_text(size = 20))\np4 &lt;- ggplot(mtcars) +\n  aes(x = factor(cyl), y = mpg) + \n  geom_boxplot() +\n  ylab(NULL)\n\nLe symbole + permet de combiner des graphiques entre eux. Le package patchwork déterminera le nombre de lignes et de colonnes en fonction du nombre de graphiques. On pourra noter que les axes des graphiques sont alignés les uns par rapports aux autres.\n\nlibrary(patchwork)\np1 + p2 + p3 + p4\n\n\n\n\n\n\n\nLes symboles | et / permettent d’indiquer une disposition côte à côte ou les uns au-dessus des autres.\n\np1 | p2 | p3\n\n\n\n\n\n\n\n\np1 / p2\n\n\n\n\n\n\n\nOn peut utiliser les parenthèses pour indiquer des arrangements plus complexes.\n\n(p1 + p2) / p3\n\n\n\n\n\n\n\n\n(p1 + p2) | p3\n\n\n\n\n\n\n\nSi l’on a une liste de graphiques, on pourra appeler patchwork::wrap_plots().\n\nlist(p1, p2, p3, p4) |&gt; \n  wrap_plots()\n\n\n\n\n\n\n\nLa fonction patchwork::plot_layout() permet de contrôler les hauteurs / largeurs relatives des lignes / colonnes.\n\np1 + p2 + p3 + p4 + plot_layout(widths = c(2, 1))\n\n\n\n\n\n\n\nOn peut également ajouter un titre ou des étiquettes avec patchwork::plot_annotation().\n\np1 + p2 + p3 + p4 +\n  plot_annotation(\n    title = \"Titre du graphique\",\n    subtitle = \"sous-titre\",\n    caption = \"notes additionelles\",\n    tag_levels = \"a\",\n    tag_suffix = \".\"\n  )\n\n\n\n\n\n\n\n\n\n\nFigure 17.1: La grammaire des graphiques\nFigure 17.2: Un exemple simple de nuage de points avec ggplot2\nFigure 17.3: Un exemple avancé de nuage de points avec ggplot2\nFigure 17.4: Cheatsheet ggplot2\nFigure 17.5: Lancement d’esquisse à partir du menu Addins de RStudio\nFigure 17.6: Import de données au lancement d’esquisse\nFigure 17.7: Choix d’une géométrie dans esquisse\nFigure 17.8: Obtenir le code du graphique obtenu avec esquisse",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Graphiques avec `ggplot2`</span>"
    ]
  },
  {
    "objectID": "analyses/statistique-univariee.html",
    "href": "analyses/statistique-univariee.html",
    "title": "18  Statistique univariée & Intervalles de confiance",
    "section": "",
    "text": "18.1 Exploration graphique\nUne première approche consiste à explorer visuelle la variable d’intérêt, notamment à l’aide de l’interface proposée par esquisse (cf Section 17.4).\nNous indiquons ci-après le code correspond aux graphiques ggplot2 les plus courants.\nlibrary(ggplot2)",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Statistique univariée & Intervalles de confiance</span>"
    ]
  },
  {
    "objectID": "analyses/statistique-univariee.html#exploration-graphique",
    "href": "analyses/statistique-univariee.html#exploration-graphique",
    "title": "18  Statistique univariée & Intervalles de confiance",
    "section": "",
    "text": "18.1.1 Variable continue\nUn histogramme est la représentation graphique la plus commune pour représenter la distribution d’une variable, par exemple ici la longueur des pétales (variable Petal.Length) du fichier de données datasets::iris. Il s’obtient avec la géométrie ggplot2::geom_histogram().\n\nggplot(iris) +\n  aes(x = Petal.Length) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nFigure 18.1: un histogramme simple\n\n\n\n\n\n\n\n\n\n\nAstuce\n\n\n\nIl faut noter qu’il nous a suffit d’associer simplement la variable Petal.Length à l’esthétique x, sans avoir eu besoin d’indiquer une variable pour l’esthétique y.\nEn fait, ggplot2 associe par défaut à toute géométrie une certaine statistique. Dans le cas de ggplot2::geom_histogram(), il s’agit de la statistique ggplot2::stat_bin() qui divise la variable continue en classes de même largeur et compte le nombre d’observation dans chacune. ggplot2::stat_bin() renvoie un certain nombre de variables calculées (la liste complète est indiquée dans la documentation dans la section Compute variables), dont la variable count qui correspond au nombre d’observations la classe. On peut associer cette variable calculée à une esthétique grâce à la fonction ggplot2::after_stat(), par exemple aes(y = after_stat(count)). Dans le cas présent, ce n’est pas nécessaire car ggplot2 fait cette association automatiquement si l’on n’a pas déjà attribué une variable à l’esthétique y.\n\n\nOn peut personnaliser la couleur de remplissage des rectangles en indiquant une valeur fixe pour l’esthétique fill dans l’appel de ggplot2::geom_histogram() (et non via la fonction ggplot2::aes() puisqu’il ne s’agit pas d’une variable du tableau de données). L’esthétique colour permet de spécifier la couleur du trait des rectangles. Enfin, le paramètre binwidth permet de spécifier la largeur des barres.\n\nggplot(iris) +\n  aes(x = Petal.Length) +\n  geom_histogram(\n    fill =\"lightblue\", \n    colour = \"black\", \n    binwidth = 1\n  ) +\n  xlab(\"Longeur du pétale\") +\n  ylab(\"Effectifs\")\n\n\n\n\n\n\nFigure 18.2: un histogramme personnalisé\n\n\n\n\nOn peut alternativement indiquer un nombre de classes avec bins.\n\nggplot(iris) +\n  aes(x = Petal.Length) +\n  geom_histogram(bins = 10, colour = \"black\")\n\n\n\n\n\n\nFigure 18.3: un histogramme en 10 classes\n\n\n\n\nUne représentation alternative de la distribution d’une variable peut être obtenue avec une courbe de densité, dont la particularité est d’avoir une surface sous la courbe égale à 1. Une telle courbe s’obtient avec ggplot2::geom_density(). Le paramètre adjust permet d’ajuster le niveau de lissage de la courbe.\n\nggplot(iris) +\n  aes(x = Petal.Length) +\n  geom_density(adjust = .5)\n\n\n\n\n\n\nFigure 18.4: une courbe de densité\n\n\n\n\n\n18.1.2 Variable catégorielle\nPour représenter la répartition des effectifs parmi les modalités d’une variable catégorielle, on a souvent tendance à utiliser des diagrammes en secteurs (camemberts). Or, ce type de représentation graphique est très rarement appropriée : l’œil humain préfère comparer des longueurs plutôt que des surfaces1.\n1 Voir en particulier https://www.data-to-viz.com/caveat/pie.html pour un exemple concret.Dans certains contextes ou pour certaines présentations, on pourra éventuellement considérer un diagramme en donut, mais le plus souvent, rien ne vaut un bon vieux diagramme en barres avec ggplot2::geom_bar(). Prenons pour l’exemple la variable occup du jeu de données hdv2003 du package questionr.\n\ndata(\"hdv2003\", package = \"questionr\")\nggplot(hdv2003) +\n  aes(x = occup) +\n  geom_bar()\n\n\n\n\n\n\nFigure 18.5: un diagramme en barres simple\n\n\n\n\n\n\n\n\n\n\nAstuce\n\n\n\nLà encore, ggplot2 a calculé de lui-même le nombre d’observations de chaque modalité, en utilisant cette fois la statistique ggplot2::stat_count().\n\n\nSi l’on souhaite représenter des pourcentages plutôt que des effectifs, le plus simple est d’avoir recours à la statistique ggstats::stat_prop() du package ggstats2. Pour appeler cette statistique, on utilisera simplement stat = \"prop\" dans les géométries concernées.\n2 Cette statistique est également disponible via le package GGally.Cette statistique, qui sera également bien utile pour des graphiques plus complexes, nécessite qu’on lui indique une esthétique by pour dans quels sous-groupes calculés des proportions. Ici, nous avons un seul groupe considéré et nous souhaitons des pourcentages du total. On indiquera simplement by = 1.\nPour formater l’axe vertical avec des pourcentages, on pourra avoir recours à la fonction scales::label_percent() que l’on appellera via ggplot2::scale_y_continuous().\n\nlibrary(ggstats)\nggplot(hdv2003) +\n  aes(x = occup, y = after_stat(prop), by = 1) +\n  geom_bar(stat = \"prop\") +\n  scale_y_continuous(labels = scales::label_percent())\n\n\n\n\n\n\nFigure 18.6: un diagramme en barres épuré\n\n\n\n\nPour une publication ou une communication, il ne faut surtout pas hésiter à épurer vos graphiques (less is better!), voire à trier les modalités en fonction de leur fréquence pour faciliter la lecture (ce qui se fait aisément avec forcats::fct_infreq()).\n\nggplot(hdv2003) +\n  aes(x = forcats::fct_infreq(occup), \n      y = after_stat(prop), by = 1) +\n  geom_bar(stat = \"prop\", \n           fill = \"#4477AA\", colour = \"black\") +\n  geom_text(\n    aes(label = after_stat(prop) |&gt; \n          scales::percent(accuracy = .1)),\n    stat = \"prop\",\n    nudge_y = .02\n  ) +\n  theme_minimal() +\n  theme(\n    panel.grid = element_blank(),\n    axis.text.y = element_blank()\n  ) +\n  xlab(NULL) + ylab(NULL) +\n  ggtitle(\"Occupation des personnes enquêtées\")\n\n\n\n\n\n\nFigure 18.7: un diagramme en barres épuré\n\n\n\n\nLe diaporama ci-dessous vous permet de visualiser chaque étape du code.",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Statistique univariée & Intervalles de confiance</span>"
    ]
  },
  {
    "objectID": "analyses/statistique-univariee.html#sec-tri-a-plat",
    "href": "analyses/statistique-univariee.html#sec-tri-a-plat",
    "title": "18  Statistique univariée & Intervalles de confiance",
    "section": "\n18.2 Tableaux et tris à plat",
    "text": "18.2 Tableaux et tris à plat\nLe package gtsummary constitue l’une des boites à outils de l’analyste quantitativiste, car il permet de réaliser très facilement des tableaux quasiment publiables en l’état. En matière de statistique univariées, la fonction clé est gtsummary::tbl_summary().\nCommençons avec un premier exemple rapide. On part d’un tableau de données et on indique, avec l’argument include, les variables à afficher dans le tableau statistique (si on n’indique rien, toutes les variables du tableau de données sont considérées). Il faut noter que l’argument include de gtsummary::tbl_summary() utilise la même syntaxe dite tidy select que dplyr::select() (cf. Section 8.2.1). On peut indiquer tout autant des variables catégorielles que des variables continues.\n\nlibrary(gtsummary)\nhdv2003 |&gt; \n  tbl_summary(include = c(age, occup))\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nN = 2,000\n1\n\n\n\n\nage\n48 (35, 60)\n\n\noccup\n\n\n\n    Exerce une profession\n1,049 (52%)\n\n\n    Chomeur\n134 (6.7%)\n\n\n    Etudiant, eleve\n94 (4.7%)\n\n\n    Retraite\n392 (20%)\n\n\n    Retire des affaires\n77 (3.9%)\n\n\n    Au foyer\n171 (8.6%)\n\n\n    Autre inactif\n83 (4.2%)\n\n\n\n\n1\nMedian (Q1, Q3); n (%)\n\n\n\n\n\n\n\n\nTable 18.1: un tableau simple\n\n\n\n\n\n\n\n\n\nRemarque sur les types de variables et les sélecteurs associés\n\n\n\ngtsummary permets de réaliser des tableaux statistiques combinant plusieurs variables, l’affichage des résultats pouvant dépendre du type de variables.\nPar défaut, gtsummary considère qu’une variable est catégorielle s’il s’agit d’un facteur, d’une variable textuelle ou d’une variable numérique ayant moins de 10 valeurs différentes.\nUne variable sera considérée comme dichotomique (variable catégorielle à seulement deux modalités) s’il s’agit d’un vecteur logique (TRUE/FALSE), d’une variable textuelle codée yes/no ou d’une variable numérique codée 0/1.\nDans les autres cas, une variable numérique sera considérée comme continue.\nSi vous utilisez des vecteurs labellisés (cf. Chapitre 12), vous devez les convertir, en amont, en facteurs ou en variables numériques. Voir l’extension labelled et les fonctions labelled::to_factor(), labelled::unlabelled() et unclass().\nAu besoin, il est possible de forcer le type d’une variable avec l’argument type de gtsummary::tbl_summary().\ngtsummary fournit des sélecteurs qui peuvent être utilisés dans les options des différentes fonctions, en particulier gtsummary::all_continuous() pour les variables continues, gtsummary::all_dichotolous() pour les variables dichotomiques et gtsummary::all_categorical() pour les variables catégorielles. Cela inclue les variables dichotomiques. Il faut utiliser all_categorical(dichotomous = FALSE) pour sélectionner les variables catégorielles en excluant les variables dichotomiques.\n\n\n\n18.2.1 Thème du tableau\ngtsummary fournit plusieurs fonctions préfixées theme_gtsummary_*() permettant de modifier l’affichage par défaut des tableaux. Vous aurez notez que, par défaut, gtsummary est anglophone.\nLa fonction gtsummary::theme_gtsummary_journal() permets d’adopter les standards de certaines grandes revues scientifiques telles que JAMA (Journal of the American Medical Association), The Lancet ou encore le NEJM (New England Journal of Medicine).\nLa fonction gtsummary::theme_gtsummary_language() permet de modifier la langue utilisée par défaut dans les tableaux. Les options decimal.mark et big.mark permettent de définir respectivement le séparateur de décimales et le séparateur des milliers. Ainsi, pour présenter un tableau en français, on appliquera en début de script :\n\ntheme_gtsummary_language(\n  language = \"fr\", \n  decimal.mark = \",\", \n  big.mark = \" \"\n)\n\nSetting theme \"language: fr\"\n\n\nCe thème sera appliqué à tous les tableaux ultérieurs.\n\nhdv2003 |&gt; \n  tbl_summary(include = c(age, occup))\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 2 000\n1\n\n\n\n\nage\n48 (35 – 60)\n\n\noccup\n\n\n\n    Exerce une profession\n1 049 (52%)\n\n\n    Chomeur\n134 (6,7%)\n\n\n    Etudiant, eleve\n94 (4,7%)\n\n\n    Retraite\n392 (20%)\n\n\n    Retire des affaires\n77 (3,9%)\n\n\n    Au foyer\n171 (8,6%)\n\n\n    Autre inactif\n83 (4,2%)\n\n\n\n\n1\nMédiane (Q1 – Q3); n (%)\n\n\n\n\n\n\n\n\nTable 18.2: un tableau simple en français\n\n\n\n\n18.2.2 Étiquettes des variables\ngtsummary, par défaut, prends en compte les étiquettes de variables (cf. Chapitre 11), si elles existent, et sinon utilisera le nom de chaque variable dans le tableau. Pour rappel, les étiquettes de variables peuvent être manipulées avec l’extension labelled et les fonctions labelled::var_label() et labelled::set_variable_labels().\nIl est aussi possible d’utiliser l’option label de gtsummary::tbl_summary() pour indiquer des étiquettes personnalisées.\n\nhdv2003 |&gt; \n  labelled::set_variable_labels(\n    occup = \"Occupation actuelle\"\n  ) |&gt; \n  tbl_summary(\n    include = c(age, occup, heures.tv),\n    label = list(age ~ \"Âge médian\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 2 000\n1\n\n\n\n\nÂge médian\n48 (35 – 60)\n\n\nOccupation actuelle\n\n\n\n    Exerce une profession\n1 049 (52%)\n\n\n    Chomeur\n134 (6,7%)\n\n\n    Etudiant, eleve\n94 (4,7%)\n\n\n    Retraite\n392 (20%)\n\n\n    Retire des affaires\n77 (3,9%)\n\n\n    Au foyer\n171 (8,6%)\n\n\n    Autre inactif\n83 (4,2%)\n\n\nheures.tv\n2,00 (1,00 – 3,00)\n\n\n    Manquant\n5\n\n\n\n\n1\nMédiane (Q1 – Q3); n (%)\n\n\n\n\n\n\n\n\nTable 18.3: un tableau étiquetté\n\n\n\nPour modifier les modalités d’une variable catégorielle, il faut modifier en amont les niveaux du facteur correspondant.\n\n\n\n\n\n\nRemarque sur la syntaxe des options\n\n\n\nDe nombreuses options des fonctions de gtsummary peuvent s’appliquer seulement à une ou certaines variables. Pour ces options-là, gtsummary attends une formule de la forme variables concernées ~ valeur de l'option ou bien une liste de formules ayant cette forme.\nPar exemple, pour modifier l’étiquette associée à une certaine variable, on peut utiliser l’option label de gtsummary::tbl_summary().\n\ntrial |&gt; \n  tbl_summary(label = age ~ \"Âge\")\n\nLorsque l’on souhaite passer plusieurs options pour plusieurs variables différentes, on utilisera une list().\n\ntrial |&gt; \n  tbl_summary(label = list(age ~ \"Âge\", trt ~ \"Traitement\"))\n\ngtsummary est très flexible sur la manière d’indiquer la ou les variables concernées. Il peut s’agir du nom de la variable, d’une chaîne de caractères contenant le nom de la variable, ou d’un vecteur contenant le nom de la variable. Les syntaxes ci-dessous sont ainsi équivalentes.\n\ntrial |&gt; \n  tbl_summary(label = age ~ \"Âge\")\ntrial |&gt; \n  tbl_summary(label = \"age\" ~ \"Âge\")\nv &lt;- \"age\"\ntrial |&gt; \n  tbl_summary(label = v ~ \"Âge\")\n\nPour appliquer le même changement à plusieurs variables, plusieurs syntaxes sont acceptées pour lister plusieurs variables.\n\ntrial |&gt; \n  tbl_summary(label = c(\"age\", \"trt\") ~ \"Une même étiquette\")\ntrial |&gt; \n  tbl_summary(label = c(age, trt) ~ \"Une même étiquette\")\n\nIl est également possible d’utiliser la syntaxe tidyselect et les sélecteurs de tidyselect comme tidyselect::everything(), tidyselect::starts_with(), tidyselect::contains() ou tidyselect::all_of(). Ces différents sélecteurs peuvent être combinés au sein d’un c().\n\ntrial |&gt; \n  tbl_summary(\n    label = everything() ~ \"Une même étiquette\"\n  )\ntrial |&gt; \n  tbl_summary(\n    label = starts_with(\"a\") ~ \"Une même étiquette\"\n  )\ntrial |&gt; \n  tbl_summary(\n    label = c(everything(), -age, -trt) ~ \"Une même étiquette\"\n  )\ntrial |&gt; \n  tbl_summary(\n    label = age:trt ~ \"Une même étiquette\"\n  )\n\nBien sûr, il est possible d’utiliser les sélecteurs propres à gtsummary.\n\ntrial |&gt; \n  tbl_summary(\n    label = all_continuous() ~ \"Une même étiquette\"\n  )\ntrial |&gt; \n  tbl_summary(\n    label = list(\n      all_continuous() ~ \"Variable continue\",\n      all_dichotomous() ~ \"Variable dichotomique\",\n      all_categorical(dichotomous = FALSE) ~ \"Variable catégorielle\"\n    )\n  )\n\nEnfin, si l’on ne précise rien à gauche du ~, ce sera considéré comme équivalent à everything(). Les deux syntaxes ci-dessous sont donc équivalentes.\n\ntrial |&gt; \n  tbl_summary(label = ~ \"Une même étiquette\")\ntrial |&gt; \n  tbl_summary(\n    label = everything() ~ \"Une même étiquette\"\n  )\n\n\n\n\n18.2.3 Statistiques affichées\nLe paramètre statistic permets de sélectionner les statistiques à afficher pour chaque variable. On indiquera une chaîne de caractères dont les différentes statistiques seront indiquées entre accolades ({}).\nPour une variable continue, on pourra utiliser {median} pour la médiane, {mean} pour la moyenne, {sd} pour l’écart type, {var} pour la variance, {min} pour le minimum, {max} pour le maximum, ou encore {p##} (en remplaçant ## par un nombre entier entre 00 et 100) pour le percentile correspondant (par exemple p25 et p75 pour le premier et le troisième quartile). Utilisez gtsummary::all_continous() pour sélectionner toutes les variables continues.\n\nhdv2003 |&gt;\n  tbl_summary(\n    include = c(age, heures.tv),\n    statistic = \n      all_continuous() ~ \"Moy. : {mean} [min-max : {min} - {max}]\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 2 000\n1\n\n\n\n\nage\nMoy. : 48 [min-max : 18 - 97]\n\n\nheures.tv\nMoy. : 2,25 [min-max : 0,00 - 12,00]\n\n\n    Manquant\n5\n\n\n\n\n1\nMoy. : Moyenne [min-max : Min - Max]\n\n\n\n\n\n\n\n\nTable 18.4: statistiques personnalisées pour une variable continue\n\n\n\nIl est possible d’afficher des statistiques différentes pour chaque variable.\n\nhdv2003 |&gt;\n  tbl_summary(\n    include = c(age, heures.tv),\n    statistic = list(\n      age ~ \"Méd. : {median} [{p25} - {p75}]\",\n      heures.tv ~ \"Moy. : {mean} ({sd})\"\n    )\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 2 000\n1\n\n\n\n\nage\nMéd. : 48 [35 - 60]\n\n\nheures.tv\nMoy. : 2,25 (1,78)\n\n\n    Manquant\n5\n\n\n\n\n1\nMéd. : Médiane [Q1 - Q3]; Moy. : Moyenne (ET)\n\n\n\n\n\n\n\n\nTable 18.5: statistiques personnalisées pour une variable continue (2)\n\n\n\nPour les variables continues, il est également possible d’indiquer le nom d’une fonction personnalisée qui prends un vecteur et renvoie une valeur résumée. Par exemple, pour afficher la moyenne des carrés :\n\nmoy_carres &lt;- function(x) {\n  mean(x^2, na.rm = TRUE)\n}\nhdv2003 |&gt;\n  tbl_summary(\n    include = heures.tv,\n    statistic = ~ \"MC : {moy_carres}\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 2 000\n1\n\n\n\n\nheures.tv\nMC : 8,20\n\n\n    Manquant\n5\n\n\n\n\n1\nMC : moy_carres\n\n\n\n\n\n\n\n\nTable 18.6: statiques personnalisées pour une variable continue (3)\n\n\n\nPour une variable catégorielle, les statistiques possibles sont {n} le nombre d’observations, {N} le nombre total d’observations, et {p} le pourcentage correspondant. Utilisez gtsummary::all_categorical() pour sélectionner toutes les variables catégorielles.\n\nhdv2003 |&gt;\n  tbl_summary(\n    include = occup,\n    statistic = all_categorical() ~ \"{p} % ({n}/{N})\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 2 000\n1\n\n\n\n\noccup\n\n\n\n    Exerce une profession\n52 % (1 049/2000)\n\n\n    Chomeur\n6,7 % (134/2000)\n\n\n    Etudiant, eleve\n4,7 % (94/2000)\n\n\n    Retraite\n20 % (392/2000)\n\n\n    Retire des affaires\n3,9 % (77/2000)\n\n\n    Au foyer\n8,6 % (171/2000)\n\n\n    Autre inactif\n4,2 % (83/2000)\n\n\n\n1\n\n\n\n\n\n\n\nTable 18.7: statiques personnalisées pour une variable catégorielle\n\n\n\nIl est possible, pour une variable catégorielle, de trier les modalités de la plus fréquente à la moins fréquente avec le paramètre sort.\n\nhdv2003 |&gt;\n  tbl_summary(\n    include = occup,\n    sort = all_categorical() ~ \"frequency\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 2 000\n1\n\n\n\n\noccup\n\n\n\n    Exerce une profession\n1 049 (52%)\n\n\n    Retraite\n392 (20%)\n\n\n    Au foyer\n171 (8,6%)\n\n\n    Chomeur\n134 (6,7%)\n\n\n    Etudiant, eleve\n94 (4,7%)\n\n\n    Autre inactif\n83 (4,2%)\n\n\n    Retire des affaires\n77 (3,9%)\n\n\n\n\n1\nn (%)\n\n\n\n\n\n\n\n\nTable 18.8: variable catégorielle triée par fréquence\n\n\n\nPour toutes les variables (catégorielles et continues), les statistiques suivantes sont également disponibles :\n\n\n{N_obs} le nombre total d’observations,\n\n{N_miss} le nombre d’observations manquantes (NA),\n\n{N_nonmiss} le nombre d’observations non manquantes,\n\n{p_miss} le pourcentage d’observations manquantes (i.e. N_miss / N_obs) et\n\n{p_nonmiss} le pourcentage d’observations non manquantes (i.e. N_nonmiss / N_obs).\n\n18.2.4 Affichage du nom des statistiques\nLorsque l’on affiche de multiples statistiques, la liste des statistiques est regroupée dans une note de tableau qui peut vite devenir un peu confuse.\n\ntbl &lt;- hdv2003 |&gt;\n  tbl_summary(\n    include = c(age, heures.tv, occup),\n    statistic = list(\n      age ~ \"{mean} ({sd})\",\n      heures.tv ~ \"{median} [{p25} - {p75}]\"\n    )\n  )\ntbl\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 2 000\n1\n\n\n\n\nage\n48 (17)\n\n\nheures.tv\n2,00 [1,00 - 3,00]\n\n\n    Manquant\n5\n\n\noccup\n\n\n\n    Exerce une profession\n1 049 (52%)\n\n\n    Chomeur\n134 (6,7%)\n\n\n    Etudiant, eleve\n94 (4,7%)\n\n\n    Retraite\n392 (20%)\n\n\n    Retire des affaires\n77 (3,9%)\n\n\n    Au foyer\n171 (8,6%)\n\n\n    Autre inactif\n83 (4,2%)\n\n\n\n\n1\nMoyenne (ET); Médiane [Q1 - Q3]; n (%)\n\n\n\n\n\n\n\n\nTable 18.9: tableau par défaut\n\n\n\nLa fonction gtsummary::add_stat_label() permets d’indiquer le type de statistique à côté du nom des variables ou bien dans une colonne dédiée, plutôt qu’en note de tableau.\n\ntbl |&gt; \n  add_stat_label()\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\nN = 2 000\n\n\n\nage, Moyenne (ET)\n48 (17)\n\n\nheures.tv, Médiane [Q1 - Q3]\n2,00 [1,00 - 3,00]\n\n\n    Manquant\n5\n\n\noccup, n (%)\n\n\n\n    Exerce une profession\n1 049 (52%)\n\n\n    Chomeur\n134 (6,7%)\n\n\n    Etudiant, eleve\n94 (4,7%)\n\n\n    Retraite\n392 (20%)\n\n\n    Retire des affaires\n77 (3,9%)\n\n\n    Au foyer\n171 (8,6%)\n\n\n    Autre inactif\n83 (4,2%)\n\n\n\n\n\n\n\n\nTable 18.10: ajout du nom des statistiques\n\n\n\n\ntbl |&gt; \n  add_stat_label(location = \"column\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\nStatistique\nN = 2 000\n\n\n\nage\nMoyenne (ET)\n48 (17)\n\n\nheures.tv\nMédiane [Q1 - Q3]\n2,00 [1,00 - 3,00]\n\n\n    Manquant\nn\n5\n\n\noccup\n\n\n\n\n    Exerce une profession\nn (%)\n1 049 (52%)\n\n\n    Chomeur\nn (%)\n134 (6,7%)\n\n\n    Etudiant, eleve\nn (%)\n94 (4,7%)\n\n\n    Retraite\nn (%)\n392 (20%)\n\n\n    Retire des affaires\nn (%)\n77 (3,9%)\n\n\n    Au foyer\nn (%)\n171 (8,6%)\n\n\n    Autre inactif\nn (%)\n83 (4,2%)\n\n\n\n\n\n\n\n\nTable 18.11: ajout du nom des statistiques dans une colonne séparée\n\n\n\n\n18.2.5 Forcer le type de variable\nComme évoqué plus haut, gtsummary détermine automatiquement le type de chaque variable. Par défaut, la variable age du tableau de données trial est traitée comme variable continue, death comme dichotomique (seule la valeur 1 est affichée) et grade comme variable catégorielle.\n\ntrial |&gt;\n  tbl_summary(\n    include = c(grade, age, death)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 200\n1\n\n\n\n\nGrade\n\n\n\n    I\n68 (34%)\n\n\n    II\n68 (34%)\n\n\n    III\n64 (32%)\n\n\nAge\n47 (38 – 57)\n\n\n    Manquant\n11\n\n\nPatient Died\n112 (56%)\n\n\n\n\n1\nn (%); Médiane (Q1 – Q3)\n\n\n\n\n\n\n\n\nTable 18.12: types de variable par défaut\n\n\n\nIl est cependant possible de forcer un certain type avec l’argument type. Précision : lorsque l’on force une variable en dichotomique, il faut indiquer avec value la valeur à afficher (les autres sont alors masquées).\n\ntrial |&gt;\n  tbl_summary(\n    include = c(grade, death),\n    type = list(\n      grade ~ \"dichotomous\",\n      death ~ \"categorical\"\n    ),\n    value = grade ~ \"III\",\n    label = grade ~ \"Grade III\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 200\n1\n\n\n\n\nGrade III\n64 (32%)\n\n\nPatient Died\n\n\n\n    0\n88 (44%)\n\n\n    1\n112 (56%)\n\n\n\n\n1\nn (%)\n\n\n\n\n\n\n\n\nTable 18.13: types de variable personnalisés\n\n\n\nIl ne faut pas oublier que, par défaut, gtsummary traite les variables quantitatives avec moins de 10 valeurs comme des variables catégorielles. Prenons un exemple :\n\ntrial$alea &lt;- sample(1:4, size = nrow(trial), replace = TRUE)\n#| label: tbl-types-defaut-alea\n#| tbl-cap: traitement par défaut d'une variable numérique à 4 valeurs uniques\ntrial |&gt;\n  tbl_summary(\n    include = alea\n  )\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 200\n1\n\n\n\n\nalea\n\n\n\n    1\n58 (29%)\n\n\n    2\n53 (27%)\n\n\n    3\n45 (23%)\n\n\n    4\n44 (22%)\n\n\n\n\n1\nn (%)\n\n\n\n\n\n\n\nOn pourra forcer le traitement de cette variable comme continue.\n\ntrial |&gt;\n  tbl_summary(\n    include = alea,\n    type = alea ~ \"continuous\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 200\n1\n\n\n\nalea\n2 (1 – 3)\n\n\n\n1\nMédiane (Q1 – Q3)\n\n\n\n\n\n\n\n\nTable 18.14: forcer le traitement continu d’une variable numérique à 4 valeurs uniques\n\n\n\n\n18.2.6 Afficher des statistiques sur plusieurs lignes (variables continues)\nPour les variables continues, gtsummary a introduit un type de variable \"continuous2\", qui doit être attribué manuellement via type, et qui permets d’afficher plusieurs lignes de statistiques (en indiquant plusieurs chaînes de caractères dans statistic). À noter le sélecteur dédié gtsummary::all_continuous2().\n\nhdv2003 |&gt;\n  tbl_summary(\n    include = c(age, heures.tv),\n    type = age ~ \"continuous2\",\n    statistic = \n      all_continuous2() ~ c(\n        \"{median} ({p25} - {p75})\", \n        \"{mean} ({sd})\",\n        \"{min} - {max}\"\n      )\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 2 000\n1\n\n\n\n\nage\n\n\n\n    Médiane (Q1 - Q3)\n48 (35 - 60)\n\n\n    Moyenne (ET)\n48 (17)\n\n\n    Min - Max\n18 - 97\n\n\nheures.tv\n2,00 (1,00 – 3,00)\n\n\n    Manquant\n5\n\n\n\n\n1\nMédiane (Q1 – Q3)\n\n\n\n\n\n\n\n\nTable 18.15: des statistiques sur plusieurs lignes (variables continues)\n\n\n\n\n18.2.7 Mise en forme des statistiques\nL’argument digits permet de spécifier comment mettre en forme les différentes statistiques. Le plus simple est d’indiquer le nombre de décimales à afficher. Il est important de tenir compte que plusieurs statistiques peuvent être affichées pour une même variable. On peut alors indiquer une valeur différente pour chaque statistique.\n\nhdv2003 |&gt;\n  tbl_summary(\n    include = c(age, occup),\n    digits = list(\n      all_continuous() ~ 1,\n      all_categorical() ~ c(0, 1)\n    )\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 2 000\n1\n\n\n\n\nage\n48,0 (35,0 – 60,0)\n\n\noccup\n\n\n\n    Exerce une profession\n1 049 (52,5%)\n\n\n    Chomeur\n134 (6,7%)\n\n\n    Etudiant, eleve\n94 (4,7%)\n\n\n    Retraite\n392 (19,6%)\n\n\n    Retire des affaires\n77 (3,9%)\n\n\n    Au foyer\n171 (8,6%)\n\n\n    Autre inactif\n83 (4,2%)\n\n\n\n\n1\nMédiane (Q1 – Q3); n (%)\n\n\n\n\n\n\n\n\nTable 18.16: personnalisation du nombre de décimales\n\n\n\nAu lieu d’un nombre de décimales, on peut indiquer plutôt une fonction à appliquer pour mettre en forme le résultat. Par exemple, gtsummary fournit les fonctions suivantes : gtsummary::style_number() pour les nombres de manière générale, gtsummary::style_percent() pour les pourcentages (les valeurs sont multipliées par 100, mais le symbole % n’est pas ajouté), gtsummary::style_pvalue() pour les p-valeurs, gtsummary::style_sigfig() qui n’affiche, par défaut, que deux chiffres significatifs, ou encore gtsummary::style_ratio() qui est une variante de gtsummary::``style_sigfig() pour les ratios (comme les odds ratios) que l’on compare à 1.\nIl faut bien noter que ce qui est attendu par digits, c’est une fonction et non le résultat d’une fonction. On indiquera donc le nom de la fonction sans parenthèse, comme dans l’exemple ci-dessous (même si pas forcément pertinent ;-)).\n\nhdv2003 |&gt;\n  tbl_summary(\n    include = age,\n    digits = \n      all_continuous() ~ c(style_percent, style_sigfig, style_ratio)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 2 000\n1\n\n\n\nage\n4 800 (35 – 60,0)\n\n\n\n1\nMédiane (Q1 – Q3)\n\n\n\n\n\n\n\n\nTable 18.17: personnalisation de la mise en forme des nombres\n\n\n\nComme digits s’attend à recevoir une fonction (et non le résultat) d’une fonction, on ne peut pas passer directement des arguments aux fonctions style_*() de gtsummary. Pour cela il faut créer une fonction à la levée :\n\ntrial |&gt;\n  tbl_summary(\n    include = marker,\n    statistic = ~ \"{mean} pour 100\",\n    digits = ~ function(x){style_percent(x, digits = 1)}\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 200\n1\n\n\n\n\nMarker Level (ng/mL)\n91,6 pour 100\n\n\n    Manquant\n10\n\n\n\n\n1\nMoyenne pour 100\n\n\n\n\n\n\n\n\nTable 18.18: passer une fonction personnalisée à digits (syntaxe 1)\n\n\n\nDepuis R 4.1, il existe une syntaxe raccourcie équivalente, avec le symbole \\ à la place de function.\n\ntrial |&gt;\n  tbl_summary(\n    include = marker,\n    statistic = ~ \"{mean} pour 100\",\n    digits = ~ \\(x){style_percent(x, digits = 1)}\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 200\n1\n\n\n\n\nMarker Level (ng/mL)\n91,6 pour 100\n\n\n    Manquant\n10\n\n\n\n\n1\nMoyenne pour 100\n\n\n\n\n\n\n\n\nTable 18.19: passer une fonction personnalisée à digits (syntaxe 2)\n\n\n\nUne syntaxe alternative consiste à avoir recours à la fonction purrr::partial() qui permet d’appeler partiellement une fonction et de renvoyer une nouvelle fonction.\n\ntrial |&gt;\n  tbl_summary(\n    include = marker,\n    statistic = ~ \"{mean} pour 100\",\n    digits = ~ purrr::partial(style_percent, digits = 1)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 200\n1\n\n\n\n\nMarker Level (ng/mL)\n91,6 pour 100\n\n\n    Manquant\n10\n\n\n\n\n1\nMoyenne pour 100\n\n\n\n\n\n\n\n\nTable 18.20: passer une fonction personnalisée à digits (syntaxe 3)\n\n\n\nÀ noter dans l’exemple précédent que les fonctions style_*() de gtsummary tiennent compte du thème défini (ici la virgule comme séparateur de décimale).\nPour une mise en forme plus avancée des nombres, il faut se tourner vers l’extension scales et ses diverses fonctions de mise en forme comme scales::label_number() ou scales::label_percent().\nATTENTION : les fonctions de scales n’héritent pas des paramètres du thème gtsummary actif. Il faut donc personnaliser le séparateur de décimal dans l’appel à la fonction.\n\ntrial |&gt;\n  tbl_summary(\n    include = marker,\n    statistic = ~ \"{mean}\",\n    digits = ~ scales::label_number(\n      accuracy = .01, \n      suffix = \" ng/mL\", \n      decimal.mark = \",\"\n    )\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 200\n1\n\n\n\n\nMarker Level (ng/mL)\n0,92 ng/mL\n\n\n    Manquant\n10\n\n\n\n\n1\nMoyenne\n\n\n\n\n\n\n\n\nTable 18.21: passer une fonction personnalisée à digits (syntaxe 4)\n\n\n\n\n18.2.8 Données manquantes\nLe paramètre missing permets d’indiquer s’il faut afficher le nombre d’observations manquantes (c’est-à-dire égales à NA) : \"ifany\" (valeur par défaut) affiche ce nombre seulement s’il y en a, \"no\" masque ce nombre et \"always\" force l’affichage de ce nombre même s’il n’y pas de valeur manquante. Le paramètre missing_text permets de personnaliser le texte affiché.\n\nhdv2003 |&gt;\n  tbl_summary(\n    include = c(age, heures.tv),\n    missing = \"always\",\n    missing_text = \"Nbre observations manquantes\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 2 000\n1\n\n\n\n\nage\n48 (35 – 60)\n\n\n    Nbre observations manquantes\n0\n\n\nheures.tv\n2,00 (1,00 – 3,00)\n\n\n    Nbre observations manquantes\n5\n\n\n\n\n1\nMédiane (Q1 – Q3)\n\n\n\n\n\n\n\n\nTable 18.22: forcer l’affichage des valeurs manquantes\n\n\n\nIl est à noter, pour les variables catégorielles, que les valeurs manquantes ne sont jamais pris en compte pour le calcul des pourcentages. Pour les inclure dans le calcul, il faut les transformer en valeurs explicites, par exemple avec forcats::fct_na_value_to_level() de forcats.\n\nhdv2003 |&gt;\n  dplyr::mutate(\n    trav.imp.explicit = trav.imp |&gt; \n      forcats::fct_na_value_to_level(\"(non renseigné)\")\n  ) |&gt; \n  tbl_summary(\n    include = c(trav.imp, trav.imp.explicit)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 2 000\n1\n\n\n\n\ntrav.imp\n\n\n\n    Le plus important\n29 (2,8%)\n\n\n    Aussi important que le reste\n259 (25%)\n\n\n    Moins important que le reste\n708 (68%)\n\n\n    Peu important\n52 (5,0%)\n\n\n    Manquant\n952\n\n\ntrav.imp.explicit\n\n\n\n    Le plus important\n29 (1,5%)\n\n\n    Aussi important que le reste\n259 (13%)\n\n\n    Moins important que le reste\n708 (35%)\n\n\n    Peu important\n52 (2,6%)\n\n\n    (non renseigné)\n952 (48%)\n\n\n\n\n1\nn (%)\n\n\n\n\n\n\n\n\nTable 18.23: valeurs manquantes explicites (variable catégorielle)\n\n\n\n\n18.2.9 Ajouter les effectifs observés\nLorsque l’on masque les manquants, il peut être pertinent d’ajouter une colonne avec les effectifs observés pour chaque variable à l’aide de la fonction gtsummary::add_n().\n\nhdv2003 |&gt;\n  tbl_summary(\n    include = c(heures.tv, trav.imp),\n    missing = \"no\"\n  ) |&gt; \n  add_n()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\nN\n\nN = 2 000\n1\n\n\n\n\nheures.tv\n1 995\n2,00 (1,00 – 3,00)\n\n\ntrav.imp\n1 048\n\n\n\n    Le plus important\n\n29 (2,8%)\n\n\n    Aussi important que le reste\n\n259 (25%)\n\n\n    Moins important que le reste\n\n708 (68%)\n\n\n    Peu important\n\n52 (5,0%)\n\n\n\n\n1\nMédiane (Q1 – Q3); n (%)\n\n\n\n\n\n\n\n\nTable 18.24: ajouter une colonne avec les effectifs observés",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Statistique univariée & Intervalles de confiance</span>"
    ]
  },
  {
    "objectID": "analyses/statistique-univariee.html#calcul-manuel",
    "href": "analyses/statistique-univariee.html#calcul-manuel",
    "title": "18  Statistique univariée & Intervalles de confiance",
    "section": "\n18.3 Calcul manuel",
    "text": "18.3 Calcul manuel\n\n18.3.1 Variable continue\nR fournit de base toutes les fonctions nécessaires pour le calcul des différentes statistiques descriptives :\n\n\nmean() pour la moyenne\n\nsd() pour l’écart-type\n\nmin() et max() pour le minimum et le maximum\n\nrange() pour l’étendue\n\nmedian() pour la médiane\n\nSi la variable contient des valeurs manquantes (NA), ces fonctions renverront une valeur manquante, sauf si on leur précise na.rm = TRUE.\n\nhdv2003$heures.tv |&gt; mean()\n\n[1] NA\n\nhdv2003$heures.tv |&gt; mean(na.rm = TRUE)\n\n[1] 2.246566\n\nhdv2003$heures.tv |&gt; sd(na.rm = TRUE)\n\n[1] 1.775853\n\nhdv2003$heures.tv |&gt; min(na.rm = TRUE)\n\n[1] 0\n\nhdv2003$heures.tv |&gt; max(na.rm = TRUE)\n\n[1] 12\n\nhdv2003$heures.tv |&gt; range(na.rm = TRUE)\n\n[1]  0 12\n\nhdv2003$heures.tv |&gt; median(na.rm = TRUE)\n\n[1] 2\n\n\nLa fonction quantile() permets de calculer tous types de quantiles.\n\nhdv2003$heures.tv |&gt; quantile(na.rm = TRUE)\n\n  0%  25%  50%  75% 100% \n   0    1    2    3   12 \n\nhdv2003$heures.tv |&gt; \n  quantile(\n    probs = c(.2, .4, .6, .8),\n    na.rm = TRUE\n  )\n\n20% 40% 60% 80% \n  1   2   2   3 \n\n\nLa fonction summary() renvoie la plupart de ces indicateurs en une seule fois, ainsi que le nombre de valeurs manquantes.\n\nhdv2003$heures.tv |&gt; summary()\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  0.000   1.000   2.000   2.247   3.000  12.000       5 \n\n\n\n18.3.2 Variable catégorielle\nLes fonctions de base pour le calcul d’un tri à plat sont les fonctions table() et xtabs(). Leur syntaxe est quelque peu différente. On passe un vecteur entier à table() alors que la syntaxe de xtabs() se rapproche de celle d’un modèle linéaire : on décrit le tableau attendu à l’aide d’une formule et on indique le tableau de données. Les deux fonctions renvoient le même résultat.\n\ntbl &lt;- hdv2003$trav.imp |&gt; table()\ntbl &lt;- xtabs(~ trav.imp, data = hdv2003)\ntbl &lt;- hdv2003 |&gt; xtabs(~ trav.imp, data = _)\ntbl\n\ntrav.imp\n           Le plus important Aussi important que le reste \n                          29                          259 \nMoins important que le reste                Peu important \n                         708                           52 \n\n\nComme on le voit, il s’agit du tableau brut des effectifs, sans les valeurs manquantes, et pas vraiment lisible dans la console de R.\nPour calculer les proportions, on appliquera prop.table() sur la table des effectifs bruts.\n\nprop.table(tbl)\n\ntrav.imp\n           Le plus important Aussi important que le reste \n                  0.02767176                   0.24713740 \nMoins important que le reste                Peu important \n                  0.67557252                   0.04961832 \n\n\nPour la réalisation rapide d’un tri à plat, on pourra donc préférer la fonction questionr::freq() qui affiche également le nombre de valeurs manquantes et les pourcentages, en un seul appel.\n\nhdv2003$trav.imp |&gt; \n  questionr::freq(total = TRUE)\n\n                                n     %  val%\nLe plus important              29   1.5   2.8\nAussi important que le reste  259  13.0  24.7\nMoins important que le reste  708  35.4  67.6\nPeu important                  52   2.6   5.0\nNA                            952  47.6    NA\nTotal                        2000 100.0 100.0",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Statistique univariée & Intervalles de confiance</span>"
    ]
  },
  {
    "objectID": "analyses/statistique-univariee.html#intervalles-de-confiance",
    "href": "analyses/statistique-univariee.html#intervalles-de-confiance",
    "title": "18  Statistique univariée & Intervalles de confiance",
    "section": "\n18.4 Intervalles de confiance",
    "text": "18.4 Intervalles de confiance\n\n18.4.1 Intervalles de confiance avec gtsummary\n\nLa fonction gtsummary::add_ci() permet d’ajouter des intervalles de confiance à un tableau créé avec gtsummary::tbl_summary().\n\n\n\n\n\n\nAvertissement\n\n\n\nPar défaut, pour les variables continues, gtsummary::tbl_summary() affiche la médiane tandis que gtsummary::add_ci() calcule l’intervalle de confiance d’une moyenne !\nIl faut donc :\n\nsoit afficher la moyenne dans gtsummary::tbl_summary() à l’aide du paramètre statistic ;\nsoit calculer les intervalles de confiance d’une médiane (méthode \"wilcox.text\") via le paramètre method de gtsummary::add_ci().\n\n\n\n\nhdv2003 |&gt;\n  tbl_summary(\n    include = c(age, heures.tv, trav.imp),\n    statistic = age ~ \"{mean} ({sd})\"\n  ) |&gt; \n  add_ci(\n    method = heures.tv ~ \"wilcox.test\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 2 000\n1\n\n\n95% IC\n2\n\n\n\n\nage\n48 (17)\n47, 49\n\n\nheures.tv\n2,00 (1,00 – 3,00)\n2,5, 2,5\n\n\n    Manquant\n5\n\n\n\ntrav.imp\n\n\n\n\n    Le plus important\n29 (2,8%)\n1,9%, 4,0%\n\n\n    Aussi important que le reste\n259 (25%)\n22%, 27%\n\n\n    Moins important que le reste\n708 (68%)\n65%, 70%\n\n\n    Peu important\n52 (5,0%)\n3,8%, 6,5%\n\n\n    Manquant\n952\n\n\n\n\n\n\n1\nMoyenne (ET); Médiane (Q1 – Q3); n (%)\n\n\n\n\n2\nIC = intervalle de confiance\n\n\n\n\n\n\n\n\n\nTable 18.25: ajouter les intervalles de confiance\n\n\n\nL’argument statistic permet de personnaliser la présentation de l’intervalle ; conf.level de changer le niveau de confiance et style_fun de modifier la mise en forme des nombres de l’intervalle.\n\nhdv2003 |&gt;\n  tbl_summary(\n    include = c(age, heures.tv),\n    statistic = ~ \"{mean}\"\n  ) |&gt; \n  add_ci(\n    statistic = ~ \"entre {conf.low} et {conf.high}\",\n    conf.level = .9,\n    style_fun = ~ purrr::partial(style_number, digits = 1)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 2 000\n1\n\n\n90% IC\n2\n\n\n\n\nage\n48\nentre 47,5 et 48,8\n\n\nheures.tv\n2,25\nentre 2,2 et 2,3\n\n\n    Manquant\n5\n\n\n\n\n\n\n1\nMoyenne\n\n\n\n\n2\nIC = intervalle de confiance\n\n\n\n\n\n\n\n\n\nTable 18.26: des intervalles de confiance personnalisés\n\n\n\n\n18.4.2 Calcul manuel des intervalles de confiance\nLe calcul de l’intervalle de confiance d’une moyenne s’effectue avec la fonction t.test().\n\nhdv2003$age |&gt; t.test()\n\n\n    One Sample t-test\n\ndata:  hdv2003$age\nt = 127.12, df = 1999, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 47.41406 48.89994\nsample estimates:\nmean of x \n   48.157 \n\n\nLe résultat renvoyé est une liste contenant de multiples informations.\n\nhdv2003$age |&gt; t.test() |&gt; str()\n\nList of 10\n $ statistic  : Named num 127\n  ..- attr(*, \"names\")= chr \"t\"\n $ parameter  : Named num 1999\n  ..- attr(*, \"names\")= chr \"df\"\n $ p.value    : num 0\n $ conf.int   : num [1:2] 47.4 48.9\n  ..- attr(*, \"conf.level\")= num 0.95\n $ estimate   : Named num 48.2\n  ..- attr(*, \"names\")= chr \"mean of x\"\n $ null.value : Named num 0\n  ..- attr(*, \"names\")= chr \"mean\"\n $ stderr     : num 0.379\n $ alternative: chr \"two.sided\"\n $ method     : chr \"One Sample t-test\"\n $ data.name  : chr \"hdv2003$age\"\n - attr(*, \"class\")= chr \"htest\"\n\n\nSi l’on a besoin d’accéder spécifiquement à l’intervalle de confiance calculé :\n\nhdv2003$age |&gt; t.test() |&gt; purrr::pluck(\"conf.int\")\n\n[1] 47.41406 48.89994\nattr(,\"conf.level\")\n[1] 0.95\n\n\nPour celui d’une médiane, on utilisera wilcox.test() en précisant conf.int = TRUE.\n\nhdv2003$age |&gt; wilcox.test(conf.int = TRUE)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  hdv2003$age\nV = 2001000, p-value &lt; 2.2e-16\nalternative hypothesis: true location is not equal to 0\n95 percent confidence interval:\n 47.00001 48.50007\nsample estimates:\n(pseudo)median \n      47.99996 \n\nhdv2003$age |&gt; \n  wilcox.test(conf.int = TRUE) |&gt;\n  purrr::pluck(\"conf.int\")\n\n[1] 47.00001 48.50007\nattr(,\"conf.level\")\n[1] 0.95\n\n\nPour une proportion, on utilisera prop.test() en lui transmettant le nombre de succès et le nombre d’observations, qu’il faudra donc avoir calculé au préalable. On peut également passer une table à deux entrées avec le nombre de succès puis le nombre d’échecs.\nAinsi, pour obtenir l’intervalle de confiance de la proportion des enquêtés qui considèrent leur travail comme peu important, en tenant compte des valeurs manquantes, le plus simple est d’effectuer le code suivant3 :\n3 Notez l’utilisation de rev() pour inverser le tableau créé avec xtabs() afin que le nombre de succès (TRUE) soit indiqués avant le nombre d’échecs (FALSE).\nxtabs(~ I(hdv2003$trav.imp == \"Peu important\"), data = hdv2003) |&gt; \n  rev() |&gt; \n  prop.test()\n\n\n    1-sample proportions test with continuity correction\n\ndata:  rev(xtabs(~I(hdv2003$trav.imp == \"Peu important\"), data = hdv2003)), null probability 0.5\nX-squared = 848.52, df = 1, p-value &lt; 2.2e-16\nalternative hypothesis: true p is not equal to 0.5\n95 percent confidence interval:\n 0.03762112 0.06502346\nsample estimates:\n         p \n0.04961832 \n\n\nPar défaut, prop.test() produit un intervalle de confiance bilatéral en utilisant la méthode de Wilson avec correction de continuité. Pour plus d’information sur les différentes manières de calculer l’intervalle de confiance d’une proportion, on pourra se référer à ce billet de blog.\n\n\n\n\n\n\nAstuce\n\n\n\nComme on le voit, il n’est pas aisé, avec les fonctions de R base de calculer les intervalles de confiance pour toutes les modalités d’une variable catégorielle.\nOn pourra éventuellement avoir recours à la petite fonction suivante qui réalise le tri à plat d’une variable catégorielle, calcule les proportions et leurs intervalles de confiance.\n\nprop_ci &lt;- function(x, conf.level = .95, correct = TRUE) {\n  tbl &lt;- as.data.frame(table(x), responseName = \"n\")\n  tbl$N &lt;- sum(tbl$n)\n  tbl$prop &lt;- tbl$n / tbl$N\n  tbl$conf.low &lt;- NA_real_\n  tbl$conf.high &lt;- NA_real_\n  for (i in 1:nrow(tbl)) {\n    test &lt;- prop.test(\n      x = tbl$n[i],\n      n = tbl$N[i],\n      conf.level = conf.level,\n      correct = correct\n    )\n    tbl$conf.low[i] &lt;- test$conf.int[1]\n    tbl$conf.high[i] &lt;- test$conf.int[2]\n  }\n  tbl\n}\nprop_ci(hdv2003$trav.imp)\n\n                             x   n    N       prop   conf.low  conf.high\n1            Le plus important  29 1048 0.02767176 0.01894147 0.04001505\n2 Aussi important que le reste 259 1048 0.24713740 0.22151849 0.27463695\n3 Moins important que le reste 708 1048 0.67557252 0.64614566 0.70369541\n4                Peu important  52 1048 0.04961832 0.03762112 0.06502346",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Statistique univariée & Intervalles de confiance</span>"
    ]
  },
  {
    "objectID": "analyses/statistique-univariee.html#webin-r",
    "href": "analyses/statistique-univariee.html#webin-r",
    "title": "18  Statistique univariée & Intervalles de confiance",
    "section": "\n18.5 webin-R",
    "text": "18.5 webin-R\nLa statistique univariée est présentée dans le webin-R #03 (statistiques descriptives avec gtsummary et esquisse) sur YouTube.\n\n\n\n\nFigure 18.1: un histogramme simple\nFigure 18.2: un histogramme personnalisé\nFigure 18.3: un histogramme en 10 classes\nFigure 18.4: une courbe de densité\nFigure 18.5: un diagramme en barres simple\nFigure 18.6: un diagramme en barres épuré\nFigure 18.7: un diagramme en barres épuré",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Statistique univariée & Intervalles de confiance</span>"
    ]
  },
  {
    "objectID": "analyses/statistique-bivariee.html",
    "href": "analyses/statistique-bivariee.html",
    "title": "19  Statistique bivariée & Tests de comparaison",
    "section": "",
    "text": "19.1 Deux variables catégorielles",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Statistique bivariée & Tests de comparaison</span>"
    ]
  },
  {
    "objectID": "analyses/statistique-bivariee.html#deux-variables-catégorielles",
    "href": "analyses/statistique-bivariee.html#deux-variables-catégorielles",
    "title": "19  Statistique bivariée & Tests de comparaison",
    "section": "",
    "text": "19.1.1 Tableau croisé avec gtsummary\n\nPour regarder le lien entre deux variables catégorielles, l’approche la plus fréquente consiste à réaliser un tableau croisé, ce qui s’obtient très facilement avec l’argument by de la fonction gtsummary::tbl_summary() que nous avons déjà abordée dans le chapitre sur la statistique univariée (cf. Section 18.2).\nPrenons pour exemple le jeu de données gtsummary::trial et croisons les variables stage et grade. On indique à by la variable à représenter en colonnes et à include celle à représenter en lignes.\n\nlibrary(gtsummary)\ntheme_gtsummary_language(\"fr\", decimal.mark = ',')\n\nSetting theme \"language: fr\"\n\ntrial |&gt; \n  tbl_summary(\n    include = stage,\n    by = grade\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nI\nN = 68\n1\n\n\nII\nN = 68\n1\n\n\nIII\nN = 64\n1\n\n\n\n\nT Stage\n\n\n\n\n\n    T1\n17 (25%)\n23 (34%)\n13 (20%)\n\n\n    T2\n18 (26%)\n17 (25%)\n19 (30%)\n\n\n    T3\n18 (26%)\n11 (16%)\n14 (22%)\n\n\n    T4\n15 (22%)\n17 (25%)\n18 (28%)\n\n\n\n\n1\nn (%)\n\n\n\n\n\n\n\n\nTable 19.1: un tableau croisé avec des pourcentages en colonne\n\n\n\nPar défaut, les pourcentages affichés correspondent à des pourcentages en colonne. On peut demander des pourcentages en ligne avec percent = \"row\" ou des pourcentages du total avec percent = \"cell\".\nIl est possible de passer plusieurs variables à include mais une seule variable peut être transmise à by. La fonction gtsummary::add_overall() permet d’ajouter une colonne totale. Comme pour un tri à plat, on peut personnaliser les statistiques affichées avec statistic.\n\nlibrary(gtsummary)\ntrial |&gt; \n  tbl_summary(\n    include = c(stage, trt),\n    by = grade,\n    statistic = ~ \"{p}% ({n}/{N})\",\n    percent = \"row\"\n  ) |&gt; \n  add_overall(last = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nI\nN = 68\n1\n\n\nII\nN = 68\n1\n\n\nIII\nN = 64\n1\n\n\nOverall\nN = 200\n1\n\n\n\n\nT Stage\n\n\n\n\n\n\n    T1\n32% (17/53)\n43% (23/53)\n25% (13/53)\n100% (53/53)\n\n\n    T2\n33% (18/54)\n31% (17/54)\n35% (19/54)\n100% (54/54)\n\n\n    T3\n42% (18/43)\n26% (11/43)\n33% (14/43)\n100% (43/43)\n\n\n    T4\n30% (15/50)\n34% (17/50)\n36% (18/50)\n100% (50/50)\n\n\nChemotherapy Treatment\n\n\n\n\n\n\n    Drug A\n36% (35/98)\n33% (32/98)\n32% (31/98)\n100% (98/98)\n\n\n    Drug B\n32% (33/102)\n35% (36/102)\n32% (33/102)\n100% (102/102)\n\n\n\n1\n\n\n\n\n\n\n\nTable 19.2: un tableau croisé avec des pourcentages en ligne\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nChoisissez bien votre type de pourcentages (en lignes ou en colonnes). Si d’un point de vue purement statistique, ils permettent tous deux de décrire la relation entre les deux variables, ils ne correspondent au même story telling. Tout dépend donc du message que vous souhaitez faire passer, de l’histoire que vous souhaitez raconter.\n\n\ngtsummary::tbl_summary() est bien adaptée dans le cadre d’une analyse de facteurs afin de représenter un outcome donné avec by et une liste de facteurs avec include.\nLorsque l’on ne croise que deux variables et que l’on souhaite un affichage un peu plus traditionnel d’un tableau croisé, on peut utiliser gtsummary::tbl_cross() à laquelle on transmettra une et une seule variable à row et une et une seule variable à col. Pour afficher des pourcentages, il faudra indiquer le type de pourcentages voulus avec percent.\n\ntrial |&gt; \n  tbl_cross(\n    row = stage,\n    col = grade,\n    percent = \"row\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrade\n\nTotal\n\n\nI\nII\nIII\n\n\n\n\nT Stage\n\n\n\n\n\n\n    T1\n17 (32%)\n23 (43%)\n13 (25%)\n53 (100%)\n\n\n    T2\n18 (33%)\n17 (31%)\n19 (35%)\n54 (100%)\n\n\n    T3\n18 (42%)\n11 (26%)\n14 (33%)\n43 (100%)\n\n\n    T4\n15 (30%)\n17 (34%)\n18 (36%)\n50 (100%)\n\n\nTotal\n68 (34%)\n68 (34%)\n64 (32%)\n200 (100%)\n\n\n\n\n\n\n\n\nTable 19.3: un tableau croisé avec tbl_cross()\n\n\n\n\n19.1.2 Représentations graphiques\nLa représentation graphique la plus commune pour le croisement de deux variables catégorielles est le diagramme en barres, que l’on réalise avec la géométrie ggplot2::geom_bar() et en utilisant les esthétiques x et fill pour représenter les deux variables.\n\nlibrary(ggplot2)\nggplot(trial) +\n  aes(x = stage, fill = grade) +\n  geom_bar() +\n  labs(x = \"T Stage\", fill = \"Grade\", y = \"Effectifs\")\n\n\n\n\n\n\nFigure 19.1: un graphique en barres croisant deux variables\n\n\n\n\nOn peut modifier la position des barres avec le paramètre position.\n\nlibrary(ggplot2)\nggplot(trial) +\n  aes(x = stage, fill = grade) +\n  geom_bar(position = \"dodge\") +\n  labs(x = \"T Stage\", fill = \"Grade\", y = \"Effectifs\")\n\n\n\n\n\n\nFigure 19.2: un graphique avec des barres côte à côte\n\n\n\n\nPour des barres cumulées, on aura recours à position = \"fill\". Pour que les étiquettes de l’axe des y soient représentées sous forme de pourcentages (i.e. 25% au lieu de 0.25), on aura recours à la fonction scales::percent() qui sera transmise à ggplot2::scale_y_continuous().\n\nlibrary(ggplot2)\nggplot(trial) +\n  aes(x = stage, fill = grade) +\n  geom_bar(position = \"fill\") +\n  labs(x = \"T Stage\", fill = \"Grade\", y = \"Proportion\") +\n  scale_y_continuous(labels = scales::percent)\n\n\n\n\n\n\nFigure 19.3: un graphique en barres cumulées\n\n\n\n\n\n\n\n\n\n\nAjouter des étiquettes sur un diagramme en barres\n\n\n\nIl est facile d’ajouter des étiquettes en ayant recours à ggplot2::geom_text(), à condition de lui passer les bons paramètres.\nTout d’abord, il faudra préciser stat = \"count\" pour indiquer que l’on souhaite utiliser la statistique ggplot2::stat_count() qui est celle utilisé par défaut par ggplot2::geom_bar(). C’est elle qui permets de compter le nombre d’observations.\nIl faut ensuite utiliser l’esthétique label pour indiquer ce que l’on souhaite afficher comme étiquettes. La fonction after_stat(count) permet d’accéder à la variable count calculée par ggplot2::stat_count().\nEnfin, il faut indiquer la position verticale avec ggplot2::position_stack(). En précisant un ajustement de vertical de 0.5, on indique que l’on souhaite positionner l’étiquette au milieu.\n\nggplot(trial) +\n  aes(\n    x = stage, fill = grade, \n    label = after_stat(count)\n  ) +\n  geom_bar() +\n  geom_text(\n    stat = \"count\", \n    position = position_stack(.5)\n  )\n\n\n\n\n\n\n\nPour un graphique en barres cumulées, on peut utiliser de manière similaire ggplot2::position_fill(). On ne peut afficher directement les proportions avec ggplot2::stat_count(). Cependant, nous pouvons avoir recours à ggstats::stat_prop(), déjà évoquée dans le chapitre sur la statistique univariée (cf. Section 18.1.2) et dont le dénominateur doit être précisé via l’esthétique by.\n\nlibrary(ggstats)\nggplot(trial) +\n  aes(\n    x = stage, \n    fill = grade, \n    by = stage,\n    label = scales::percent(after_stat(prop), accuracy = .1)\n  ) +\n  geom_bar(position = \"fill\") +\n  geom_text(\n    stat = \"prop\", \n    position = position_fill(.5)\n  ) +\n  scale_y_continuous(labels = scales::percent)\n\n\n\n\n\n\n\nOn peut aussi comparer facilement deux distributions, ici la proportion de chaque niveau de qualification au sein chaque sexe.\n\np &lt;- ggplot(trial) +\n  aes(\n    x = stage,\n    y = after_stat(prop),\n    fill = grade, \n    by = grade,\n    label = scales::percent(after_stat(prop), accuracy = 1)\n  ) +\n  geom_bar(\n    stat = \"prop\", \n    position = position_dodge(.9)\n  ) +\n  geom_text(\n    aes(y = after_stat(prop) - 0.01),\n    stat = \"prop\", \n    position = position_dodge(.9),\n    vjust = \"top\"\n  ) +\n  scale_y_continuous(labels = scales::percent)\np\n\n\n\n\n\n\n\nIl est possible d’alléger le graphique en retirant des éléments superflus.\n\np + \n  theme_light() +\n  xlab(\"\") +\n  ylab(\"\") +\n  labs(fill = \"\") +\n  ggtitle(\"Distribution selon le niveau, par grade\") +\n  theme(\n    panel.grid = element_blank(),\n    panel.border = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks = element_blank(),\n    legend.position = \"top\"\n  ) +\n  scale_fill_brewer()\n\n\n\n\n\n\n\n\n\nLe diaporama ci-dessous vous permet de visualiser chaque étape du code correspondant au graphique précédent.\n\n\n\n\n\n19.1.3 Calcul manuel\nLes deux fonctions de base permettant le calcul d’un tri à plat sont table() et xtabs() (cf. Section 18.3.2). Ces mêmes fonctions permettent le calcul du tri croisé de deux variables (ou plus). Pour table(), on passera les deux vecteurs à croisés, tandis que pour xtabs() on décrira le tableau attendu à l’aide d’une formule.\n\ntable(trial$stage, trial$grade)\n\n    \n      I II III\n  T1 17 23  13\n  T2 18 17  19\n  T3 18 11  14\n  T4 15 17  18\n\ntab &lt;- xtabs(~ stage + grade, data = trial)\ntab\n\n     grade\nstage  I II III\n   T1 17 23  13\n   T2 18 17  19\n   T3 18 11  14\n   T4 15 17  18\n\n\nLe tableau obtenu est basique et ne contient que les effectifs. La fonction addmargins() permet d’ajouter les totaux par ligne et par colonne.\n\ntab |&gt; addmargins()\n\n     grade\nstage   I  II III Sum\n  T1   17  23  13  53\n  T2   18  17  19  54\n  T3   18  11  14  43\n  T4   15  17  18  50\n  Sum  68  68  64 200\n\n\nPour le calcul des pourcentages, le plus simple est d’avoir recours au package questionr qui fournit les fonctions questionr::cprop(), questionr::rprop() et questionr::prop() qui permettent de calculer, respectivement, les pourcentages en colonne, en ligne et totaux.\n\nquestionr::cprop(tab)\n\n       grade\nstage   I     II    III   Ensemble\n  T1     25.0  33.8  20.3  26.5   \n  T2     26.5  25.0  29.7  27.0   \n  T3     26.5  16.2  21.9  21.5   \n  T4     22.1  25.0  28.1  25.0   \n  Total 100.0 100.0 100.0 100.0   \n\nquestionr::rprop(tab)\n\n          grade\nstage      I     II    III   Total\n  T1        32.1  43.4  24.5 100.0\n  T2        33.3  31.5  35.2 100.0\n  T3        41.9  25.6  32.6 100.0\n  T4        30.0  34.0  36.0 100.0\n  Ensemble  34.0  34.0  32.0 100.0\n\nquestionr::prop(tab)\n\n       grade\nstage   I     II    III   Total\n  T1      8.5  11.5   6.5  26.5\n  T2      9.0   8.5   9.5  27.0\n  T3      9.0   5.5   7.0  21.5\n  T4      7.5   8.5   9.0  25.0\n  Total  34.0  34.0  32.0 100.0\n\n\n\n19.1.4 Test du Chi² et dérivés\nDans le cadre d’un tableau croisé, on peut tester l’existence d’un lien entre les modalités de deux variables, avec le très classique test du Chi² (parfois écrit χ² ou Chi²). Pour une présentation plus détaillée du test, on pourra se référer à ce cours de Julien Barnier.\nLe test du Chi² peut se calculer très facilement avec la fonction chisq.test() appliquée au tableau obtenu avec table() ou xtabs().\n\ntab &lt;- xtabs(~ stage + grade, data = trial)\ntab\n\n     grade\nstage  I II III\n   T1 17 23  13\n   T2 18 17  19\n   T3 18 11  14\n   T4 15 17  18\n\nchisq.test(tab)\n\n\n    Pearson's Chi-squared test\n\ndata:  tab\nX-squared = 4.8049, df = 6, p-value = 0.5691\n\n\nSi l’on est adepte de gtsummary, il suffit d’appliquer gtsummary::add_p() au tableau produit avec gtsummary::tbl_summary().\n\ntrial |&gt; \n  tbl_summary(\n    include = stage,\n    by = grade\n  ) |&gt; \n  add_p()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nI\nN = 68\n1\n\n\nII\nN = 68\n1\n\n\nIII\nN = 64\n1\n\n\np-valeur\n2\n\n\n\n\nT Stage\n\n\n\n0,6\n\n\n    T1\n17 (25%)\n23 (34%)\n13 (20%)\n\n\n\n    T2\n18 (26%)\n17 (25%)\n19 (30%)\n\n\n\n    T3\n18 (26%)\n11 (16%)\n14 (22%)\n\n\n\n    T4\n15 (22%)\n17 (25%)\n18 (28%)\n\n\n\n\n\n\n1\nn (%)\n\n\n\n\n2\ntest du khi-deux d’indépendance\n\n\n\n\n\n\n\n\n\nTable 19.4: un tableau croisé avec test du khi²\n\n\n\nDans notre exemple, les deux variables stage et grade ne sont clairement pas corrélées.\nUn test alternatif est le test exact de Fisher. Il s’obtient aisément avec fisher.test() ou bien en le spécifiant via l’argument test de gtsummary::add_p().\n\ntab &lt;- xtabs(~ stage + grade, data = trial)\nfisher.test(tab)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  tab\np-value = 0.5801\nalternative hypothesis: two.sided\n\n\n\ntrial |&gt; \n  tbl_summary(\n    include = stage,\n    by = grade\n  ) |&gt; \n  add_p(test = all_categorical() ~ \"fisher.test\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nI\nN = 68\n1\n\n\nII\nN = 68\n1\n\n\nIII\nN = 64\n1\n\n\np-valeur\n2\n\n\n\n\nT Stage\n\n\n\n0,6\n\n\n    T1\n17 (25%)\n23 (34%)\n13 (20%)\n\n\n\n    T2\n18 (26%)\n17 (25%)\n19 (30%)\n\n\n\n    T3\n18 (26%)\n11 (16%)\n14 (22%)\n\n\n\n    T4\n15 (22%)\n17 (25%)\n18 (28%)\n\n\n\n\n\n\n1\nn (%)\n\n\n\n\n2\ntest exact de Fisher\n\n\n\n\n\n\n\n\n\nTable 19.5: un tableau croisé avec test exact de Fisher\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFormellement, le test de Fisher suppose que les marges du tableau (totaux lignes et colonnes) sont fixées, puisqu’il repose sur une loi hypergéométrique, et donc celui-ci se prête plus au cas des situations expérimentales (plans d’expérience, essais cliniques) qu’au cas des données tirées d’études observationnelles.\nEn pratique, le test du Chi² étant assez robuste quant aux déviations par rapport aux hypothèses d’applications du test (effectifs théoriques supérieurs ou égaux à 5), le test de Fisher présente en général peu d’intérêt dans le cas de l’analyse des tableaux de contingence.\n\n\n\n19.1.5 Comparaison de deux proportions\nPour comparer deux proportions, la fonction de base est prop.test() à laquelle on passera un tableau à 2×2 dimensions.\n\ntab &lt;- xtabs(~ I(stage == \"T1\") + trt, data = trial)\ntab |&gt; questionr::cprop()\n\n                trt\nI(stage == \"T1\") Drug A Drug B Ensemble\n           FALSE  71.4   75.5   73.5   \n           TRUE   28.6   24.5   26.5   \n           Total 100.0  100.0  100.0   \n\ntab |&gt; prop.test()\n\n\n    2-sample test for equality of proportions with continuity correction\n\ndata:  tab\nX-squared = 0.24047, df = 1, p-value = 0.6239\nalternative hypothesis: two.sided\n95 percent confidence interval:\n -0.2217278  0.1175050\nsample estimates:\n   prop 1    prop 2 \n0.4761905 0.5283019 \n\n\nIl est également envisageable d’avoir recours à un test exact de Fisher. Dans le cas d’un tableau à 2×2 dimensions, le test exact de Fisher ne teste pas si les deux proportions sont différents, mais plutôt si leur odds ratio (qui est d’ailleurs renvoyé par la fonction) est différent de 1.\n\nfisher.test(tab)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  tab\np-value = 0.5263\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.4115109 1.5973635\nsample estimates:\nodds ratio \n 0.8125409 \n\n\nMais le plus simple reste encore d’avoir recours à gtsummary et à sa fonction gtsummary::add_difference() que l’on peut appliquer à un tableau où le paramètre by n’a que deux modalités. Pour la différence de proportions, il faut que les variables transmises à include soit dichotomiques.\n\ntrial |&gt; \n  tbl_summary(\n    by = trt,\n    include = response\n  ) |&gt; \n  add_difference()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nDrug A\nN = 98\n1\n\n\nDrug B\nN = 102\n1\n\n\nDifference\n2\n\n\n95% IC\n2,3\n\n\np-valeur\n2\n\n\n\n\nTumor Response\n28 (29%)\n33 (34%)\n-4,2%\n-18% – 9,9%\n0,6\n\n\n    Manquant\n3\n4\n\n\n\n\n\n\n\n\n1\nn (%)\n\n\n\n\n2\n2-sample test for equality of proportions with continuity correction\n\n\n\n\n3\nIC = intervalle de confiance\n\n\n\n\n\n\n\n\n\nTable 19.6: différence entre deux proportions\n\n\n\nAttention : si l’on passe une variable catégorielle à trois modalités ou plus, c’est la différence des moyennes standardisées (globale pour la variable) qui sera calculée et non la différence des proportions dans chaque groupe.\n\ntrial |&gt; \n  tbl_summary(\n    by = trt,\n    include = grade\n  ) |&gt; \n  add_difference()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nDrug A\nN = 98\n1\n\n\nDrug B\nN = 102\n1\n\n\nDifference\n2\n\n\n95% IC\n2,3\n\n\n\n\nGrade\n\n\n0,07\n-0,20 – 0,35\n\n\n    I\n35 (36%)\n33 (32%)\n\n\n\n\n    II\n32 (33%)\n36 (35%)\n\n\n\n\n    III\n31 (32%)\n33 (32%)\n\n\n\n\n\n\n\n1\nn (%)\n\n\n\n\n2\nStandardized Mean Difference\n\n\n\n\n3\nIC = intervalle de confiance\n\n\n\n\n\n\n\n\n\nTable 19.7: différence moyenne standardisée\n\n\n\nPour calculer la différence des proportions pour chaque modalité de grade, il est nécessaire de transformer, en amont, la variable catégorielle grade en trois variables dichotomiques (de type oui/non, une par modalité), ce qui peut se faire facilement avec la fonction fastDummies::dummy_cols() de l’extension fastDummies.\n\ntrial |&gt; \n  fastDummies::dummy_cols(\"grade\") |&gt; \n  tbl_summary(\n    by = trt,\n    include = starts_with(\"grade_\"),\n    digits = ~ c(0, 1)\n  ) |&gt; \n  add_difference()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nDrug A\nN = 98\n1\n\n\nDrug B\nN = 102\n1\n\n\nDifference\n2\n\n\n95% IC\n2,3\n\n\np-valeur\n2\n\n\n\n\ngrade_I\n35 (35,7%)\n33 (32,4%)\n3,4%\n-11% – 17%\n0,7\n\n\ngrade_II\n32 (32,7%)\n36 (35,3%)\n-2,6%\n-17% – 11%\n0,8\n\n\ngrade_III\n31 (31,6%)\n33 (32,4%)\n-0,72%\n-14% – 13%\n&gt;0,9\n\n\n\n\n\n1\nn (%)\n\n\n\n\n2\n2-sample test for equality of proportions with continuity correction\n\n\n\n\n3\nIC = intervalle de confiance\n\n\n\n\n\n\n\n\n\nTable 19.8: différence entre proportions avec création de variables dichotomiques",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Statistique bivariée & Tests de comparaison</span>"
    ]
  },
  {
    "objectID": "analyses/statistique-bivariee.html#une-variable-continue-selon-une-variable-catégorielle",
    "href": "analyses/statistique-bivariee.html#une-variable-continue-selon-une-variable-catégorielle",
    "title": "19  Statistique bivariée & Tests de comparaison",
    "section": "\n19.2 Une variable continue selon une variable catégorielle",
    "text": "19.2 Une variable continue selon une variable catégorielle\n\n19.2.1 Tableau comparatif avec gtsummary\n\nDans le chapitre sur la statistique univariée (cf. Section 18.2), nous avons abordé comment afficher les statistiques descriptives d’une variable continue avec gtsummary::tbl_summary(). Pour comparer une variable continue selon plusieurs groupes définis par une variable catégorielle, il suffit d’utiliser le paramètre by :\n\ntrial |&gt; \n  tbl_summary(\n    include = age,\n    by = grade\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nI\nN = 68\n1\n\n\nII\nN = 68\n1\n\n\nIII\nN = 64\n1\n\n\n\n\nAge\n47 (37 – 56)\n49 (37 – 57)\n47 (38 – 58)\n\n\n    Manquant\n2\n6\n3\n\n\n\n\n1\nMédiane (Q1 – Q3)\n\n\n\n\n\n\n\n\nTable 19.9: âge médian et intervalle interquartile selon le grade\n\n\n\nLa fonction gtsummary::add_overall() permet d’ajouter une colonne total et gtsummary::modify_spanning_header() peut-être utilisé pour ajouter un en-tête de colonne.\n\ntrial |&gt; \n  tbl_summary(\n    include = age,\n    by = grade\n  ) |&gt; \n  add_overall(last = TRUE) |&gt; \n  modify_spanning_header(\n    all_stat_cols(stat_0 = FALSE) ~ \"**Grade**\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\n\nGrade\n\n\nOverall\nN = 200\n1\n\n\n\n\nI\nN = 68\n1\n\n\nII\nN = 68\n1\n\n\nIII\nN = 64\n1\n\n\n\n\n\nAge\n47 (37 – 56)\n49 (37 – 57)\n47 (38 – 58)\n47 (38 – 57)\n\n\n    Manquant\n2\n6\n3\n11\n\n\n\n\n1\nMédiane (Q1 – Q3)\n\n\n\n\n\n\n\n\nTable 19.10: âge médian et intervalle interquartile selon le grade\n\n\n\nComme pour un tri à plat, on peut personnaliser les statistiques à afficher avec statistic.\n\ntrial |&gt; \n  tbl_summary(\n    include = age,\n    by = grade,\n    statistic = all_continuous() ~ \"{mean} ({sd})\",\n    digits = all_continuous() ~ c(1, 1)\n  ) |&gt; \n  add_overall(last = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nI\nN = 68\n1\n\n\nII\nN = 68\n1\n\n\nIII\nN = 64\n1\n\n\nOverall\nN = 200\n1\n\n\n\n\nAge\n46,2 (15,2)\n47,5 (13,7)\n48,1 (14,1)\n47,2 (14,3)\n\n\n    Manquant\n2\n6\n3\n11\n\n\n\n\n1\nMoyenne (ET)\n\n\n\n\n\n\n\n\nTable 19.11: âge moyen et écart-type selon le grade\n\n\n\n\n19.2.2 Représentations graphiques\nLa moyenne ou la médiane sont des indicateurs centraux et ne suffisent pas à rendre compte des différences de distribution d’une variable continue entre plusieurs sous-groupes.\nUne représentation usuelle pour comparer deux distributions consiste à avoir recours à des boîtes à moustaches que l’on obtient avec ggplot2::geom_boxplot().\n\nggplot(trial) +\n  aes(x = grade, y = age) +\n  geom_boxplot(fill = \"lightblue\") +\n  theme_light()\n\n\n\n\n\n\nFigure 19.4: boîtes à moustache\n\n\n\n\n\n\n\n\n\n\nAstuce\n\n\n\nLe trait central représente la médiane, le rectangle est délimité par le premier et le troisième quartiles (i.e. le 25e et le 75e percentiles). Les traits verticaux vont jusqu’aux extrêmes (minimum et maximum) ou jusqu’à 1,5 fois l’intervalle interquartile. Si des points sont situés à plus d’1,5 fois l’intervalle interquartile au-dessus du 3e quartile ou en-dessous du 1er quartile, ils sont considérés comme des valeurs atypiques et représentés par un point. Dans l’exemple précédent, c’est le cas des deux plus petites valeurs observées pour le grade I.\n\n\nAlternativement, on peut utiliser un graphique en violons qui représentent des courbes de densité dessinées en miroir.\n\nggplot(trial) +\n  aes(x = grade, y = age) +\n  geom_violin(fill = \"lightblue\") +\n  theme_light()\n\n\n\n\n\n\nFigure 19.5: graphique en violons\n\n\n\n\nIl est toujours possible de représenter les observations individuelles sous la forme d’un nuage de points. Le paramètre alpha permet de rendre les points transparents afin de mieux visualiser les superpositions de points.\n\nggplot(trial) +\n  aes(x = grade, y = age) +\n  geom_point(alpha = .25, colour = \"blue\") +\n  theme_light()\n\n\n\n\n\n\nFigure 19.6: un nuage de points avec une variable continue et une variable catégorielle\n\n\n\n\nComme la variable grade est catégorielle, tous les points d’une même modalité sont représentées sur une même ligne. La représentation peut être améliorée en ajoutant un décalage aléatoire sur l’axe horizontal. Cela s’obtient avec ggplot2::position_jitter() en précisant height = 0 pour ne pas ajouter de décalage vertical et width = .2 pour décaler horizontalement les points entre -20% et +20%.\n\nggplot(trial) +\n  aes(x = grade, y = age) +\n  geom_point(\n    alpha = .25,\n    colour = \"blue\",\n    position = position_jitter(height = 0, width = .2)\n  ) +\n  theme_light()\n\n\n\n\n\n\nFigure 19.7: un nuage de points avec une variable continue et une variable catégorielle et avec un décalage horizontal aléatoire\n\n\n\n\nLa statistique ggstats::stat_weighted_mean() de ggstats permets de calculer à la volée la moyenne du nuage de points.\n\nggplot(trial) +\n  aes(x = grade, y = age) +\n  geom_point(stat = \"weighted_mean\", colour = \"blue\") +\n  theme_light()\n\n\n\n\n\n\nFigure 19.8: âge moyen selon le grade\n\n\n\n\nCela peut être utile pour effectuer des comparaisons multiples.\n\nggplot(trial) +\n  aes(x = grade, y = age, colour = stage, group = stage) +\n  geom_line(stat = \"weighted_mean\") +\n  geom_point(stat = \"weighted_mean\") +\n  facet_grid(cols = vars(trt)) +\n  theme_light()\n\n\n\n\n\n\nFigure 19.9: âge moyen selon le grade, par traitement et état d’avancement de la maladie\n\n\n\n\n\n\n\n\n\n\nPyramide des âges\n\n\n\nIl est possible de réaliser assez facilement une pyramide des âges en combinant un histogramme avec position_likert_count() fournie par le package ggstats.\nNous allons pour illustrer cela prendre le jeu de données hdv2003 fourni par le package questionr.\n\ndata(\"hdv2003\", package = \"questionr\")\nlibrary(ggplot2)\nlibrary(ggstats)\nggplot(hdv2003) +\n  aes(fill = sexe, y = age) +\n  geom_histogram(\n    position = \"likert_count\",\n    binwidth = 1,\n    color = \"black\"\n  ) +\n  scale_x_continuous(label = label_number_abs()) +\n  scale_y_continuous(breaks = 1:10 * 10)\n\n\n\n\n\n\n\n\n\n\n19.2.3 Calcul manuel\nLe plus simple pour calculer des indicateurs par sous-groupe est d’avoir recours à dplyr::summarise() avec dplyr::group_by().\n\nlibrary(dplyr)\ntrial |&gt;\n  group_by(grade) |&gt; \n  summarise(\n    age_moy = mean(age, na.rm = TRUE),\n    age_med = median(age, na.rm = TRUE)\n  )\n\n# A tibble: 3 × 3\n  grade age_moy age_med\n  &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 I        46.2    47  \n2 II       47.5    48.5\n3 III      48.1    47  \n\n\nEn base R, on peut avoir recours à tapply(). On lui indique d’abord le vecteur sur lequel on souhaite réaliser le calcul, puis un facteur qui indiquera les sous-groupes, puis une fonction qui sera appliquée à chaque sous-groupe et enfin, optionnellement, des arguments additionnels qui seront transmis à cette fonction.\n\ntapply(trial$age, trial$grade, mean, na.rm = TRUE)\n\n       I       II      III \n46.15152 47.53226 48.11475 \n\n\n\n19.2.4 Tests de comparaison\nPour comparer des moyennes ou des médianes, le plus facile est encore d’avoir recours à gtsummary et sa fonction gtsummary::add_p().\n\ntrial |&gt; \n  tbl_summary(\n    include = age,\n    by = grade\n  ) |&gt; \n  add_p()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nI\nN = 68\n1\n\n\nII\nN = 68\n1\n\n\nIII\nN = 64\n1\n\n\np-valeur\n2\n\n\n\n\nAge\n47 (37 – 56)\n49 (37 – 57)\n47 (38 – 58)\n0,8\n\n\n    Manquant\n2\n6\n3\n\n\n\n\n\n\n1\nMédiane (Q1 – Q3)\n\n\n\n\n2\nTest de Kruskal-Wallis\n\n\n\n\n\n\n\n\n\nTable 19.12: test de comparaison sur la somme des rangs\n\n\n\nPar défaut, pour les variables continues, un test de Kruskal-Wallis calculé avec la fonction stats::kruskal.test() est utilisé lorsqu’il y a trois groupes ou plus, et un test de Wilcoxon-Mann-Whitney calculé avec stats::wilcox.test() (test de comparaison des rangs) lorsqu’il n’y a que deux groupes. Au sens strict, il ne s’agit pas de tests de comparaison des médianes mais de tests sur la somme des rangs1. En pratique, ces tests sont appropriés lorsque l’on présente les médianes et les intervalles inter-quartiles.\n1 Si l’on a besoin spécifiquement d’un test de comparaison des médianes, il existe le test de Brown-Mood disponible dans le package coin avec la fonction coin::median_test(). Attention, il ne faut pas confondre ce test avec le test de dispersion de Mood implémenté dans la fonction stats::mood.test().Si l’on affiche des moyennes, il serait plus juste d’utiliser un test t de Student (test de comparaison des moyennes) calculé avec stats::t.test(), valable seulement si l’on compare deux moyennes. Pour tester si trois moyennes ou plus sont égales, on aura plutôt recours à stats::oneway.test().\nOn peut indiquer à gtsummary::add_p() le test à utiliser avec le paramètre test.\n\ntrial |&gt; \n  tbl_summary(\n    include = age,\n    by = grade,\n    statistic = all_continuous() ~ \"{mean} ({sd})\"\n  ) |&gt; \n  add_p(\n    test = all_continuous() ~ \"oneway.test\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nI\nN = 68\n1\n\n\nII\nN = 68\n1\n\n\nIII\nN = 64\n1\n\n\np-valeur\n2\n\n\n\n\nAge\n46 (15)\n48 (14)\n48 (14)\n0,7\n\n\n    Manquant\n2\n6\n3\n\n\n\n\n\n\n1\nMoyenne (ET)\n\n\n\n\n2\nOne-way analysis of means (not assuming equal variances)\n\n\n\n\n\n\n\n\n\nTable 19.13: test de comparaison des moyennes\n\n\n\n\n\n\n\n\n\nPrécision statistique\n\n\n\nClassiquement, le test t de Student présuppose l’égalité des variances entre les deux sous-groupes, ce qui permet de former une estimation commune de la variance des deux échantillons (on parle de pooled variance), qui revient à une moyenne pondérée des variances estimées à partir des deux échantillons. Pour tester l’égalité des variances de deux échantillons, on peut utiliser stats::var.test().\nDans le cas où l’on souhaite relaxer cette hypothèse d’égalité des variances, le test de Welch ou la correction de Satterthwaite reposent sur l’idée que l’on utilise les deux estimations de variance séparément, suivie d’une approximation des degrés de liberté pour la somme de ces deux variances.\nPar défaut, la fonction stats::t.test() réalise un test de Welch. Pour un test classique de Student, il faut lui préciser var.equal = TRUE.\nDe manière similaire, stats::oneway.test() ne présuppose pas, par défaut, l’égalité des variances et généralise donc le test de Welch au cas à trois modalités ou plus. Cependant, on peut là encore indiquer var.equal = TRUE, auquel cas une analyse de variance (ANOVA) classique sera réalisée, que l’on peut aussi obtenir avec stats::aov().\nIl est possible d’indiquer à gtsummary::add_p() des arguments additionnels à passer à la fonction utilisée pour réaliser le test :\n\ntrial |&gt; \n  tbl_summary(\n    include = age,\n    by = trt,\n    statistic = all_continuous() ~ \"{mean} ({sd})\"\n  ) |&gt; \n  add_p(\n    test = all_continuous() ~ \"t.test\",\n    test.args = all_continuous() ~ list(var.equal = TRUE)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nDrug A\nN = 98\n1\n\n\nDrug B\nN = 102\n1\n\n\np-valeur\n2\n\n\n\n\nAge\n47 (15)\n47 (14)\n0,8\n\n\n    Manquant\n7\n4\n\n\n\n\n\n\n1\nMoyenne (ET)\n\n\n\n\n2\nTwo Sample t-test\n\n\n\n\n\n\n\n\n\n\n\n19.2.5 Différence de deux moyennes\nLa fonctions gtsummary::add_difference() permet, pour une variable continue et si la variable catégorielle spécifiée via by n’a que deux modalités, de calculer la différence des deux moyennes, l’intervalle de confiance de cette différence et test si cette différence est significativement différente de 0 avec stats::t.test().\n\ntrial |&gt; \n  tbl_summary(\n    include = age,\n    by = trt,\n    statistic = all_continuous() ~ \"{mean} ({sd})\"\n  ) |&gt; \n  add_difference()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nDrug A\nN = 98\n1\n\n\nDrug B\nN = 102\n1\n\n\nDifference\n2\n\n\n95% IC\n2,3\n\n\np-valeur\n2\n\n\n\n\nAge\n47 (15)\n47 (14)\n-0,44\n-4,6 – 3,7\n0,8\n\n\n    Manquant\n7\n4\n\n\n\n\n\n\n\n\n1\nMoyenne (ET)\n\n\n\n\n2\ntest de Student\n\n\n\n\n3\nIC = intervalle de confiance\n\n\n\n\n\n\n\n\n\nTable 19.14: différence de deux moyennes",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Statistique bivariée & Tests de comparaison</span>"
    ]
  },
  {
    "objectID": "analyses/statistique-bivariee.html#sec-deux-variables-continues",
    "href": "analyses/statistique-bivariee.html#sec-deux-variables-continues",
    "title": "19  Statistique bivariée & Tests de comparaison",
    "section": "\n19.3 Deux variables continues",
    "text": "19.3 Deux variables continues\n\n19.3.1 Représentations graphiques\nLa comparaison de deux variables continues se fait en premier lieu graphique, en représentant, via un nuage de points, l’ensemble des couples de valeurs. Notez ici l’application d’un niveau de transparence (alpha) afin de faciliter la lecture des points superposés.\n\nggplot(iris) +\n  aes(x = Petal.Length, y = Petal.Width) +\n  geom_point(colour = \"blue\", alpha = .25) +\n  theme_light()\n\n\n\n\n\n\nFigure 19.10: nuage de points\n\n\n\n\nLa géométrie ggplot2::geom_smooth() permets d’ajouter une courbe de tendance au graphique, avec son intervalle de confiance. Par défaut, il s’agit d’une régression polynomiale locale obtenue avec stats::loess().\n\nggplot(iris) +\n  aes(x = Petal.Length, y = Petal.Width) +\n  geom_smooth() +\n  geom_point(colour = \"blue\", alpha = .25) +\n  theme_light()\n\n\n\n\n\n\nFigure 19.11: nuage de points avec une courbe de tendance\n\n\n\n\nPour afficher plutôt la droite de régression linéaire entre les deux variables, on précisera method = \"lm\".\n\nggplot(iris) +\n  aes(x = Petal.Length, y = Petal.Width) +\n  geom_smooth(method = \"lm\") +\n  geom_point(colour = \"blue\", alpha = .25) +\n  theme_light()\n\n\n\n\n\n\nFigure 19.12: nuage de points avec droite de régression linéaire\n\n\n\n\n\n\n\n\n\n\nAstuce pour afficher l’intercept\n\n\n\nSupposons que nous souhaitions montrer l’endroit où la droite de régression coupe l’axe des ordonnées (soit le point sur l’axe y pour x = 0).\nNous pouvons étendre la surface du graphique avec ggplot2::expand_limits(). Cependant, cela n’étend pas pour autant la droite de régression.\n\nggplot(iris) +\n  aes(x = Petal.Length, y = Petal.Width) +\n  geom_smooth(method = \"lm\") +\n  geom_point(colour = \"blue\", alpha = .25) +\n  theme_light() +\n  expand_limits(x = 0, y = -0.5)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nUne solution simple consiste à utiliser l’option fullrange = TRUE dans ggplot2::geom_smooth() pour étendre la droite de régression à l’ensemble du graphique.\n\nggplot(iris) +\n  aes(x = Petal.Length, y = Petal.Width) +\n  geom_smooth(method = \"lm\", fullrange = TRUE) +\n  geom_point(colour = \"blue\", alpha = .25) +\n  theme_light() +\n  expand_limits(x = 0, y = -0.5)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nOn peut contrôler plus finement la partie de droite à afficher avec l’argument xseq (liste des valeurs pour lesquelles on prédit et affiche le lissage). On peut coupler deux appels à ggplot2::geom_smooth() pour afficher l’extension de la droite vers la gauche en pointillés. L’option se = FALSE permet de ne pas calculer d’intervalles de confiance pour ce second appel.\n\nggplot(iris) +\n  aes(x = Petal.Length, y = Petal.Width) +\n  geom_smooth(\n    method = \"lm\", \n    xseq = seq(0, 1, by = .1),\n    linetype = \"dotted\",\n    se = FALSE\n  ) +\n  geom_smooth(method = \"lm\") +\n  geom_point(colour = \"blue\", alpha = .25) +\n  theme_light() +\n  expand_limits(x = 0, y = -0.5)\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nLa géométrie ggplot2::geom_rug() permet d’afficher une représentation synthétique de la densité de chaque variable sur les deux axes.\n\nggplot(iris) +\n  aes(x = Petal.Length, y = Petal.Width) +\n  geom_smooth(method = \"lm\") +\n  geom_point(colour = \"blue\", alpha = .25) +\n  geom_rug() +\n  theme_light()\n\n\n\n\n\n\nFigure 19.13: nuage de points avec représentation synthétique des densités marginales\n\n\n\n\n\n19.3.2 Tester la relation entre les deux variables\nSi l’on a besoin de calculer le coefficient de corrélation de Pearson entre deux variables, on aura recours à stats::cor().\n\ncor(iris$Petal.Length, iris$Petal.Width)\n\n[1] 0.9628654\n\n\nPour aller plus loin, on peut calculer une régression linéaire entre les deux variables avec stats::lm().\n\nm &lt;- lm(Petal.Length ~ Petal.Width, data = iris)\nsummary(m)\n\n\nCall:\nlm(formula = Petal.Length ~ Petal.Width, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.33542 -0.30347 -0.02955  0.25776  1.39453 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.08356    0.07297   14.85   &lt;2e-16 ***\nPetal.Width  2.22994    0.05140   43.39   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4782 on 148 degrees of freedom\nMultiple R-squared:  0.9271,    Adjusted R-squared:  0.9266 \nF-statistic:  1882 on 1 and 148 DF,  p-value: &lt; 2.2e-16\n\n\nLes résultats montrent une corrélation positive et significative entre les deux variables.\nPour une présentation propre des résultats de la régression linéaire, on utilisera gtsummary::tbl_regression(). La fonction gtsummary::add_glance_source_note() permet d’ajouter différentes statistiques en notes du tableau de résultats.\n\nm |&gt; \n  tbl_regression() |&gt; \n  add_glance_source_note()\n\n\n\n\n\n\nCaractéristique\n\n      \nBeta\n\n      \n\n95% IC\n\n1\n\n      \np-valeur\n\n    \n\nPetal.Width\n2,2\n2,1 – 2,3\n&lt;0,001\n\n\n\nR² = 0,927; Adjusted R² = 0,927; Sigma = 0,478; Statistique = 1 882; p-valeur = &lt;0,001; df = 1; Log-likelihood = -101; AIC = 208; BIC = 217; Deviance = 33,8; degrés de liberté des résidus = 148; No. Obs. = 150\n\n    \n\n\n1 \nIC = intervalle de confiance",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Statistique bivariée & Tests de comparaison</span>"
    ]
  },
  {
    "objectID": "analyses/statistique-bivariee.html#matrice-de-corrélations",
    "href": "analyses/statistique-bivariee.html#matrice-de-corrélations",
    "title": "19  Statistique bivariée & Tests de comparaison",
    "section": "\n19.4 Matrice de corrélations",
    "text": "19.4 Matrice de corrélations\nLe package GGally et sa fonction GGally::ggpairs() permettent de représenter facilement une matrice de corrélation entre plusieurs variables, tant quantitatives que qualitatives.\n\nlibrary(GGally)\nggpairs(iris)\n\n\n\n\n\n\nFigure 19.14: une matrice de corrélation avec ggpairs()\n\n\n\n\nGGally::ggpairs() et sa petite sœur GGally::ggduo() offrent de nombreuses options de personnalisation qui sont détaillées sur le site dédié du package.\n\nggpairs(trial, mapping = aes(colour = trt))\n\n\n\n\n\n\nFigure 19.15: un second example de matrice de corrélation",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Statistique bivariée & Tests de comparaison</span>"
    ]
  },
  {
    "objectID": "analyses/statistique-bivariee.html#webin-r",
    "href": "analyses/statistique-bivariee.html#webin-r",
    "title": "19  Statistique bivariée & Tests de comparaison",
    "section": "\n19.5 webin-R",
    "text": "19.5 webin-R\nLa statistique univariée est présentée dans le webin-R #03 (statistiques descriptives avec gtsummary et esquisse) sur YouTube.\n\n\n\n\nFigure 19.1: un graphique en barres croisant deux variables\nFigure 19.2: un graphique avec des barres côte à côte\nFigure 19.3: un graphique en barres cumulées\nFigure 19.4: boîtes à moustache\nFigure 19.5: graphique en violons\nFigure 19.6: un nuage de points avec une variable continue et une variable catégorielle\nFigure 19.7: un nuage de points avec une variable continue et une variable catégorielle et avec un décalage horizontal aléatoire\nFigure 19.8: âge moyen selon le grade\nFigure 19.9: âge moyen selon le grade, par traitement et état d’avancement de la maladie\nFigure 19.10: nuage de points\nFigure 19.11: nuage de points avec une courbe de tendance\nFigure 19.12: nuage de points avec droite de régression linéaire\nFigure 19.13: nuage de points avec représentation synthétique des densités marginales\nFigure 19.14: une matrice de corrélation avec ggpairs()\nFigure 19.15: un second example de matrice de corrélation",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Statistique bivariée & Tests de comparaison</span>"
    ]
  },
  {
    "objectID": "analyses/likert.html",
    "href": "analyses/likert.html",
    "title": "20  Échelles de Likert",
    "section": "",
    "text": "20.1 Exemple de données\nGénérons un jeu de données qui nous servira pour les différents exemples.\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(labelled)\nniveaux &lt;- c(\n  \"Pas du tout d'accord\",\n  \"Plutôt pas d'accord\",\n  \"Ni d'accord, ni pas d'accord\",\n  \"Plutôt d'accord\",\n  \"Tout à fait d'accord\"\n)\nset.seed(42)\ndf &lt;-\n  tibble(\n    groupe = sample(c(\"A\", \"B\"), 150, replace = TRUE),\n    q1 = sample(niveaux, 150, replace = TRUE),\n    q2 = sample(niveaux, 150, replace = TRUE, prob = 5:1),\n    q3 = sample(niveaux, 150, replace = TRUE, prob = 1:5),\n    q4 = sample(niveaux, 150, replace = TRUE, prob = 1:5),\n    q5 = sample(c(niveaux, NA), 150, replace = TRUE),\n    q6 = sample(niveaux, 150, replace = TRUE, prob = c(1, 0, 1, 1, 0))\n  ) |&gt; \n  mutate(across(q1:q6, ~ factor(.x, levels = niveaux))) |&gt; \n  set_variable_labels(\n    q1 = \"Première question\",\n    q2 = \"Seconde question\",\n    q3 = \"Troisième question\",\n    q4 = \"Quatrième question\",\n    q5 = \"Cinquième question\",\n    q6 = \"Sixième question\"\n  )",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Échelles de Likert</span>"
    ]
  },
  {
    "objectID": "analyses/likert.html#tableau-de-fréquence",
    "href": "analyses/likert.html#tableau-de-fréquence",
    "title": "20  Échelles de Likert",
    "section": "\n20.2 Tableau de fréquence",
    "text": "20.2 Tableau de fréquence\nOn peut tout à fait réaliser un tableau de fréquence classique avec gtsummary::tbl_summary().\n\nlibrary(gtsummary)\ndf |&gt; \n  tbl_summary(include = q1:q6)\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nN = 150\n1\n\n\n\n\nPremière question\n\n\n\n    Pas du tout d'accord\n39 (26%)\n\n\n    Plutôt pas d'accord\n32 (21%)\n\n\n    Ni d'accord, ni pas d'accord\n25 (17%)\n\n\n    Plutôt d'accord\n30 (20%)\n\n\n    Tout à fait d'accord\n24 (16%)\n\n\nSeconde question\n\n\n\n    Pas du tout d'accord\n56 (37%)\n\n\n    Plutôt pas d'accord\n44 (29%)\n\n\n    Ni d'accord, ni pas d'accord\n19 (13%)\n\n\n    Plutôt d'accord\n26 (17%)\n\n\n    Tout à fait d'accord\n5 (3.3%)\n\n\nTroisième question\n\n\n\n    Pas du tout d'accord\n8 (5.3%)\n\n\n    Plutôt pas d'accord\n17 (11%)\n\n\n    Ni d'accord, ni pas d'accord\n29 (19%)\n\n\n    Plutôt d'accord\n43 (29%)\n\n\n    Tout à fait d'accord\n53 (35%)\n\n\nQuatrième question\n\n\n\n    Pas du tout d'accord\n11 (7.3%)\n\n\n    Plutôt pas d'accord\n19 (13%)\n\n\n    Ni d'accord, ni pas d'accord\n31 (21%)\n\n\n    Plutôt d'accord\n40 (27%)\n\n\n    Tout à fait d'accord\n49 (33%)\n\n\nCinquième question\n\n\n\n    Pas du tout d'accord\n33 (26%)\n\n\n    Plutôt pas d'accord\n25 (20%)\n\n\n    Ni d'accord, ni pas d'accord\n28 (22%)\n\n\n    Plutôt d'accord\n25 (20%)\n\n\n    Tout à fait d'accord\n16 (13%)\n\n\n    Unknown\n23\n\n\nSixième question\n\n\n\n    Pas du tout d'accord\n50 (33%)\n\n\n    Plutôt pas d'accord\n0 (0%)\n\n\n    Ni d'accord, ni pas d'accord\n50 (33%)\n\n\n    Plutôt d'accord\n50 (33%)\n\n\n    Tout à fait d'accord\n0 (0%)\n\n\n\n\n1\nn (%)\n\n\n\n\n\n\n\nCependant, cela produit un tableau inutilement long, d’autant plus que les variables q1 à q6 ont les mêmes modalités de réponse. La fonction gtsummary::tbl_likert() offre un affichage plus compact.\n\ndf |&gt; \n  tbl_likert(\n    include = q1:q6\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nPas du tout d’accord\nPlutôt pas d’accord\nNi d’accord, ni pas d’accord\nPlutôt d’accord\nTout à fait d’accord\n\n\n\nPremière question\n39 (26%)\n32 (21%)\n25 (17%)\n30 (20%)\n24 (16%)\n\n\nSeconde question\n56 (37%)\n44 (29%)\n19 (13%)\n26 (17%)\n5 (3.3%)\n\n\nTroisième question\n8 (5.3%)\n17 (11%)\n29 (19%)\n43 (29%)\n53 (35%)\n\n\nQuatrième question\n11 (7.3%)\n19 (13%)\n31 (21%)\n40 (27%)\n49 (33%)\n\n\nCinquième question\n33 (26%)\n25 (20%)\n28 (22%)\n25 (20%)\n16 (13%)\n\n\nSixième question\n50 (33%)\n0 (0%)\n50 (33%)\n50 (33%)\n0 (0%)\n\n\n\n\n\n\n\nOn peut utiliser add_n() pour ajouter les effectifs totaux.\n\ndf |&gt; \n  tbl_likert(\n    include = q1:q6,\n    statistic = ~ \"{p}%\"\n  ) |&gt; \n  add_n()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN\nPas du tout d’accord\nPlutôt pas d’accord\nNi d’accord, ni pas d’accord\nPlutôt d’accord\nTout à fait d’accord\n\n\n\nPremière question\n150\n26%\n21%\n17%\n20%\n16%\n\n\nSeconde question\n150\n37%\n29%\n13%\n17%\n3.3%\n\n\nTroisième question\n150\n5.3%\n11%\n19%\n29%\n35%\n\n\nQuatrième question\n150\n7.3%\n13%\n21%\n27%\n33%\n\n\nCinquième question\n127\n26%\n20%\n22%\n20%\n13%\n\n\nSixième question\n150\n33%\n0%\n33%\n33%\n0%\n\n\n\n\n\n\n\n\n\n\n\n\n\nAstuce\n\n\n\nDans certains contextes, il est envisageable de traiter notre variable ordinale comme un score numérique. Ici, nous allons attribuer les valeurs -2, -1, 0, +1 et +2 à nos 5 modalités. Dès lors, nous pourrions être intéressé de rajouter à notre tableau le score moyen. Cela est possible en quelques étapes :\n\ntransformer nos facteurs en scores : les fonctions as.integer() ou unclass() permettent de transformer un facteur en valeurs numériques (1 pour la première modalité, 2 pour la seconde, etc.). Dans le cas présent, il est préférable d’utiliser unclass() qui préserve les étiquettes de variables ce qui n’est pas le cas de as.integer(). Il ne faut pas oublier de retirer 3 pour obtenir des scores allant de -2 à +2. La fonction dplyr::across() permet d’effectuer l’opération sur plusieurs variables en même temps.\ncalculer / générer un tableau statistique avec une colonne par statistique, ce qui se fait avec gtsummary::tbl_wide_summary() qui est très similaire à gtsummary::tbl_summary().\nmettre les deux tableaux dans une liste et les fusionner avec gtsummary::tbl_merge().\n\n\nlist(\n  df |&gt; tbl_likert(include = q1:q6),\n  tbl_wide_summary(\n    df|&gt; mutate(across(q1:q6, \\(x) unclass(x) - 3)),\n    statistic = c(\"{mean}\", \"{sd}\"),\n    type = ~ \"continuous\",\n    include = q1:q6,\n    digits = ~ 1\n  )\n) |&gt;\n  tbl_merge(tab_spanner = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nPas du tout d’accord\nPlutôt pas d’accord\nNi d’accord, ni pas d’accord\nPlutôt d’accord\nTout à fait d’accord\nMean\nSD\n\n\n\nPremière question\n39 (26%)\n32 (21%)\n25 (17%)\n30 (20%)\n24 (16%)\n-0.2\n1.4\n\n\nSeconde question\n56 (37%)\n44 (29%)\n19 (13%)\n26 (17%)\n5 (3.3%)\n-0.8\n1.2\n\n\nTroisième question\n8 (5.3%)\n17 (11%)\n29 (19%)\n43 (29%)\n53 (35%)\n0.8\n1.2\n\n\nQuatrième question\n11 (7.3%)\n19 (13%)\n31 (21%)\n40 (27%)\n49 (33%)\n0.6\n1.3\n\n\nCinquième question\n33 (26%)\n25 (20%)\n28 (22%)\n25 (20%)\n16 (13%)\n-0.3\n1.4\n\n\nSixième question\n50 (33%)\n0 (0%)\n50 (33%)\n50 (33%)\n0 (0%)\n-0.3\n1.3",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Échelles de Likert</span>"
    ]
  },
  {
    "objectID": "analyses/likert.html#représentations-graphiques",
    "href": "analyses/likert.html#représentations-graphiques",
    "title": "20  Échelles de Likert",
    "section": "\n20.3 Représentations graphiques",
    "text": "20.3 Représentations graphiques\nLe package ggstats propose une fonction ggstats::gglikert() pour représenter des données de Likert sous la forme d’un diagramme en barres centré sur la modalité centrale.\n\nlibrary(ggstats)\ngglikert(df, include = q1:q6)\n\n\n\n\n\n\n\nPar défaut, les pourcentages totaux ne prennent pas en compte la modalité centrale (lorsque le nombre de modalité est impair). On peut inclure la modalité centrale avec totals_include_center = TRUE, auquel cas la modalité centrale seront comptabilisée pour moitié de chaque côté. Le paramètre sort permet de trier les modalités (voir l’aide de ggstats::gglikert() pour plus de détails sur les différentes méthodes de tri).\n\ndf |&gt; \n  gglikert(\n    include = q1:q6,\n    totals_include_center = TRUE,\n    sort = \"ascending\"\n  ) +\n  guides(\n    fill = guide_legend(nrow = 2)\n  )\n\n\n\n\n\n\n\nIl est possible de séparer les résultats par sous-groupe avec des facettes.\n\ndf |&gt; \n  gglikert(\n    include = q1:q6,\n    facet_cols = vars(groupe)\n  )\n\n\n\n\n\n\ndf |&gt; \n  gglikert(\n    include = q1:q6,\n    y = \"groupe\",\n    facet_rows = vars(.question),\n    facet_label_wrap = 15\n  )\n\n\n\n\n\n\n\nUne représentation alternative consiste à réaliser un graphique en barres classiques, ce que l’on peut aisément obtenir avec ggstats::gglikert_stacked().\n\ndf |&gt;\n  gglikert_stacked(\n    include = q1:q6,\n    sort = \"ascending\",\n    add_median_line = TRUE\n  )",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Échelles de Likert</span>"
    ]
  },
  {
    "objectID": "analyses/regression-lineaire.html",
    "href": "analyses/regression-lineaire.html",
    "title": "21  Régression linéaire",
    "section": "",
    "text": "21.1 Modèle à une seule variable explicative continue\nNous avons déjà abordé très rapidement la régression linéaire dans le chapitre sur la statistique bivariée (cf. Section 19.3).\nReprenons le même exemple à partir du jeu de données iris qui comporte les caractéristiques de 150 fleurs de trois espèces différentes d’iris. Nous cherchons dans un premier temps à explorer la relation entre la largeur (Petal.Width) et la longueur des pétales (Petal.Length). Représentons cette relation sous la forme d’un nuage de points.\nlibrary(tidyverse)\nggplot(iris) +\n  aes(x = Petal.Length, y = Petal.Width) +\n  geom_point(colour = \"blue\", alpha = .25) +\n  labs(x = \"Longueur\", y = \"Largeur\") +\n  theme_light()\n\n\n\n\n\n\nFigure 21.1: Relation entre la largeur et la longueur des pétales (nuage de points)\nIl semble bien qu’il y a une relation linéaire entre ces deux variables, c’est-à-dire que la relation entre ces deux variables peut être représentée sous la forme d’une droite. Pour cela, on va rechercher la droite telle que la distance entre les points observés et la droite soit la plus petite possible. Cette droite peut être représentée graphique avec ggplot2::geom_smooth() et l’option method = \"lm\" :\nggplot(iris) +\n  aes(x = Petal.Length, y = Petal.Width) +\n  geom_point(colour = \"blue\", alpha = .25) +\n  geom_smooth(method = \"lm\") +\n  labs(x = \"Longueur\", y = \"Largeur\") +\n  theme_light()\n\n\n\n\n\n\nFigure 21.2: Relation linéaire entre la largeur et la longueur des pétales\nLa fonction de base pour calculer une régression linéaire est la fonction stats::m(). On doit en premier lieu spécifier le modèle à l’aide d’une formule : on indique la variable à expliquer dans la partie gauche de la formule et la variable explicative dans la partie droite, les deux parties étant séparées par un tilde1 (~).\nDans le cas présent, la variable Petal.Width fait office de variable à expliquer et Petal.Length de variable explicative. Le modèle s’écrit donc Petal.Width ~ Petal.Length.\nmod &lt;- lm(Petal.Width ~ Petal.Length, data = iris)\nmod\n\n\nCall:\nlm(formula = Petal.Width ~ Petal.Length, data = iris)\n\nCoefficients:\n (Intercept)  Petal.Length  \n     -0.3631        0.4158\nLe résultat comporte deux coefficients. Le premier, d’une valeur de \\(0,4158\\), est associé à la variable Petal.Length et indique la pente de la courbe (on parle de slope en anglais). Le second, d’une valeur de \\(-0,3631\\), représente l’ordonnée à l’origine (intercept en anglais), c’est-à-dire la valeur estimée de Petal.Width lorsque Petal.Length vaut 0. Nous pouvons rendre cela plus visible en élargissant notre graphique.\nggplot(iris) +\n  aes(x = Petal.Length, y = Petal.Width) +\n  geom_point(colour = \"blue\", alpha = .25) +\n  geom_abline(\n    intercept = mod$coefficients[1],\n    slope = mod$coefficients[2],\n    linewidth = 1,\n    colour = \"red\"\n  ) +\n  geom_vline(xintercept = 0, linewidth = 1, linetype = \"dotted\") +\n  labs(x = \"Longueur\", y = \"Largeur\") +\n  expand_limits(x = 0, y = -1) +\n  theme_light()\n\n\n\n\n\n\nFigure 21.3: Relation linéaire entre la largeur et la longueur des pétales (représentation graphique de l’intercept)\nLe modèle linéaire calculé estime donc que le relation entre nos deux variables peut s’écrire sous la forme suivante :\n\\[\nPetal.Width = 0,4158 \\cdot Petal.Length - 0,3631\n\\]\nLe package gtsummary fournit gtsummary::tbl_regression(), une fonction bien pratique pour produire un tableau propre avec les coefficients du modèle, leur intervalle de confiance à 95% et leur p-valeurs2. On précisera intercept = TRUE pour forcer l’affichage de l’intercept qui est masqué par défaut.\nlibrary(gtsummary)\nmod %&gt;%\n  tbl_regression(intercept = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nBeta\n\n95% CI\n1\n\np-value\n\n\n\n(Intercept)\n-0.36\n-0.44, -0.28\n&lt;0.001\n\n\nPetal.Length\n0.42\n0.40, 0.43\n&lt;0.001\n\n\n\n\n1\nCI = Confidence Interval\n\n\n\n\n\n\n\n\nTable 21.1: un tableau mis en forme des coefficients du modèle\nLes p-valeurs calculées nous indique si le coefficient est statistiquement différent de 0. En effet, pour la variable explicative, cela nous indique si la relation est statistiquement significative. Le signe du coefficient (positif ou négatif) nous indique le sens de la relation.",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Régression linéaire</span>"
    ]
  },
  {
    "objectID": "analyses/regression-lineaire.html#sec-regression-lineaire-variable-explicative-continue",
    "href": "analyses/regression-lineaire.html#sec-regression-lineaire-variable-explicative-continue",
    "title": "21  Régression linéaire",
    "section": "",
    "text": "1 Avec un clavier français, sous Windows, le caractère tilde s’obtient en pressant simultanément les touches Alt Gr et 7.\n\n\n\n\n\n\n2 Si l’on a besoin de ces informations sous la forme d’un tableau de données classique, on pourra se référer à broom.helpers::tidy_plus_plus(), utilisée de manière sous-jacente par gtsummary::tbl_regression(), ainsi qu’à la méthode broom::tidy(). Ces fonctions sont génériques et peut être utilisées avec une très grande variété de modèles.\n\n\n\n\n\n\n\nAstuce\n\n\n\nDans certains cas, si l’on suppose que la relation entre les deux variables est proportionnelle, on peut souhaiter calculer un modèle sans intercept. Par défaut, R ajoute un intercept à ses modèles. Pour forcer le calcul d’un modèle sans intercept, on ajoutera - 1 à la formule définissant le modèle.\n\nlm(Petal.Width ~ Petal.Length - 1, data = iris)\n\n\nCall:\nlm(formula = Petal.Width ~ Petal.Length - 1, data = iris)\n\nCoefficients:\nPetal.Length  \n      0.3365",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Régression linéaire</span>"
    ]
  },
  {
    "objectID": "analyses/regression-lineaire.html#sec-regression-lineaire-variable-explicative-categorielle",
    "href": "analyses/regression-lineaire.html#sec-regression-lineaire-variable-explicative-categorielle",
    "title": "21  Régression linéaire",
    "section": "\n21.2 Modèle à une seule variable explicative catégorielle",
    "text": "21.2 Modèle à une seule variable explicative catégorielle\nSi dans un modèle linéaire la variable à expliquer est nécessairement continue, il est possible de définir une variable explicative catégorielle. Prenons la variable Species.\n\nlibrary(labelled)\niris %&gt;% look_for(\"Species\")\n\n pos variable label col_type missing values    \n 5   Species  —     fct      0       setosa    \n                                     versicolor\n                                     virginica \n\n\nIl s’agit d’un facteur à trois modalités. Par défaut, la première valeur du facteur (ici setosa) va servir de modalité de référence.\n\nmod &lt;- lm(Petal.Width ~ Species, data = iris)\nmod\n\n\nCall:\nlm(formula = Petal.Width ~ Species, data = iris)\n\nCoefficients:\n      (Intercept)  Speciesversicolor   Speciesvirginica  \n            0.246              1.080              1.780  \n\n\n\nmod %&gt;%\n  tbl_regression(intercept = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nBeta\n\n95% CI\n1\n\np-value\n\n\n\n(Intercept)\n0.25\n0.19, 0.30\n&lt;0.001\n\n\nSpecies\n\n\n\n\n\n    setosa\n—\n—\n\n\n\n    versicolor\n1.1\n1.0, 1.2\n&lt;0.001\n\n\n    virginica\n1.8\n1.7, 1.9\n&lt;0.001\n\n\n\n\n1\nCI = Confidence Interval\n\n\n\n\n\n\n\n\nTable 21.2: régression linaire avec une variable explicative catégorielle\n\n\n\nDans ce cas de figure, l’intercept représente la situation à la référence, donc pour l’espèce setosa.\nCalculons les moyennes par espèce :\n\niris %&gt;%\n  group_by(Species) %&gt;%\n  summarise(mean(Petal.Width))\n\n# A tibble: 3 × 2\n  Species    `mean(Petal.Width)`\n  &lt;fct&gt;                    &lt;dbl&gt;\n1 setosa                   0.246\n2 versicolor               1.33 \n3 virginica                2.03 \n\n\nComme on le voit, l’intercept nous indique donc la moyenne observée pour l’espèce de référence (\\(0,246\\)).\nLe coefficient associé à versicolor correspond à la différence par rapport à la référence (ici \\(+1,080\\)). Comme vous pouvez le constater, il s’agit de la différence entre la moyenne observée pour versicolor (\\(1,326\\)) et celle de la référence setosa (\\(0,246\\)) : \\(1,326-0,246=1,080\\).\nCe coefficient est significativement différent de 0 (p&lt;0,001), indiquant que la largeur des pétales diffère significativement entre les deux espèces.\n\n\n\n\n\n\nAstuce\n\n\n\nLorsque l’on calcule le même modèle sans intercept, les coefficients s’interprètent un différemment :\n\nlm(Petal.Width ~ Species - 1, data = iris)\n\n\nCall:\nlm(formula = Petal.Width ~ Species - 1, data = iris)\n\nCoefficients:\n    Speciessetosa  Speciesversicolor   Speciesvirginica  \n            0.246              1.326              2.026  \n\n\nEn l’absence d’intercept, trois coefficients sont calculés et il n’y a plus ici de modalité de référence. Chaque coefficient représente donc la moyenne observée pour chaque modalité.\nOn appelle contrastes les différents manières de coder des variables catégorielles dans un modèle. Nous y reviendrons plus en détail dans un chapitre dédié (cf. Chapitre 25).",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Régression linéaire</span>"
    ]
  },
  {
    "objectID": "analyses/regression-lineaire.html#sec-regression-lineaire-multivariee",
    "href": "analyses/regression-lineaire.html#sec-regression-lineaire-multivariee",
    "title": "21  Régression linéaire",
    "section": "\n21.3 Modèle à plusieurs variables explicatives",
    "text": "21.3 Modèle à plusieurs variables explicatives\nUn des intérêts de la régression linéaire est de pouvoir estimer un modèle multivariable, c’est-à-dire avec plusieurs variables explicatives.\nPour cela, on listera les différentes variables explicatives dans la partie droite de la formule, séparées par le symbole +.\n\nmod &lt;- lm(\n  Petal.Width ~ Petal.Length + Sepal.Width + Sepal.Length + Species,\n  data = iris\n)\nmod\n\n\nCall:\nlm(formula = Petal.Width ~ Petal.Length + Sepal.Width + Sepal.Length + \n    Species, data = iris)\n\nCoefficients:\n      (Intercept)       Petal.Length        Sepal.Width       Sepal.Length  \n         -0.47314            0.24220            0.24220           -0.09293  \nSpeciesversicolor   Speciesvirginica  \n          0.64811            1.04637  \n\n\n\n\n\n\n\n\nNote\n\n\n\nDans la littérature, on trouve fréquemment utilisée à tort l’expression de modèle multivarié en lieu et place de modèle multivariable. Ces dernières années, de nombreux auteurs ont poussé à une clarification de la terminologie et à une distinction entre un modèle multivarié et un modèle multivariable.\nLa régression c’est l’analyse la relation d’un outcome (variable à expliquer) par rapport à une ou plusieurs variables prédictives (variables explicatives).\nUn modèle peut être simple ou univariable s’il ne comporte qu’une seule variable prédictive. Par contre, s’il comporte plusieurs variables prédictives, on parlera d’une régression multiple ou multivariable (multiple ou multivariable en anglais).\nSi la variable à expliquer (outcome) est répétée, c’est-à-dire que l’on a plusieurs observations pour un même individu statistique, par exemple dans le cadre d’une étude longitudinale, on parlera alors d’une régression multivariées (multivariate en anglais). Il peut alors s’agir d’une régression simple multivariée ou bien d’une régression multivariable multivariée.\nPar ailleurs, il ne faut pas confondre l’emploi des adjectifs univarié et bivarié appliqué aux termes statistiques ou analyses. L’analyse univariée ou la statistique univariée correspondent à l’analyse d’une seule variable (cf. Chapitre 18) tandis que la statistique bivariée correspond à l’analyse simultanée de deux variables (cf. Chapitre 19). Or, une régression simple ou univariable peut être utilisée dans le cadre d’une analyse bivariée.\n\n\n\nmod %&gt;%\n  tbl_regression(intercept = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nBeta\n\n95% CI\n1\n\np-value\n\n\n\n(Intercept)\n-0.47\n-0.82, -0.12\n0.008\n\n\nPetal.Length\n0.24\n0.15, 0.34\n&lt;0.001\n\n\nSepal.Width\n0.24\n0.15, 0.34\n&lt;0.001\n\n\nSepal.Length\n-0.09\n-0.18, 0.00\n0.039\n\n\nSpecies\n\n\n\n\n\n    setosa\n—\n—\n\n\n\n    versicolor\n0.65\n0.40, 0.89\n&lt;0.001\n\n\n    virginica\n1.0\n0.72, 1.4\n&lt;0.001\n\n\n\n\n1\nCI = Confidence Interval\n\n\n\n\n\n\n\n\nTable 21.3: régression linaire avec plusieurs variables explicatives\n\n\n\nCe type de modèle permet d’estimer l’effet de chaque variable explicative, toutes choses égales par ailleurs. Dans le cas présent, on s’aperçoit que la largeur des pétales diffère significativement selon les espèces, est fortement corrélée positivement à la longueur du pétale et la largeur du sépale et qu’il y a, lorsque l’on ajuste sur l’ensemble des autres variables, une relation négative (faiblement significative) avec la longueur du sépale.\nLorsque le nombre de coefficients est élevé, une représentation graphique est souvent plus facile à lire qu’un tableau. On parle alors de graphique en forêt ou forest plot en anglais. Rien de plus facile ! Il suffit d’avoir recours à ggstats::ggcoef_model().\n\nlibrary(ggstats)\nggcoef_model(mod)\n\n\n\n\n\n\nFigure 21.4: un graphique en forêt des coefficients du modèle\n\n\n\n\n\n\n\nFigure 21.1: Relation entre la largeur et la longueur des pétales (nuage de points)\nFigure 21.2: Relation linéaire entre la largeur et la longueur des pétales\nFigure 21.3: Relation linéaire entre la largeur et la longueur des pétales (représentation graphique de l’intercept)\nFigure 21.4: un graphique en forêt des coefficients du modèle",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Régression linéaire</span>"
    ]
  },
  {
    "objectID": "analyses/regression-logistique-binaire.html",
    "href": "analyses/regression-logistique-binaire.html",
    "title": "22  Régression logistique binaire",
    "section": "",
    "text": "22.1 Préparation des données\nDans ce chapitre, nous allons encore une fois utiliser les données de l’enquête Histoire de vie, fournies avec l’extension questionr.\ndata(hdv2003, package = \"questionr\")\nd &lt;- hdv2003\nÀ titre d’exemple, nous allons étudier l’effet de l’âge, du sexe, du niveau d’étude, de la pratique religieuse et du nombre moyen d’heures passées à regarder la télévision par jour sur la probabilité de pratiquer un sport.\nEn premier lieu, il importe de vérifier, par exemple avec labelled::look_for(), que notre variable d’intérêt (ici sport) est correctement codée, c’est-à-dire que la première modalité correspondent à la référence (soit ne pas avoir vécu l’évènement d’intérêt) et que la seconde modalité corresponde au fait d’avoir vécu l’évènement.\nlibrary(labelled)\nd |&gt; look_for(\"sport\")\n\n pos variable label col_type missing values\n 19  sport    —     fct      0       Non   \n                                     Oui\nDans notre exemple, la modalité Non est déjà la première modalité. Il n’y a donc pas besoin de modifier notre variable.\nIl faut également la présence éventuelle de données manquantes (NA)1. Les observations concernées seront tout simplement exclues du modèle lors de son calcul. Ce n’est pas notre cas ici.\nLa notion de modalité de référence s’applique également aux variables explicatives catégorielles. En effet, dans un modèle, tous les coefficients sont calculés par rapport à la modalité de référence (cf. Section 21.2). Il importe donc de choisir une modalité de référence qui fasse sens afin de faciliter l’interprétation. Par ailleurs, ce choix doit dépendre de la manière dont on souhaite présenter les résultats (le data storytelling est essentiel). De manière générale on évitera de choisir comme référence une modalité peu représentée dans l’échantillon ou bien une modalité correspondant à une situation atypique.\nPrenons l’exemple de la variable sexe. Souhaite-t-on connaitre l’effet d’être une femme par rapport au fait d’être un homme ou bien l’effet d’être un homme par rapport au fait d’être une femme ? Si l’on opte pour le second, alors notre modalité de référence sera le sexe féminin. Comme est codée cette variable ?\nd |&gt; look_for(\"sexe\")\n\n pos variable label col_type missing values\n 3   sexe     —     fct      0       Homme \n                                     Femme\nLa modalité Femme s’avère ne pas être la première modalité. Nous devons appliquer la fonction forcats::fct_relevel() ou la fonction stats::relevel() :\nlibrary(tidyverse)\nd &lt;- d |&gt; \n  mutate(sexe = sexe |&gt; fct_relevel(\"Femme\"))\nd$sexe |&gt; questionr::freq()\n\n         n  % val%\nFemme 1101 55   55\nHomme  899 45   45\nLes variables age et heures.tv sont des variables quantitatives. Il importe de vérifier qu’elles sont bien enregistrées en tant que variables numériques. En effet, il arrive parfois que dans le fichier source les variables quantitatives soient renseignées sous forme de valeur textuelle et non sous forme numérique.\nd |&gt; look_for(\"age\", \"heures\")\n\n pos variable  label col_type missing values\n 2   age       —     int      0             \n 20  heures.tv —     dbl      5\nNos deux variables sont bien renseignées sous forme numérique (respectivement des entiers et des nombres décimaux).\nCependant, l’effet de l’âge est rarement linéaire. Un exemple trivial est par exemple le fait d’occuper un emploi qui sera moins fréquent aux jeunes âges et aux âges élevés. Dès lors, on pourra transformer la variable age en groupe d’âges (et donc en variable catégorielle) avec la fonction cut() (cf. Section 9.4) :\nd &lt;- d |&gt; \n  mutate(\n    groupe_ages = age |&gt;\n      cut(\n        c(18, 25, 45, 65, 99),\n        right = FALSE,\n        include.lowest = TRUE,\n        labels = c(\"18-24 ans\", \"25-44 ans\",\n                   \"45-64 ans\", \"65 ans et plus\")\n      )\n  )\nd$groupe_ages |&gt; questionr::freq()\n\n                 n    % val%\n18-24 ans      169  8.5  8.5\n25-44 ans      706 35.3 35.3\n45-64 ans      745 37.2 37.2\n65 ans et plus 380 19.0 19.0\nJetons maintenant un œil à la variable nivetud :\nd$nivetud |&gt; questionr::freq()\n\n                                                                  n    % val%\nN'a jamais fait d'etudes                                         39  2.0  2.1\nA arrete ses etudes, avant la derniere annee d'etudes primaires  86  4.3  4.6\nDerniere annee d'etudes primaires                               341 17.0 18.1\n1er cycle                                                       204 10.2 10.8\n2eme cycle                                                      183  9.2  9.7\nEnseignement technique ou professionnel court                   463 23.2 24.5\nEnseignement technique ou professionnel long                    131  6.6  6.9\nEnseignement superieur y compris technique superieur            441 22.0 23.4\nNA                                                              112  5.6   NA\nEn premier lieu, cette variable est détaillée en pas moins de huit modalités dont certaines sont peu représentées (seulement 39 individus soit 2 % n’ont jamais fait d’études par exemple). Afin d’améliorer notre modèle logistique, il peut être pertinent de regrouper certaines modalités (cf. Section 9.3) :\nd &lt;- d |&gt; \n  mutate(\n    etudes = nivetud |&gt; \n      fct_recode(\n      \"Primaire\" = \"N'a jamais fait d'etudes\",\n      \"Primaire\" = \"A arrete ses etudes, avant la derniere annee d'etudes primaires\",\n      \"Primaire\" = \"Derniere annee d'etudes primaires\",\n      \"Secondaire\" = \"1er cycle\",\n      \"Secondaire\" = \"2eme cycle\",\n      \"Technique / Professionnel\" = \"Enseignement technique ou professionnel court\",\n      \"Technique / Professionnel\" = \"Enseignement technique ou professionnel long\",\n      \"Supérieur\" = \"Enseignement superieur y compris technique superieur\"\n    )    \n  )\nd$etudes |&gt; questionr::freq()\n\n                            n    % val%\nPrimaire                  466 23.3 24.7\nSecondaire                387 19.4 20.5\nTechnique / Professionnel 594 29.7 31.5\nSupérieur                 441 22.0 23.4\nNA                        112  5.6   NA\nNotre variable comporte également 112 individus avec une valeur manquante. Si nous conservons cette valeur manquante, ces 112 individus seront, par défaut, exclus de l’analyse. Ces valeurs manquantes n’étant pas négligeable (5,6 %), nous pouvons également faire le choix de considérer ces valeurs manquantes comme une modalité supplémentaire. Auquel cas, nous utiliserons la fonction forcats::fct_na_value_to_level()  :\nd$etudes &lt;- d$etudes |&gt; \n  fct_na_value_to_level(\"Non documenté\")\nEnfin, pour améliorer les différentes sorties (tableaux et figures), nous allons ajouter des étiquettes de variables (cf. Chapitre 11) avec labelled::set_variable_labels().\nd &lt;- d |&gt; \n  set_variable_labels(\n    sport = \"Pratique un sport ?\",\n    sexe = \"Sexe\",\n    groupe_ages = \"Groupe d'âges\",\n    etudes = \"Niveau d'études\",\n    relig = \"Rapport à la religion\",\n    heures.tv = \"Heures de télévision / jour\"\n  )",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Régression logistique binaire</span>"
    ]
  },
  {
    "objectID": "analyses/regression-logistique-binaire.html#préparation-des-données",
    "href": "analyses/regression-logistique-binaire.html#préparation-des-données",
    "title": "22  Régression logistique binaire",
    "section": "",
    "text": "1 Pour visualiser le nombre de données manquantes (NA) de l’ensemble des variables d’un tableau, on pourra avoir recours à questionr::freq.na().\n\n\n\n\n\nAstuce\n\n\n\nAlternativement, on pourra aussi coder notre variable à expliquer sous forme booléenne (FALSE / TRUE) ou numériquement en 0/1.\nIl est possible d’indiquer un facteur à plus de deux modalités. Dans une telle situation, R considérera que tous les modalités, sauf la modalité de référence, est une réalisation de la variable d’intérêt. Cela serait correct, par exemple, si notre variable sport était codée ainsi : Non, Oui, de temps en temps, Oui, régulièrement. Cependant, afin d’éviter tout risque d’erreur ou de mauvaise interprétation, il est vivement conseillé de recoder au préalable sa variable d’intérêt en un facteur à deux modalités.\n\n\n\n\n\n\n\n\n\nDonnées labellisées\nSi l’on utilise des données labellisées (voir Chapitre 12), nos variables catégorielles seront stockées sous la forme d’un vecteur numérique avec des étiquettes. Il sera donc nécessaire de convertir ces variables en facteurs, tout simplement avec labelled::to_factor() ou labelled::unlabelled().\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode récapitulatif (préparation des données)\n\n\n\n\ndata(hdv2003, package = \"questionr\")\nd &lt;-\n  hdv2003 |&gt; \n  mutate(\n    sexe = sexe |&gt; fct_relevel(\"Femme\"),\n    groupe_ages = age |&gt;\n      cut(\n        c(18, 25, 45, 65, 99),\n        right = FALSE,\n        include.lowest = TRUE,\n        labels = c(\"18-24 ans\", \"25-44 ans\",\n                   \"45-64 ans\", \"65 ans et plus\")\n      ),\n    etudes = nivetud |&gt; \n      fct_recode(\n        \"Primaire\" = \"N'a jamais fait d'etudes\",\n        \"Primaire\" = \"A arrete ses etudes, avant la derniere annee d'etudes primaires\",\n        \"Primaire\" = \"Derniere annee d'etudes primaires\",\n        \"Secondaire\" = \"1er cycle\",\n        \"Secondaire\" = \"2eme cycle\",\n        \"Technique / Professionnel\" = \"Enseignement technique ou professionnel court\",\n        \"Technique / Professionnel\" = \"Enseignement technique ou professionnel long\",\n        \"Supérieur\" = \"Enseignement superieur y compris technique superieur\"\n    ) |&gt; \n    fct_na_value_to_level(\"Non documenté\")  \n  ) |&gt; \n  set_variable_labels(\n    sport = \"Pratique un sport ?\",\n    sexe = \"Sexe\",\n    groupe_ages = \"Groupe d'âges\",\n    etudes = \"Niveau d'études\",\n    relig = \"Rapport à la religion\",\n    heures.tv = \"Heures de télévision / jour\"\n  )",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Régression logistique binaire</span>"
    ]
  },
  {
    "objectID": "analyses/regression-logistique-binaire.html#statistiques-descriptives",
    "href": "analyses/regression-logistique-binaire.html#statistiques-descriptives",
    "title": "22  Régression logistique binaire",
    "section": "\n22.2 Statistiques descriptives",
    "text": "22.2 Statistiques descriptives\nAvant toute analyse multivariable, il est toujours bon de procéder à une analyse descriptive bivariée simple, tout simplement avec gtsummary::tbl_summary(). Ajoutons quelques tests de comparaison avec gtsummary::add_p(). Petite astuce : gtsummary::modify_spanning_header() permet de rajouter un en-tête sur plusieurs colonnes.\n\nlibrary(gtsummary)\ntheme_gtsummary_language(\"fr\", decimal.mark = \",\", big.mark = \" \")\n\n\nd |&gt; \n  tbl_summary(\n    by = sport,\n    include = c(sexe, groupe_ages, etudes, relig, heures.tv)\n  ) |&gt;\n  add_overall(last = TRUE) |&gt; \n  add_p() |&gt; \n  bold_labels() |&gt; \n  modify_spanning_header(\n    update = all_stat_cols() ~ \"**Pratique un sport ?**\"\n  )\n\nWarning: The `update` argument of `modify_spanning_header()` is deprecated as of\ngtsummary 2.0.0.\nℹ Use `modify_spanning_header(...)` input instead. Dynamic dots allow for\n  syntax like `modify_spanning_header(!!!list(...))`.\nℹ The deprecated feature was likely used in the gtsummary package.\n  Please report the issue at &lt;https://github.com/ddsjoberg/gtsummary/issues&gt;.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\n\nPratique un sport ?\n\n\np-valeur\n2\n\n\n\n\nNon\nN = 1 277\n1\n\n\nOui\nN = 723\n1\n\n\nOverall\nN = 2 000\n1\n\n\n\n\n\nSexe\n\n\n\n&lt;0,001\n\n\n    Femme\n747 (58%)\n354 (49%)\n1 101 (55%)\n\n\n\n    Homme\n530 (42%)\n369 (51%)\n899 (45%)\n\n\n\nGroupe d'âges\n\n\n\n&lt;0,001\n\n\n    18-24 ans\n58 (4,5%)\n111 (15%)\n169 (8,5%)\n\n\n\n    25-44 ans\n359 (28%)\n347 (48%)\n706 (35%)\n\n\n\n    45-64 ans\n541 (42%)\n204 (28%)\n745 (37%)\n\n\n\n    65 ans et plus\n319 (25%)\n61 (8,4%)\n380 (19%)\n\n\n\nNiveau d'études\n\n\n\n&lt;0,001\n\n\n    Primaire\n416 (33%)\n50 (6,9%)\n466 (23%)\n\n\n\n    Secondaire\n270 (21%)\n117 (16%)\n387 (19%)\n\n\n\n    Technique / Professionnel\n378 (30%)\n216 (30%)\n594 (30%)\n\n\n\n    Supérieur\n186 (15%)\n255 (35%)\n441 (22%)\n\n\n\n    Non documenté\n27 (2,1%)\n85 (12%)\n112 (5,6%)\n\n\n\nRapport à la religion\n\n\n\n0,14\n\n\n    Pratiquant regulier\n182 (14%)\n84 (12%)\n266 (13%)\n\n\n\n    Pratiquant occasionnel\n295 (23%)\n147 (20%)\n442 (22%)\n\n\n\n    Appartenance sans pratique\n473 (37%)\n287 (40%)\n760 (38%)\n\n\n\n    Ni croyance ni appartenance\n239 (19%)\n160 (22%)\n399 (20%)\n\n\n\n    Rejet\n60 (4,7%)\n33 (4,6%)\n93 (4,7%)\n\n\n\n    NSP ou NVPR\n28 (2,2%)\n12 (1,7%)\n40 (2,0%)\n\n\n\nHeures de télévision / jour\n2,00 (1,00 – 3,00)\n2,00 (1,00 – 3,00)\n2,00 (1,00 – 3,00)\n&lt;0,001\n\n\n    Manquant\n2\n3\n5\n\n\n\n\n\n\n1\nn (%); Médiane (Q1 – Q3)\n\n\n\n\n2\ntest du khi-deux d’indépendance; test de Wilcoxon-Mann-Whitney\n\n\n\n\n\n\n\n\n\nTable 22.1: Pratique d’un sport selon différentes variables explicatives (analyse bivariée)",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Régression logistique binaire</span>"
    ]
  },
  {
    "objectID": "analyses/regression-logistique-binaire.html#calcul-de-la-régression-logistique-binaire",
    "href": "analyses/regression-logistique-binaire.html#calcul-de-la-régression-logistique-binaire",
    "title": "22  Régression logistique binaire",
    "section": "\n22.3 Calcul de la régression logistique binaire",
    "text": "22.3 Calcul de la régression logistique binaire\nLa spécification d’une régression logistique se fait avec stats::glm() et est très similaire à celle d’une régression linéaire simple (cf. Section 21.3) : on indique la variable à expliquer suivie d’un tilde (~) puis des variables explicatives séparées par un plus (+)2. Il faut indiquer à glm() la famille du modèle souhaité : on indiquera simplement family = binomial pour un modèle logit3.\n2 Il est possible de spécifier des modèles plus complexes, notamment avec des effets d’interaction, qui seront aborder plus loin (cf. Chapitre 26).3 Pour un modèle probit, on indiquera family = binomial(\"probit\").\nmod &lt;- glm(\n  sport ~ sexe + groupe_ages + etudes + relig + heures.tv,\n  family = binomial,\n  data = d\n)\n\nPour afficher les résultats du modèle, le plus simple est d’avoir recours à gtsummary::tbl_regression().\n\nmod |&gt; \n  tbl_regression(intercept = TRUE) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nlog(OR)\n1\n\n\n95% IC\n1\n\np-valeur\n\n\n\n(Intercept)\n-0,80\n-1,4 – -0,17\n0,014\n\n\nSexe\n\n\n\n\n\n    Femme\n—\n—\n\n\n\n    Homme\n0,44\n0,23 – 0,65\n&lt;0,001\n\n\nGroupe d'âges\n\n\n\n\n\n    18-24 ans\n—\n—\n\n\n\n    25-44 ans\n-0,42\n-0,87 – 0,03\n0,065\n\n\n    45-64 ans\n-1,1\n-1,6 – -0,62\n&lt;0,001\n\n\n    65 ans et plus\n-1,4\n-1,9 – -0,85\n&lt;0,001\n\n\nNiveau d'études\n\n\n\n\n\n    Primaire\n—\n—\n\n\n\n    Secondaire\n0,95\n0,57 – 1,3\n&lt;0,001\n\n\n    Technique / Professionnel\n1,0\n0,68 – 1,4\n&lt;0,001\n\n\n    Supérieur\n1,9\n1,5 – 2,3\n&lt;0,001\n\n\n    Non documenté\n2,2\n1,5 – 2,8\n&lt;0,001\n\n\nRapport à la religion\n\n\n\n\n\n    Pratiquant regulier\n—\n—\n\n\n\n    Pratiquant occasionnel\n-0,02\n-0,39 – 0,35\n&gt;0,9\n\n\n    Appartenance sans pratique\n-0,01\n-0,35 – 0,34\n&gt;0,9\n\n\n    Ni croyance ni appartenance\n-0,22\n-0,59 – 0,16\n0,3\n\n\n    Rejet\n-0,38\n-0,95 – 0,17\n0,2\n\n\n    NSP ou NVPR\n-0,08\n-0,92 – 0,70\n0,8\n\n\nHeures de télévision / jour\n-0,12\n-0,19 – -0,06\n&lt;0,001\n\n\n\n\n1\nOR = rapport de cotes, IC = intervalle de confiance\n\n\n\n\n\n\n\n\nTable 22.2: Facteurs associés à la pratique d’un sport (régression logistique binaire)",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Régression logistique binaire</span>"
    ]
  },
  {
    "objectID": "analyses/regression-logistique-binaire.html#sec-interpreter-coefficients-regression-logistique",
    "href": "analyses/regression-logistique-binaire.html#sec-interpreter-coefficients-regression-logistique",
    "title": "22  Régression logistique binaire",
    "section": "\n22.4 Interpréter les coefficients",
    "text": "22.4 Interpréter les coefficients\nL’intercept traduit la situation à la référence (i.e. toutes les variables catégorielles à leur modalité de référence et les variables continues à 0), après transformation selon la fonction de lien (i.e. après la transformation logit).\nIllustrons cela. Supposons donc une personne de sexe féminin, âgée entre 18 et 24 ans, de niveau d’étude primaire, pratiquante régulière et ne regardant pas la télévision (situation de référence). Seul l’intercept s’applique dans le modèle, et donc le modèle prédit que sa probabilité de faire du sport est de \\(-0,80\\) selon l’échelle logit. Retraduisons cela en probabilité classique avec la fonction logit inverse.\n\nlogit_inverse &lt;- binomial(\"logit\") |&gt; purrr::pluck(\"linkinv\")\nlogit_inverse(-0.80)\n\n[1] 0.3100255\n\n\nSelon le modèle, la probabilité que cette personne fasse du sport est donc de \\(31\\%\\).\nPrenons maintenant une personne identique mais de sexe masculin. Nous devons donc considérer, en plus de l’intercept, le coefficient associé à la modalité Homme. Sa probabilité de faire du sport est donc :\n\nlogit_inverse(-0.80 + 0.44)\n\n[1] 0.4109596\n\n\nLe coefficient associé à Homme est donc un modificateur par rapport à la situation de référence.\nEnfin, considérons que cette dernière personne regarde également la télévision 2 heures en moyenne par jour. Nous devons alors considérer le coefficient associé à la variable heures.tv et, comme il s’agit d’une variable continue, multiplier ce coefficient par 2, car le coefficient représente le changement pour un incrément de 1 unité.\n\nlogit_inverse(-0.80 + 0.44 + 2 * -0.12)\n\n[1] 0.3543437\n\n\nIl est crucial de bien comprendre comment dans quels cas et comment chaque coefficient est utilisé par le modèle.\nLe package {breakdown} permet de mieux visualiser notre dernier exemple.\n\nindividu3 &lt;- d[1, ]\nindividu3$sexe[1] &lt;- \"Homme\"\nindividu3$groupe_ages[1] &lt;- \"18-24 ans\"\nindividu3$etudes[1] &lt;- \"Primaire\"\nindividu3$relig[1] &lt;- \"Pratiquant regulier\"\nindividu3$heures.tv[1] &lt;- 2\n\n\nlibrary(breakDown)\nlogit &lt;- function(x) exp(x) / (1 + exp(x))\nplot(\n  broken(mod, individu3, predict.function = betas),\n  trans = logit\n) +\n  scale_y_continuous(\n    labels = scales::label_percent(),\n    breaks = 0:5/5,\n    limits = c(0, 1)\n  )\n\n\n\nDécomposition de la probabilité de faire du sport de l’individu 3",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Régression logistique binaire</span>"
    ]
  },
  {
    "objectID": "analyses/regression-logistique-binaire.html#la-notion-dodds-ratio",
    "href": "analyses/regression-logistique-binaire.html#la-notion-dodds-ratio",
    "title": "22  Régression logistique binaire",
    "section": "\n22.5 La notion d’odds ratio\n",
    "text": "22.5 La notion d’odds ratio\n\nL’un des intérêts de la régression logistique logit réside dans le fait que l’exponentiel des coefficients correspond à des odds ratio ou rapport des côtes en français.\n\n\n\n\n\n\nAstuce\n\n\n\nPour comprendre la notion de côte (odd en anglais), on peut se référer aux paris sportifs. Par exemple, lorsque les trois quarts des parieurs parient que le cheval A va remporter la course, on dit alors que ce cheval à une côte de trois contre un (trois personnes parient qu’il va gagner contre une personne qu’il va perdre). Prenons un autre cheval : si les deux tiers pensent que le cheval B va perdre (donc un tiers pense qu’il va gagner), on dira alors que sa côte est de un contre deux (une personne pense qu’il va gagner contre deux qu’il va perdre).\nSi l’on connait la proportion ou probabilité p d’avoir vécu ou de vivre un évènement donné (ici gagner la course), la côte (l’odd) s’obtient avec la formule suivante : \\(p/(1-p)\\). La côte du cheval A est bien \\(0,75/(1-0,75)=0,75/0,25=3\\) est celle du cheval B \\((1/3)/(2/3)=1/2=0,5\\).\nPour comparer deux côtes (par exemple pour savoir si le cheval A a une probabilité plus élevée de remporter la course que le cheval B, selon les parieurs), on calculera tout simplement le rapport des côtes ou odds ratio (OR) : \\(OR_{A/B}=Odds_{A}/Odds_{B}=3/0,5=6\\).\nCe calcul peut se faire facilement dans R avec la fonction questionr::odds.ratio().\n\nquestionr::odds.ratio(.75, 1/3)\n\n[1] 6\n\n\nL’odds ratio est donc égal à 1 si les deux côtes sont identiques, est supérieur à 1 si le cheval A une probabilité supérieure à celle du cheval B, et inférieur à 1 si c’est probabilité est inférieure.\nOn le voit, par construction, l’odds ratio de B par rapport à A est l’inverse de celui de A par rapport à B : \\(OR_{B/A}=1/OR_{A/B}\\).\n\n\nPour afficher les odds ratio il suffit d’indiquer exponentiate = TRUE à gtsummary::tbl_regression().\n\nmod |&gt; \n  tbl_regression(exponentiate = TRUE) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nOR\n1\n\n\n95% IC\n1\n\np-valeur\n\n\n\nSexe\n\n\n\n\n\n    Femme\n—\n—\n\n\n\n    Homme\n1,55\n1,26 – 1,91\n&lt;0,001\n\n\nGroupe d'âges\n\n\n\n\n\n    18-24 ans\n—\n—\n\n\n\n    25-44 ans\n0,66\n0,42 – 1,03\n0,065\n\n\n    45-64 ans\n0,34\n0,21 – 0,54\n&lt;0,001\n\n\n    65 ans et plus\n0,25\n0,15 – 0,43\n&lt;0,001\n\n\nNiveau d'études\n\n\n\n\n\n    Primaire\n—\n—\n\n\n\n    Secondaire\n2,59\n1,77 – 3,83\n&lt;0,001\n\n\n    Technique / Professionnel\n2,86\n1,98 – 4,17\n&lt;0,001\n\n\n    Supérieur\n6,63\n4,55 – 9,80\n&lt;0,001\n\n\n    Non documenté\n8,59\n4,53 – 16,6\n&lt;0,001\n\n\nRapport à la religion\n\n\n\n\n\n    Pratiquant regulier\n—\n—\n\n\n\n    Pratiquant occasionnel\n0,98\n0,68 – 1,42\n&gt;0,9\n\n\n    Appartenance sans pratique\n0,99\n0,71 – 1,40\n&gt;0,9\n\n\n    Ni croyance ni appartenance\n0,81\n0,55 – 1,18\n0,3\n\n\n    Rejet\n0,68\n0,39 – 1,19\n0,2\n\n\n    NSP ou NVPR\n0,92\n0,40 – 2,02\n0,8\n\n\nHeures de télévision / jour\n0,89\n0,83 – 0,95\n&lt;0,001\n\n\n\n\n1\nOR = rapport de cotes, IC = intervalle de confiance\n\n\n\n\n\n\n\n\nTable 22.3: Facteurs associés à la pratique d’un sport (odds ratios)\n\n\n\nPour une représentation visuelle, graphique en forêt ou forest plot en anglais, on aura tout simplement recours à ggstats::ggcoef_model().\n\nmod |&gt; \n  ggstats::ggcoef_model(exponentiate = TRUE)\n\n\n\n\n\n\nFigure 22.1: Facteurs associés à la pratique d’un sport (forest plot)\n\n\n\n\nOn pourra alternativement préférer ggstats::ggcoef_table()4 qui affiche un tableau des coefficients à la droite du forest plot.\n4 ggstats::ggcoef_table() est disponible à partir de la version 0.4.0 de ggstats.\nmod |&gt; \n  ggstats::ggcoef_table(exponentiate = TRUE)\n\n\n\n\n\n\nFigure 22.2: Facteurs associés à la pratique d’un sport (forest plot avec table des coefficients)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nLorsque l’on réalise un forest plot de coefficients exponentialisés tels que des odds ratios, une bonne pratique consiste à utiliser une échelle logarithmique. En effet, l’inverse d’un odds ratio de 2 est 0,5. Avec une échelle logarithmique, la distance entre 0,5 et 1 est égale à celle entre 1 et 2. Sur la figure précédente, vous pourrez noter que ggstats::ggcoef_model() applique automatiquement une échelle logarithmique lorsque exponentiate = TRUE.\nQuelques références : Forest Plots: Linear or Logarithmic Scale? ou encore Graphing Ratio Measures on Forest Plot.\n\n\n\n\n\n\n\n\nMise en garde\n\n\n\nEn rédigeant les résultats de la régression, il faudra être vigilant à ne pas confondre les odds ratios avec des prevalence ratios. Avec un odds ratio de 1,55, il serait tentant d’écrire que les hommes ont une probabilité 55% supérieure de pratique un sport que les femmes (toutes choses égales par ailleurs). Une telle formulation correspond à un prevalence ratio (rapport des prévalences en français) ou risk ratio (rapport des risques), à savoir diviser la probabilité de faire du sport des hommes par celle des femmes, \\(p_{hommes}/p_{femmes}\\). Or, cela ne correspond pas à la formule de l’odds ratio, à savoir \\((p_{hommes}/(1-p_{hommes}))/(p_{femmes}/(1-p_{femmes}))\\).\nLorsque le phénomène étudié est rare et donc que les probabilités sont faibles (inférieures à quelques pour-cents), alors il est vrai que les odds ratio sont approximativement égaux aux prevalence ratios. Mais ceci n’est plus du tout vrai pour des phénomènes plus fréquents.",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Régression logistique binaire</span>"
    ]
  },
  {
    "objectID": "analyses/regression-logistique-binaire.html#afficher-les-écarts-types-plutôt-que-les-intervalles-de-confiance",
    "href": "analyses/regression-logistique-binaire.html#afficher-les-écarts-types-plutôt-que-les-intervalles-de-confiance",
    "title": "22  Régression logistique binaire",
    "section": "\n22.6 Afficher les écarts-types plutôt que les intervalles de confiance",
    "text": "22.6 Afficher les écarts-types plutôt que les intervalles de confiance\nLa manière de présenter les résultats d’un modèle de régression varie selon les disciplines, les champs thématiques et les revues. Si en sociologie et épidémiologie on aurait plutôt tendance à afficher les odds ratio avec leur intervalle de confiance, il est fréquent en économétrie de présenter plutôt les coefficients bruts et leurs écarts-types (standard deviation ou sd en anglais). De même, plutôt que d’ajouter une colonne avec les p valeurs, un usage consiste à afficher des étoiles de significativité à la droite des coefficients significatifs.\nPour cela, on pourra personnaliser le tableau produit avec gtsummary::tbl_regression(), notamment avec gtsummary::add_significance_stars() pour l’ajout des étoiles de significativité, ainsi que gtsummary::modify_column_hide() et gtsummary::modify_column_unhide() pour afficher / masquer les colonnes du tableau produit5.\n5 La liste des colonnes disponibles peut être obtenues avec mod |&gt; tbl_regression() |&gt; purrr::pluck(\"table_body\") |&gt; colnames().\nmod |&gt; \n  tbl_regression() |&gt; \n  add_significance_stars() |&gt; \n  modify_column_hide(c(\"ci\", \"p.value\")) |&gt; \n  modify_column_unhide(\"std.error\") |&gt; \n  bold_labels()\n\nWarning: Use of the \"ci\" column was deprecated in gtsummary v2.0, and the column will\neventually be removed from the tables.\n! Review `?deprecated_ci_column()` for details on how to update your code.\nℹ The \"ci\" column has been replaced by the merged \"conf.low\" and \"conf.high\"\n  columns (merged with `modify_column_merge()`).\nℹ In most cases, a simple update from `ci = 'a new label'` to `conf.low = 'a\n  new label'` is sufficient.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nlog(OR)\n1,2\n\n\nET\n2\n\n\n\n\nSexe\n\n\n\n\n    Femme\n—\n—\n\n\n    Homme\n0,44***\n0,106\n\n\nGroupe d'âges\n\n\n\n\n    18-24 ans\n—\n—\n\n\n    25-44 ans\n-0,42\n0,228\n\n\n    45-64 ans\n-1,1***\n0,238\n\n\n    65 ans et plus\n-1,4***\n0,274\n\n\nNiveau d'études\n\n\n\n\n    Primaire\n—\n—\n\n\n    Secondaire\n0,95***\n0,197\n\n\n    Technique / Professionnel\n1,0***\n0,190\n\n\n    Supérieur\n1,9***\n0,195\n\n\n    Non documenté\n2,2***\n0,330\n\n\nRapport à la religion\n\n\n\n\n    Pratiquant regulier\n—\n—\n\n\n    Pratiquant occasionnel\n-0,02\n0,189\n\n\n    Appartenance sans pratique\n-0,01\n0,175\n\n\n    Ni croyance ni appartenance\n-0,22\n0,193\n\n\n    Rejet\n-0,38\n0,286\n\n\n    NSP ou NVPR\n-0,08\n0,411\n\n\nHeures de télévision / jour\n-0,12***\n0,034\n\n\n\n\n\n1\np&lt;0.05; p&lt;0.01; p&lt;0.001\n\n\n\n\n2\nOR = rapport de cotes, ET = écart-type\n\n\n\n\n\n\n\n\n\nTable 22.4: Présentation économétrique des facteurs associés à la pratique d’un sport\n\n\n\nLes économistes pourraient préférer le package modelsummary à gtsummary. Ces deux packages ont un objectif similaire (la production de tableaux statistiques) mais abordent cet objectif avec des approches différentes. Il faut noter que modelsummary::modelsummary() n’affiche pas les modalités de référence, ni les étiquettes de variable.\n\nmod |&gt; modelsummary::modelsummary(stars = TRUE)\n\n\n\n \n\n  \n    \n\ntinytable_k9vd3obzk0e658o3bieo\n\n\n      \n\n \n                (1)\n              \n+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n(Intercept)                     \n                  -0.798*  \n                \n\n                                \n                  (0.324)  \n                \n\nsexeHomme                       \n                  0.440*** \n                \n\n                                \n                  (0.106)  \n                \n\ngroupe_ages25-44 ans            \n                  -0.420+  \n                \n\n                                \n                  (0.228)  \n                \n\ngroupe_ages45-64 ans            \n                  -1.085***\n                \n\n                                \n                  (0.238)  \n                \n\ngroupe_ages65 ans et plus       \n                  -1.381***\n                \n\n                                \n                  (0.274)  \n                \n\netudesSecondaire                \n                  0.951*** \n                \n\n                                \n                  (0.197)  \n                \n\netudesTechnique / Professionnel \n                  1.049*** \n                \n\n                                \n                  (0.190)  \n                \n\netudesSupérieur                 \n                  1.892*** \n                \n\n                                \n                  (0.195)  \n                \n\netudesNon documenté             \n                  2.150*** \n                \n\n                                \n                  (0.330)  \n                \n\nreligPratiquant occasionnel     \n                  -0.022   \n                \n\n                                \n                  (0.189)  \n                \n\nreligAppartenance sans pratique \n                  -0.007   \n                \n\n                                \n                  (0.175)  \n                \n\nreligNi croyance ni appartenance\n                  -0.215   \n                \n\n                                \n                  (0.193)  \n                \n\nreligRejet                      \n                  -0.384   \n                \n\n                                \n                  (0.286)  \n                \n\nreligNSP ou NVPR                \n                  -0.084   \n                \n\n                                \n                  (0.411)  \n                \n\nheures.tv                       \n                  -0.121***\n                \n\n                                \n                  (0.034)  \n                \n\nNum.Obs.                        \n                  1995     \n                \n\nAIC                             \n                  2236.2   \n                \n\nBIC                             \n                  2320.1   \n                \n\nLog.Lik.                        \n                  -1103.086\n                \n\nF                               \n                  21.691   \n                \n\nRMSE                            \n                  0.43     \n                \n\n\n\n\n    \n\n\n\nTable 22.5: Présentation des facteurs associés à la pratique d’un sport avec modelsummary()\n\n\n\nLa fonction modelsummary::modelplot() permet d’afficher un graphique des coefficients.\n\nmod |&gt; modelsummary::modelplot()\n\n\n\n\n\n\nFigure 22.3: Facteurs associés à la pratique d’un sport avec modelplot()\n\n\n\n\nATTENTION : si l’on affiche les odds ratio avec exponentiate = TRUE, modelsummary::modelplot() conserve par défaut une échelle linéaire. On sera donc vigilant à appliquer ggplot2::scale_x_log10() manuellement pour utiliser une échelle logarithmique.\n\nmod |&gt;\n  modelsummary::modelplot(exponentiate = TRUE) +\n  ggplot2::scale_x_log10()\n\n\n\n\n\n\nFigure 22.4: Odds Ratios associés à la pratique d’un sport avec modelplot()",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Régression logistique binaire</span>"
    ]
  },
  {
    "objectID": "analyses/regression-logistique-binaire.html#afficher-toutes-les-comparaisons-pairwise-contrasts",
    "href": "analyses/regression-logistique-binaire.html#afficher-toutes-les-comparaisons-pairwise-contrasts",
    "title": "22  Régression logistique binaire",
    "section": "\n22.7 Afficher toutes les comparaisons (pairwise contrasts)",
    "text": "22.7 Afficher toutes les comparaisons (pairwise contrasts)\nDans le tableau des résultats (Table 22.3), pour les variables catégorielles, il importe de bien garder en mémoire que chaque odds ratio doit se comparer à la valeur de référence. Ainsi, les odds ratios affichés pour chaque classe d’âges correspondent à une comparaison avec la classe d’âges de références, les 18-24 ans. La p-valeur associée nous indique quant à elle si cet odds ratio est significativement de 1, donc si cette classe d’âges données se comporte différemment de celle de référence.\nMais cela ne nous dit nullement si les 65 ans et plus diffèrent des 45-64 ans. Il est tout à fait possible de recalculer l’odds ratio correspondant en rapport les odds ratio à la référence : \\(OR_{65+/45-64}=OR_{65+/18-24}/OR_{45-64/18-24}\\).\nLe package emmeans et sa fonction emmeans::emmeans() permettent de recalculer toutes les combinaisons d’odds ratio (on parle alors de pairwise contrasts) ainsi que leur intervalle de confiance et la p-valeur correspondante.\nOn peut ajouter facilement6 cela au tableau produit avec gtsummary::tbl_regression() en ajoutant l’option add_pairwise_contrasts = TRUE.\n6 Cela nécessite néanmoins au minimum la version 1.11.0 du package broom.helpers et la version 1.6.3 de gtsummary.\nmod |&gt; \n  tbl_regression(\n    exponentiate = TRUE,\n    add_pairwise_contrasts = TRUE\n  ) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nOR\n1\n\n\n95% IC\n1\n\np-valeur\n\n\n\nSexe\n\n\n\n\n\n    Homme / Femme\n1,55\n1,26 – 1,91\n&lt;0,001\n\n\nGroupe d'âges\n\n\n\n\n\n    (25-44 ans) / (18-24 ans)\n0,66\n0,37 – 1,18\n0,3\n\n\n    (45-64 ans) / (18-24 ans)\n0,34\n0,18 – 0,62\n&lt;0,001\n\n\n    (45-64 ans) / (25-44 ans)\n0,51\n0,38 – 0,70\n&lt;0,001\n\n\n    65 ans et plus / (18-24 ans)\n0,25\n0,12 – 0,51\n&lt;0,001\n\n\n    65 ans et plus / (25-44 ans)\n0,38\n0,24 – 0,61\n&lt;0,001\n\n\n    65 ans et plus / (45-64 ans)\n0,74\n0,47 – 1,17\n0,3\n\n\nNiveau d'études\n\n\n\n\n\n    Secondaire / Primaire\n2,59\n1,51 – 4,43\n&lt;0,001\n\n\n    (Technique / Professionnel) / Primaire\n2,86\n1,70 – 4,79\n&lt;0,001\n\n\n    (Technique / Professionnel) / Secondaire\n1,10\n0,74 – 1,64\n&gt;0,9\n\n\n    Supérieur / Primaire\n6,63\n3,89 – 11,3\n&lt;0,001\n\n\n    Supérieur / Secondaire\n2,56\n1,69 – 3,88\n&lt;0,001\n\n\n    Supérieur / (Technique / Professionnel)\n2,32\n1,61 – 3,36\n&lt;0,001\n\n\n    Non documenté / Primaire\n8,59\n3,49 – 21,1\n&lt;0,001\n\n\n    Non documenté / Secondaire\n3,32\n1,46 – 7,53\n&lt;0,001\n\n\n    Non documenté / (Technique / Professionnel)\n3,01\n1,38 – 6,56\n0,001\n\n\n    Non documenté / Supérieur\n1,30\n0,58 – 2,90\n&gt;0,9\n\n\nRapport à la religion\n\n\n\n\n\n    Pratiquant occasionnel / Pratiquant regulier\n0,98\n0,57 – 1,68\n&gt;0,9\n\n\n    Appartenance sans pratique / Pratiquant regulier\n0,99\n0,60 – 1,63\n&gt;0,9\n\n\n    Appartenance sans pratique / Pratiquant occasionnel\n1,02\n0,68 – 1,52\n&gt;0,9\n\n\n    Ni croyance ni appartenance / Pratiquant regulier\n0,81\n0,47 – 1,40\n0,9\n\n\n    Ni croyance ni appartenance / Pratiquant occasionnel\n0,82\n0,52 – 1,31\n0,8\n\n\n    Ni croyance ni appartenance / Appartenance sans pratique\n0,81\n0,54 – 1,21\n0,7\n\n\n    Rejet / Pratiquant regulier\n0,68\n0,30 – 1,54\n0,8\n\n\n    Rejet / Pratiquant occasionnel\n0,70\n0,33 – 1,49\n0,8\n\n\n    Rejet / Appartenance sans pratique\n0,69\n0,33 – 1,41\n0,7\n\n\n    Rejet / Ni croyance ni appartenance\n0,85\n0,40 – 1,79\n&gt;0,9\n\n\n    NSP ou NVPR / Pratiquant regulier\n0,92\n0,29 – 2,97\n&gt;0,9\n\n\n    NSP ou NVPR / Pratiquant occasionnel\n0,94\n0,30 – 2,92\n&gt;0,9\n\n\n    NSP ou NVPR / Appartenance sans pratique\n0,93\n0,30 – 2,82\n&gt;0,9\n\n\n    NSP ou NVPR / Ni croyance ni appartenance\n1,14\n0,37 – 3,55\n&gt;0,9\n\n\n    NSP ou NVPR / Rejet\n1,35\n0,37 – 4,88\n&gt;0,9\n\n\nHeures de télévision / jour\n0,89\n0,83 – 0,95\n&lt;0,001\n\n\n\n\n1\nOR = rapport de cotes, IC = intervalle de confiance\n\n\n\n\n\n\n\n\nTable 22.6: Facteurs associés à la pratique d’un sport (pairwise contrasts)\n\n\n\nDe même, on peur visualiser les coefficients avec la même option dans ggstats::ggcoef_model()7. On peut d’ailleurs choisir les variables concernées avec l’argument pairwise_variables.\n7 Cela nécessite néanmoins au minimum la version 1.11.0 du package broom.helpers et la version 0.2.0 de ggstats.\nmod |&gt; \n  ggstats::ggcoef_model(\n    exponentiate = TRUE,\n    add_pairwise_contrasts = TRUE,\n    pairwise_variables = c(\"groupe_ages\", \"etudes\")\n  )\n\n\n\n\n\n\nFigure 22.5: Facteurs associés à la pratique d’un sport (pairwise contrasts)",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Régression logistique binaire</span>"
    ]
  },
  {
    "objectID": "analyses/regression-logistique-binaire.html#sec-reg-log-anova",
    "href": "analyses/regression-logistique-binaire.html#sec-reg-log-anova",
    "title": "22  Régression logistique binaire",
    "section": "\n22.8 Identifier les variables ayant un effet significatif",
    "text": "22.8 Identifier les variables ayant un effet significatif\nPour les variables catégorielles à trois modalités ou plus, les p-valeurs associées aux odds ratios nous indique si un odd ratio est significativement différent de 1, par rapport à la modalité de référence. Mais cela n’indique pas si globalement une variable a un effet significatif sur le modèle. Pour tester l’effet global d’une variable, on peut avoir recours à la fonction car::Anova(). Cette dernière va tour à tour supprimer chaque variable du modèle et réaliser une analyse de variance (ANOVA) pour voir si la variance change significativement.\n\ncar::Anova(mod)\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: sport\n            LR Chisq Df Pr(&gt;Chisq)    \nsexe          17.309  1  3.176e-05 ***\ngroupe_ages   52.803  3  2.020e-11 ***\netudes       123.826  4  &lt; 2.2e-16 ***\nrelig          4.232  5  0.5165401    \nheures.tv     13.438  1  0.0002465 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAinsi, dans le cas présent, la suppression de la variable relig ne modifie significativement pas le modèle, indiquant l’absence d’effet de cette variable.\nSi l’on a recours à gtsummary::tbl_regression(), on peut facilement ajouter les p-valeurs globales avec gtsummary::add_global_p()8.\n8 Si l’on veut conserver les p-valeurs individuelles associées à chaque odds ratio, on ajoutera l’option keep = TRUE.\nmod |&gt;\n  tbl_regression(exponentiate = TRUE) |&gt;\n  bold_labels() |&gt; \n  add_global_p()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nOR\n1\n\n\n95% IC\n1\n\np-valeur\n\n\n\nSexe\n\n\n&lt;0,001\n\n\n    Femme\n—\n—\n\n\n\n    Homme\n1,55\n1,26 – 1,91\n\n\n\nGroupe d'âges\n\n\n&lt;0,001\n\n\n    18-24 ans\n—\n—\n\n\n\n    25-44 ans\n0,66\n0,42 – 1,03\n\n\n\n    45-64 ans\n0,34\n0,21 – 0,54\n\n\n\n    65 ans et plus\n0,25\n0,15 – 0,43\n\n\n\nNiveau d'études\n\n\n&lt;0,001\n\n\n    Primaire\n—\n—\n\n\n\n    Secondaire\n2,59\n1,77 – 3,83\n\n\n\n    Technique / Professionnel\n2,86\n1,98 – 4,17\n\n\n\n    Supérieur\n6,63\n4,55 – 9,80\n\n\n\n    Non documenté\n8,59\n4,53 – 16,6\n\n\n\nRapport à la religion\n\n\n0,5\n\n\n    Pratiquant regulier\n—\n—\n\n\n\n    Pratiquant occasionnel\n0,98\n0,68 – 1,42\n\n\n\n    Appartenance sans pratique\n0,99\n0,71 – 1,40\n\n\n\n    Ni croyance ni appartenance\n0,81\n0,55 – 1,18\n\n\n\n    Rejet\n0,68\n0,39 – 1,19\n\n\n\n    NSP ou NVPR\n0,92\n0,40 – 2,02\n\n\n\nHeures de télévision / jour\n0,89\n0,83 – 0,95\n&lt;0,001\n\n\n\n\n1\nOR = rapport de cotes, IC = intervalle de confiance\n\n\n\n\n\n\n\n\nTable 22.7: Ajout des p-valeurs globales\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nConcernant le test réalisé dans le cadre d’une Anova, il existe trois tests différents que l’on présente comme le type 1, le type 2 et le type 3 (ou I, II et III). Pour une explication sur ces différents types, on pourra se référer (en anglais) à https://mcfromnz.wordpress.com/2011/03/02/anova-type-iiiiii-ss-explained/ ou encore http://md.psych.bio.uni-goettingen.de/mv/unit/lm_cat/lm_cat_unbal_ss_explained.html.\nLe type I n’est pas recommandé dans le cas présent car il dépend de l’ordre dans lequel les différentes variables sont testées.\nLorsqu’il n’y a pas d’interaction dans un modèle, le type II serait à privilégier car plus puissant (nous aborderons les interactions dans un prochain chapitre, cf. Chapitre 26).\nEn présence d’interactions, il est conseillé d’avoir plutôt recours au type III. Cependant, en toute rigueur, pour utiliser le type III, il faut que les variables catégorielles soient codées en utilisant un contrastes dont la somme est nulle (un contraste de type somme ou polynomial). Or, par défaut, les variables catégorielles sont codées avec un contraste de type traitement (nous aborderons les différents types de contrastes plus tard, cf. Chapitre 25).\nPar défaut, car::Anova() utilise le type II et gtsummary::add_global_p() le type III. Dans les deux cas, il est possible de préciser le type de test avec type = \"II\" ou type = \"III\".\nDans le cas de notre exemple, un modèle simple sans interaction, le type de test ne change pas les résultats.",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Régression logistique binaire</span>"
    ]
  },
  {
    "objectID": "analyses/regression-logistique-binaire.html#sec-regressions-logistiques-univariables",
    "href": "analyses/regression-logistique-binaire.html#sec-regressions-logistiques-univariables",
    "title": "22  Régression logistique binaire",
    "section": "\n22.9 Régressions logistiques univariables",
    "text": "22.9 Régressions logistiques univariables\nLes usages varient selon les disciplines et les revues scientifiques, mais il n’est pas rare de présenter, avant le modèle logistique multivariable, une succession de modèles logistiques univariables (i.e. avec une seule variable explicative à la fois) afin de présenter les odds ratios et leur intervalle de confiance et p-valeur associés avant l’ajustement multiniveau.\nAfin d’éviter le code fastidieux consistant à réaliser chaque modèle un par un (par exemple glm(sport ~ sexe, family = binomial, data = d)) puis à en fusionner les résultats, on pourra tirer partie de gtsummary::tbl_uvregression() qui permet de réaliser toutes ces régressions individuelles en une fois et de les présenter dans un tableau synthétique.\n\nd |&gt;\n  tbl_uvregression(\n    y = sport,\n    include = c(sexe, groupe_ages, etudes, relig, heures.tv),\n    method = glm,\n    method.args = list(family = binomial),\n    exponentiate = TRUE\n  ) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\nN\n\nOR\n1\n\n\n95% IC\n1\n\np-valeur\n\n\n\nSexe\n2 000\n\n\n\n\n\n    Femme\n\n—\n—\n\n\n\n    Homme\n\n1,47\n1,22 – 1,77\n&lt;0,001\n\n\nGroupe d'âges\n2 000\n\n\n\n\n\n    18-24 ans\n\n—\n—\n\n\n\n    25-44 ans\n\n0,51\n0,35 – 0,71\n&lt;0,001\n\n\n    45-64 ans\n\n0,20\n0,14 – 0,28\n&lt;0,001\n\n\n    65 ans et plus\n\n0,10\n0,07 – 0,15\n&lt;0,001\n\n\nNiveau d'études\n2 000\n\n\n\n\n\n    Primaire\n\n—\n—\n\n\n\n    Secondaire\n\n3,61\n2,52 – 5,23\n&lt;0,001\n\n\n    Technique / Professionnel\n\n4,75\n3,42 – 6,72\n&lt;0,001\n\n\n    Supérieur\n\n11,4\n8,11 – 16,3\n&lt;0,001\n\n\n    Non documenté\n\n26,2\n15,7 – 44,9\n&lt;0,001\n\n\nRapport à la religion\n2 000\n\n\n\n\n\n    Pratiquant regulier\n\n—\n—\n\n\n\n    Pratiquant occasionnel\n\n1,08\n0,78 – 1,50\n0,6\n\n\n    Appartenance sans pratique\n\n1,31\n0,98 – 1,78\n0,071\n\n\n    Ni croyance ni appartenance\n\n1,45\n1,05 – 2,02\n0,026\n\n\n    Rejet\n\n1,19\n0,72 – 1,95\n0,5\n\n\n    NSP ou NVPR\n\n0,93\n0,44 – 1,88\n0,8\n\n\nHeures de télévision / jour\n1 995\n0,79\n0,74 – 0,84\n&lt;0,001\n\n\n\n\n1\nOR = rapport de cotes, IC = intervalle de confiance\n\n\n\n\n\n\n\n\nTable 22.8: Régressions logistiques univariables",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Régression logistique binaire</span>"
    ]
  },
  {
    "objectID": "analyses/regression-logistique-binaire.html#présenter-lensemble-des-résultats-dans-un-même-tableau",
    "href": "analyses/regression-logistique-binaire.html#présenter-lensemble-des-résultats-dans-un-même-tableau",
    "title": "22  Régression logistique binaire",
    "section": "\n22.10 Présenter l’ensemble des résultats dans un même tableau",
    "text": "22.10 Présenter l’ensemble des résultats dans un même tableau\nLa fonction gtsummary::tbl_merge() permet de fusionner plusieurs tableaux (en tenant compte du nom des variables) et donc de présenter les différents résultats de l’analyse descriptive, univariable et multivariable dans un seul et même tableau.\n\ntbl_desc &lt;-\n  d |&gt; \n  tbl_summary(\n    by = sport,\n    include = c(sexe, groupe_ages, etudes, relig, heures.tv),\n    statistic = all_categorical() ~ \"{p}% ({n}/{N})\",\n    percent = \"row\",\n    digits = all_categorical() ~ c(1, 0, 0)\n  ) |&gt; \n  modify_column_hide(\"stat_1\") |&gt; \n  modify_header(\"stat_2\" ~ \"**Pratique d'un sport**\")\n\ntbl_uni &lt;-\n  d |&gt;\n  tbl_uvregression(\n    y = sport,\n    include = c(sexe, groupe_ages, etudes, relig, heures.tv),\n    method = glm,\n    method.args = list(family = binomial),\n    exponentiate = TRUE\n  ) |&gt; \n  modify_column_hide(\"stat_n\")\n\ntbl_multi &lt;-\n  mod |&gt; \n  tbl_regression(exponentiate = TRUE)\n\nlist(tbl_desc, tbl_uni, tbl_multi) |&gt; \n  tbl_merge(\n    tab_spanner = c(\n      NA,\n      \"**Régressions univariables**\",\n      \"**Régression multivariable**\"\n    )\n  ) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nPratique d’un sport\n1\n\n\n\nRégressions univariables\n\n\n\nRégression multivariable\n\n\n\n\nOR\n2\n\n\n95% IC\n2\n\np-valeur\n\nOR\n2\n\n\n95% IC\n2\n\np-valeur\n\n\n\n\nSexe\n\n\n\n\n\n\n\n\n\n    Femme\n32,2% (354/1 101)\n—\n—\n\n—\n—\n\n\n\n    Homme\n41,0% (369/899)\n1,47\n1,22 – 1,77\n&lt;0,001\n1,55\n1,26 – 1,91\n&lt;0,001\n\n\nGroupe d'âges\n\n\n\n\n\n\n\n\n\n    18-24 ans\n65,7% (111/169)\n—\n—\n\n—\n—\n\n\n\n    25-44 ans\n49,2% (347/706)\n0,51\n0,35 – 0,71\n&lt;0,001\n0,66\n0,42 – 1,03\n0,065\n\n\n    45-64 ans\n27,4% (204/745)\n0,20\n0,14 – 0,28\n&lt;0,001\n0,34\n0,21 – 0,54\n&lt;0,001\n\n\n    65 ans et plus\n16,1% (61/380)\n0,10\n0,07 – 0,15\n&lt;0,001\n0,25\n0,15 – 0,43\n&lt;0,001\n\n\nNiveau d'études\n\n\n\n\n\n\n\n\n\n    Primaire\n10,7% (50/466)\n—\n—\n\n—\n—\n\n\n\n    Secondaire\n30,2% (117/387)\n3,61\n2,52 – 5,23\n&lt;0,001\n2,59\n1,77 – 3,83\n&lt;0,001\n\n\n    Technique / Professionnel\n36,4% (216/594)\n4,75\n3,42 – 6,72\n&lt;0,001\n2,86\n1,98 – 4,17\n&lt;0,001\n\n\n    Supérieur\n57,8% (255/441)\n11,4\n8,11 – 16,3\n&lt;0,001\n6,63\n4,55 – 9,80\n&lt;0,001\n\n\n    Non documenté\n75,9% (85/112)\n26,2\n15,7 – 44,9\n&lt;0,001\n8,59\n4,53 – 16,6\n&lt;0,001\n\n\nRapport à la religion\n\n\n\n\n\n\n\n\n\n    Pratiquant regulier\n31,6% (84/266)\n—\n—\n\n—\n—\n\n\n\n    Pratiquant occasionnel\n33,3% (147/442)\n1,08\n0,78 – 1,50\n0,6\n0,98\n0,68 – 1,42\n&gt;0,9\n\n\n    Appartenance sans pratique\n37,8% (287/760)\n1,31\n0,98 – 1,78\n0,071\n0,99\n0,71 – 1,40\n&gt;0,9\n\n\n    Ni croyance ni appartenance\n40,1% (160/399)\n1,45\n1,05 – 2,02\n0,026\n0,81\n0,55 – 1,18\n0,3\n\n\n    Rejet\n35,5% (33/93)\n1,19\n0,72 – 1,95\n0,5\n0,68\n0,39 – 1,19\n0,2\n\n\n    NSP ou NVPR\n30,0% (12/40)\n0,93\n0,44 – 1,88\n0,8\n0,92\n0,40 – 2,02\n0,8\n\n\nHeures de télévision / jour\n2,00 (1,00 – 3,00)\n0,79\n0,74 – 0,84\n&lt;0,001\n0,89\n0,83 – 0,95\n&lt;0,001\n\n\n    Manquant\n3\n\n\n\n\n\n\n\n\n\n\n1\n\n\n\n2\nOR = rapport de cotes, IC = intervalle de confiance\n\n\n\n\n\n\n\n\n\nTable 22.9: tableau synthétique de l’analyse\n\n\n\nLe diaporama ci-dessous vous permet de visualiser chaque étape du code correspondant au graphique précédent.",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Régression logistique binaire</span>"
    ]
  },
  {
    "objectID": "analyses/regression-logistique-binaire.html#webin-r",
    "href": "analyses/regression-logistique-binaire.html#webin-r",
    "title": "22  Régression logistique binaire",
    "section": "\n22.11 webin-R",
    "text": "22.11 webin-R\nLa régression logistique est présentée sur YouTube dans le webin-R #06 (régression logistique (partie 1)) et le le webin-R #07 (régression logistique (partie 2)).\n\n\n\n\n\nDécomposition de la probabilité de faire du sport de l’individu 3\nFigure 22.1: Facteurs associés à la pratique d’un sport (forest plot)\nFigure 22.2: Facteurs associés à la pratique d’un sport (forest plot avec table des coefficients)\nFigure 22.3: Facteurs associés à la pratique d’un sport avec modelplot()\nFigure 22.4: Odds Ratios associés à la pratique d’un sport avec modelplot()\nFigure 22.5: Facteurs associés à la pratique d’un sport (pairwise contrasts)",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Régression logistique binaire</span>"
    ]
  },
  {
    "objectID": "analyses/selection-modele-pas-a-pas.html",
    "href": "analyses/selection-modele-pas-a-pas.html",
    "title": "23  Sélection pas à pas d’un modèle réduit",
    "section": "",
    "text": "23.1 Données d’illustration\nPour illustrer ce chapitre, nous allons prendre un modèle logistique inspiré de celui utilisé dans le chapitre sur la régression logistique binaire (cf. Chapitre 22).\nlibrary(tidyverse)\nlibrary(labelled)\nlibrary(gtsummary)\ntheme_gtsummary_language(\n  \"fr\",\n  decimal.mark = \",\",\n  big.mark = \" \"\n)\n\ndata(hdv2003, package = \"questionr\")\n\nd &lt;-\n  hdv2003 |&gt; \n  mutate(\n    sexe = sexe |&gt; fct_relevel(\"Femme\"),\n    groupe_ages = age |&gt;\n      cut(\n        c(18, 25, 45, 65, 99),\n        right = FALSE,\n        include.lowest = TRUE,\n        labels = c(\"18-24 ans\", \"25-44 ans\",\n                   \"45-64 ans\", \"65 ans et plus\")\n      ),\n    etudes = nivetud |&gt; \n      fct_recode(\n        \"Primaire\" = \"N'a jamais fait d'etudes\",\n        \"Primaire\" = \"A arrete ses etudes, avant la derniere annee d'etudes primaires\",\n        \"Primaire\" = \"Derniere annee d'etudes primaires\",\n        \"Secondaire\" = \"1er cycle\",\n        \"Secondaire\" = \"2eme cycle\",\n        \"Technique / Professionnel\" = \"Enseignement technique ou professionnel court\",\n        \"Technique / Professionnel\" = \"Enseignement technique ou professionnel long\",\n        \"Supérieur\" = \"Enseignement superieur y compris technique superieur\"\n    ) |&gt; \n    fct_na_value_to_level(\"Non documenté\")  \n  ) |&gt; \n  set_variable_labels(\n    sport = \"Pratique un sport ?\",\n    sexe = \"Sexe\",\n    groupe_ages = \"Groupe d'âges\",\n    etudes = \"Niveau d'études\",\n    relig = \"Rapport à la religion\",\n    lecture.bd = \"Lit des bandes dessinées ?\"\n  )\n\nmod &lt;- glm(\n  sport ~ sexe + groupe_ages + etudes + relig + lecture.bd,\n  family = binomial,\n  data = d\n)",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Sélection pas à pas d'un modèle réduit</span>"
    ]
  },
  {
    "objectID": "analyses/selection-modele-pas-a-pas.html#présentation-de-laic",
    "href": "analyses/selection-modele-pas-a-pas.html#présentation-de-laic",
    "title": "23  Sélection pas à pas d’un modèle réduit",
    "section": "\n23.2 Présentation de l’AIC",
    "text": "23.2 Présentation de l’AIC\nIl faut définir un critère pour déterminer la qualité d’un modèle. L’un des plus utilisés est le Akaike Information Criterion ou AIC. Il s’agit d’un compromis entre le nombre de degrés de liberté (e.g. le nombre de coefficients dans le modèle) que l’on cherche à minimiser et la variance expliquée que l’on cherche à maximiser (la vraisemblance).\nPlus précisément \\(AIC=2k-2ln(L)\\) où \\(L\\) est le maximum de la fonction de vraisemblance du modèle et \\(k\\) le nombre de paramètres (i.e. de coefficients) du modèle. Plus l’AIC sera faible, meilleur sera le modèle.\nL’AIC d’un modèle s’obtient aisément avec AIC().\n\nAIC(mod)\n\n[1] 2257.101",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Sélection pas à pas d'un modèle réduit</span>"
    ]
  },
  {
    "objectID": "analyses/selection-modele-pas-a-pas.html#sélection-pas-à-pas-descendante",
    "href": "analyses/selection-modele-pas-a-pas.html#sélection-pas-à-pas-descendante",
    "title": "23  Sélection pas à pas d’un modèle réduit",
    "section": "\n23.3 Sélection pas à pas descendante",
    "text": "23.3 Sélection pas à pas descendante\nLa fonction step() permet de sélectionner le meilleur modèle par une procédure pas à pas descendante basée sur la minimisation de l’AIC. La fonction affiche à l’écran les différentes étapes de la sélection et renvoie le modèle final.\n\nmod2 &lt;- step(mod)\n\nStart:  AIC=2257.1\nsport ~ sexe + groupe_ages + etudes + relig + lecture.bd\n\n              Df Deviance    AIC\n- relig        5   2231.9 2251.9\n- lecture.bd   1   2227.9 2255.9\n&lt;none&gt;             2227.1 2257.1\n- sexe         1   2245.6 2273.6\n- groupe_ages  3   2280.1 2304.1\n- etudes       4   2375.5 2397.5\n\nStep:  AIC=2251.95\nsport ~ sexe + groupe_ages + etudes + lecture.bd\n\n              Df Deviance    AIC\n- lecture.bd   1   2232.6 2250.6\n&lt;none&gt;             2231.9 2251.9\n- sexe         1   2248.8 2266.8\n- groupe_ages  3   2282.1 2296.1\n- etudes       4   2380.5 2392.5\n\nStep:  AIC=2250.56\nsport ~ sexe + groupe_ages + etudes\n\n              Df Deviance    AIC\n&lt;none&gt;             2232.6 2250.6\n- sexe         1   2249.2 2265.2\n- groupe_ages  3   2282.5 2294.5\n- etudes       4   2385.2 2395.2\n\n\nLe modèle initial a un AIC de 2257,1.\nÀ la première étape, il apparaît que la suppression de la variable relig permettrait diminuer l’AIC à 2251,9 et la suppression de la variable lecture.bd de le diminuer à 2255,9. Le gain maximal est obtenu en supprimant relig et donc cette variable est supprimée à ce stade. On peut noter que la suppression de la variable entraîne de facto une augmentation des résidus (colonne Deviance) et donc une baisse de la vraisemblance du modèle, mais cela est compensé par la réduction du nombre de degrés de liberté.\nLe processus est maintenant répété. À la seconde étape, supprimer lecture.bd permettrait de diminuer encore l’AIC à 2250,6 et cette variable est supprimée.\nÀ la troisième étape, tout retrait d’une variable additionnelle reviendrait à augmenter l’AIC.\nLors de la seconde étape, toute suppression d’une autre variable ferait augmenter l’AIC. La procédure s’arrête donc.\nL’objet mod2 renvoyé par step() est le modèle final.\n\nmod2\n\n\nCall:  glm(formula = sport ~ sexe + groupe_ages + etudes, family = binomial, \n    data = d)\n\nCoefficients:\n                    (Intercept)                        sexeHomme  \n                        -1.2815                           0.4234  \n           groupe_ages25-44 ans             groupe_ages45-64 ans  \n                        -0.3012                          -0.9261  \n      groupe_ages65 ans et plus                 etudesSecondaire  \n                        -1.2696                           0.9670  \netudesTechnique / Professionnel                  etudesSupérieur  \n                         1.0678                           1.9955  \n            etudesNon documenté  \n                         2.3192  \n\nDegrees of Freedom: 1999 Total (i.e. Null);  1991 Residual\nNull Deviance:      2617 \nResidual Deviance: 2233     AIC: 2251\n\n\nOn peut effectuer une analyse de variance ou ANOVA pour comparer les deux modèles avec la fonction anova().\n\nanova(mod, mod2, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: sport ~ sexe + groupe_ages + etudes + relig + lecture.bd\nModel 2: sport ~ sexe + groupe_ages + etudes\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)\n1      1985     2227.1                     \n2      1991     2232.6 -6  -5.4597   0.4863\n\n\nIl n’y a pas de différences significatives entre nos deux modèles (p=0,55). Autrement dit, notre second modèle explique tout autant de variance que notre premier modèle, tout en étant plus parcimonieux.\n\n\n\n\n\n\nAstuce\n\n\n\nUne alternative à la fonction step() est la fonction MASS::stepAIC() du package MASS qui fonctionne de la même manière. Si cela ne change rien aux régressions logistiques classiques, il arrive que pour certains types de modèle la méthode step() ne soit pas disponible, mais que MASS::stepAIC() puisse être utilisée à la place.\n\nlibrary(MASS)\n\n\nAttachement du package : 'MASS'\n\n\nL'objet suivant est masqué depuis 'package:gtsummary':\n\n    select\n\n\nL'objet suivant est masqué depuis 'package:dplyr':\n\n    select\n\nmod2bis &lt;- stepAIC(mod)\n\nStart:  AIC=2257.1\nsport ~ sexe + groupe_ages + etudes + relig + lecture.bd\n\n              Df Deviance    AIC\n- relig        5   2231.9 2251.9\n- lecture.bd   1   2227.9 2255.9\n&lt;none&gt;             2227.1 2257.1\n- sexe         1   2245.6 2273.6\n- groupe_ages  3   2280.1 2304.1\n- etudes       4   2375.5 2397.5\n\nStep:  AIC=2251.95\nsport ~ sexe + groupe_ages + etudes + lecture.bd\n\n              Df Deviance    AIC\n- lecture.bd   1   2232.6 2250.6\n&lt;none&gt;             2231.9 2251.9\n- sexe         1   2248.8 2266.8\n- groupe_ages  3   2282.1 2296.1\n- etudes       4   2380.5 2392.5\n\nStep:  AIC=2250.56\nsport ~ sexe + groupe_ages + etudes\n\n              Df Deviance    AIC\n&lt;none&gt;             2232.6 2250.6\n- sexe         1   2249.2 2265.2\n- groupe_ages  3   2282.5 2294.5\n- etudes       4   2385.2 2395.2\n\n\n\n\nOn peut facilement comparer visuellement deux modèles avec ggstats::ggcoef_compare() de ggstats.\n\nlibrary(ggstats)\nggcoef_compare(\n  list(\"modèle complet\" = mod, \"modèle réduit\" = mod2), \n  exponentiate = TRUE\n)\n\n\n\n\n\n\nFigure 23.1: Comparaison visuelle des deux modèles (dodge)\n\n\n\n\n\nggcoef_compare(\n  list(\"modèle complet\" = mod, \"modèle réduit\" = mod2), \n  type = \"faceted\",\n  exponentiate = TRUE\n)\n\n\n\n\n\n\nFigure 23.2: Comparaison visuelle des deux modèles (faceted)",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Sélection pas à pas d'un modèle réduit</span>"
    ]
  },
  {
    "objectID": "analyses/selection-modele-pas-a-pas.html#sélection-pas-à-pas-ascendante",
    "href": "analyses/selection-modele-pas-a-pas.html#sélection-pas-à-pas-ascendante",
    "title": "23  Sélection pas à pas d’un modèle réduit",
    "section": "\n23.4 Sélection pas à pas ascendante",
    "text": "23.4 Sélection pas à pas ascendante\nPour une approche ascendante, nous allons partir d’un modèle vide, c’est-à-dire d’un modèle sans variable explicative avec simplement un intercept.\n\nmod_vide &lt;- glm(\n  sport ~ 1,\n  family = binomial,\n  data = d\n)\n\nNous allons ensuite passer ce modèle vide à step() et préciser, via un élément nommé upper dans une liste passée à l’argument scope, la formule du modèle maximum à considérer. Nous précisons direction = \"forward\" pour indiquer que nous souhaitons une procédure ascendante.\n\nmod3 &lt;- step(\n  mod_vide,\n  direction = \"forward\",\n  scope = list(\n    upper = ~ sexe + groupe_ages + etudes + relig + lecture.bd\n  )\n)\n\nStart:  AIC=2619.11\nsport ~ 1\n\n              Df Deviance    AIC\n+ etudes       4   2294.9 2304.9\n+ groupe_ages  3   2405.4 2413.4\n+ sexe         1   2600.2 2604.2\n+ lecture.bd   1   2612.7 2616.7\n&lt;none&gt;             2617.1 2619.1\n+ relig        5   2608.8 2620.8\n\nStep:  AIC=2304.92\nsport ~ etudes\n\n              Df Deviance    AIC\n+ groupe_ages  3   2249.2 2265.2\n+ sexe         1   2282.5 2294.5\n&lt;none&gt;             2294.9 2304.9\n+ lecture.bd   1   2294.7 2306.7\n+ relig        5   2293.0 2313.0\n\nStep:  AIC=2265.17\nsport ~ etudes + groupe_ages\n\n             Df Deviance    AIC\n+ sexe        1   2232.6 2250.6\n&lt;none&gt;            2249.2 2265.2\n+ lecture.bd  1   2248.8 2266.8\n+ relig       5   2246.0 2272.0\n\nStep:  AIC=2250.56\nsport ~ etudes + groupe_ages + sexe\n\n             Df Deviance    AIC\n&lt;none&gt;            2232.6 2250.6\n+ lecture.bd  1   2231.9 2251.9\n+ relig       5   2227.9 2255.9\n\n\nCette fois-ci, à chaque étape, la fonction step() évalue le gain à ajouter chaque variable dans le modèle, ajoute la variable la plus pertinente, pour recommence le processus jusqu’à ce qu’il n’y ait plus de gain à ajouter une variable au modèle. Notons que nous aboutissons ici au même résultat.\n\n\n\n\n\n\nAstuce\n\n\n\nNous aurions pu nous passer de préciser direction = \"forward\". Dans cette situation, step() regarde simultanément les gains à ajouter une variable additionnelle au modèle et à supprimer une variable déjà inclue pour . Lorsque l’on part d’un modèle vide, cela ne change rien au résultat.\n\nmod3 &lt;- step(\n  mod_vide,\n  scope = list(\n    upper = ~ sexe + groupe_ages + etudes + relig + lecture.bd\n  )\n)\n\nStart:  AIC=2619.11\nsport ~ 1\n\n              Df Deviance    AIC\n+ etudes       4   2294.9 2304.9\n+ groupe_ages  3   2405.4 2413.4\n+ sexe         1   2600.2 2604.2\n+ lecture.bd   1   2612.7 2616.7\n&lt;none&gt;             2617.1 2619.1\n+ relig        5   2608.8 2620.8\n\nStep:  AIC=2304.92\nsport ~ etudes\n\n              Df Deviance    AIC\n+ groupe_ages  3   2249.2 2265.2\n+ sexe         1   2282.5 2294.5\n&lt;none&gt;             2294.9 2304.9\n+ lecture.bd   1   2294.7 2306.7\n+ relig        5   2293.0 2313.0\n- etudes       4   2617.1 2619.1\n\nStep:  AIC=2265.17\nsport ~ etudes + groupe_ages\n\n              Df Deviance    AIC\n+ sexe         1   2232.6 2250.6\n&lt;none&gt;             2249.2 2265.2\n+ lecture.bd   1   2248.8 2266.8\n+ relig        5   2246.0 2272.0\n- groupe_ages  3   2294.9 2304.9\n- etudes       4   2405.4 2413.4\n\nStep:  AIC=2250.56\nsport ~ etudes + groupe_ages + sexe\n\n              Df Deviance    AIC\n&lt;none&gt;             2232.6 2250.6\n+ lecture.bd   1   2231.9 2251.9\n+ relig        5   2227.9 2255.9\n- sexe         1   2249.2 2265.2\n- groupe_ages  3   2282.5 2294.5\n- etudes       4   2385.2 2395.2",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Sélection pas à pas d'un modèle réduit</span>"
    ]
  },
  {
    "objectID": "analyses/selection-modele-pas-a-pas.html#forcer-certaines-variables-dans-le-modèle-réduit",
    "href": "analyses/selection-modele-pas-a-pas.html#forcer-certaines-variables-dans-le-modèle-réduit",
    "title": "23  Sélection pas à pas d’un modèle réduit",
    "section": "\n23.5 Forcer certaines variables dans le modèle réduit",
    "text": "23.5 Forcer certaines variables dans le modèle réduit\nMême si l’on a recourt à step(), on peut vouloir forcer la présence de certaines variables dans le modèle, même si leur suppression minimiserait l’AIC. Par exemple, si l’on a des hypothèses spécifiques pour ces variables et que l’on a intérêt à montrer qu’elles n’ont pas d’effet dans le modèle multivariable.\nSupposons que nous avons une hypothèse sur le lien entre la pratique d’un sport et la lecture de bandes dessinées. Nous souhaitons donc forcer la présence de la variable lecture.bd dans le modèle final. Cette fois-ci, nous allons indiquer, via la liste passée à scope, un élément lower indiquant le modèle minimum souhaité. Toutes les variables de ce modèle minimum seront donc conserver dans le modèle final.\n\nmod4 &lt;- step(\n  mod,\n  scope = list(\n    lower = ~ lecture.bd\n  )\n)\n\nStart:  AIC=2257.1\nsport ~ sexe + groupe_ages + etudes + relig + lecture.bd\n\n              Df Deviance    AIC\n- relig        5   2231.9 2251.9\n&lt;none&gt;             2227.1 2257.1\n- sexe         1   2245.6 2273.6\n- groupe_ages  3   2280.1 2304.1\n- etudes       4   2375.5 2397.5\n\nStep:  AIC=2251.95\nsport ~ sexe + groupe_ages + etudes + lecture.bd\n\n              Df Deviance    AIC\n&lt;none&gt;             2231.9 2251.9\n- sexe         1   2248.8 2266.8\n- groupe_ages  3   2282.1 2296.1\n- etudes       4   2380.5 2392.5\n\n\nCette fois-ci, nous constatons que la fonction step() n’a pas considéré la suppression éventuelle de la variable lecture.bd qui est donc conservée.\n\nmod4$formula\n\nsport ~ sexe + groupe_ages + etudes + lecture.bd",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Sélection pas à pas d'un modèle réduit</span>"
    ]
  },
  {
    "objectID": "analyses/selection-modele-pas-a-pas.html#minimisation-du-bic",
    "href": "analyses/selection-modele-pas-a-pas.html#minimisation-du-bic",
    "title": "23  Sélection pas à pas d’un modèle réduit",
    "section": "\n23.6 Minimisation du BIC",
    "text": "23.6 Minimisation du BIC\nUn critère similaire à l’AIC est le critère BIC (Bayesian Information Criterion) appelé aussi SBC (Schwarz information criterion).\nSa formule est proche de celle de l’AIC : \\(BIC=ln(n)k-2ln(L)\\) où \\(n\\) correspond au nombre d’observations dans l’échantillon. Par rapport à l’AIC, il pénalise donc plus le nombre de degrés de liberté du modèle.\nPour réaliser une sélection pas à pas par optimisation du BIC, on appellera step() en ajoutant l’argument k = log(n) où n est le nombre d’observations inclues dans le modèle. Par défaut, un modèle est calculé en retirant les observations pour lesquelles des données sont manquantes. Dès lors, pour obtenir le nombre exact d’observations incluses dans le modèle, on peut utiliser la syntaxe mod |&gt; model.matrix() |&gt; nrow(), model.matrix() renvoyant la matrice de données ayant servi au calcul du modèle et nrow() le nombre de lignes.\n\nmod5 &lt;- mod |&gt;\n  step(\n    k = mod |&gt; model.matrix() |&gt; nrow() |&gt; log()\n  )\n\nStart:  AIC=2341.11\nsport ~ sexe + groupe_ages + etudes + relig + lecture.bd\n\n              Df Deviance    AIC\n- relig        5   2231.9 2308.0\n- lecture.bd   1   2227.9 2334.3\n&lt;none&gt;             2227.1 2341.1\n- sexe         1   2245.6 2352.0\n- groupe_ages  3   2280.1 2371.3\n- etudes       4   2375.5 2459.1\n\nStep:  AIC=2307.96\nsport ~ sexe + groupe_ages + etudes + lecture.bd\n\n              Df Deviance    AIC\n- lecture.bd   1   2232.6 2301.0\n&lt;none&gt;             2231.9 2308.0\n- sexe         1   2248.8 2317.2\n- groupe_ages  3   2282.1 2335.3\n- etudes       4   2380.5 2426.1\n\nStep:  AIC=2300.97\nsport ~ sexe + groupe_ages + etudes\n\n              Df Deviance    AIC\n&lt;none&gt;             2232.6 2301.0\n- sexe         1   2249.2 2310.0\n- groupe_ages  3   2282.5 2328.1\n- etudes       4   2385.2 2423.2",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Sélection pas à pas d'un modèle réduit</span>"
    ]
  },
  {
    "objectID": "analyses/selection-modele-pas-a-pas.html#afficher-les-indicateurs-de-performance",
    "href": "analyses/selection-modele-pas-a-pas.html#afficher-les-indicateurs-de-performance",
    "title": "23  Sélection pas à pas d’un modèle réduit",
    "section": "\n23.7 Afficher les indicateurs de performance",
    "text": "23.7 Afficher les indicateurs de performance\nIl existe plusieurs indicateurs de performance ou qualité d’un modèle. Pour les calculer/afficher (dont l’AIC et le BIC), on pourra avoir recours à broom::glance() ou encore à performance::model_performance().\n\nmod |&gt; broom::glance()\n\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1         2617.    1999 -1114. 2257. 2341.    2227.        1985  2000\n\nmod |&gt; performance::model_performance()\n\n# Indices of model performance\n\nAIC      |     AICc |      BIC | Tjur's R2 |  RMSE | Sigma | Log_loss | Score_log | Score_spherical |   PCP\n-----------------------------------------------------------------------------------------------------------\n2257.101 | 2257.343 | 2341.115 |     0.183 | 0.434 | 1.000 |    0.557 |      -Inf |           0.001 | 0.623\n\n\nLe fonction performance::compare_performance() permet de comparer rapidement plusieurs modèles.\n\nperformance::compare_performance(mod, mod2, mod4)\n\n# Comparison of Model Performance Indices\n\nName | Model |  AIC (weights) | AICc (weights) |  BIC (weights) | Tjur's R2 |  RMSE | Sigma | Log_loss | Score_log | Score_spherical |   PCP\n--------------------------------------------------------------------------------------------------------------------------------------------\nmod  |   glm | 2257.1 (0.025) | 2257.3 (0.023) | 2341.1 (&lt;.001) |     0.183 | 0.434 | 1.000 |    0.557 |      -Inf |           0.001 | 0.623\nmod2 |   glm | 2250.6 (0.651) | 2250.7 (0.654) | 2301.0 (0.971) |     0.181 | 0.435 | 1.000 |    0.558 |      -Inf |           0.002 | 0.622\nmod4 |   glm | 2252.0 (0.325) | 2252.1 (0.323) | 2308.0 (0.029) |     0.181 | 0.435 | 1.000 |    0.558 |      -Inf |           0.002 | 0.622\n\n\nSi l’on souhaite afficher l’AIC (ainsi que d’autres statistiques globales du modèle) en note du tableau des coefficients, on pourra utiliser gtsummary::add_glance_source_note().\n\nmod2 |&gt; \n  tbl_regression(exponentiate = TRUE) |&gt; \n  bold_labels() |&gt; \n  add_glance_source_note()\n\n\n\n\n\n\n\n\nCaractéristique\n\n      \n\nOR\n\n1\n\n      \n\n95% IC\n\n1\n\n      \np-valeur\n\n    \n\n\nSexe\n\n\n\n\n\n    Femme\n—\n—\n\n\n\n    Homme\n1,53\n1,25 – 1,87\n&lt;0,001\n\n\nGroupe d'âges\n\n\n\n\n\n    18-24 ans\n—\n—\n\n\n\n    25-44 ans\n0,74\n0,48 – 1,15\n0,2\n\n\n    45-64 ans\n0,40\n0,25 – 0,62\n&lt;0,001\n\n\n    65 ans et plus\n0,28\n0,17 – 0,47\n&lt;0,001\n\n\nNiveau d'études\n\n\n\n\n\n    Primaire\n—\n—\n\n\n\n    Secondaire\n2,63\n1,80 – 3,88\n&lt;0,001\n\n\n    Technique / Professionnel\n2,91\n2,03 – 4,22\n&lt;0,001\n\n\n    Supérieur\n7,36\n5,10 – 10,8\n&lt;0,001\n\n\n    Non documenté\n10,2\n5,43 – 19,4\n&lt;0,001\n\n\n\n\ndéviance nulle = 2 617; degrés de liberté du modèle nul = 1 999; Log-likelihood = -1 116; AIC = 2 251; BIC = 2 301; Deviance = 2 233; degrés de liberté des résidus = 1 991; No. Obs. = 2 000\n\n    \n\n\n1 \nOR = rapport de cotes, IC = intervalle de confiance\n\n\n    \n\n\n\n\n\nTable 23.1: Modèle obtenu après réduction du nombre de variables",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Sélection pas à pas d'un modèle réduit</span>"
    ]
  },
  {
    "objectID": "analyses/selection-modele-pas-a-pas.html#sec-step-avec-na",
    "href": "analyses/selection-modele-pas-a-pas.html#sec-step-avec-na",
    "title": "23  Sélection pas à pas d’un modèle réduit",
    "section": "\n23.8 Sélection pas à pas et valeurs manquantes",
    "text": "23.8 Sélection pas à pas et valeurs manquantes\nSi certaines de nos variables explications contiennent des valeurs manquantes (NA), cela peut entraîner des erreurs au moment d’avoir recours à step(), car le nombre d’observations dans le modèle va changer si on retire du modèle une variable explicative avec des valeurs manquantes.\nPrenons un exemple, en ajoutant des valeurs manquantes à la variable relig (pour cela nous allons recoder les refus et les ne sait pas en NA).\n\nd$relig_na &lt;- \n  d$relig |&gt; \n  fct_recode(\n    NULL = \"Rejet\",\n    NULL = \"NSP ou NVPR\"\n  )\n\nmod_na &lt;- glm(\n  sport ~ sexe + groupe_ages + etudes + relig_na + lecture.bd,\n  family = binomial,\n  data = d\n)\n\nAu moment d’exécuter step() nous obtenons l’erreur mentionnée précédemment.\n\nstep(mod_na)\n\nStart:  AIC=2096.64\nsport ~ sexe + groupe_ages + etudes + relig_na + lecture.bd\n\n              Df Deviance    AIC\n- relig_na     3   2073.2 2093.2\n- lecture.bd   1   2072.2 2096.2\n&lt;none&gt;             2070.6 2096.6\n- sexe         1   2088.6 2112.6\n- groupe_ages  3   2118.0 2138.0\n- etudes       4   2218.1 2236.1\n\n\nError in step(mod_na): le nombre de lignes utilisées a changé : supprimer les valeurs manquantes ?\n\n\nPas d’inquiétude ! Il y a moyen de s’en sortir en adoptant la stratégie suivante :\n\ncréer une copie du jeu de données avec uniquement des observations sans valeur manquante pour nos variables explicatives ;\ncalculer notre modèle complet à partir de ce jeu de données ;\nappliquer step() ;\nrecalculer le modèle réduit en repartant du jeu de données complet.\n\nPremière étape, ne garder que les observations complètes à l’aide de tidyr::drop_na(), en lui indiquant la liste des variables dans lesquelles vérifier la présence ou non de NA.\n\nd_complet &lt;- d |&gt; \n  drop_na(sexe, groupe_ages, etudes, relig_na, lecture.bd)\n\nDeuxième étape, calculons le modèle complet avec ce jeu données.\n\nmod_na_alt &lt;- glm(\n  sport ~ sexe + groupe_ages + etudes + relig_na +lecture.bd,\n  family = binomial,\n  data = d_complet\n)\n\nLe modèle mod_na_alt est tout à fait identique au modèle mod_na, car glm() supprime de lui-même les valeurs manquantes quand elles existent. Nous pouvons maintenant utiliser step().\n\nmod_na_reduit &lt;- step(mod_na_alt)\n\nStart:  AIC=2096.64\nsport ~ sexe + groupe_ages + etudes + relig_na + lecture.bd\n\n              Df Deviance    AIC\n- relig_na     3   2073.2 2093.2\n- lecture.bd   1   2072.2 2096.2\n&lt;none&gt;             2070.6 2096.6\n- sexe         1   2088.6 2112.6\n- groupe_ages  3   2118.0 2138.0\n- etudes       4   2218.1 2236.1\n\nStep:  AIC=2093.19\nsport ~ sexe + groupe_ages + etudes + lecture.bd\n\n              Df Deviance    AIC\n- lecture.bd   1   2074.6 2092.6\n&lt;none&gt;             2073.2 2093.2\n- sexe         1   2090.2 2108.2\n- groupe_ages  3   2118.5 2132.5\n- etudes       4   2221.4 2233.4\n\nStep:  AIC=2092.59\nsport ~ sexe + groupe_ages + etudes\n\n              Df Deviance    AIC\n&lt;none&gt;             2074.6 2092.6\n- sexe         1   2091.1 2107.1\n- groupe_ages  3   2119.6 2131.6\n- etudes       4   2227.2 2237.2\n\n\nCela s’exécute sans problème car tous les sous-modèles sont calculés à partir de d_complet et donc ont bien le même nombre d’observations. Cependant, dans notre modèle réduit, on a retiré 137 observations en raison d’une valeur manquante sur la variable relig_na, variable qui n’est plus présente dans notre modèle réduit. Il serait donc pertinent de réintégrer ces observations.\nNous allons donc recalculer le modèle réduit mais à partir de d. Inutile de recopier à la main la formule du modèle réduit, car nous pouvons l’obtenir directement avec mod_na_reduit$formula.\n\nmod_na_reduit2 &lt;- glm(\n  mod_na_reduit$formula,\n  family = binomial,\n  data = d\n)\n\nAttention : mod_na_reduit et mod_na_reduit2 ne sont pas identiques puisque le second a été calculé sur un plus grand nombre d’observations, ce qui change très légèrement les valeurs des coefficients.\n\n\n\n\n\n\nAstuce\n\n\n\nPour automatiser l’ensemble de ce processus, on peut copier/coller le code de la fonction générique suivante1 :\n\nstep_with_na &lt;- function(model,\n                         full_data = eval(model$call$data),\n                         ...) {\n  # data with no NAs\n  if (is.null(full_data)) {\n    ...data_no_na &lt;- model.frame(model)\n  } else {\n    ...data_no_na &lt;- get_all_vars(model, data = full_data) |&gt; na.omit()\n  }\n  \n  # assign ...data_no_na in parent.frame()\n  assign(\"...data_no_na\", ...data_no_na, envir = parent.frame())\n  \n  # refit the model without NAs\n  model_no_na &lt;- update(\n    model,\n    formula = terms(model),\n    data = ...data_no_na\n  )\n  \n  # apply step()\n  model_simplified &lt;- step(model_no_na, ...)\n  \n  # recompute simplified model using full data\n  if (is.null(full_data)) {\n    update(\n      model,\n      formula = terms(model_simplified)\n    )\n  } else {\n    update(\n      model,\n      formula = terms(model_simplified),\n      data = full_data\n    )\n  }\n}\n\nElle réalise l’ensemble des opérations décrites plus haut en profitant de la flexibilité offerte par la fonction update(). La fonction terms() permet de récupérer l’équation du modèle. La fonction model.frame() permet de récupérer le jeu de données utilisé par un modèle (et dans lequel les lignes incomplètes ont été supprimées), mais cela ne marchera que si c’est un modèle simple (chaque terme du modèle est une variable directe du tableau de données et non une variable calculée). Sinon, on peut appeler step_with_na() en lui passant en plus le tableau de données original. Cela permet d’avoir recours à la fonction get_all_vars() qui permet d’extraire d’un tableau de données toutes les variables nécessaires au calcul d’un modèle.\nAttention : il s’agit d’une fonction expérimentale et elle n’est peut-être pas compatible avec tous les types de modèles. Elle a été testée avec les modèles lm(), glm() et nnet::multinom().\n\nmod_na_reduit_direct &lt;- step_with_na(mod_na, trace = 0)\n\nLe résultat obtenu est strictement identique.\n\nanova(mod_na_reduit2, mod_na_reduit_direct)\n\nAnalysis of Deviance Table\n\nModel 1: sport ~ sexe + groupe_ages + etudes\nModel 2: sport ~ sexe + groupe_ages + etudes\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)\n1      1991     2232.6                     \n2      1991     2232.6  0        0         \n\n\n\n\n\n\n1 L’argument full_data peut-être utile lorsque le jeu de données n’est pas disponible dans l’environnement parent, par exemple lorsque l’on imbrique des calculs avec lapply() ou purrr:map(). On pourra lors passer manuellement le jeu de données complet à la fonction.\nFigure 23.1: Comparaison visuelle des deux modèles (dodge)\nFigure 23.2: Comparaison visuelle des deux modèles (faceted)",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Sélection pas à pas d'un modèle réduit</span>"
    ]
  },
  {
    "objectID": "analyses/estimations-marginales.html",
    "href": "analyses/estimations-marginales.html",
    "title": "24  Prédictions marginales, contrastes marginaux & effets marginaux",
    "section": "",
    "text": "24.1 Terminologie\nDans ce guide, nous avons décidé d’adopter une terminologie consistante avec celle du package broom.helpers, elle même basée sur celle du package {marginaleffects}, dont la première version a été publié en septembre 2021, et avec le billet d’Andrew Heiss intitulé Marginalia et publié en mai 2022.\nLorsque l’on utilise un modèle ajusté pour prédire l’outcome selon certaines combinaisons de valeurs des régresseurs / variables explicatives, par exemple leurs valeurs observées ou leur moyenne, on obtient des prédictions ajustées. Lorsque ces dernières sont moyennées selon un régresseur spécifique, nous parlerons alors de prédictions marginales.\nLes contrastes marginaux correspondent au calcul d’une différence entre des prédictions marginales, que ce soit pour une variable catégorielle (e.g. différence entre deux modalités) ou pour une variable continue (différence observée au niveau de l’outcome pour un certain changement du prédicteur).\nLes pentes marginales ou effets marginaux sont définis, pour des variables continues, comme la dérivée partielle (slope) de l’équation de régression pour certains valeurs de la variable explicative. Dit autrement, un effet marginal correspond à la pente locale de la fonction de régression pour certaines valeurs choisies d’un prédicteur continue. De manière pratique, les effets marginaux sont similaires aux contrastes marginaux.\nL’ensemble de ces indicateurs marginaux se calculent pour certaines valeurs typiques des variables explicatives, avec plusieurs approches possibles pour définir des valeurs typiques : moyenne / mode, valeurs observées, valeurs personnalisées…\nNous présenterons ces différents concepts plus en détail dans la suite de ce chapitre.\nPlusieurs packages proposent des fonctions pour le calcul d’estimations marginales, marginaleffects, emmeans, margins, effects, ou encore ggeffects, chacun avec des approches et un vocabulaire légèrement différent.\nLe package broom.helpers fournit plusieurs tidiers qui permettent d’appeler les fonctions de ces autres packages et de renvoyer un tableau de données compatible avec la fonction broom.helpers::tidy_plus_plus() et dès lors de pouvoir générer un tableau mis en forme avec gtsummary::tbl_regression() ou un graphique avec ggstats::ggcoef_model().",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Prédictions marginales, contrastes marginaux & effets marginaux</span>"
    ]
  },
  {
    "objectID": "analyses/estimations-marginales.html#données-dillustration",
    "href": "analyses/estimations-marginales.html#données-dillustration",
    "title": "24  Prédictions marginales, contrastes marginaux & effets marginaux",
    "section": "\n24.2 Données d’illustration",
    "text": "24.2 Données d’illustration\nPour illustrer ce chapitre, nous allons prendre un modèle logistique issu du chapitre sur la régression logistique binaire (cf. Chapitre 22).\n\nlibrary(tidyverse)\nlibrary(labelled)\nlibrary(gtsummary)\ntheme_gtsummary_language(\n  \"fr\",\n  decimal.mark = \",\",\n  big.mark = \" \"\n)\n\ndata(hdv2003, package = \"questionr\")\n\nd &lt;-\n  hdv2003 |&gt; \n  mutate(\n    sexe = sexe |&gt; fct_relevel(\"Femme\"),\n    groupe_ages = age |&gt;\n      cut(\n        c(18, 25, 45, 65, 99),\n        right = FALSE,\n        include.lowest = TRUE,\n        labels = c(\"18-24 ans\", \"25-44 ans\",\n                   \"45-64 ans\", \"65 ans et plus\")\n      ),\n    etudes = nivetud |&gt; \n      fct_recode(\n        \"Primaire\" = \"N'a jamais fait d'etudes\",\n        \"Primaire\" = \"A arrete ses etudes, avant la derniere annee d'etudes primaires\",\n        \"Primaire\" = \"Derniere annee d'etudes primaires\",\n        \"Secondaire\" = \"1er cycle\",\n        \"Secondaire\" = \"2eme cycle\",\n        \"Technique / Professionnel\" = \"Enseignement technique ou professionnel court\",\n        \"Technique / Professionnel\" = \"Enseignement technique ou professionnel long\",\n        \"Supérieur\" = \"Enseignement superieur y compris technique superieur\"\n    ) |&gt; \n    fct_na_value_to_level(\"Non documenté\")  \n  ) |&gt; \n  set_variable_labels(\n    sport = \"Pratique un sport ?\",\n    sexe = \"Sexe\",\n    groupe_ages = \"Groupe d'âges\",\n    etudes = \"Niveau d'études\",\n    heures.tv = \"Heures de télévision / jour\"\n  )\n\nmod &lt;- glm(\n  sport ~ sexe + groupe_ages + etudes + heures.tv,\n  family = binomial,\n  data = d\n)\n\n\nmod |&gt; \n  tbl_regression(exponentiate = TRUE) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nOR\n1\n\n\n95% IC\n1\n\np-valeur\n\n\n\nSexe\n\n\n\n\n\n    Femme\n—\n—\n\n\n\n    Homme\n1,52\n1,24 – 1,87\n&lt;0,001\n\n\nGroupe d'âges\n\n\n\n\n\n    18-24 ans\n—\n—\n\n\n\n    25-44 ans\n0,68\n0,43 – 1,06\n0,084\n\n\n    45-64 ans\n0,36\n0,23 – 0,57\n&lt;0,001\n\n\n    65 ans et plus\n0,27\n0,16 – 0,46\n&lt;0,001\n\n\nNiveau d'études\n\n\n\n\n\n    Primaire\n—\n—\n\n\n\n    Secondaire\n2,54\n1,73 – 3,75\n&lt;0,001\n\n\n    Technique / Professionnel\n2,81\n1,95 – 4,10\n&lt;0,001\n\n\n    Supérieur\n6,55\n4,50 – 9,66\n&lt;0,001\n\n\n    Non documenté\n8,54\n4,51 – 16,5\n&lt;0,001\n\n\nHeures de télévision / jour\n0,89\n0,83 – 0,95\n&lt;0,001\n\n\n\n\n1\nOR = rapport de cotes, IC = intervalle de confiance\n\n\n\n\n\n\n\n\nTable 24.1: Odds Ratios du modèle logistique\n\n\n\nIl faut se rappeler que pour calculer le modèle, les observations ayant au moins une valeur manquante ont été exclues. Le modèle n’a donc pas été calculé sur 2000 observations (nombre de lignes de hdv2003) mais sur 1995. On peut obtenir le tableau de données du modèle (model frame), qui ne contient que les variables et les observations utilisées, avec broom.helpers::model_get_model_frame().\n\nmf &lt;- mod %&gt;%\n  broom.helpers::model_get_model_frame()\nnrow(mf)\n\n[1] 1995\n\ncolnames(mf)\n\n[1] \"sport\"       \"sexe\"        \"groupe_ages\" \"etudes\"      \"heures.tv\"",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Prédictions marginales, contrastes marginaux & effets marginaux</span>"
    ]
  },
  {
    "objectID": "analyses/estimations-marginales.html#sec-predictions-marginales",
    "href": "analyses/estimations-marginales.html#sec-predictions-marginales",
    "title": "24  Prédictions marginales, contrastes marginaux & effets marginaux",
    "section": "\n24.3 Prédictions marginales",
    "text": "24.3 Prédictions marginales\n\n24.3.1 Prédictions marginales moyennes\nPour illustrer et mieux comprendre ce que représente la différence entre les femmes et les hommes, nous allons effectuer des prédictions avec notre modèle en ne faisant varier que la variable sexe.\nUne première approche consiste à dupliquer nos données observées et à supposer que tous les individus sont des femmes, puis à supposer que tous les individus sont des hommes.\n\nmf_femmes &lt;- mf |&gt; mutate(sexe = \"Femme\")\nmf_hommes &lt;- mf |&gt; mutate(sexe = \"Homme\")\n\nNos deux jeux de données sont donc identiques pour toutes les autres variables et ne varient que pour le sexe. Nous pouvons maintenant prédire, à partir de notre modèle ajusté, la probabilité de faire du sport de chacun des individus de ces deux nouveaux jeux de données, puis à en calculer la moyenne.\n\nmod |&gt; predict(type = \"response\", newdata = mf_femmes) |&gt; mean()\n\n[1] 0.324814\n\nmod |&gt; predict(type = \"response\", newdata = mf_hommes) |&gt; mean()\n\n[1] 0.4036624\n\n\nNous obtenons ainsi des prédictions marginales moyennes, average marginal predictions en anglais, de respectivement 32% et 40% pour les femmes et pour les hommes.\nLe même résultat, avec en plus un intervalle de confiance, peut s’obtenir avec marginaleffects::predictions().\n\nlibrary(marginaleffects)\nmod |&gt; \n  predictions(variables = \"sexe\", by = \"sexe\", type = \"response\")\n\n\n  sexe Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n Femme    0.325     0.0130 25.0   &lt;0.001 456.7 0.299  0.350\n Homme    0.404     0.0147 27.5   &lt;0.001 549.0 0.375  0.432\n\nColumns: sexe, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\nPour une variable continue, on peut procéder de la même manière en générant des prédictions marginales pour certaines valeurs de la variable. Par défaut, marginaleffects::predictions() réalise des prédictions selon les 5 nombres de Tukey (Tukey’s five numbers, à savoir minimum, premier quartile, médiane, troisième quartile et maximum).\n\nmod |&gt; \n  predictions(variables = \"heures.tv\", by = \"heures.tv\", type = \"response\")\n\n\n heures.tv Estimate Std. Error     z Pr(&gt;|z|)     S  2.5 % 97.5 %\n         0    0.410    0.01711 23.96   &lt;0.001 419.0 0.3764  0.443\n         1    0.386    0.01220 31.64   &lt;0.001 727.2 0.3621  0.410\n         2    0.363    0.00991 36.58   &lt;0.001 970.7 0.3432  0.382\n         3    0.340    0.01145 29.66   &lt;0.001 639.9 0.3173  0.362\n        12    0.168    0.04220  3.99   &lt;0.001  13.9 0.0855  0.251\n\nColumns: heures.tv, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\nLe package broom.helpers fournit la fonction broom.helpers::tidy_marginal_predictions() qui génèrent les prédictions marginales de chaque variable1 avec marginaleffects::predictions() et renvoie les résultat dans un format directement utilisable avec gtsummary::tbl_regression().\n1 La fonction broom.helpers::tidy_marginal_predictions() peut également gérer des combinaisons de variables ou interactions, voir Chapitre 26).\n\n\n\n\n\nNote\n\n\n\nIl est à noter que broom.helpers::tidy_marginal_predictions() renvoie des p-valeurs qui, par défaut, teste si les valeurs prédites sont différentes de 0 (sur l’échelle de la fonction de lien, donc différentes de 50% dans le cas d’une régression logistique). Ce type de tests n’est pas vraiment pertinent dans le cas présent. On peut facilement masquer la colonne des p-valeurs avec modify_column_hide(\"p.value\").\n\n\n\nmod |&gt; \n  tbl_regression(\n    tidy_fun = broom.helpers::tidy_marginal_predictions,\n    type = \"response\",\n    estimate_fun = scales::label_percent(accuracy = 0.1)\n  ) |&gt; \n  bold_labels() |&gt; \n  modify_column_hide(\"p.value\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\nPrédictions Marginales Moyennes\n\n95% IC\n1\n\n\n\n\nSexe\n\n\n\n\n    Femme\n32.5%\n29.9% – 35.0%\n\n\n    Homme\n40.4%\n37.5% – 43.2%\n\n\nGroupe d'âges\n\n\n\n\n    18-24 ans\n51.2%\n42.2% – 60.1%\n\n\n    25-44 ans\n42.7%\n39.3% – 46.2%\n\n\n    45-64 ans\n29.9%\n26.6% – 33.2%\n\n\n    65 ans et plus\n24.9%\n19.7% – 30.0%\n\n\nNiveau d'études\n\n\n\n\n    Primaire\n16.1%\n11.9% – 20.4%\n\n\n    Secondaire\n31.8%\n27.2% – 36.4%\n\n\n    Technique / Professionnel\n34.0%\n30.3% – 37.7%\n\n\n    Supérieur\n53.2%\n48.4% – 57.9%\n\n\n    Non documenté\n59.2%\n47.0% – 71.5%\n\n\nHeures de télévision / jour\n\n\n\n\n    0\n41.0%\n37.6% – 44.3%\n\n\n    1\n38.6%\n36.2% – 41.0%\n\n\n    2\n36.3%\n34.3% – 38.2%\n\n\n    3\n34.0%\n31.7% – 36.2%\n\n\n    12\n16.8%\n8.6% – 25.1%\n\n\n\n\n1\nIC = intervalle de confiance\n\n\n\n\n\n\n\n\nTable 24.2: Prédictions marginales moyennes\n\n\n\nLa fonction broom.helpers::plot_marginal_predictions() permet de visualiser les prédictions marginales à la moyenne en réalisant une liste de graphiques, un par variable, que nous pouvons combiner avec patchwork::wrap_plots(). L’opérateur & permet d’appliquer une fonction de ggplot2 à chaque sous-graphique. Ici, nous allons uniformiser l’axe des y.\n\np &lt;- mod |&gt; \n  broom.helpers::plot_marginal_predictions(type = \"response\") |&gt; \n  patchwork::wrap_plots() &\n  scale_y_continuous(\n    limits = c(0, .8),\n    labels = scales::label_percent()\n  )\n\n\np\n\n\n\n\n\n\nFigure 24.1: Prédictions marginales moyennes\n\n\n\n\nIl est ici difficile de lire les étiquettes de la variable etudes. Nous pouvons éventuellement inverser l’axe des x et celui des y avec ggplot2::coord_flip().\n\np & coord_flip()\n\n\n\n\n\n\nFigure 24.2: Prédictions marginales moyennes\n\n\n\n\nUne alternative possible avec d’avoir recours à ggtstats::ggcoef_model().\n\nmod |&gt; \n  ggstats::ggcoef_model(\n    tidy_fun = broom.helpers::tidy_marginal_predictions,\n    tidy_args = list(type = \"response\"),\n    show_p_values = FALSE,\n    signif_stars = FALSE,\n    significance = NULL,\n    vline = FALSE\n  ) +\n  scale_x_continuous(labels = scales::label_percent())\n\n\n\n\n\n\nFigure 24.3: Prédictions marginales moyennes\n\n\n\n\n\n\n\n\n\n\nImportance de l’argument type pour les modèles glm\n\n\n\nLorsque l’on a recours à des modèles calculés avec glm(), il est possible de réaliser des prédictions selon deux échelles : l’échelle de notre outcome ou variable à expliquer (type = \"response\"), ici exprimée en probabilités ou proportions puisqu’il s’agit d’une régression logistique, ou bien selon l’échelle de la fonction de lien (type = \"link\") du modèle, ici la fonction logit (voir Section 22.4).\nAvec l’option type = \"reponse\", on indique à marginaleffects de calculer pour chaque individu une prédiction selon l’échelle de l’outcome puis de procéder à la moyenne, ce que nous avons fait dans les exemples précédents.\nSi nous avions indiqué type = \"link\", les prédictions auraient été faites selon l’échelle de la fonction de lien avant d’être moyennée.\n\nmod |&gt; predict(type = \"link\", newdata = mf_femmes) |&gt; mean()\n\n[1] -0.910525\n\nmod |&gt; predict(type = \"link\", newdata = mf_hommes) |&gt; mean()\n\n[1] -0.4928844\n\nmod |&gt; \n  predictions(variables = \"sexe\", by = \"sexe\", type = \"link\")\n\n\n  sexe Estimate Std. Error      z Pr(&gt;|z|)     S  2.5 % 97.5 %\n Femme   -0.911     0.0751 -12.13   &lt;0.001 110.0 -1.058 -0.763\n Homme   -0.493     0.0779  -6.33   &lt;0.001  31.9 -0.646 -0.340\n\nColumns: sexe, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  link \n\n\nDepuis la version 0.10.0 de marginaleffects, si l’on ne précise pas le paramètre type (i.e. si type = NULL), la fonction marginaleffects::predictions() réalise les prédictions selon l’échelle de la fonction de lien, calcule les moyennes puis re-transforme ce résultat selon l’échelle de la variable à expliquer.\n\nlogit_inverse &lt;- binomial(\"logit\") |&gt; purrr::pluck(\"linkinv\")\nmod |&gt; predict(type = \"link\", newdata = mf_femmes) |&gt; mean() |&gt; logit_inverse()\n\n[1] 0.2868924\n\nmod |&gt; predict(type = \"link\", newdata = mf_hommes) |&gt; mean() |&gt; logit_inverse()\n\n[1] 0.3792143\n\nmod |&gt; \n  predictions(variables = \"sexe\", by = \"sexe\")\n\n\n  sexe Estimate Pr(&gt;|z|)     S 2.5 % 97.5 %\n Femme    0.287   &lt;0.001 110.0 0.258  0.318\n Homme    0.379   &lt;0.001  31.9 0.344  0.416\n\nColumns: sexe, estimate, p.value, s.value, conf.low, conf.high \nType:  invlink(link) \n\n\nOr, la plupart du temps, le logit inverse de la moyenne des prédictions est différent de la moyenne des logit inverse des prédictions !\nLes résultats seront similaires et du même ordre de grandeur, mais pas identiques.\n\n\n\n24.3.2 Prédictions marginales à la moyenne\nPour les prédictions marginales moyennes, nous avons réalisé des prédictions pour chaque observations du tableau d’origine, en faisant varier juste une variable à la fois, avant de calculer la moyenne des prédictions.\nUne alternative consiste à générer une sorte d’individu moyen / typique puis à réaliser des prédictions pour cette unique individu, en faisant juste varier la variable explicative d’intérêt. On parle alors de prédictions marginales à la moyenne, marginal predictions at the mean en anglais.\n\n24.3.2.1 avec {marginaleffects}\n\nOn peut réaliser cela avec marginaleffects en précisant newdata = \"mean\". Prenons un exemple pour la variable sexe :\n\nmod |&gt; predictions(variables = \"sexe\", newdata = \"mean\")\n\n\n groupe_ages                    etudes heures.tv  sexe Estimate Pr(&gt;|z|)    S\n   45-64 ans Technique / Professionnel      2.25 Femme    0.239   &lt;0.001 59.5\n   45-64 ans Technique / Professionnel      2.25 Homme    0.323   &lt;0.001 29.5\n 2.5 % 97.5 %\n 0.196  0.289\n 0.273  0.378\n\nColumns: rowid, rowidcf, estimate, p.value, s.value, conf.low, conf.high, sport, groupe_ages, etudes, heures.tv, sexe \nType:  invlink(link) \n\n\nDans ce cas de figure, marginaleffects considère pour chaque variable continue sa moyenne (ici 2.246 pour heures.tv) et pour chaque variable catégorielle son mode (la valeur observée la plus fréquente, ici \"Technique / Professionnel\" pour la variable etudes). On fait juste varier les modalités de sexe puis on calculer la probabilité de faire du sport de ces individus moyens.\nOn peut également passer le paramètre newdata = \"mean\" à broom.helpers::tidy_marginal_predictions() ou même à gtsummary::tbl_regression()2.\n2 Les paramètres additionnels indiqués à gtsummary::tbl_regression() sont transmis en cascade à broom.helpers::tidy_plus_plus() puis à broom.helpers::tidy_marginal_predictions() et enfin à marginaleffects::predictions().\nmod |&gt; \n  tbl_regression(\n    tidy_fun = broom.helpers::tidy_marginal_predictions,\n    newdata = \"mean\",\n    estimate_fun = scales::label_percent(accuracy = 0.1)\n  ) |&gt; \n  bold_labels() |&gt; \n  modify_column_hide(\"p.value\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\nPrédictions Marginales à la Moyenne\n\n95% IC\n1\n\n\n\n\nSexe\n\n\n\n\n    Femme\n23.9%\n19.6% – 28.9%\n\n\n    Homme\n32.3%\n27.3% – 37.8%\n\n\nGroupe d'âges\n\n\n\n\n    18-24 ans\n46.8%\n36.1% – 57.8%\n\n\n    25-44 ans\n37.3%\n32.1% – 42.8%\n\n\n    45-64 ans\n23.9%\n19.6% – 28.9%\n\n\n    65 ans et plus\n19.2%\n14.0% – 25.6%\n\n\nNiveau d'études\n\n\n\n\n    Primaire\n10.1%\n7.3% – 13.7%\n\n\n    Secondaire\n22.1%\n17.7% – 27.2%\n\n\n    Technique / Professionnel\n23.9%\n19.6% – 28.9%\n\n\n    Supérieur\n42.3%\n36.0% – 48.9%\n\n\n    Non documenté\n48.9%\n34.7% – 63.2%\n\n\nHeures de télévision / jour\n\n\n\n\n    0\n29.2%\n23.6% – 35.5%\n\n\n    1\n26.8%\n21.9% – 32.3%\n\n\n    2\n24.5%\n20.1% – 29.5%\n\n\n    3\n22.3%\n18.1% – 27.2%\n\n\n    12\n8.8%\n4.6% – 16.4%\n\n\n\n\n1\nIC = intervalle de confiance\n\n\n\n\n\n\n\n\nTable 24.3: Prédictions marginales à la moyenne\n\n\n\nDe même, on peut générer une représentation graphique :\n\np &lt;- mod |&gt; \n  broom.helpers::plot_marginal_predictions(newdata = \"mean\") |&gt; \n  patchwork::wrap_plots() &\n  scale_y_continuous(\n    limits = c(0, .8),\n    labels = scales::label_percent()\n  ) &\n  coord_flip()\n\n\np\n\n\n\n\n\n\nFigure 24.4: Prédictions marginales à la moyenne\n\n\n\n\nSi l’on souhaite utiliser ggstats::ggcoef_model(), on peut directement indiquer newdata = \"mean\". Il faudra passer cette option via tidy_args qui prend une liste d’arguments à transmettre à tidy_fun.\n\nmod |&gt; \n  ggstats::ggcoef_model(\n    tidy_fun = broom.helpers::tidy_marginal_predictions,\n    tidy_args = list(newdata = \"mean\"),\n    show_p_values = FALSE,\n    signif_stars = FALSE,\n    significance = NULL,\n    vline = FALSE\n  ) +\n  scale_x_continuous(labels = scales::label_percent())\n\n\n\n\n\n\nFigure 24.5: Prédictions marginales à la moyenne\n\n\n\n\n\n24.3.2.2 avec {effects}\n\nLe package effects3 adopte une approche un peu différente pour définir un individu moyen.\n3 Malgré son nom, le package effects ne calcule pas des effets marginaux mais des prédictions marginales, selon la terminologie retenue au début de ce document.Calculons les prédictions marginales à la moyenne avec la fonction effects::Effect().\n\ne &lt;- effects::Effect(\"sexe\", mod)\ne\n\n\n sexe effect\nsexe\n    Femme     Homme \n0.2868924 0.3792143 \n\n\nOn le voit, les résultats sont là encore assez proches mais différents. Regardons de plus près les données utilisées pour les prédictions.\n\ne$model.matrix\n\n  (Intercept) sexeHomme groupe_ages25-44 ans groupe_ages45-64 ans\n1           1         0            0.3533835            0.3719298\n2           1         1            0.3533835            0.3719298\n  groupe_ages65 ans et plus etudesSecondaire etudesTechnique / Professionnel\n1                 0.1904762         0.193985                       0.2962406\n2                 0.1904762         0.193985                       0.2962406\n  etudesSupérieur etudesNon documenté heures.tv\n1       0.2205514          0.05614035  2.246566\n2       0.2205514          0.05614035  2.246566\nattr(,\"assign\")\n [1] 0 1 2 2 2 3 3 3 3 4\nattr(,\"contrasts\")\nattr(,\"contrasts\")$sexe\n[1] \"contr.treatment\"\n\nattr(,\"contrasts\")$groupe_ages\n[1] \"contr.treatment\"\n\nattr(,\"contrasts\")$etudes\n[1] \"contr.treatment\"\n\n\nPour les variables continues, effects utilise la moyenne observée de la variable, comme précédemment avec marginaleffects. Par contre, pour les variables catégorielles, ce n’est pas le mode qui est utilisé, mais l’ensemble des modalités, pondérées selon leur proportion observée dans l’échantillon. Cette approche a l’avantage de moyenniser également les variables catégorielles, même si les individus pour lesquels une prédiction est réalisée sont complètement fictifs.\nOn peut utiliser broom.helpers::tidy_all_effects() pour générer un tableau de prédictions marginales avec effects.\n\nmod |&gt; \n  tbl_regression(\n    tidy_fun = broom.helpers::tidy_all_effects,\n    estimate_fun = scales::label_percent(accuracy = 0.1)\n  ) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\nPrédictions Marginales à la Moyenne\n\n95% IC\n1\n\n\n\n\nSexe\n\n\n\n\n    Femme\n28.7%\n25.8% – 31.8%\n\n\n    Homme\n37.9%\n34.4% – 41.6%\n\n\nGroupe d'âges\n\n\n\n\n    18-24 ans\n51.2%\n41.0% – 61.3%\n\n\n    25-44 ans\n41.5%\n37.4% – 45.7%\n\n\n    45-64 ans\n27.3%\n23.9% – 30.9%\n\n\n    65 ans et plus\n22.0%\n17.4% – 27.5%\n\n\nNiveau d'études\n\n\n\n\n    Primaire\n14.9%\n11.3% – 19.3%\n\n\n    Secondaire\n30.7%\n26.2% – 35.7%\n\n\n    Technique / Professionnel\n32.9%\n29.1% – 37.0%\n\n\n    Supérieur\n53.4%\n48.3% – 58.4%\n\n\n    Non documenté\n59.9%\n46.6% – 71.8%\n\n\nHeures de télévision / jour\n\n\n\n\n    0\n38.9%\n34.8% – 43.2%\n\n\n    3\n30.7%\n28.1% – 33.4%\n\n\n    6\n23.6%\n18.9% – 28.9%\n\n\n    9\n17.7%\n11.9% – 25.4%\n\n\n    10\n16.0%\n10.1% – 24.4%\n\n\n\n\n1\nIC = intervalle de confiance\n\n\n\n\n\n\n\n\nTable 24.4: Prédictions marginales à la moyenne avec le package effects\n\n\n\nPour une représentation graphique, nous pouvons utiliser les fonctions internes d’effects en appliquant plot() aux résultats de effects::allEffects() qui calcule les prédictions marginales de chaque variable.\n\nmod |&gt; \n  effects::allEffects() |&gt; \n  plot()\n\n\n\n\n\n\nFigure 24.6: Prédictions marginales à la moyenne avec le package effects\n\n\n\n\nOn peut aussi utiliser ggstats::ggcoef_model()4.\n4 De manière générale, ggstats::ggcoef_model() est compatible avec les mêmes tidy_fun que gtsummary::tbl_regression(), les deux fonctions utilisant en interne broom.helpers::tidy_plus_plus().\nmod |&gt; \n  ggstats::ggcoef_model(\n    tidy_fun = broom.helpers::tidy_all_effects,\n    vline = FALSE\n  ) +\n  scale_x_continuous(labels = scales::label_percent())\n\n\n\n\n\n\nFigure 24.7: Prédictions marginales à la moyenne avec le package effects\n\n\n\n\n\n24.3.3 Variantes\nLe package ggeffects propose une fonction ggeffects::ggpredict() qui calcule des prédictions marginales à la moyenne des variables continues et à la première modalité (utilisée comme référence) des variables catégorielles. On ne peut donc plus, au sens strict, parler de prédictions à la moyenne. broom.helpers fournit une fonction tidy_ggpredict().\n\nmod |&gt; \n  tbl_regression(\n    tidy_fun = broom.helpers::tidy_ggpredict,\n    estimate_fun = scales::label_percent(accuracy = 0.1)\n  ) |&gt; \n  bold_labels()\n\nData were 'prettified'. Consider using `terms=\"heures.tv [all]\"` to get\n  smooth plots.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\nPrédictions Marginales\n\n95% IC\n1\n\n\n\n\nSexe\n\n\n\n\n    Femme\n23.8%\n15.3% – 35.1%\n\n\n    Homme\n32.2%\n21.4% – 45.4%\n\n\nGroupe d'âges\n\n\n\n\n    18-24 ans\n23.8%\n15.3% – 35.1%\n\n\n    25-44 ans\n17.5%\n12.7% – 23.5%\n\n\n    45-64 ans\n10.1%\n7.3% – 13.7%\n\n\n    65 ans et plus\n7.8%\n5.5% – 10.9%\n\n\nNiveau d'études\n\n\n\n\n    Primaire\n23.8%\n15.3% – 35.1%\n\n\n    Secondaire\n44.2%\n33.0% – 56.1%\n\n\n    Technique / Professionnel\n46.8%\n36.1% – 57.8%\n\n\n    Supérieur\n67.2%\n56.2% – 76.6%\n\n\n    Non documenté\n72.8%\n62.8% – 80.9%\n\n\nHeures de télévision / jour\n\n\n\n\n    0\n29.1%\n18.7% – 42.3%\n\n\n    1\n26.7%\n17.2% – 38.9%\n\n\n    2\n24.4%\n15.7% – 35.8%\n\n\n    3\n22.2%\n14.2% – 33.0%\n\n\n    4\n20.2%\n12.8% – 30.4%\n\n\n    5\n18.3%\n11.4% – 28.2%\n\n\n    6\n16.6%\n10.0% – 26.1%\n\n\n    7\n15.0%\n8.8% – 24.3%\n\n\n    8\n13.5%\n7.7% – 22.7%\n\n\n    9\n12.1%\n6.6% – 21.2%\n\n\n    10\n10.9%\n5.7% – 19.9%\n\n\n    11\n9.8%\n4.9% – 18.7%\n\n\n    12\n8.8%\n4.2% – 17.6%\n\n\n\n\n1\nIC = intervalle de confiance\n\n\n\n\n\n\n\n\nTable 24.5: Prédictions marginales avec ggpredict()\n\n\n\nPour une représentation graphique, on peut utiliser les fonctionnalités natives inclues dans le package ggeffects.\n\nmod |&gt; \n  ggeffects::ggpredict() |&gt; \n  lapply(plot) |&gt; \n  patchwork::wrap_plots()\n\n\n\n\n\n\nFigure 24.8: Prédictions marginales avec ggpredict()",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Prédictions marginales, contrastes marginaux & effets marginaux</span>"
    ]
  },
  {
    "objectID": "analyses/estimations-marginales.html#sec-contrastes-marginaux",
    "href": "analyses/estimations-marginales.html#sec-contrastes-marginaux",
    "title": "24  Prédictions marginales, contrastes marginaux & effets marginaux",
    "section": "\n24.4 Contrastes marginaux",
    "text": "24.4 Contrastes marginaux\nMaintenant que nous savons estimer des prédictions marginales, nous pouvons facilement calculer des contrastes marginaux, à savoir des différences entre prédictions marginales.\n\n24.4.1 Contrastes marginaux moyens\nConsidérons tout d’abord la variable catégorielle sexe et calculons les prédictions marginales moyennes avec marginaleffects::predictions().\n\npred &lt;- predictions(mod, variables = \"sexe\", by = \"sexe\", type = \"response\")\npred\n\n\n  sexe Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n Femme    0.325     0.0130 25.0   &lt;0.001 456.7 0.299  0.350\n Homme    0.404     0.0147 27.5   &lt;0.001 549.0 0.375  0.432\n\nColumns: sexe, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\nLe contraste entre les hommes et les femmes est tout simplement la différence et les deux prédictions marginales.\n\npred$estimate[2] - pred$estimate[1]\n\n[1] 0.07884839\n\n\nLa fonction marginaleffects::avg_comparisons() permet de réaliser directement ce calcul.\n\navg_comparisons(mod, variables = \"sexe\")\n\n\n Term                  Contrast Estimate Std. Error z Pr(&gt;|z|)    S  2.5 %\n sexe mean(Homme) - mean(Femme)   0.0788     0.0197 4   &lt;0.001 14.0 0.0402\n 97.5 %\n  0.117\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\n\n\n\n\n\n\nAstuce\n\n\n\nDans les faits, marginaleffects::avg_comparisons() a calculé la différence entre les hommes et les femmes pour chaque observation d’origine puis a réalisé la moyenne des différences. Mathématiquement, la moyenne des différences est équivalente à la différence des moyennes.\n\n\nLes contrastes calculés ici ont été moyennés sur l’ensemble des valeurs observées. On parle donc de contrastes marginaux moyens (average marginal contrasts).\nPar défaut, chaque modalité est contrastée avec la première modalité prise comme référence (voir exemple ci-dessous avec la variable groupe_ages.\nRegardons maintenant une variable continue.\n\navg_comparisons(mod, variables = \"heures.tv\")\n\n\n      Term Contrast Estimate Std. Error    z Pr(&gt;|z|)    S   2.5 %  97.5 %\n heures.tv mean(+1)  -0.0224    0.00606 -3.7   &lt;0.001 12.2 -0.0343 -0.0105\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\nPar défaut, marginaleffects::avg_comparisons() calcule, pour chaque valeur observée de heures.tv, l’effet sur la probabilité de pratiquer un sport d’augmenter de 1 le nombre d’heures quotidiennes de télévision (plus précisément la différence des valeurs prédites pour la valeur observée plus 0,5 et la valeur observée moins 0,5).\nOn peut facilement obtenir la liste des contrastes marginaux pour l’ensemble des variables.\n\navg_comparisons(mod)\n\n\n        Term                                         Contrast Estimate\n etudes      mean(Non documenté) - mean(Primaire)               0.4309\n etudes      mean(Secondaire) - mean(Primaire)                  0.1568\n etudes      mean(Supérieur) - mean(Primaire)                   0.3701\n etudes      mean(Technique / Professionnel) - mean(Primaire)   0.1781\n groupe_ages mean(25-44 ans) - mean(18-24 ans)                 -0.0844\n groupe_ages mean(45-64 ans) - mean(18-24 ans)                 -0.2127\n groupe_ages mean(65 ans et plus) - mean(18-24 ans)            -0.2631\n heures.tv   mean(+1)                                          -0.0224\n sexe        mean(Homme) - mean(Femme)                          0.0788\n Std. Error     z Pr(&gt;|z|)    S   2.5 %  97.5 %\n    0.06915  6.23   &lt;0.001 31.0  0.2954  0.5665\n    0.03143  4.99   &lt;0.001 20.6  0.0952  0.2184\n    0.03370 10.98   &lt;0.001 90.8  0.3040  0.4361\n    0.02948  6.04   &lt;0.001 29.3  0.1203  0.2359\n    0.04921 -1.71   0.0865  3.5 -0.1808  0.0121\n    0.05070 -4.20   &lt;0.001 15.2 -0.3121 -0.1133\n    0.05558 -4.73   &lt;0.001 18.8 -0.3720 -0.1541\n    0.00606 -3.70   &lt;0.001 12.2 -0.0343 -0.0105\n    0.01970  4.00   &lt;0.001 14.0  0.0402  0.1175\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\nIl est important de noter que le nom des colonnes n’est pas compatible avec les fonctions de broom.helpers et par extension avec gtsummary::tbl_regression() et ggstats::ggcoef_model(). On utilisera donc broom.helpers::tidy_marginal_contrasts()5 qui remets en forme le tableau de résultats dans un format compatible. On pourra ainsi produire un tableau propre des résultats6. Au sens strict, les contrastes obtenus s’expriment en points de pourcentage. Pour éviter toute mauvaise interprétation des résultats, on privilégiera la notation pp (points de pourcentage) plutôt que le symbole %.\n5 Il existe également une fonction broom.helpers::tidy_avg_comparisons() mais on lui préférera broom.helpers::tidy_marginal_contrasts(). Pour un modèle sans interaction, les résultats sont identiques. Mais broom.helpers::tidy_marginal_contrasts() peut gérer des termes d’interactions, ce qui sera utile dans un prochain chapitre (cf. Chapitre 26).6 Notez l’utilisation de style_positive = \"plus\" dans l’appel de scales::label_percent() pour ajouter un signe + devant les valeurs positives, afin de bien indiquer que l’on représente le résultat d’une différence.\nmod |&gt; \n  tbl_regression(\n    tidy_fun = broom.helpers::tidy_marginal_contrasts,\n    estimate_fun = scales::label_percent(\n      accuracy = 0.1,\n      style_positive = \"plus\",\n      suffix = \" pp\"\n    )\n  ) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\nContrastes Marginaux Moyens\n\n95% IC\n1\n\np-valeur\n\n\n\nSexe\n\n\n\n\n\n    mean(Homme) - mean(Femme)\n+7.9 pp\n+4.0 pp – +11.7 pp\n&lt;0,001\n\n\nGroupe d'âges\n\n\n\n\n\n    mean(25-44 ans) - mean(18-24 ans)\n-8.4 pp\n-18.1 pp – +1.2 pp\n0,086\n\n\n    mean(45-64 ans) - mean(18-24 ans)\n-21.3 pp\n-31.2 pp – -11.3 pp\n&lt;0,001\n\n\n    mean(65 ans et plus) - mean(18-24 ans)\n-26.3 pp\n-37.2 pp – -15.4 pp\n&lt;0,001\n\n\nNiveau d'études\n\n\n\n\n\n    mean(Non documenté) - mean(Primaire)\n+43.1 pp\n+29.5 pp – +56.6 pp\n&lt;0,001\n\n\n    mean(Secondaire) - mean(Primaire)\n+15.7 pp\n+9.5 pp – +21.8 pp\n&lt;0,001\n\n\n    mean(Supérieur) - mean(Primaire)\n+37.0 pp\n+30.4 pp – +43.6 pp\n&lt;0,001\n\n\n    mean(Technique / Professionnel) - mean(Primaire)\n+17.8 pp\n+12.0 pp – +23.6 pp\n&lt;0,001\n\n\nHeures de télévision / jour\n\n\n\n\n\n    mean(+1)\n-2.2 pp\n-3.4 pp – -1.1 pp\n&lt;0,001\n\n\n\n\n1\nIC = intervalle de confiance\n\n\n\n\n\n\n\n\nTable 24.6: Contrastes marginaux moyens\n\n\n\nDe même, on peut représenter les contrastes marginaux moyens avec ggstats::ggcoef_model().\n\nggstats::ggcoef_model(\n  mod,\n  tidy_fun = broom.helpers::tidy_marginal_contrasts\n) +\n  ggplot2::scale_x_continuous(\n    labels = scales::label_percent(\n      style_positive = \"plus\",\n      suffix = \"pp\"\n    )\n  )\n\n\n\n\n\n\nFigure 24.9: Contrastes marginaux moyens\n\n\n\n\n\n\n\n\n\n\nAstuce\n\n\n\nIl est possible de personnaliser le type de contrastes calculés, variable par variable, avec l’option variables_list de broom.helpers::tidy_marginal_contrasts(). La syntaxe est un peu particulière : il faut transmettre une liste de listes.\n\nmod |&gt; \n  tbl_regression(\n    tidy_fun = broom.helpers::tidy_marginal_contrasts,\n    variables_list = list(\n      list(heures.tv = 2),\n      list(groupe_ages = \"pairwise\"),\n      list(etudes = \"sequential\")\n    ),\n    estimate_fun = scales::label_percent(\n      accuracy = 0.1,\n      style_positive = \"plus\",\n      suffix = \" pp\"\n    )\n  ) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\nContrastes Marginaux Moyens\n\n95% IC\n1\n\np-valeur\n\n\n\nHeures de télévision / jour\n\n\n\n\n\n    mean(+2)\n-4.4 pp\n-6.7 pp – -2.1 pp\n&lt;0,001\n\n\nGroupe d'âges\n\n\n\n\n\n    mean(25-44 ans) - mean(18-24 ans)\n-8.4 pp\n-18.1 pp – +1.2 pp\n0,086\n\n\n    mean(45-64 ans) - mean(18-24 ans)\n-21.3 pp\n-31.2 pp – -11.3 pp\n&lt;0,001\n\n\n    mean(45-64 ans) - mean(25-44 ans)\n-12.8 pp\n-17.6 pp – -8.1 pp\n&lt;0,001\n\n\n    mean(65 ans et plus) - mean(18-24 ans)\n-26.3 pp\n-37.2 pp – -15.4 pp\n&lt;0,001\n\n\n    mean(65 ans et plus) - mean(25-44 ans)\n-17.9 pp\n-24.3 pp – -11.4 pp\n&lt;0,001\n\n\n    mean(65 ans et plus) - mean(45-64 ans)\n-5.0 pp\n-11.0 pp – +0.9 pp\n0,10\n\n\nNiveau d'études\n\n\n\n\n\n    mean(Non documenté) - mean(Supérieur)\n+6.1 pp\n-7.0 pp – +19.2 pp\n0,4\n\n\n    mean(Secondaire) - mean(Primaire)\n+15.7 pp\n+9.5 pp – +21.8 pp\n&lt;0,001\n\n\n    mean(Supérieur) - mean(Technique / Professionnel)\n+19.2 pp\n+13.3 pp – +25.1 pp\n&lt;0,001\n\n\n    mean(Technique / Professionnel) - mean(Secondaire)\n+2.1 pp\n-3.8 pp – +8.0 pp\n0,5\n\n\n\n\n1\nIC = intervalle de confiance\n\n\n\n\n\n\n\nOn peut obtenir le même résultat avec broom.helpers::tidy_avg_comparison() avec une syntaxe un peu plus simple (en passant une liste via variables au lieu d’une liste de listes via variables_list).\n\nmod |&gt; \n  tbl_regression(\n    tidy_fun = broom.helpers::tidy_avg_comparisons,\n    variables = list(\n      heures.tv = 2,\n      groupe_ages = \"pairwise\",\n      etudes = \"sequential\"\n    ),\n    estimate_fun = scales::label_percent(\n      accuracy = 0.1,\n      style_positive = \"plus\",\n      suffix = \" pp\"\n    )\n  ) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\nContrastes Marginaux Moyens\n\n95% IC\n1\n\np-valeur\n\n\n\nNiveau d'études\n\n\n\n\n\n    mean(Non documenté) - mean(Supérieur)\n+6.1 pp\n-7.0 pp – +19.2 pp\n0,4\n\n\n    mean(Secondaire) - mean(Primaire)\n+15.7 pp\n+9.5 pp – +21.8 pp\n&lt;0,001\n\n\n    mean(Supérieur) - mean(Technique / Professionnel)\n+19.2 pp\n+13.3 pp – +25.1 pp\n&lt;0,001\n\n\n    mean(Technique / Professionnel) - mean(Secondaire)\n+2.1 pp\n-3.8 pp – +8.0 pp\n0,5\n\n\nGroupe d'âges\n\n\n\n\n\n    mean(25-44 ans) - mean(18-24 ans)\n-8.4 pp\n-18.1 pp – +1.2 pp\n0,086\n\n\n    mean(45-64 ans) - mean(18-24 ans)\n-21.3 pp\n-31.2 pp – -11.3 pp\n&lt;0,001\n\n\n    mean(45-64 ans) - mean(25-44 ans)\n-12.8 pp\n-17.6 pp – -8.1 pp\n&lt;0,001\n\n\n    mean(65 ans et plus) - mean(18-24 ans)\n-26.3 pp\n-37.2 pp – -15.4 pp\n&lt;0,001\n\n\n    mean(65 ans et plus) - mean(25-44 ans)\n-17.9 pp\n-24.3 pp – -11.4 pp\n&lt;0,001\n\n\n    mean(65 ans et plus) - mean(45-64 ans)\n-5.0 pp\n-11.0 pp – +0.9 pp\n0,10\n\n\nHeures de télévision / jour\n\n\n\n\n\n    mean(+2)\n-4.4 pp\n-6.7 pp – -2.1 pp\n&lt;0,001\n\n\n\n\n1\nIC = intervalle de confiance\n\n\n\n\n\n\n\n\n\n\n24.4.2 Contrastes marginaux à la moyenne\nComme précédemment, plutôt que de calculer les contrastes marginaux pour chaque individu observé avant de faire la moyenne des résultats, une approche alternative consiste à considérer un individu moyen / typique et à calculer les contrastes marginaux pour cet individu. On parle alors de contrastes marginaux à la moyenne (marginal contrasts at the mean).\nAvec marginaleffects, il suffit de spécifier newdata = \"mean\". Les variables continues seront fixées à leur moyenne et les variables catégorielles à leur mode (modalité la plus fréquente dans l’échantillon).\n\nmod |&gt; \n  tbl_regression(\n    tidy_fun = broom.helpers::tidy_marginal_contrasts,\n    newdata = \"mean\",\n    estimate_fun = scales::label_percent(\n      accuracy = 0.1,\n      style_positive = \"plus\",\n      suffix = \" pp\"\n    )\n  ) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\nContrastes Marginaux à la Moyenne\n\n95% IC\n1\n\np-valeur\n\n\n\nSexe\n\n\n\n\n\n    mean(Homme) - mean(Femme)\n+8.4 pp\n+4.3 pp – +12.5 pp\n&lt;0,001\n\n\nGroupe d'âges\n\n\n\n\n\n    mean(25-44 ans) - mean(18-24 ans)\n-9.5 pp\n-20.5 pp – +1.5 pp\n0,090\n\n\n    mean(45-64 ans) - mean(18-24 ans)\n-22.9 pp\n-33.8 pp – -11.9 pp\n&lt;0,001\n\n\n    mean(65 ans et plus) - mean(18-24 ans)\n-27.6 pp\n-39.2 pp – -16.1 pp\n&lt;0,001\n\n\nNiveau d'études\n\n\n\n\n\n    mean(Non documenté) - mean(Primaire)\n+38.8 pp\n+24.1 pp – +53.5 pp\n&lt;0,001\n\n\n    mean(Secondaire) - mean(Primaire)\n+12.0 pp\n+7.0 pp – +17.1 pp\n&lt;0,001\n\n\n    mean(Supérieur) - mean(Primaire)\n+32.2 pp\n+25.7 pp – +38.7 pp\n&lt;0,001\n\n\n    mean(Technique / Professionnel) - mean(Primaire)\n+13.9 pp\n+9.0 pp – +18.7 pp\n&lt;0,001\n\n\nHeures de télévision / jour\n\n\n\n\n\n    mean(+1)\n-2.1 pp\n-3.3 pp – -1.0 pp\n&lt;0,001\n\n\n\n\n1\nIC = intervalle de confiance\n\n\n\n\n\n\n\n\nTable 24.7: Contrastes marginaux à la moyenne\n\n\n\nPour la fonction ggstats::ggcoef_model(), on utilisera l’argument tidy_args pour transmettre l’option newdata = \"mean\".\n\nggstats::ggcoef_model(\n  mod,\n  tidy_fun = broom.helpers::tidy_marginal_contrasts,\n  tidy_args = list(newdata = \"mean\")\n) +\n  ggplot2::scale_x_continuous(\n    labels = scales::label_percent(\n      style_positive = \"plus\",\n      suffix = \"pp\"\n    )\n  )\n\n\n\n\n\n\nFigure 24.10: Contrastes marginaux à la moyenne",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Prédictions marginales, contrastes marginaux & effets marginaux</span>"
    ]
  },
  {
    "objectID": "analyses/estimations-marginales.html#pentes-marginales-effets-marginaux",
    "href": "analyses/estimations-marginales.html#pentes-marginales-effets-marginaux",
    "title": "24  Prédictions marginales, contrastes marginaux & effets marginaux",
    "section": "\n24.5 Pentes marginales / Effets marginaux",
    "text": "24.5 Pentes marginales / Effets marginaux\nLes effets marginaux, ou plus précisément les pentes marginales, sont similaires aux contrastes marginaux, avec un différence subtile. Pour une variable continue, les contrastes marginaux sont une différence entre deux prédictions tandis que les effets marginaux (marginal effects) ou pentes marginales (marginal slopes). Dis autrement, l’effet marginal d’un régresseur continu \\(x\\) est la pente / dérivée \\({\\partial y}/{\\partial x}\\) la fonction de prédiction \\(y\\), mesurée à des valeurs spécifiques de \\(x\\).\nLes effets marginaux sont le plus souvent calculés selon l’échelle de l’outcome et représentent le changement attendu de l’outcome pour une augmentation du régresseur d’une unité.\nPar définition, les effets marginaux ne sont pas définis pour les variables catégorielles. La plupart des fonctions rapportent, à la place, les contrastes marginaux pour ces variables catégorielles.\nComme pour les prédictions marginales et les contrastes marginaux, plusieurs approches existent (voir par exemple la vignette dédiée du package marginaleffects).\n\n24.5.1 Pentes marginales moyennes / Effets marginaux moyens\nLes effets marginaux moyens (average marginal effects) sont calculés en deux temps : (1) un effet marginal est calculé pour chaque individu observé dans le modèle ; (ii) puis la moyenne de ces effets individuels est calculée.\nOn aura tout simplement recours à la fonction marginaleffects::avg_slopes().\n\navg_slopes(mod)\n\n\n        Term                                         Contrast Estimate\n etudes      mean(Non documenté) - mean(Primaire)               0.4309\n etudes      mean(Secondaire) - mean(Primaire)                  0.1568\n etudes      mean(Supérieur) - mean(Primaire)                   0.3701\n etudes      mean(Technique / Professionnel) - mean(Primaire)   0.1781\n groupe_ages mean(25-44 ans) - mean(18-24 ans)                 -0.0844\n groupe_ages mean(45-64 ans) - mean(18-24 ans)                 -0.2127\n groupe_ages mean(65 ans et plus) - mean(18-24 ans)            -0.2631\n heures.tv   mean(dY/dX)                                       -0.0227\n sexe        mean(Homme) - mean(Femme)                          0.0788\n Std. Error     z Pr(&gt;|z|)    S   2.5 %  97.5 %\n     0.0691  6.23   &lt;0.001 31.0  0.2954  0.5665\n     0.0314  4.99   &lt;0.001 20.6  0.0952  0.2184\n     0.0337 10.98   &lt;0.001 90.8  0.3040  0.4361\n     0.0295  6.04   &lt;0.001 29.3  0.1203  0.2359\n     0.0492 -1.71   0.0865  3.5 -0.1808  0.0121\n     0.0507 -4.20   &lt;0.001 15.2 -0.3121 -0.1133\n     0.0556 -4.73   &lt;0.001 18.8 -0.3720 -0.1541\n     0.0062 -3.66   &lt;0.001 11.9 -0.0348 -0.0105\n     0.0197  4.00   &lt;0.001 14.0  0.0402  0.1175\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\nPour un usage avec broom.helpers::tidy_plus_plus(), gtsummary::tbl_regression() ou ggstats::ggcoef_model(), on utilisera broom.helpers::tidy_avg_slopes().\n\nmod |&gt; \n  tbl_regression(\n    tidy_fun = broom.helpers::tidy_avg_slopes,\n    estimate_fun = scales::label_percent(\n      accuracy = 0.1,\n      style_positive = \"plus\",\n      suffix = \" pp\"\n    )\n  ) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\nEffets Marginaux Moyens\n\n95% IC\n1\n\np-valeur\n\n\n\nNiveau d'études\n\n\n\n\n\n    mean(Non documenté) - mean(Primaire)\n+43.1 pp\n+29.5 pp – +56.6 pp\n&lt;0,001\n\n\n    mean(Secondaire) - mean(Primaire)\n+15.7 pp\n+9.5 pp – +21.8 pp\n&lt;0,001\n\n\n    mean(Supérieur) - mean(Primaire)\n+37.0 pp\n+30.4 pp – +43.6 pp\n&lt;0,001\n\n\n    mean(Technique / Professionnel) - mean(Primaire)\n+17.8 pp\n+12.0 pp – +23.6 pp\n&lt;0,001\n\n\nGroupe d'âges\n\n\n\n\n\n    mean(25-44 ans) - mean(18-24 ans)\n-8.4 pp\n-18.1 pp – +1.2 pp\n0,086\n\n\n    mean(45-64 ans) - mean(18-24 ans)\n-21.3 pp\n-31.2 pp – -11.3 pp\n&lt;0,001\n\n\n    mean(65 ans et plus) - mean(18-24 ans)\n-26.3 pp\n-37.2 pp – -15.4 pp\n&lt;0,001\n\n\nHeures de télévision / jour\n\n\n\n\n\n    mean(dY/dX)\n-2.3 pp\n-3.5 pp – -1.1 pp\n&lt;0,001\n\n\nSexe\n\n\n\n\n\n    mean(Homme) - mean(Femme)\n+7.9 pp\n+4.0 pp – +11.7 pp\n&lt;0,001\n\n\n\n\n1\nIC = intervalle de confiance\n\n\n\n\n\n\n\n\nTable 24.8: Effets marginaux moyens\n\n\n\n\nggstats::ggcoef_model(\n  mod,\n  tidy_fun = broom.helpers::tidy_avg_slopes\n) +\n  ggplot2::scale_x_continuous(\n    labels = scales::label_percent(\n      style_positive = \"plus\",\n      suffix = \"pp\"\n    )\n  )\n\n\n\n\n\n\nFigure 24.11: Effets marginaux moyens\n\n\n\n\nUn résultat similaire peut être obtenu avec margins::margins(), le package margins s’inspirant de la commande Stata margins.\n\nmargins::margins(mod) %&gt;% tidy()\n\nWarning: tidying a `margins` object was deprecated in broom 1.0.6.\nℹ margins was removed from CRAN in April 2024 and its tidiers are thus\n  untested.\n! Please interpret output with caution.\n\n\n# A tibble: 9 × 5\n  term                            estimate std.error statistic  p.value\n  &lt;chr&gt;                              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 etudesNon documenté               0.431    0.0691       6.23 4.60e-10\n2 etudesSecondaire                  0.157    0.0314       4.99 6.10e- 7\n3 etudesSupérieur                   0.370    0.0337      11.0  4.69e-28\n4 etudesTechnique / Professionnel   0.178    0.0295       6.04 1.53e- 9\n5 groupe_ages25-44 ans             -0.0844   0.0492      -1.71 8.65e- 2\n6 groupe_ages45-64 ans             -0.213    0.0507      -4.20 2.73e- 5\n7 groupe_ages65 ans et plus        -0.263    0.0556      -4.73 2.21e- 6\n8 heures.tv                        -0.0227   0.00620     -3.66 2.56e- 4\n9 sexeHomme                         0.0788   0.0197       4.00 6.26e- 5\n\n\nFor broom.helpers, gtsummary or ggstats, use broom.helpers::tidy_margins().\n\nmod |&gt; \n  tbl_regression(\n    tidy_fun = broom.helpers::tidy_margins,\n    estimate_fun = scales::label_percent(\n      accuracy = 0.1,\n      style_positive = \"plus\",\n      suffix = \" pp\"\n    )\n  ) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\nEffets Marginaux Moyens\n\n95% IC\n1\n\np-valeur\n\n\n\nNiveau d'études\n\n\n\n\n\n    Primaire\n—\n—\n\n\n\n    Non documenté\n+43.1 pp\n+29.5 pp – +56.6 pp\n&lt;0,001\n\n\n    Secondaire\n+15.7 pp\n+9.5 pp – +21.8 pp\n&lt;0,001\n\n\n    Supérieur\n+37.0 pp\n+30.4 pp – +43.6 pp\n&lt;0,001\n\n\n    Technique / Professionnel\n+17.8 pp\n+12.0 pp – +23.6 pp\n&lt;0,001\n\n\nGroupe d'âges\n\n\n\n\n\n    18-24 ans\n—\n—\n\n\n\n    25-44 ans\n-8.4 pp\n-18.1 pp – +1.2 pp\n0,086\n\n\n    45-64 ans\n-21.3 pp\n-31.2 pp – -11.3 pp\n&lt;0,001\n\n\n    65 ans et plus\n-26.3 pp\n-37.2 pp – -15.4 pp\n&lt;0,001\n\n\nHeures de télévision / jour\n-2.3 pp\n-3.5 pp – -1.1 pp\n&lt;0,001\n\n\nSexe\n\n\n\n\n\n    Femme\n—\n—\n\n\n\n    Homme\n+7.9 pp\n+4.0 pp – +11.7 pp\n&lt;0,001\n\n\n\n\n1\nIC = intervalle de confiance\n\n\n\n\n\n\n\n\nTable 24.9: Effets marginaux moyens avec margins\n\n\n\n\nggstats::ggcoef_model(\n  mod,\n  tidy_fun = broom.helpers::tidy_margins\n) +\n  ggplot2::scale_x_continuous(\n    labels = scales::label_percent(\n      style_positive = \"plus\",\n      suffix = \"pp\"\n    )\n  )\n\n\n\n\n\n\nFigure 24.12: Effets marginaux moyens avec margins\n\n\n\n\n\n24.5.2 Pentes marginales à la moyenne / Effets marginaux à la moyenne\nPour les effets marginaux à la moyenne (marginal effects at the mean), simplement indiquer newdata = \"mean\" à broom.helpers::tidy_marginaleffects().",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Prédictions marginales, contrastes marginaux & effets marginaux</span>"
    ]
  },
  {
    "objectID": "analyses/estimations-marginales.html#lectures-complémentaires-en-anglais",
    "href": "analyses/estimations-marginales.html#lectures-complémentaires-en-anglais",
    "title": "24  Prédictions marginales, contrastes marginaux & effets marginaux",
    "section": "\n24.6 Lectures complémentaires (en anglais)",
    "text": "24.6 Lectures complémentaires (en anglais)\n\n\nDocumentation of the marginaleffects package par Vincent Arel-Bundock\n\nMarginalia: A guide to figuring out what the heck marginal effects, marginal slopes, average marginal effects, marginal effects at the mean, and all these other marginal things are par Andrew Heiss\n\nIntroduction to Adjusted Predictions and Marginal Effects in R par Daniel Lüdecke\nAn Introduction to margins\nMarginal effects / slopes, contrasts, means and predictions with broom.helpers\n\nThe Marginal Effects Zoo par Vincent Arel-Bundock",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Prédictions marginales, contrastes marginaux & effets marginaux</span>"
    ]
  },
  {
    "objectID": "analyses/estimations-marginales.html#webin-r",
    "href": "analyses/estimations-marginales.html#webin-r",
    "title": "24  Prédictions marginales, contrastes marginaux & effets marginaux",
    "section": "\n24.7 webin-R",
    "text": "24.7 webin-R\nLa régression logistique est présentée sur YouTube dans le webin-R #24 (Prédictions, contrastes & effets marginaux).\n\n\n\n\nFigure 24.1: Prédictions marginales moyennes\nFigure 24.2: Prédictions marginales moyennes\nFigure 24.3: Prédictions marginales moyennes\nFigure 24.4: Prédictions marginales à la moyenne\nFigure 24.5: Prédictions marginales à la moyenne\nFigure 24.6: Prédictions marginales à la moyenne avec le package effects\nFigure 24.7: Prédictions marginales à la moyenne avec le package effects\nFigure 24.8: Prédictions marginales avec ggpredict()\nFigure 24.9: Contrastes marginaux moyens\nFigure 24.10: Contrastes marginaux à la moyenne\nFigure 24.11: Effets marginaux moyens\nFigure 24.12: Effets marginaux moyens avec margins",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Prédictions marginales, contrastes marginaux & effets marginaux</span>"
    ]
  },
  {
    "objectID": "analyses/contrastes.html",
    "href": "analyses/contrastes.html",
    "title": "25  Contrastes (variables catégorielles)",
    "section": "",
    "text": "25.1 Contrastes de type traitement\nPar défaut, R applique des contrastes de type traitement pour un facteur non ordonné. Il s’agit notamment des contrastes utilisés par défaut dans les chapitres précédents.",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Contrastes (variables catégorielles)</span>"
    ]
  },
  {
    "objectID": "analyses/contrastes.html#contrastes-de-type-traitement",
    "href": "analyses/contrastes.html#contrastes-de-type-traitement",
    "title": "25  Contrastes (variables catégorielles)",
    "section": "",
    "text": "25.1.1 Exemple 1 : un modèle linéaire avec une variable catégorielle\nCommençons avec un premier exemple que nous allons calculer avec le jeu de données trial chargé en mémoire lorsque l’on appelle l’extension gtsummary. Ce jeu de données contient les observations de 200 patients. Nous nous intéressons à deux variables en particulier : marker une variable numérique correspondant à un marqueur biologique et grade un facteur à trois modalités correspondant à différent groupes de patients.\nRegardons la moyenne de marker pour chaque valeur de grade.\n\nlibrary(tidyverse)\nlibrary(gtsummary)\ntrial |&gt;\n  select(marker, grade) |&gt;\n  tbl_summary(\n    by = grade,\n    statistic = marker ~ \"{mean}\",\n    digits = marker ~ 4\n  ) |&gt;\n  add_overall(last = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nI\nN = 68\n1\n\n\nII\nN = 68\n1\n\n\nIII\nN = 64\n1\n\n\nOverall\nN = 200\n1\n\n\n\n\nMarker Level (ng/mL)\n1.0669\n0.6805\n0.9958\n0.9160\n\n\n    Unknown\n2\n5\n3\n10\n\n\n\n\n1\nMean\n\n\n\n\n\n\n\nUtilisons maintenant une régression linaire pour modéliser la valeur de marker en fonction de grade.\n\nmod1_trt &lt;- lm(marker ~ grade, data = trial)\nmod1_trt\n\n\nCall:\nlm(formula = marker ~ grade, data = trial)\n\nCoefficients:\n(Intercept)      gradeII     gradeIII  \n     1.0669      -0.3864      -0.0711  \n\n\nLe modèle obtenu contient trois coefficients ou termes : un intercept et deux termes associés à la variable grade.\nPour bien interpréter ces coefficients, il faut comprendre comment la variable grade a été transformée avant d’être inclue dans le modèle. Nous pouvons voir cela avec la fonction contrasts().\n\ncontrasts(trial$grade)\n\n    II III\nI    0   0\nII   1   0\nIII  0   1\n\n\nCe que nous montre cette matrice, c’est que la variable catégorielle grade à 3 modalités a été transformée en 2 variables binaires que l’on retrouve sous les noms de gradeII et gradeIII dans le modèle : gradeII vaut 1 si grade est égal à II et 0 sinon; gradeIII vaut 1 si grade est égal à III et 0 sinon. Si grade est égal à I, alors gradeII et gradeIII valent 0.\nIl s’agit ici d’un contraste dit de traitement ou la première modalité joue ici le rôle de modalité de référence.\nDans ce modèle linéaire, la valeur de l’intercept correspond à la moyenne de marker lorsque nous nous trouvons à la référence, donc quand grade est égal à I dans cet exemple. Et nous pouvons le constater dans notre tableau précédent des moyennes, 1.0669 correspond bien à la moyenne de marker pour la modalité I.\nLa valeur du coefficient associé à markerII correspond à l’écart par rapport à la référence lorsque marker est égal à II. Autrement dit, la moyenne de marker pour la modalité II correspond à la somme de l’intercept et du coefficient markerII. Et nous retrouvons bien la relation suivante : 0.6805 = 1.0669 + -0.3864. De même, la moyenne de marker lorsque grade vaut III est égale à la somme de l’intercept et du terme markerIII.\nLorsqu’on utilise des contrastes de type traitement, chaque terme du modèle peut être associé à une et une seule modalité d’origine de la variable catégorielle. Dès lors, il est possible de rajouter la modalité de référence lorsque l’on présente les résultats et on peut même lui associer la valeurs 0, ce qui peut être fait avec gtsummary::tbl_regression() avec l’option add_estimate_to_reference_rows = TRUE.\n\nmod1_trt |&gt;\n  tbl_regression(\n    intercept = TRUE, \n    add_estimate_to_reference_rows = TRUE\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nBeta\n\n95% CI\n1\n\np-value\n\n\n\n(Intercept)\n1.1\n0.86, 1.3\n&lt;0.001\n\n\nGrade\n\n\n\n\n\n    I\n0.00\n—\n\n\n\n    II\n-0.39\n-0.68, -0.09\n0.010\n\n\n    III\n-0.07\n-0.37, 0.23\n0.6\n\n\n\n\n1\nCI = Confidence Interval\n\n\n\n\n\n\n\n\n25.1.2 Exemple 2 : une régression logistique avec deux variables catégorielles\nPour ce deuxième exemple, nous allons utiliser le jeu de données hdv2003 fourni par l’extension questionr et recoder la variable age en groupes d’âges à 4 modalités.\n\nlibrary(questionr)\ndata(\"hdv2003\")\n\nlibrary(tidyverse)\n\n\nhdv2003 &lt;- hdv2003 |&gt;\n  mutate(\n    groupe_ages = cut(\n      age, \n      c(16, 25, 45, 65, 99), \n      right = FALSE, \n      include.lowest = TRUE\n    ) |&gt;\n      fct_recode(\n        \"16-24\" = \"[16,25)\",\n        \"25-44\" = \"[25,45)\",\n        \"45-64\" = \"[45,65)\",\n        \"65+\" = \"[65,99]\"\n      ) \n  ) |&gt;\n  labelled::set_variable_labels(\n    groupe_ages = \"Groupe d'âges\",\n    sexe = \"Sexe\"\n  )\n\nNous allons faire une régression logistique binaire pour investiguer l’effet du sexe (variable à 2 modalités) et du groupe d’âges (variable à 4 modalités) sur la pratique du sport.\n\nmod2_trt &lt;- glm(\n  sport ~ sexe + groupe_ages,\n  family = binomial,\n  data = hdv2003\n)\nmod2_trt\n\n\nCall:  glm(formula = sport ~ sexe + groupe_ages, family = binomial, \n    data = hdv2003)\n\nCoefficients:\n     (Intercept)         sexeFemme  groupe_ages25-44  groupe_ages45-64  \n          0.9021           -0.4455           -0.6845           -1.6535  \n  groupe_ages65+  \n         -2.3198  \n\nDegrees of Freedom: 1999 Total (i.e. Null);  1995 Residual\nNull Deviance:      2617 \nResidual Deviance: 2385     AIC: 2395\n\n\nLe modèle contient 5 termes : 1 intercept, 1 coefficient pour la variable sexe et 3 coefficients pour la variable groupe_ages. Comme précédemment, nous pouvons constater que les variables à n modalités sont remplacées par défaut (contrastes de type traitement) par n-1 variables binaires, la première modalité jouant à chaque fois le rôle de modalité de référence.\n\ncontrasts(hdv2003$sexe)\n\n      Femme\nHomme     0\nFemme     1\n\ncontrasts(hdv2003$groupe_ages)\n\n      25-44 45-64 65+\n16-24     0     0   0\n25-44     1     0   0\n45-64     0     1   0\n65+       0     0   1\n\n\nL’intercept correspond donc à la situation à la référence, c’est-à-dire à la prédiction du modèle pour les hommes (référence de sexe) âgés de 16 à 24 ans (référence de groupe_ages).\nIl est possible d’exprimer cela en termes de probabilité en utilisant l’inverse de la fonction logit (puisque nous avons utilisé un modèle logit).\n\ninv_logit &lt;- binomial(\"logit\")$linkinv\ninv_logit(0.9021)\n\n[1] 0.7113809\n\n\nSelon le modèle, les hommes âgés de 16 à 24 ans ont donc 71% de chance de pratiquer du sport.\nRegardons maintenant le coefficient associé à sexeFemme (-0.4455) : il représente (pour la modalité de référence des autres variables, soit pour les 16-24 ans ici) la correction à appliquer à l’intercept pour obtenir la probabilité de faire du sport. Il s’agit donc de la différence entre les femmes et les hommes pour le groupe des 16-24 ans.\n\ninv_logit(0.9021 - 0.4455)\n\n[1] 0.6122073\n\n\nAutrement dit, selon le modèle, la probabilité de faire du sport pour une femme âgée de 16 à 24 ans est de 61%. On peut représenter cela avec la fonction ggeffects::ggpredict() de ggeffects, qui représente les prédictions d’une variable toutes les autres variables étant à la référence.\n\nlibrary(ggeffects)\nggpredict(mod2_trt, \"sexe\") |&gt; plot()\n\n\n\n\n\n\n\nBien souvent, pour une régression logistique, on préfère représenter les exponentielles des coefficients qui correspondent à des odds ratios.\n\nmod2_trt |&gt;\n  tbl_regression(\n    exponentiate = TRUE,\n    intercept = TRUE, \n    add_estimate_to_reference_rows = TRUE\n  ) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nOR\n1\n\n\n95% CI\n1\n\np-value\n\n\n\n(Intercept)\n2.46\n1.76, 3.48\n&lt;0.001\n\n\nSexe\n\n\n\n\n\n    Homme\n1.00\n—\n\n\n\n    Femme\n0.64\n0.53, 0.78\n&lt;0.001\n\n\nGroupe d'âges\n\n\n\n\n\n    16-24\n1.00\n—\n\n\n\n    25-44\n0.50\n0.35, 0.71\n&lt;0.001\n\n\n    45-64\n0.19\n0.13, 0.27\n&lt;0.001\n\n\n    65+\n0.10\n0.06, 0.15\n&lt;0.001\n\n\n\n\n1\nOR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\nOr, 0,64 correspond bien à l’odds ratio entre 61% et 71% (que l’on peut calculer avec questionr::odds.ratio()).\n\nquestionr::odds.ratio(0.6122, 0.7114)\n\n[1] 0.6404246\n\n\nDe la même manière, les différents coefficients associés à groupe_ages correspondent à la différence entre chaque groupe d’âges et sa modalité de référence (ici 16-24 ans), quand les autres variables (ici le sexe) sont à leur référence (ici les hommes).\nPour prédire la probabilité de faire du sport pour un profil particulier, il faut prendre en compte toutes les termes qui s’appliquent et qui s’ajoutent à l’intercept. Par exemple, pour une femme de 50 ans il faut considérer l’intercept (0.9021), le coefficient sexeFemme (-0.4455) et le coefficient groupe_ages45-64 (-1.6535). Sa probabilité de faire du sport est donc de 23%.\n\ninv_logit(0.9021 - 0.4455 - 1.6535)\n\n[1] 0.2320271\n\n\n\n25.1.3 Changer la modalité de référence\nIl est possible de personnaliser les contrastes à utiliser et avoir un recours à un contraste de type traitement mais en utilisant une autre modalité que la première comme référence, avec la fonction contr.treatment(). Le premier argument de la fonction corresponds au nombre de modalités de la variable et le paramètre base permets de spécifier la modalité de référence (1 par défaut).\n\ncontr.treatment(4, base = 2)\n\n  1 3 4\n1 1 0 0\n2 0 0 0\n3 0 1 0\n4 0 0 1\n\n\ncontr.SAS() permets de spécifier un contraste de type traitement dont la modalité de référence est la dernière.\n\ncontr.SAS(4)\n\n  1 2 3\n1 1 0 0\n2 0 1 0\n3 0 0 1\n4 0 0 0\n\n\nLes contrastes peuvent être modifiés de deux manières : au moment de la construction du modèle (via l’option contrasts) ou comme attribut des variables (via la fonction contrasts()).\n\ncontrasts(hdv2003$sexe) &lt;- contr.SAS(2)\nmod2_trt_bis &lt;- glm(\n  sport ~ sexe + groupe_ages, \n  family = binomial, \n  data = hdv2003,\n  contrasts = list(groupe_ages = contr.treatment(4, 3))\n)\nmod2_trt_bis |&gt;\n  tbl_regression(exponentiate = TRUE, intercept = TRUE) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nOR\n1\n\n\n95% CI\n1\n\np-value\n\n\n\n(Intercept)\n0.30\n0.25, 0.36\n&lt;0.001\n\n\nSexe\n\n\n\n\n\n    Homme\n1.56\n1.29, 1.90\n&lt;0.001\n\n\n    Femme\n—\n—\n\n\n\nGroupe d'âges\n\n\n\n\n\n    16-24\n5.23\n3.67, 7.52\n&lt;0.001\n\n\n    25-44\n2.64\n2.12, 3.29\n&lt;0.001\n\n\n    45-64\n—\n—\n\n\n\n    65+\n0.51\n0.37, 0.70\n&lt;0.001\n\n\n\n\n1\nOR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\nComme les modalités de référence ont changé, l’intercept et les différents termes ont également changé (puisque l’on ne compare plus à la même référence).\n\nggstats::ggcoef_compare(\n  list(mod2_trt, mod2_trt_bis),\n  exponentiate = TRUE,\n  type = \"faceted\"\n)\n\n\n\n\n\n\n\nCependant, du point de vue explicatif et prédictif, les deux modèles sont rigoureusement identiques.\n\nanova(mod2_trt, mod2_trt_bis, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: sport ~ sexe + groupe_ages\nModel 2: sport ~ sexe + groupe_ages\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)\n1      1995     2385.2                     \n2      1995     2385.2  0        0         \n\n\nDe même, leurs prédictions marginales (cf. Chapitre 24) sont identiques.\n\nggstats::ggcoef_compare(\n  list(mod2_trt, mod2_trt_bis),\n  tidy_fun = broom.helpers::tidy_marginal_predictions,\n  type = \"dodge\",\n  vline = FALSE\n)",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Contrastes (variables catégorielles)</span>"
    ]
  },
  {
    "objectID": "analyses/contrastes.html#contrastes-de-type-somme",
    "href": "analyses/contrastes.html#contrastes-de-type-somme",
    "title": "25  Contrastes (variables catégorielles)",
    "section": "\n25.2 Contrastes de type somme",
    "text": "25.2 Contrastes de type somme\nNous l’avons vu, les contrastes de type traitement nécessitent de définir une modalité de référence et toutes les autres modalités seront comparées à cette modalité de référence. Une alternative consiste à comparer toutes les modalités à la grande moyenne, ce qui s’obtient avec un contraste de type somme que l’on obtient avec contr.sum().\n\n25.2.1 Exemple 1 : un modèle linéaire avec une variable catégorielle\nReprenons notre premier exemple de tout à l’heure et modifions seulement le contraste.\n\ncontrasts(trial$grade) &lt;- contr.sum\nmod1_sum &lt;- lm(\n  marker ~ grade,\n  data = trial\n)\nmod1_sum\n\n\nCall:\nlm(formula = marker ~ grade, data = trial)\n\nCoefficients:\n(Intercept)       grade1       grade2  \n     0.9144       0.1525      -0.2339  \n\n\nL’intercept correspond à ce qu’on appelle parfois la grande moyenne (ou great average en anglais). Il ne s’agit pas de la moyenne observée de marker mais de la moyenne des moyennes de chaque sous-groupe. Cela va constituer la situation de référence de notre modèle, en quelque sorte indépendante des effets de la variable grade.\n\nmean(trial$marker, na.rm = TRUE)\n\n[1] 0.9159895\n\nmoy_groupe &lt;-\n  trial |&gt; \n  dplyr::group_by(grade) |&gt; \n  dplyr::summarise(moyenne_marker = mean(marker, na.rm = TRUE))\nmoy_groupe\n\n# A tibble: 3 × 2\n  grade moyenne_marker\n  &lt;fct&gt;          &lt;dbl&gt;\n1 I              1.07 \n2 II             0.681\n3 III            0.996\n\nmean(moy_groupe$moyenne_marker)\n\n[1] 0.9144384\n\n\nLe terme grade1 correspond quant à lui au modificateur associé à la première modalité de la variable grade à savoir I. C’est l’écart, pour cette modalité, à la grande moyenne : 1.0669 - 0.9144 = 0.1525.\nDe même, le terme grade2 correspond à l’écart pour la modalité II par rapport à la grande moyenne : 0.6805 - 0.9144 = -0.2339.\nQu’en est-il de l’écart à la grande moyenne pour la modalité III ? Pour cela, voyons tout d’abord comment la variable grade a été codée :\n\ncontrasts(trial$grade)\n\n    [,1] [,2]\nI      1    0\nII     0    1\nIII   -1   -1\n\n\nComme précédemment, cette variable à trois modalités a été codée avec deux termes. Les deux premiers termes correspondent aux écarts à la grande moyenne des deux premières modalités. La troisième modalité est, quant à elle, codée systématiquement -1. C’est ce qui assure que la somme des contributions soit nulle et donc que l’intercept capture la grande moyenne.\nL’écart à la grande moyenne pour la troisième modalité s’obtient donc en faisant la somme des autres termes et en l’inversant : (0.1525 - 0.2339) * -1 = 0.0814 = 0.9958 - 0.9144.\nOn peut calculer / afficher la valeur associée à la dernière modalité en précisant add_estimate_to_reference_rows = TRUE lorsque l’on appelle gtsummary::tbl_regression().\n\nmod1_sum |&gt;\n  tbl_regression(\n    intercept = TRUE, \n    add_estimate_to_reference_rows = TRUE\n  ) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nBeta\n\n95% CI\n1\n\np-value\n\n\n\n(Intercept)\n0.91\n0.79, 1.0\n&lt;0.001\n\n\nGrade\n\n\n\n\n\n    I\n0.15\n-0.02, 0.32\n0.078\n\n\n    II\n-0.23\n-0.41, -0.06\n0.008\n\n\n    III\n0.08\n-0.13, 0.29\n0.4\n\n\n\n\n1\nCI = Confidence Interval\n\n\n\n\n\n\n\nDe même, cette valeur est correctement affichée par ggstats::ggcoef_model().\n\nggstats::ggcoef_model(mod1_sum)\n\n\n\n\n\n\n\nLe fait d’utiliser des contrastes de type traitement ou somme n’a aucun impact sur la valeur prédictive du modèle. La quantité de variance expliquée, la somme des résidus ou encore l’AIC sont identiques. En un sens, il s’agit du même modèle. C’est seulement la manière d’interpréter les coefficients du modèle qui change.\n\nanova(mod1_trt, mod1_sum, test = \"Chisq\")\n\nAnalysis of Variance Table\n\nModel 1: marker ~ grade\nModel 2: marker ~ grade\n  Res.Df    RSS Df Sum of Sq Pr(&gt;Chi)\n1    187 134.17                      \n2    187 134.17  0         0         \n\n\n\n25.2.2 Exemple 2 : une régression logistique avec deux variables catégorielles\nReprenons notre second exemple et codons les variables catégorielles avec un traitement de type somme.\n\nmod2_sum &lt;- glm(\n  sport ~ sexe + groupe_ages,\n  family = binomial,\n  data = hdv2003,\n  contrasts = list(sexe = contr.sum, groupe_ages = contr.sum)\n)\nmod2_sum |&gt;\n  tbl_regression(\n    exponentiate = TRUE,\n    intercept = TRUE, \n    add_estimate_to_reference_rows = TRUE\n  ) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nOR\n1\n\n\n95% CI\n1\n\np-value\n\n\n\n(Intercept)\n0.62\n0.55, 0.69\n&lt;0.001\n\n\nSexe\n\n\n\n\n\n    Homme\n1.25\n1.13, 1.38\n&lt;0.001\n\n\n    Femme\n0.80\n0.72, 0.89\n&lt;0.001\n\n\nGroupe d'âges\n\n\n\n\n\n    16-24\n3.20\n2.49, 4.15\n&lt;0.001\n\n\n    25-44\n1.62\n1.38, 1.89\n&lt;0.001\n\n\n    45-64\n0.61\n0.52, 0.72\n&lt;0.001\n\n\n    65+\n0.31\n0.24, 0.42\n&lt;0.001\n\n\n\n\n1\nOR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\nggstats::ggcoef_model(mod2_sum, exponentiate = TRUE)\n\n\n\n\n\n\n\nCette fois-ci, l’intercept capture la situation à la grande moyenne à la fois du sexe et du groupe d’âges, et les coefficients s’interprètent donc comme modificateurs de chaque modalité par rapport à cette grande moyenne. En ce sens, les contrastes de type somme permettent donc de capturer l’effet de chaque modalité.\nDu point de vue explicatif et prédictif, le fait d’avoir recours à des contrastes de type somme ou traitement n’a aucun impact : les deux modèles sont rigoureusement identiques. Il n’y a que la manière d’interpréter les coefficients qui change.\n\nanova(mod2_trt, mod2_sum, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: sport ~ sexe + groupe_ages\nModel 2: sport ~ sexe + groupe_ages\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)\n1      1995     2385.2                     \n2      1995     2385.2  0        0         \n\n\nLes prédictions marginales (cf. Chapitre 24) sont identiques.\n\nggstats::ggcoef_compare(\n  list(mod2_trt, mod2_sum),\n  tidy_fun = broom.helpers::tidy_marginal_predictions,\n  type = \"dodge\",\n  vline = FALSE\n)",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Contrastes (variables catégorielles)</span>"
    ]
  },
  {
    "objectID": "analyses/contrastes.html#contrastes-par-différences-successives",
    "href": "analyses/contrastes.html#contrastes-par-différences-successives",
    "title": "25  Contrastes (variables catégorielles)",
    "section": "\n25.3 Contrastes par différences successives",
    "text": "25.3 Contrastes par différences successives\nLes contrastes par différences successives consistent à comparer la deuxième modalité à la première, puis la troisième modalité à la seconde, etc. Ils sont disponibles avec la fonction MASS::contr.sdif().\nIllustrons cela avec un exemple.\n\n25.3.1 Exemple 1 : un modèle linéaire avec une variable catégorielle\n\nmod1_sdif &lt;- lm(\n  marker ~ grade,\n  data = trial,\n  contrasts = list(grade = MASS::contr.sdif)\n)\nmod1_sdif |&gt; \n  tbl_regression(intercept = TRUE) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nBeta\n\n95% CI\n1\n\np-value\n\n\n\n(Intercept)\n0.91\n0.79, 1.0\n&lt;0.001\n\n\nGrade\n\n\n\n\n\n    II - I\n-0.39\n-0.68, -0.09\n0.010\n\n\n    III - II\n0.32\n0.02, 0.62\n0.040\n\n\n\n\n1\nCI = Confidence Interval\n\n\n\n\n\n\n\nEn premier lieu, on notera que l’intercept, comme avec les contrastes de type somme, correspond ici à la grande moyenne.\n\nmean(moy_groupe$moyenne_marker)\n\n[1] 0.9144384\n\n\nCela est lié au fait que la somme des coefficients dans ce type de contrastes est égale à 0.\n\nMASS::contr.sdif(3)\n\n         2-1        3-2\n1 -0.6666667 -0.3333333\n2  0.3333333 -0.3333333\n3  0.3333333  0.6666667\n\n\nDe plus, la matrice de contrastes est calculée de telle manière que l’écart entre les deux premières modalités vaut 1 pour le premier terme, et l’écart entre la seconde et la troisième modalité vaut également 1 pour le deuxième terme.\nAinsi, le terme gradeII-I correspond à la différence entre la moyenne du grade de niveau II et celle du niveau I1.\n1 On peut remarquer que la même valeur était obtenue avec un contraste de type traitement où toutes les modalités étaient comparées à la modalité de référence I.\nmoy_groupe$moyenne_marker[2] - moy_groupe$moyenne_marker[1]\n\n[1] -0.3863997\n\n\nEt le coefficient gradeIII-II à l’écart entre la moyenne du niveau III et celle du niveau II.\n\nmoy_groupe$moyenne_marker[3] - moy_groupe$moyenne_marker[2]\n\n[1] 0.3152964\n\n\n\n25.3.2 Exemple 2 : une régression logistique avec deux variables catégorielles\nLa même approche peut être appliquée à une régression logistique.\n\nmod2_sdif &lt;- glm(\n  sport ~ sexe + groupe_ages,\n  family = binomial,\n  data = hdv2003,\n  contrasts = list(\n    sexe = MASS::contr.sdif,\n    groupe_ages = MASS::contr.sdif\n  )\n)\nmod2_sdif |&gt;\n  tbl_regression(\n    exponentiate = TRUE,\n    intercept = TRUE\n  ) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nOR\n1\n\n\n95% CI\n1\n\np-value\n\n\n\n(Intercept)\n0.62\n0.55, 0.69\n&lt;0.001\n\n\nSexe\n\n\n\n\n\n    Femme / Homme\n0.64\n0.53, 0.78\n&lt;0.001\n\n\nGroupe d'âges\n\n\n\n\n\n    25-44 / 16-24\n0.50\n0.35, 0.71\n&lt;0.001\n\n\n    45-64 / 25-44\n0.38\n0.30, 0.47\n&lt;0.001\n\n\n    65+ / 45-64\n0.51\n0.37, 0.70\n&lt;0.001\n\n\n\n\n1\nOR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\nOn pourra noter que les odds ratios “femme/homme” et “25-44/16-24” obtenus ici sont équivalents à ceux que l’on avait obtenus précédemment avec des contrastes de types de traitement. Pour la modalité “45-64 ans” par contre, elle est ici comparée aux 25-44 ans, alors qu’avec un contraste de type traitement, toutes les comparaisons auraient eu lieu avec la même modalité de référence, à savoir les 16-24 ans.\nLes contrastes par différences successives font donc plutôt sens lorsque les modalités sont ordonnées (d’où l’intérêt de comparer avec la modalité précédente), ce qui n’est pas forcément le cas lorsque les modalités ne sont pas ordonnées.\n\n\n\n\n\n\nAstuce\n\n\n\nDe manière générale, et quels que soient les contrastes utilisés pour le calcul du modèle, il est toujours possible de recalculer a posteriori les différences entre chaque combinaison de modalités deux à deux avec emmeans::emmeans(). Cela peut même se faire directement en passant l’argument add_pairwise_contrasts = TRUE à tbl_regression().\n\nmod2_trt |&gt; \n  tbl_regression(\n    exponentiate = TRUE,\n    add_pairwise_contrasts = TRUE\n  ) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nOR\n1\n\n\n95% CI\n1\n\np-value\n\n\n\nSexe\n\n\n\n\n\n    Femme / Homme\n0.64\n0.53, 0.78\n&lt;0.001\n\n\nGroupe d'âges\n\n\n\n\n\n    (25-44) / (16-24)\n0.50\n0.32, 0.80\n&lt;0.001\n\n\n    (45-64) / (16-24)\n0.19\n0.12, 0.31\n&lt;0.001\n\n\n    (45-64) / (25-44)\n0.38\n0.28, 0.51\n&lt;0.001\n\n\n    (65+) / (16-24)\n0.10\n0.06, 0.17\n&lt;0.001\n\n\n    (65+) / (25-44)\n0.19\n0.13, 0.29\n&lt;0.001\n\n\n    (65+) / (45-64)\n0.51\n0.34, 0.78\n&lt;0.001\n\n\n\n\n1\nOR = Odds Ratio, CI = Confidence Interval",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Contrastes (variables catégorielles)</span>"
    ]
  },
  {
    "objectID": "analyses/contrastes.html#autres-types-de-contrastes",
    "href": "analyses/contrastes.html#autres-types-de-contrastes",
    "title": "25  Contrastes (variables catégorielles)",
    "section": "\n25.4 Autres types de contrastes",
    "text": "25.4 Autres types de contrastes\n\n25.4.1 Contrastes de type Helmert\nLes contrastes de Helmert sont un peu plus complexes : ils visent à comparer la seconde modalité à la première, la troisième à la moyenne des deux premières, la quatrième à la moyenne des trois premières, etc.\nPrenons un exemple avec une variable catégorielle à quatre modalités.\n\ncontrasts(trial$stage) &lt;- contr.helmert\ncontrasts(trial$stage)\n\n   [,1] [,2] [,3]\nT1   -1   -1   -1\nT2    1   -1   -1\nT3    0    2   -1\nT4    0    0    3\n\nmod_helmert &lt;- lm(\n  marker ~ stage,\n  data = trial\n)\nmod_helmert\n\n\nCall:\nlm(formula = marker ~ stage, data = trial)\n\nCoefficients:\n(Intercept)       stage1       stage2       stage3  \n    0.91661      0.19956      0.03294     -0.02085  \n\n\nPour bien comprendre comment interpréter ces coefficients, calculons déjà la grande moyenne.\n\nm &lt;- trial |&gt; \n  dplyr::group_by(stage) |&gt; \n  dplyr::summarise(moy = mean(marker, na.rm = TRUE))\nmean(m$moy)\n\n[1] 0.9166073\n\n\nOn le voit, l’intercept (0.9166) capture ici cette grande moyenne, à savoir la moyenne des moyennes de chaque sous-groupe.\nMaintenant, pour interpréter les coefficients, regardons comment évolue la moyenne à chaque fois que l’on ajoute une modalité. La fonction dplyr::cummean() nous permet de calculer la moyenne cumulée, c’est-à-dire la moyenne de la valeur actuelle et des valeurs des lignes précédentes. Avec dplyr::lag() nous pouvons obtenir la moyenne cumulée de la ligne précédente. Il nous est alors possible de calculer l’écart entre les deux, et donc de voir comment la moyenne a changé avec l’ajout d’une modalité.\n\nm &lt;- m |&gt; \n  dplyr::mutate(\n    moy_cum = dplyr::cummean(moy),\n    moy_cum_prec = dplyr::lag(moy_cum),\n    ecart = moy_cum - moy_cum_prec\n  )\nm\n\n# A tibble: 4 × 5\n  stage   moy moy_cum moy_cum_prec   ecart\n  &lt;fct&gt; &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;\n1 T1    0.705   0.705       NA     NA     \n2 T2    1.10    0.905        0.705  0.200 \n3 T3    1.00    0.937        0.905  0.0329\n4 T4    0.854   0.917        0.937 -0.0208\n\n\nOn le voit, les valeurs de la colonne ecart correspondent aux coefficients du modèle.\nLe premier terme stage1 compare la deuxième modalité (T2) à la première (T1) et indique l’écart entre la moyenne des moyennes de T1 et T2 et la moyenne de T1.\nLe second terme stage2 compare la troisième modalité (T3) aux deux premières (T1 et T2) et indique l’écart entre la moyenne des moyennes de T1, T2 et T3 par rapport à la moyenne des moyennes de T1 et T2.\nLe troisième terme stage3 compare la quatrième modalité (T4) aux trois premières (T1, T2 et T3) et indique l’écart entre la moyenne des moyennes de T1, T2, T3 et T4 par rapport à la moyenne des moyennes de T1, T2 et T3.\nLes contrastes de Helmert sont ainsi un peu plus complexes à interpréter et à réserver à des cas particuliers où ils prennent tout leur sens.\n\n25.4.2 Contrastes polynomiaux\nLes contrastes polynomiaux, définis avec contr.poly(), sont utilisés par défaut pour les variables catégorielles ordonnées. Ils permettent de décomposer les effets selon une composante linéaire, une composante quadratique, une composante cubique, voire des composantes de degrés supérieurs.\n\ncontrasts(trial$stage) &lt;- contr.poly\ncontrasts(trial$stage)\n\n           .L   .Q         .C\nT1 -0.6708204  0.5 -0.2236068\nT2 -0.2236068 -0.5  0.6708204\nT3  0.2236068 -0.5 -0.6708204\nT4  0.6708204  0.5  0.2236068\n\nmod_poly &lt;- lm(\n  marker ~ stage,\n  data = trial\n)\nmod_poly\n\n\nCall:\nlm(formula = marker ~ stage, data = trial)\n\nCoefficients:\n(Intercept)      stage.L      stage.Q      stage.C  \n    0.91661      0.07749     -0.27419      0.10092  \n\n\nIci aussi, l’intercept correspond à la grande moyenne des moyennes. Il est par contre plus difficile de donner un sens interprétatif / sociologique aux différents coefficients.",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Contrastes (variables catégorielles)</span>"
    ]
  },
  {
    "objectID": "analyses/contrastes.html#lectures-additionnelles",
    "href": "analyses/contrastes.html#lectures-additionnelles",
    "title": "25  Contrastes (variables catégorielles)",
    "section": "\n25.5 Lectures additionnelles",
    "text": "25.5 Lectures additionnelles\n\n\nA (sort of) Complete Guide to Contrasts in R par Rose Maier\n\nAn introductory explanation of contrast coding in R linear models par Athanassios Protopapas\n\nUnderstanding Sum Contrasts for Regression Models: A Demonstration par Mona Zhu",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Contrastes (variables catégorielles)</span>"
    ]
  },
  {
    "objectID": "analyses/interactions.html",
    "href": "analyses/interactions.html",
    "title": "26  Interactions",
    "section": "",
    "text": "26.1 Données d’illustration\nReprenons le modèle que nous avons utilisé dans le chapitre sur la régression logistique binaire (cf. Chapitre 22).\nlibrary(tidyverse)\nlibrary(labelled)\n\ndata(hdv2003, package = \"questionr\")\n\nd &lt;-\n  hdv2003 |&gt; \n  mutate(\n    sexe = sexe |&gt; fct_relevel(\"Femme\"),\n    groupe_ages = age |&gt;\n      cut(\n        c(18, 25, 45, 65, 99),\n        right = FALSE,\n        include.lowest = TRUE,\n        labels = c(\"18-24 ans\", \"25-44 ans\",\n                   \"45-64 ans\", \"65 ans et plus\")\n      ),\n    etudes = nivetud |&gt; \n      fct_recode(\n        \"Primaire\" = \"N'a jamais fait d'etudes\",\n        \"Primaire\" = \"A arrete ses etudes, avant la derniere annee d'etudes primaires\",\n        \"Primaire\" = \"Derniere annee d'etudes primaires\",\n        \"Secondaire\" = \"1er cycle\",\n        \"Secondaire\" = \"2eme cycle\",\n        \"Technique / Professionnel\" = \"Enseignement technique ou professionnel court\",\n        \"Technique / Professionnel\" = \"Enseignement technique ou professionnel long\",\n        \"Supérieur\" = \"Enseignement superieur y compris technique superieur\"\n    ) |&gt; \n    fct_na_value_to_level(\"Non documenté\")  \n  ) |&gt; \n  set_variable_labels(\n    sport = \"Pratique un sport ?\",\n    sexe = \"Sexe\",\n    groupe_ages = \"Groupe d'âges\",\n    etudes = \"Niveau d'études\",\n    heures.tv = \"Heures de télévision / jour\"\n  )",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Interactions</span>"
    ]
  },
  {
    "objectID": "analyses/interactions.html#modèle-sans-interaction",
    "href": "analyses/interactions.html#modèle-sans-interaction",
    "title": "26  Interactions",
    "section": "\n26.2 Modèle sans interaction",
    "text": "26.2 Modèle sans interaction\nNous avions alors exploré les facteurs associés au fait de pratiquer du sport.\n\nmod &lt;- glm(\n  sport ~ sexe + groupe_ages + etudes + heures.tv,\n  family = binomial,\n  data = d\n)\nlibrary(gtsummary)\ntheme_gtsummary_language(\n  \"fr\",\n  decimal.mark = \",\",\n  big.mark = \" \"\n)\n\n\nmod |&gt; \n  tbl_regression(exponentiate = TRUE) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nOR\n1\n\n\n95% IC\n1\n\np-valeur\n\n\n\nSexe\n\n\n\n\n\n    Femme\n—\n—\n\n\n\n    Homme\n1,52\n1,24 – 1,87\n&lt;0,001\n\n\nGroupe d'âges\n\n\n\n\n\n    18-24 ans\n—\n—\n\n\n\n    25-44 ans\n0,68\n0,43 – 1,06\n0,084\n\n\n    45-64 ans\n0,36\n0,23 – 0,57\n&lt;0,001\n\n\n    65 ans et plus\n0,27\n0,16 – 0,46\n&lt;0,001\n\n\nNiveau d'études\n\n\n\n\n\n    Primaire\n—\n—\n\n\n\n    Secondaire\n2,54\n1,73 – 3,75\n&lt;0,001\n\n\n    Technique / Professionnel\n2,81\n1,95 – 4,10\n&lt;0,001\n\n\n    Supérieur\n6,55\n4,50 – 9,66\n&lt;0,001\n\n\n    Non documenté\n8,54\n4,51 – 16,5\n&lt;0,001\n\n\nHeures de télévision / jour\n0,89\n0,83 – 0,95\n&lt;0,001\n\n\n\n\n1\nOR = rapport de cotes, IC = intervalle de confiance\n\n\n\n\n\n\n\n\nTable 26.1: Odds Ratios du modèle logistique simple\n\n\n\nSelon les résultats de notre modèle, les hommes pratiquent plus un sport que les femmes et la pratique du sport diminue avec l’âge.\nDans le chapitre sur les estimations marginales, cf. Chapitre 24, nous avons présenté la fonction broom.helpers::plot_marginal_predictions() qui permet de représenter les prédictions marginales moyennes du modèle.\n\nmod |&gt; \n  broom.helpers::plot_marginal_predictions(type = \"response\") |&gt; \n  patchwork::wrap_plots() &\n  scale_y_continuous(\n    limits = c(0, .8),\n    labels = scales::label_percent()\n  )\n\n\n\n\n\n\nFigure 26.1: Prédictions marginales moyennes du modèle simple",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Interactions</span>"
    ]
  },
  {
    "objectID": "analyses/interactions.html#définition-dune-interaction",
    "href": "analyses/interactions.html#définition-dune-interaction",
    "title": "26  Interactions",
    "section": "\n26.3 Définition d’une interaction",
    "text": "26.3 Définition d’une interaction\nCependant, l’effet de l’âge est-il le même selon le sexe ? Nous allons donc introduire une interaction entre l’âge et le sexe dans notre modèle, ce qui sera représenté par sexe * groupe_agesdans l’équation du modèle.\n\nmod2 &lt;- glm(\n  sport ~ sexe * groupe_ages + etudes + heures.tv,\n  family = binomial,\n  data = d\n)\n\nCommençons par regarder les prédictions marginales du modèle avec interaction.\n\nmod2 |&gt; \n  broom.helpers::plot_marginal_predictions(type = \"response\") |&gt; \n  patchwork::wrap_plots(ncol = 1) &\n  scale_y_continuous(\n    labels = scales::label_percent()\n  )\n\n\n\n\n\n\nFigure 26.2: Prédictions marginales moyennes du modèle avec interaction\n\n\n\n\nSur ce graphique, on voit que la pratique d’un sport diminue fortement avec l’âge chez les hommes, tandis que cette diminution est bien plus modérée chez les femmes.\n\n\n\n\n\n\nAstuce\n\n\n\nPar défaut, broom.helpers::plot_marginal_predictions() détecte la présence d’interactions dans le modèle et calcule les prédictions marginales pour chaque combinaison de variables incluent dans une interaction. Il reste possible de calculer des prédictions marginales individuellement pour chaque variable du modèle. Pour cela, il suffit d’indiquer variables_list = \"no_interaction\".\n\nmod2 |&gt; \n  broom.helpers::plot_marginal_predictions(\n    variables_list = \"no_interaction\",\n    type = \"response\"\n  ) |&gt; \n  patchwork::wrap_plots() &\n  scale_y_continuous(\n    labels = scales::label_percent()\n  )",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Interactions</span>"
    ]
  },
  {
    "objectID": "analyses/interactions.html#significativité-de-linteraction",
    "href": "analyses/interactions.html#significativité-de-linteraction",
    "title": "26  Interactions",
    "section": "\n26.4 Significativité de l’interaction",
    "text": "26.4 Significativité de l’interaction\nL’ajout d’une interaction au modèle augmente la capacité prédictive du modèle mais, dans le même temps, augmente le nombre de coefficients (et donc de degrés de liberté). La question se pose donc de savoir si l’ajout d’un terme d’interaction améliore notre modèle.\nEn premier lieu, nous pouvons comparer les AIC des modèles avec et sans interaction.\n\nAIC(mod)\n\n[1] 2230.404\n\nAIC(mod2)\n\n[1] 2223.382\n\n\nL’AIC du modèle avec interaction est plus faible que celui sans interaction, nous indiquant un gain : notre modèle avec interaction est donc meilleur.\nOn peut tester avec car::Anova() si l’interaction est statistiquement significative1.\n1 Lorsqu’il y a une interaction, il est préférable d’utiliser le type III, cf. Section 22.8. En toute rigueur, il serait préférable de coder nos variables catégorielles avec un contraste de type somme (cf. Chapitre 25). En pratique, nous pouvons nous en passer ici.\ncar::Anova(mod2, type = \"III\")\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: sport\n                 LR Chisq Df Pr(&gt;Chisq)    \nsexe               19.349  1  1.089e-05 ***\ngroupe_ages        15.125  3  0.0017131 ** \netudes            125.575  4  &lt; 2.2e-16 ***\nheures.tv          12.847  1  0.0003381 ***\nsexe:groupe_ages   13.023  3  0.0045881 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLa p-valeur associée au terme d’interaction (sexe:groupe_ages) est inférieure à 1% : l’interaction a donc bien un effet significatif.\nNous pouvons également utiliser gtsummary::add_global_p().\n\nmod2 |&gt; \n  tbl_regression(exponentiate = TRUE) |&gt; \n  add_global_p() |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nOR\n1\n\n\n95% IC\n1\n\np-valeur\n\n\n\nSexe\n\n\n&lt;0,001\n\n\n    Femme\n—\n—\n\n\n\n    Homme\n5,10\n2,41 – 11,4\n\n\n\nGroupe d'âges\n\n\n0,002\n\n\n    18-24 ans\n—\n—\n\n\n\n    25-44 ans\n1,06\n0,61 – 1,85\n\n\n\n    45-64 ans\n0,64\n0,36 – 1,15\n\n\n\n    65 ans et plus\n0,49\n0,25 – 0,97\n\n\n\nNiveau d'études\n\n\n&lt;0,001\n\n\n    Primaire\n—\n—\n\n\n\n    Secondaire\n2,55\n1,74 – 3,78\n\n\n\n    Technique / Professionnel\n2,84\n1,97 – 4,14\n\n\n\n    Supérieur\n6,69\n4,60 – 9,89\n\n\n\n    Non documenté\n8,94\n4,64 – 17,6\n\n\n\nHeures de télévision / jour\n0,89\n0,83 – 0,95\n&lt;0,001\n\n\nSexe * Groupe d'âges\n\n\n0,005\n\n\n    Homme * 25-44 ans\n0,31\n0,13 – 0,70\n\n\n\n    Homme * 45-64 ans\n0,24\n0,10 – 0,54\n\n\n\n    Homme * 65 ans et plus\n0,23\n0,09 – 0,60\n\n\n\n\n\n1\nOR = rapport de cotes, IC = intervalle de confiance\n\n\n\n\n\n\n\n\nTable 26.2: Odds Ratios du modèle logistique avec interaction",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Interactions</span>"
    ]
  },
  {
    "objectID": "analyses/interactions.html#interprétation-des-coefficients",
    "href": "analyses/interactions.html#interprétation-des-coefficients",
    "title": "26  Interactions",
    "section": "\n26.5 Interprétation des coefficients",
    "text": "26.5 Interprétation des coefficients\nJetons maintenant un œil aux coefficients du modèle. Pour rendre les choses plus visuelles, nous aurons recours à ggtstats::ggcoef_model().\n\nmod2 |&gt; \n  ggstats::ggcoef_model(exponentiate = TRUE)\n\n\n\n\n\n\nFigure 26.3: Coefficients (odds ratio) du modèle avec interaction\n\n\n\n\nConcernant les variables sexe et groupe_ages, nous avons trois séries de coefficients : une série pour le sexe, une pour le groupe d’âges et enfin des coefficients pour l’interaction entre le sexe et le groupe d’âges.\nPour bien interpréter ces coefficients, il faut toujours avoir en tête les modalités choisies comme référence pour chaque variable.\nSupposons une femme de 60 ans, dont toutes les autres variables correspondent aux modalités de référence (i.e. de niveau primaire, qui ne regarde pas la télévision). Regardons ce que prédit le modèle quant à sa probabilité de faire du sport au travers d’une représentation graphique, grâce au package breakDown.\n\nlibrary(breakDown)\nlogit &lt;- function(x) exp(x)/(1+exp(x))\nnouvelle_observation &lt;- d[1, ]\nnouvelle_observation$sexe[1] = \"Femme\"\nnouvelle_observation$groupe_ages[1] = \"45-64 ans\"\nnouvelle_observation$etud[1] = \"Primaire\"\nnouvelle_observation$heures.tv[1] = 0\nplot(\n  broken(mod2, nouvelle_observation, predict.function = betas),\n  trans = logit\n) +\n  ylim(0, 1) +\n  ylab(\"Probabilité de faire du sport\")\n\n\n\n\n\n\nFigure 26.4: Représentation graphique de l’estimation de la probabilité de faire du sport pour une femme de 60 ans\n\n\n\n\nEn premier lieu, l’intercept s’applique et permet de déterminer la probabilité de base de faire du sport à la référence. Femme étant la modalité de référence pour la variable sexe, cela ne modifie pas le calcul de la probabilité de faire du sport. Par contre, il y a une modification induite par la modalité 45-64 ans de la variable groupe_ages.\nRegardons maintenant la situation d’un homme de 20 ans.\n\nnouvelle_observation$sexe[1] = \"Homme\"\nnouvelle_observation$groupe_ages[1] = \"18-24 ans\"\nplot(\n  broken(mod2, nouvelle_observation, predict.function = betas),\n  trans = logit\n) +\n  ylim(0, 1.2) +\n  ylab(\"Probabilité de faire du sport\")\n\n\n\n\n\n\nFigure 26.5: Représentation graphique de l’estimation de la probabilité de faire du sport pour un homme de 20 ans\n\n\n\n\nNous sommes à la modalité de référence pour l’âge par contre il y a un effet important du sexe. Le coefficient associé globalement à la variable sexe correspond donc à l’effet du sexe à la modalité de référence du groupe d’âges.\nRegardons enfin la situation d’un homme de 60 ans.\n\nnouvelle_observation$groupe_ages[1] = \"45-64 ans\"\nplot(\n  broken(mod2, nouvelle_observation, predict.function = betas),\n  trans = logit\n) +\n  ylim(0, 1.2) +\n  ylab(\"Probabilité de faire du sport\")\n\n\n\n\n\n\nFigure 26.6: Représentation graphique de l’estimation de la probabilité de faire du sport pour un homme de 60 ans\n\n\n\n\nCette fois, plusieurs coefficients s’appliquent : à la fois le coefficient sexe = Homme (effet du sexe pour les 18-24 ans), le coefficient groupe_ages = 45-64 ans qui est l’effet de l’âge pour les femmes de 45-64 ans par rapport aux 18-24 ans et le coefficient sexe:groupe_ages = Homme:45-64 ans qui indique l’effet spécifique qui s’applique aux hommes de 45-64 ans, d’une part par rapport aux femmes du même âge et d’autre part par rapport aux hommes de 18-24 ans. L’effet des coefficients d’interaction doivent donc être interprétés par rapport aux autres coefficients du modèle qui s’appliquent, en tenant compte des modalités de référence.",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Interactions</span>"
    ]
  },
  {
    "objectID": "analyses/interactions.html#définition-alternative-de-linteraction",
    "href": "analyses/interactions.html#définition-alternative-de-linteraction",
    "title": "26  Interactions",
    "section": "\n26.6 Définition alternative de l’interaction",
    "text": "26.6 Définition alternative de l’interaction\nIl est cependant possible d’écrire le même modèle différemment. En effet, sexe * groupe_ages dans la formule du modèle est équivalent à l’écriture sexe + groupe_ages + sexe:groupe_ages, c’est-à-dire que l’on demande des coefficients pour la variable sexe à la référence de groupe_ages, des coefficients pour groupe_ages à la référence de sexe et enfin des coefficients pour tenir compte de l’interaction.\nOn peut se contenter d’une série de coefficients uniques pour l’interaction en indiquant seulement sexe : groupe_ages.\n\nmod3 &lt;- glm(\n  sport ~ sexe : groupe_ages + etudes + heures.tv,\n  family = binomial,\n  data = d\n)\n\nAu sens strict, ce modèle explique tout autant le phénomène étudié que le modèle précédent. On peut le vérifier facilement avec stats::anova().\n\nanova(mod2, mod3, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: sport ~ sexe * groupe_ages + etudes + heures.tv\nModel 2: sport ~ sexe:groupe_ages + etudes + heures.tv\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)\n1      1982     2197.4                     \n2      1982     2197.4  0        0         \n\n\nDe même, les prédictions marginales sont les mêmes, comme nous pouvons le constater avec ggstats::ggcoef_compare().\n\nggstats::ggcoef_compare(\n  list(\"sexe * groupe_ages\" = mod2, \"sexe : groupe_ages\" = mod3),\n  tidy_fun = broom.helpers::tidy_marginal_predictions,\n  significance = NULL,\n  vline = FALSE\n) +\n  scale_x_continuous(labels = scales::label_percent())\n\nWarning: Model matrix is rank deficient. Some variance-covariance parameters are\n  missing.\nWarning: Model matrix is rank deficient. Some variance-covariance parameters are\n  missing.\nWarning: Model matrix is rank deficient. Some variance-covariance parameters are\n  missing.\n\n\n\n\n\n\n\nFigure 26.7: Comparaison des prédictions marginales moyennes des deux modèles avec interaction\n\n\n\n\nPar contre, regardons d’un peu plus près les coefficients de ce nouveau modèle. Nous allons voir que leur interprétation est légèrement différente.\n\nmod3 |&gt; \n  ggstats::ggcoef_model(exponentiate = TRUE)\n\n\n\n\n\n\nFigure 26.8: Coefficients (odds ratio) du modèle avec interaction simple entre le sexe et le groupe d’âges\n\n\n\n\nCette fois-ci, il n’y a plus de coefficients globaux pour la variable sexe ni pour groupe_ages mais des coefficients pour chaque combinaison de ces deux variables. Reprenons l’exemple de notre homme de 60 ans.\n\nplot(\n  broken(mod3, nouvelle_observation, predict.function = betas),\n  trans = logit\n) +\n  ylim(0, 1.2) +\n  ylab(\"Probabilité de faire du sport\")\n\n\n\n\n\n\nFigure 26.9: Représentation graphique de l’estimation de la probabilité de faire du sport pour un homme de 60 ans (interaction simple)\n\n\n\n\nCette fois-ci, le coefficient d’interaction fournit indique l’effet combiné du sexe et du groupe d’âges par rapport à la situation de référence (femme de 18-24 ans).\nQue l’on définisse une interaction simple (sexe:groupe_ages) ou complète (sexe*groupe_ages), les deux modèles calculés sont donc identiques en termes prédictifs et explicatifs, mais l’interprétation de leurs coefficients diffèrent.",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Interactions</span>"
    ]
  },
  {
    "objectID": "analyses/interactions.html#identifier-les-interactions-pertinentes",
    "href": "analyses/interactions.html#identifier-les-interactions-pertinentes",
    "title": "26  Interactions",
    "section": "\n26.7 Identifier les interactions pertinentes",
    "text": "26.7 Identifier les interactions pertinentes\nIl peut y avoir de multiples interactions dans un modèle, d’ordre 2 (entre deux variables) ou plus (entre trois variables ou plus). Il est toujours bon, selon notre connaissance du sujet et de la littérature, d’explorer manuellement les interactions attendues / prévisibles.\nMais, il est tentant de vouloir tester les multiples interactions possibles de manière itératives afin d’identifier celles à retenir.\nUne possibilité2 est d’avoir recours à une sélection de modèle pas à pas ascendante (voir Chapitre 23). Nous allons partir de notre modèle sans interaction, indiquer à step() l’ensemble des interactions possibles et voir si nous pouvons minimiser l’AIC.\n2 On pourra également regarder du côté de glmulti::glmulti() pour des approches alternatives.\nmod4 &lt;- mod |&gt; \n  step(scope = list(upper = ~ sexe * groupe_ages * etudes * heures.tv))\n\nStart:  AIC=2230.4\nsport ~ sexe + groupe_ages + etudes + heures.tv\n\n                        Df Deviance    AIC\n+ sexe:groupe_ages       3   2197.4 2223.4\n+ sexe:etudes            4   2199.6 2227.6\n+ sexe:heures.tv         1   2207.6 2229.6\n&lt;none&gt;                       2210.4 2230.4\n+ groupe_ages:heures.tv  3   2207.0 2233.0\n+ etudes:heures.tv       4   2207.4 2235.4\n+ groupe_ages:etudes    11   2194.6 2236.6\n- heures.tv              1   2224.0 2242.0\n- sexe                   1   2226.4 2244.4\n- groupe_ages            3   2260.6 2274.6\n- etudes                 4   2334.3 2346.3\n\nStep:  AIC=2223.38\nsport ~ sexe + groupe_ages + etudes + heures.tv + sexe:groupe_ages\n\n                        Df Deviance    AIC\n+ sexe:heures.tv         1   2194.7 2222.7\n&lt;none&gt;                       2197.4 2223.4\n+ groupe_ages:heures.tv  3   2193.5 2225.5\n+ sexe:etudes            4   2192.1 2226.1\n+ etudes:heures.tv       4   2194.6 2228.6\n- sexe:groupe_ages       3   2210.4 2230.4\n+ groupe_ages:etudes    11   2183.1 2231.1\n- heures.tv              1   2210.2 2234.2\n- etudes                 4   2323.0 2341.0\n\nStep:  AIC=2222.67\nsport ~ sexe + groupe_ages + etudes + heures.tv + sexe:groupe_ages + \n    sexe:heures.tv\n\n                        Df Deviance    AIC\n&lt;none&gt;                       2194.7 2222.7\n- sexe:heures.tv         1   2197.4 2223.4\n+ groupe_ages:heures.tv  3   2190.4 2224.4\n+ sexe:etudes            4   2189.0 2225.0\n+ etudes:heures.tv       4   2191.6 2227.6\n- sexe:groupe_ages       3   2207.6 2229.6\n+ groupe_ages:etudes    11   2180.7 2230.7\n- etudes                 4   2319.9 2339.9\n\nmod4$formula\n\nsport ~ sexe + groupe_ages + etudes + heures.tv + sexe:groupe_ages + \n    sexe:heures.tv\n\n\nLe modèle final suggéré comprends une interaction entre le sexe et le groupe d’âges et une interaction entre le sexe et le nombre quotidien d’heures de télévision. Nous pouvons utiliser broom.helpers::plot_marginal_predictions() pour visualiser l’effet de ces deux interactions.\n\nmod4 |&gt; \n  broom.helpers::plot_marginal_predictions(type = \"response\") |&gt; \n  patchwork::wrap_plots(ncol = 1) &\n  scale_y_continuous(\n    labels = scales::label_percent()\n  )\n\n\n\n\n\n\nFigure 26.10: Prédictions marginales moyennes du modèle avec deux interactions",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Interactions</span>"
    ]
  },
  {
    "objectID": "analyses/interactions.html#pour-aller-plus-loin",
    "href": "analyses/interactions.html#pour-aller-plus-loin",
    "title": "26  Interactions",
    "section": "\n26.8 Pour aller plus loin",
    "text": "26.8 Pour aller plus loin\nIl y a d’autres extensions dédiées à l’analyse des interactions d’un modèle, de même que de nombreux supports de cours en ligne dédiés à cette question.\n\n\nLes effets d’interaction par Jean-François Bickel\n\nAnalysing interactions of fitted models par Helios De Rosario Martínez",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Interactions</span>"
    ]
  },
  {
    "objectID": "analyses/interactions.html#webin-r",
    "href": "analyses/interactions.html#webin-r",
    "title": "26  Interactions",
    "section": "\n26.9 webin-R",
    "text": "26.9 webin-R\nLes interactions sont abordées dans le webin-R #07 (régression logistique partie 2) sur YouTube.\n\n\n\n\nFigure 26.1: Prédictions marginales moyennes du modèle simple\nFigure 26.2: Prédictions marginales moyennes du modèle avec interaction\nFigure 26.3: Coefficients (odds ratio) du modèle avec interaction\nFigure 26.4: Représentation graphique de l’estimation de la probabilité de faire du sport pour une femme de 60 ans\nFigure 26.5: Représentation graphique de l’estimation de la probabilité de faire du sport pour un homme de 20 ans\nFigure 26.6: Représentation graphique de l’estimation de la probabilité de faire du sport pour un homme de 60 ans\nFigure 26.7: Comparaison des prédictions marginales moyennes des deux modèles avec interaction\nFigure 26.8: Coefficients (odds ratio) du modèle avec interaction simple entre le sexe et le groupe d’âges\nFigure 26.9: Représentation graphique de l’estimation de la probabilité de faire du sport pour un homme de 60 ans (interaction simple)\nFigure 26.10: Prédictions marginales moyennes du modèle avec deux interactions",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Interactions</span>"
    ]
  },
  {
    "objectID": "analyses/multicolinearite.html",
    "href": "analyses/multicolinearite.html",
    "title": "27  Multicolinéarité",
    "section": "",
    "text": "27.1 Définition\nAu sens strict, on parle de multicolinéarité parfaite lorsqu’une des variables explicatives d’un modèle est une combinaison linéaire d’une ou plusieurs autres variables explicatives introduites dans le même modèle. L’absence de multicolinéarité parfaite est une des conditions requises pour pouvoir estimer un modèle linéaire et, par extension, un modèle linéaire généralisé (dont les modèles de régression logistique).\nDans les faits, une multicolinéarité parfaite n’est quasiment jamais observée. Mais une forte multicolinéarité entre plusieurs variables peut poser problème dans l’estimation et l’interprétation d’un modèle.\nUne erreur fréquente est de confondre multicolinéarité et corrélation. Si des variables colinéaires sont de facto fortement corrélées entre elles, deux variables corrélées ne sont pas forcément colinéaires. En termes non statistiques, il y a colinéarité lorsque deux ou plusieurs variables mesurent la même chose.\nPrenons un exemple. Nous étudions les complications après l’accouchement dans différentes maternités d’un pays en développement. On souhaite mettre dans le modèle, à la fois le milieu de résidence (urbain ou rural) et le fait qu’il y ait ou non un médecin dans la clinique. Or, dans la zone d’enquête, les maternités rurales sont dirigées seulement par des sage-femmes tandis que l’on trouve un médecin dans toutes les maternités urbaines sauf une. Dès lors, dans ce contexte précis, le milieu de résidence prédit presque totalement la présence d’un médecin et on se retrouve face à une multicolinéarité (qui serait même parfaite s’il n’y avait pas une clinique urbaine sans médecin). On ne peut donc distinguer l’effet de la présence d’un médecin de celui du milieu de résidence et il ne faut mettre qu’une seule de ces deux variables dans le modèle, sachant que du point de vue de l’interprétation elle capturera à la fois l’effet de la présence d’un médecin et celui du milieu de résidence.\nPar contre, si dans notre région d’étude, seule la moitié des maternités urbaines disposait d’un médecin, alors le milieu de résidence n’aurait pas été suffisant pour prédire la présence d’un médecin. Certes, les deux variables seraient corrélées mais pas colinéaires. Un autre exemple de corrélation sans colinéarité, c’est la relation entre milieu de résidence et niveau d’instruction. Il y a une corrélation entre ces deux variables, les personnes résidant en ville étant généralement plus instruites. Cependant, il existe également des personnes non instruites en ville et des personnes instruites en milieu rural. Le milieu de résidence n’est donc pas suffisant pour prédire le niveau d’instruction.",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Multicolinéarité</span>"
    ]
  },
  {
    "objectID": "analyses/multicolinearite.html#mesure-de-la-colinéarité",
    "href": "analyses/multicolinearite.html#mesure-de-la-colinéarité",
    "title": "27  Multicolinéarité",
    "section": "\n27.2 Mesure de la colinéarité",
    "text": "27.2 Mesure de la colinéarité\nIl existe différentes mesures de la multicolinéarité. L’extension {mctest} en fournie plusieurs, mais elle n’est utilisable que si l’ensemble des variables explicatives sont de type numérique.\nL’approche la plus classique consiste à examiner les facteurs d’inflation de la variance (FIV) ou variance inflation factor (VIF) en anglais. Les FIV estiment de combien la variance d’un coefficient est augmentée en raison d’une relation linéaire avec d’autres prédicteurs. Ainsi, un FIV de 1,8 nous dit que la variance de ce coefficient particulier est supérieure de 80 % à la variance que l’on aurait dû observer si ce facteur n’est absolument pas corrélé aux autres prédicteurs.\nSi tous les FIV sont égaux à 1, il n’existe pas de multicolinéarité, mais si certains FIV sont supérieurs à 1, les prédicteurs sont corrélés. Il n’y a pas de consensus sur la valeur au-delà de laquelle on doit considérer qu’il y a multicolinéarité. Certains auteurs, comme Paul Allison1, disent de regarder plus en détail les variables avec un FIV supérieur à 2,5. D’autres ne s’inquiètent qu’à partir de 5. Il n’existe pas de test statistique qui permettrait de dire s’il y a colinéarité ou non2.\n1 When Can You Safely Ignore Multicollinearity?2 Pour plus de détails, voir ce post de Davig Giles, Can You Actually TEST for Multicollinearity?, qui explique pourquoi ce n’est pas possible.L’extension car fournit une fonction car::vif() permettant de calculer les FIV à partir d’un modèle. Elle implémente même une version généralisée permettant de considérer des facteurs catégoriels et des modèles linéaires généralisés comme la régression logistique.\nReprenons, pour exemple, un modèle logistique que nous avons déjà abordé dans d’autres chapitres.\n\nlibrary(tidyverse)\nlibrary(labelled)\n\ndata(hdv2003, package = \"questionr\")\n\nd &lt;-\n  hdv2003 |&gt; \n  mutate(\n    sexe = sexe |&gt; fct_relevel(\"Femme\"),\n    groupe_ages = age |&gt;\n      cut(\n        c(18, 25, 45, 65, 99),\n        right = FALSE,\n        include.lowest = TRUE,\n        labels = c(\"18-24 ans\", \"25-44 ans\",\n                   \"45-64 ans\", \"65 ans et plus\")\n      ),\n    etudes = nivetud |&gt; \n      fct_recode(\n        \"Primaire\" = \"N'a jamais fait d'etudes\",\n        \"Primaire\" = \"A arrete ses etudes, avant la derniere annee d'etudes primaires\",\n        \"Primaire\" = \"Derniere annee d'etudes primaires\",\n        \"Secondaire\" = \"1er cycle\",\n        \"Secondaire\" = \"2eme cycle\",\n        \"Technique / Professionnel\" = \"Enseignement technique ou professionnel court\",\n        \"Technique / Professionnel\" = \"Enseignement technique ou professionnel long\",\n        \"Supérieur\" = \"Enseignement superieur y compris technique superieur\"\n    ) |&gt; \n    fct_na_value_to_level(\"Non documenté\")  \n  ) |&gt; \n  set_variable_labels(\n    sport = \"Pratique un sport ?\",\n    sexe = \"Sexe\",\n    groupe_ages = \"Groupe d'âges\",\n    etudes = \"Niveau d'études\",\n    heures.tv = \"Heures de télévision / jour\"\n  )\n\nmod &lt;- glm(\n  sport ~ sexe + groupe_ages + etudes + heures.tv,\n  family = binomial,\n  data = d\n)\n\nLe calcul des FIV se fait simplement en passant le modèle à la fonction car::vif().\n\nmod |&gt; car::vif()\n\n                GVIF Df GVIF^(1/(2*Df))\nsexe        1.024640  1        1.012245\ngroupe_ages 1.745492  3        1.097285\netudes      1.811370  4        1.077087\nheures.tv   1.057819  1        1.028503\n\n\nDans notre exemple, tous les FIV sont proches de 1. Il n’y a donc pas de problème potentiel de colinéarité à explorer.\nPour un tableau propre, nous pouvons aussi utiliser gtsummary::add_vif().\n\nlibrary(gtsummary)\ntheme_gtsummary_language(\n  \"fr\",\n  decimal.mark = \",\",\n  big.mark = \" \"\n)\n\n\nmod |&gt; \n  tbl_regression(exponentiate = TRUE) |&gt; \n  bold_labels() |&gt; \n  add_vif()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nOR\n1\n\n\n95% IC\n1\n\np-valeur\n\nGVIF\n1\n\n\nAdjusted GVIF\n2,1\n\n\n\n\nSexe\n\n\n\n1,0\n1,0\n\n\n    Femme\n—\n—\n\n\n\n\n\n    Homme\n1,52\n1,24 – 1,87\n&lt;0,001\n\n\n\n\nGroupe d'âges\n\n\n\n1,7\n1,1\n\n\n    18-24 ans\n—\n—\n\n\n\n\n\n    25-44 ans\n0,68\n0,43 – 1,06\n0,084\n\n\n\n\n    45-64 ans\n0,36\n0,23 – 0,57\n&lt;0,001\n\n\n\n\n    65 ans et plus\n0,27\n0,16 – 0,46\n&lt;0,001\n\n\n\n\nNiveau d'études\n\n\n\n1,8\n1,1\n\n\n    Primaire\n—\n—\n\n\n\n\n\n    Secondaire\n2,54\n1,73 – 3,75\n&lt;0,001\n\n\n\n\n    Technique / Professionnel\n2,81\n1,95 – 4,10\n&lt;0,001\n\n\n\n\n    Supérieur\n6,55\n4,50 – 9,66\n&lt;0,001\n\n\n\n\n    Non documenté\n8,54\n4,51 – 16,5\n&lt;0,001\n\n\n\n\nHeures de télévision / jour\n0,89\n0,83 – 0,95\n&lt;0,001\n1,1\n1,0\n\n\n\n\n\n1\nOR = rapport de cotes, IC = intervalle de confiance, GVIF = Generalized Variance Inflation Factor\n\n\n\n\n2\nGVIF3\n\n\n\n\n3 1/(2*df)\n\n\n\n\nTable 27.1: Résumé du modèle logistique simple avec affichage des VIF généralisés\n\n\n\nLe package performance propose quant à lui une fonction performance::check_collinearity() pour le calcul des FIV et de leur intervalle de confiance.\n\nmod |&gt; performance::check_collinearity()\n\n# Check for Multicollinearity\n\nLow Correlation\n\n        Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n        sexe 1.02 [1.00, 1.16]         1.01      0.98     [0.86, 1.00]\n groupe_ages 1.75 [1.64, 1.86]         1.32      0.57     [0.54, 0.61]\n      etudes 1.81 [1.70, 1.93]         1.35      0.55     [0.52, 0.59]\n   heures.tv 1.06 [1.02, 1.13]         1.03      0.95     [0.88, 0.98]\n\n\nLes variables avec un FIV entre 5 et 10 sont présentées comme ayant une corrélation moyenne et celles avec un FIV de 10 ou plus une corrélation forte. Prenons un autre exemple.\n\nmod2 &lt;- lm(mpg ~ wt + am + gear + vs * cyl, data = mtcars)\nmc &lt;- mod2 |&gt; performance::check_collinearity()\n\nModel has interaction terms. VIFs might be inflated.\n  You may check multicollinearity among predictors of a model without\n  interaction terms.\n\nmc\n\n# Check for Multicollinearity\n\nLow Correlation\n\n Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n   wt 3.64 [ 2.46,  5.77]         1.91      0.27     [0.17, 0.41]\n   am 4.32 [ 2.88,  6.89]         2.08      0.23     [0.15, 0.35]\n gear 3.06 [ 2.11,  4.82]         1.75      0.33     [0.21, 0.47]\n\nModerate Correlation\n\n Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n  cyl 7.87 [ 5.03, 12.70]         2.80      0.13     [0.08, 0.20]\n\nHigh Correlation\n\n   Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n     vs 38.55 [23.69, 63.15]         6.21      0.03     [0.02, 0.04]\n vs:cyl 25.79 [15.93, 42.16]         5.08      0.04     [0.02, 0.06]\n\n\nUne représentation graphique des FIV peut être obtenue avec plot() appliquée au résultat de performance::check_collinearity().\n\nplot(mc)\n\nVariable `Component` is not in your data frame :/\n\n\n\n\n\n\n\nFigure 27.1: Représentation graphique des FIV d’un modèle\n\n\n\n\nLa fonction performance::print_md() peut être utilisée quant à elle pour une sortie des résultats dans un rapport markdown.\n\nmc |&gt; performance::print_md()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTerm\nVIF\nVIF_CI_low\nVIF_CI_high\nSE_factor\nTolerance\nTolerance_CI_low\nTolerance_CI_high\n\n\n\nwt\n3.64\n2.46\n5.77\n1.91\n0.27\n0.17\n0.41\n\n\nam\n4.32\n2.88\n6.89\n2.08\n0.23\n0.15\n0.35\n\n\ngear\n3.06\n2.11\n4.82\n1.75\n0.33\n0.21\n0.47\n\n\nvs\n38.55\n23.69\n63.15\n6.21\n0.03\n0.02\n0.04\n\n\ncyl\n7.87\n5.03\n12.70\n2.80\n0.13\n0.08\n0.20\n\n\nvs:cyl\n25.79\n15.93\n42.16\n5.08\n0.04\n0.02\n0.06\n\n\n\n\n\n\nTable 27.2: Table des FIV d’un modèle",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Multicolinéarité</span>"
    ]
  },
  {
    "objectID": "analyses/multicolinearite.html#la-multicolinéarité-est-elle-toujours-un-problème",
    "href": "analyses/multicolinearite.html#la-multicolinéarité-est-elle-toujours-un-problème",
    "title": "27  Multicolinéarité",
    "section": "\n27.3 La multicolinéarité est-elle toujours un problème ?",
    "text": "27.3 La multicolinéarité est-elle toujours un problème ?\nLà encore, il n’y a pas de consensus sur cette question. Certains analystes considèrent que tout modèle où certains prédicteurs seraient colinéaires n’est pas valable. Dans le billet When Can You Safely Ignore Multicollinearity?, Paul Allison évoque quant à lui des situations où la multicolinéarité peut être ignorée en toute sécurité. Le texte ci-dessous est une traduction de ce billet.\n1. Les variables avec des FIV élevés sont des variables de contrôle, et les variables d’intérêt n’ont pas de FIV élevés.\nVoici le problème de la multicolinéarité : ce n’est un problème que pour les variables qui sont colinéaires. Il augmente les erreurs-types de leurs coefficients et peut rendre ces coefficients instables de plusieurs façons. Mais tant que les variables colinéaires ne sont utilisées que comme variables de contrôle, et qu’elles ne sont pas colinéaires avec vos variables d’intérêt, il n’y a pas de problème. Les coefficients des variables d’intérêt ne sont pas affectés et la performance des variables de contrôle n’est pas altérée.\nVoici un exemple tiré de ces propres travaux : l’échantillon est constitué de collèges américains, la variable dépendante est le taux d’obtention de diplôme et la variable d’intérêt est un indicateur (factice) pour les secteurs public et privé. Deux variables de contrôle sont les scores moyens au SAT et les scores moyens à l’ACT pour l’entrée en première année. Ces deux variables ont une corrélation supérieure à ,9, ce qui correspond à des FIV d’au moins 5,26 pour chacune d’entre elles. Mais le FIV pour l’indicateur public/privé n’est que de 1,04. Il n’y a donc pas de problème à se préoccuper et il n’est pas nécessaire de supprimer l’un ou l’autre des deux contrôles, à condition que l’on ne cherche pas à interpréter ou comparer l’un par rapport à l’autre les coefficients de ces deux variables de contrôle.\n2. Les FIV élevés sont causés par l’inclusion de puissances ou de produits d’autres variables.\nSi vous spécifiez un modèle de régression avec x et x2, il y a de bonnes chances que ces deux variables soient fortement corrélées. De même, si votre modèle a x, z et xz, x et z sont susceptibles d’être fortement corrélés avec leur produit. Il n’y a pas de quoi s’inquiéter, car la valeur p de xz n’est pas affectée par la multicolinéarité. Ceci est facile à démontrer : vous pouvez réduire considérablement les corrélations en centrant les variables (c’est-à-dire en soustrayant leurs moyennes) avant de créer les puissances ou les produits. Mais la valeur p pour x2 ou pour xz sera exactement la même, que l’on centre ou non. Et tous les résultats pour les autres variables (y compris le R2 mais sans les termes d’ordre inférieur) seront les mêmes dans les deux cas. La multicolinéarité n’a donc pas de conséquences négatives.\n3. Les variables avec des FIV élevés sont des variables indicatrices (factices) qui représentent une variable catégorielle avec trois catégories ou plus.\nSi la proportion de cas dans la catégorie de référence est faible, les variables indicatrices auront nécessairement des FIV élevés, même si la variable catégorielle n’est pas associée à d’autres variables dans le modèle de régression.\nSupposons, par exemple, qu’une variable de l’état matrimonial comporte trois catégories : actuellement marié, jamais marié et anciennement marié. Vous choisissez anciennement marié comme catégorie de référence, avec des variables d’indicateur pour les deux autres. Ce qui se passe, c’est que la corrélation entre ces deux indicateurs devient plus négative à mesure que la fraction de personnes dans la catégorie de référence diminue. Par exemple, si 45 % des personnes ne sont jamais mariées, 45 % sont mariées et 10 % sont anciennement mariées, les valeurs du FIV pour les personnes mariées et les personnes jamais mariées seront d’au moins 3,0.\nEst-ce un problème ? Eh bien, cela signifie que les valeurs p des variables indicatrices peuvent être élevées. Mais le test global selon lequel tous les indicateurs ont des coefficients de zéro n’est pas affecté par des FIV élevés. Et rien d’autre dans la régression n’est affecté. Si vous voulez vraiment éviter des FIV élevés, il suffit de choisir une catégorie de référence avec une plus grande fraction des cas. Cela peut être souhaitable pour éviter les situations où aucun des indicateurs individuels n’est statistiquement significatif, même si l’ensemble des indicateurs est significatif.",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Multicolinéarité</span>"
    ]
  },
  {
    "objectID": "analyses/multicolinearite.html#webin-r",
    "href": "analyses/multicolinearite.html#webin-r",
    "title": "27  Multicolinéarité",
    "section": "\n27.4 webin-R",
    "text": "27.4 webin-R\nLa multicolinéarité est abordée dans le webin-R #07 (régression logistique partie 2) sur YouTube.\n\n\n\n\nFigure 27.1: Représentation graphique des FIV d’un modèle",
    "crumbs": [
      "**Analyses**",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Multicolinéarité</span>"
    ]
  },
  {
    "objectID": "donnees_ponderees/plan-echantillonnage.html",
    "href": "donnees_ponderees/plan-echantillonnage.html",
    "title": "28  Définir un plan d’échantillonnage",
    "section": "",
    "text": "28.1 Différents types d’échantillonnage\nL’échantillonnage aléatoire simple ou échantillonnage équiprobable est une méthode pour laquelle tous les échantillons possibles (de même taille) ont la même probabilité d’être choisis et tous les éléments de la population ont une chance égale de faire partie de l’échantillon. C’est l’échantillonnage le plus simple : chaque individu à la même probabilité d’être sélectionné.\nL’échantillonnage stratifié est une méthode qui consiste d’abord à subdiviser la population en groupes homogènes (strates) pour ensuite extraire un échantillon aléatoire de chaque strate. Cette méthode suppose une connaissance de la structure de la population. Pour estimer les paramètres, les résultats doivent être pondérés par l’importance relative de chaque strate dans la population.\nL’échantillonnage par grappes est une méthode qui consiste à choisir un échantillon aléatoire d’unités qui sont elles-mêmes des sous-ensembles de la population (grappes ou clusters en anglais). Cette méthode suppose que les unités de chaque grappe sont représentatives. Elle possède l’avantage d’être souvent plus économique.\nIl est possible de combiner plusieurs de ces approches. Par exemple, les Enquêtes Démographiques et de Santé1 (EDS) sont des enquêtes stratifiées en grappes à deux degrés. Dans un premier temps, la population est divisée en strates par région et milieu de résidence. Dans chaque strate, des zones d’enquêtes, correspondant à des unités de recensement, sont tirées au sort avec une probabilité proportionnelle au nombre de ménages de chaque zone au dernier recensement de population. Enfin, au sein de chaque zone d’enquête sélectionnée, un recensement de l’ensemble des ménages est effectué puis un nombre identique de ménages par zone d’enquête est tiré au sort de manière aléatoire simple.",
    "crumbs": [
      "**Données pondérées avec `survey`**",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Définir un plan d'échantillonnage</span>"
    ]
  },
  {
    "objectID": "donnees_ponderees/plan-echantillonnage.html#différents-types-déchantillonnage",
    "href": "donnees_ponderees/plan-echantillonnage.html#différents-types-déchantillonnage",
    "title": "28  Définir un plan d’échantillonnage",
    "section": "",
    "text": "1 Vaste programme d’enquêtes réalisées à intervalles réguliers dans les pays à faible et moyen revenu, disponibles sur https://dhsprogram.com/.",
    "crumbs": [
      "**Données pondérées avec `survey`**",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Définir un plan d'échantillonnage</span>"
    ]
  },
  {
    "objectID": "donnees_ponderees/plan-echantillonnage.html#avec-surveysvydesign",
    "href": "donnees_ponderees/plan-echantillonnage.html#avec-surveysvydesign",
    "title": "28  Définir un plan d’échantillonnage",
    "section": "\n28.2 Avec survey::svydesign()\n",
    "text": "28.2 Avec survey::svydesign()\n\nLa fonction survey::svydesign() accepte plusieurs arguments décrits en détail sur sa page d’aide (obtenue avec la commande ?svydesign).\nL’argument data permet de spécifier le tableau de données contenant les observations.\nL’argument ids est obligatoire et spécifie sous la forme d’une formule les identifiants des différents niveaux d’un tirage en grappe. S’il s’agit d’un échantillon aléatoire simple, on entrera ids = ~ 1. Autre situation : supposons une étude portant sur la population française. Dans un premier temps, on a tiré au sort un certain nombre de départements français. Dans un second temps, on tire au sort dans chaque département des communes. Dans chaque commune sélectionnée, on tire au sort des quartiers. Enfin, on interroge de manière exhaustive toutes les personnes habitant les quartiers enquêtés. Notre fichier de données devra donc comporter pour chaque observation les variables id_departement, id_commune et id_quartier. On écrira alors pour l’argument ids la valeur suivante :ids = ~ id_departement + id_commune + id_quartier.\nSi l’échantillon est stratifié, on spécifiera les strates à l’aide de l’argument strata en spécifiant la variable contenant l’identifiant des strates. Par exemple : strata = ~ id_strate.\nIl faut encore spécifier les probabilités de tirage de chaque cluster /grappe ou bien la pondération des individus. Si l’on dispose de la probabilité de chaque observation d’être sélectionnée, on utilisera l’argument probs. Si, par contre, on connaît la pondération de chaque observation (qui doit être proportionnelle à l’inverse de cette probabilité), on utilisera l’argument weights.\nSi l’échantillon est stratifié, qu’au sein de chaque strate les individus ont été tirés au sort de manière aléatoire et que l’on connaît la taille de chaque strate, il est possible de ne pas avoir à spécifier la probabilité de tirage ou la pondération de chaque observation. Il est préférable de fournir une variable contenant la taille de chaque strate à l’argument fpc. De plus, dans ce cas-là, une petite correction sera appliquée au modèle pour prendre en compte la taille finie de chaque strate.\nOn peut tout à fait définir un échantillonnage aléatoire simple (on considère donc que toutes les observations ont le même poids, égal à 1). Pour rappel, en l’absence de clusters/grappes, il faut préciser ids = ~ 1, ce paramètre n’ayant pas de valeur par défaut.\n\np_iris &lt;- survey::svydesign(\n  ids = ~ 1, \n  data = iris\n)\n\nWarning in svydesign.default(ids = ~1, data = iris): No weights or\nprobabilities supplied, assuming equal probability\n\np_iris\n\nIndependent Sampling design (with replacement)\nsurvey::svydesign(ids = ~1, data = iris)\n\n\nPour un jeu de données simplement pondéré (chaque ligne représente plusieurs observations) :\n\ntitanic &lt;- dplyr::as_tibble(Titanic)\ntitanic |&gt; labelled::look_for()\n\n pos variable label col_type missing values\n 1   Class    —     chr      0             \n 2   Sex      —     chr      0             \n 3   Age      —     chr      0             \n 4   Survived —     chr      0             \n 5   n        —     dbl      0             \n\np_titanic &lt;- survey::svydesign(\n  ids = ~ 1, \n  data = titanic, \n  weights = ~ n\n)\np_titanic\n\nIndependent Sampling design (with replacement)\nsurvey::svydesign(ids = ~1, data = titanic, weights = ~n)\n\n\nPour un échantillon stratifié pour lequel les strates sont indiquées dans la variable stype et les poids indiquées dans la variable pw.\n\ndata(\"api\", package = \"survey\")\np_strates &lt;- survey::svydesign(\n  id = ~ 1, \n  strata = ~ stype, \n  weights = ~ pw, \n  data = apistrat\n)\np_strates\n\nStratified Independent Sampling design (with replacement)\nsurvey::svydesign(id = ~1, strata = ~stype, weights = ~pw, data = apistrat)\n\n\nPour une enquête en grappes à 1 degré, pour laquelle l’identifiant des grappes (clusters) est indiqué par la variable dnum.\n\ndata(\"api\", package = \"survey\")\np_grappes &lt;- survey::svydesign(\n  id = ~ dnum, \n  weights = ~ pw, \n  data = apiclus1\n)\np_grappes\n\n1 - level Cluster Sampling design (with replacement)\nWith (15) clusters.\nsurvey::svydesign(id = ~dnum, weights = ~pw, data = apiclus1)\n\n\nVoici un exemple un peu plus complexe d’une enquête en grappes à deux degrés (les deux niveaux étant donnés par les variables dnum et snum). Les poids ne sont pas fournis mais la taille des grappes est connue et renseignée dans les variables fpc1 et fpc2 que nous pourrons donc transmettre via l’argument fpc.\n\ndata(\"api\", package = \"survey\")\np_grappes2 &lt;- survey::svydesign(\n  id = ~ dnum + snum,\n  fpc = ~ fpc1 + fpc2,\n  data = apiclus2\n)\np_grappes2\n\n2 - level Cluster Sampling design\nWith (40, 126) clusters.\nsurvey::svydesign(id = ~dnum + snum, fpc = ~fpc1 + fpc2, data = apiclus2)\n\n\nDans le cas présent, survey a calculé les poids s’appliquant à chaque individu. On peut les obtenir avec la fonction weights(), en l’occurrence avec p_grappes2 |&gt; weights().\nEnfin, prenons l’exemple d’une Enquête Démographique et de Santé. Le nom des différentes variables est standardisé et commun quelle que soit l’enquête. Nous supposerons que vous avez importé le fichier individus dans un tableau de données nommés eds. Le poids statistique de chaque individu est fourni par la variable V005 qui doit au préalable être divisée par un million. Les grappes d’échantillonnage au premier degré sont fournies par la variable V021 (primary sample unit). Si elle n’est pas renseignée, on pourra utiliser le numéro de grappe V001. Enfin, le milieu de résidence (urbain / rural) est fourni par V025 et la région par V024. Pour rappel, l’échantillon a été stratifié à la fois par région et par milieu de résidence. Certaines enquêtes fournissent directement un numéro de strate via V022. Si tel est le cas, on pourra préciser le plan d’échantillonnage ainsi :\n\neds$poids &lt;- eds$V005/1000000\np_eds &lt;- survey::svydesign(\n  ids = ~ V021, \n  data = eds, \n  strata = ~ V022, \n  weights = ~ poids\n)",
    "crumbs": [
      "**Données pondérées avec `survey`**",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Définir un plan d'échantillonnage</span>"
    ]
  },
  {
    "objectID": "donnees_ponderees/plan-echantillonnage.html#avec-srvyras_survey_design",
    "href": "donnees_ponderees/plan-echantillonnage.html#avec-srvyras_survey_design",
    "title": "28  Définir un plan d’échantillonnage",
    "section": "\n28.3 Avec srvyr::as_survey_design()\n",
    "text": "28.3 Avec srvyr::as_survey_design()\n\nDans le prochain chapitre (cf. Chapitre 29), nous aborderons le package srvyr qui est aux objets survey ce que dplyr est aux tableaux de données : plus précisément, ce package étend les verbes de dplyr aux plans d’échantillonnage complexe.\nLa fonction srvyr::as_survey_design() est équivalente à survey::svydesign() mais avec quelques différences :\n\nle paramètre ids dispose d’une valeur par défaut et on peut l’ignorer en l’absence de grappes ;\nles variables ne sont pas spécifiées avec une formule mais avec les mêmes sélecteurs que dplyr::select() ;\nl’objet renvoyé est à la fois du type \"survey.design\" et du type \"tbl_svy\", une sorte de tibble pour les objets survey.\n\nReprenons nos exemples précédents en commençant par un échantillonnage aléatoire simple.\n\nt_iris &lt;- iris |&gt; \n  srvyr::as_survey_design()\nt_iris\n\nIndependent Sampling design (with replacement)\nCalled via srvyr\nSampling variables:\n  - ids: `1` \nData variables: \n  - Sepal.Length (dbl), Sepal.Width (dbl), Petal.Length (dbl), Petal.Width\n    (dbl), Species (fct)\n\nclass(t_iris)\n\n[1] \"tbl_svy\"        \"survey.design2\" \"survey.design\" \n\n\nPour un jeu de données simplement pondéré (chaque ligne représente plusieurs observations) :\n\ntitanic &lt;- dplyr::as_tibble(Titanic)\nt_titanic &lt;- titanic |&gt; \n  srvyr::as_survey_design(weights = n)\nt_titanic\n\nIndependent Sampling design (with replacement)\nCalled via srvyr\nSampling variables:\n  - ids: `1` \n  - weights: n \nData variables: \n  - Class (chr), Sex (chr), Age (chr), Survived (chr), n (dbl)\n\n\nPour un échantillon stratifié pour lequel les strates sont indiquées dans la variable stype et les poids indiquées dans la variable pw.\n\ndata(\"api\", package = \"survey\")\nt_strates &lt;- apistrat |&gt; \n  srvyr::as_survey_design(strata = stype, weights = pw)\nt_strates\n\nStratified Independent Sampling design (with replacement)\nCalled via srvyr\nSampling variables:\n  - ids: `1` \n  - strata: stype \n  - weights: pw \nData variables: \n  - cds (chr), stype (fct), name (chr), sname (chr), snum (dbl), dname (chr),\n    dnum (int), cname (chr), cnum (int), flag (int), pcttest (int), api00\n    (int), api99 (int), target (int), growth (int), sch.wide (fct), comp.imp\n    (fct), both (fct), awards (fct), meals (int), ell (int), yr.rnd (fct),\n    mobility (int), acs.k3 (int), acs.46 (int), acs.core (int), pct.resp (int),\n    not.hsg (int), hsg (int), some.col (int), col.grad (int), grad.sch (int),\n    avg.ed (dbl), full (int), emer (int), enroll (int), api.stu (int), pw\n    (dbl), fpc (dbl)\n\n\nPour une enquête en grappes à 1 degré, pour laquelle l’identifiant des grappes (clusters) est indiqué par la variable dnum.\n\ndata(\"api\", package = \"survey\")\nt_grappes &lt;- apiclus1 |&gt; \n    srvyr::as_survey_design(id = dnum, weights = pw)\nt_grappes\n\n1 - level Cluster Sampling design (with replacement)\nWith (15) clusters.\nCalled via srvyr\nSampling variables:\n  - ids: dnum \n  - weights: pw \nData variables: \n  - cds (chr), stype (fct), name (chr), sname (chr), snum (dbl), dname (chr),\n    dnum (int), cname (chr), cnum (int), flag (int), pcttest (int), api00\n    (int), api99 (int), target (int), growth (int), sch.wide (fct), comp.imp\n    (fct), both (fct), awards (fct), meals (int), ell (int), yr.rnd (fct),\n    mobility (int), acs.k3 (int), acs.46 (int), acs.core (int), pct.resp (int),\n    not.hsg (int), hsg (int), some.col (int), col.grad (int), grad.sch (int),\n    avg.ed (dbl), full (int), emer (int), enroll (int), api.stu (int), fpc\n    (dbl), pw (dbl)\n\n\nVoici un exemple un peu plus complexe d’une enquête en grappes à deux degrés (les deux niveaux étant donnés par les variables dnum et snum). Les poids ne sont pas fournis mais la taille des grappes est connue et renseignée dans les variables fpc1 et fpc2 que nous pourrons donc transmettre via l’argument fpc.\n\ndata(\"api\", package = \"survey\")\ndata(\"api\", package = \"survey\")\nt_grappes2 &lt;- apiclus2 |&gt; \n    srvyr::as_survey_design(id = c(dnum, snum), fpc = c(fpc1, fpc2))\nt_grappes2\n\n2 - level Cluster Sampling design\nWith (40, 126) clusters.\nCalled via srvyr\nSampling variables:\n  - ids: `dnum + snum` \n  - fpc: `fpc1 + fpc2` \nData variables: \n  - cds (chr), stype (fct), name (chr), sname (chr), snum (dbl), dname (chr),\n    dnum (int), cname (chr), cnum (int), flag (int), pcttest (int), api00\n    (int), api99 (int), target (int), growth (int), sch.wide (fct), comp.imp\n    (fct), both (fct), awards (fct), meals (int), ell (int), yr.rnd (fct),\n    mobility (int), acs.k3 (int), acs.46 (int), acs.core (int), pct.resp (int),\n    not.hsg (int), hsg (int), some.col (int), col.grad (int), grad.sch (int),\n    avg.ed (dbl), full (int), emer (int), enroll (int), api.stu (int), pw\n    (dbl), fpc1 (dbl), fpc2 (int[1d])\n\n\nEnfin, prenons l’exemple d’une Enquête Démographique et de Santé. Le nom des différentes variables est standardisé et commun quelle que soit l’enquête. Nous supposerons que vous avez importé le fichier individus dans un tableau de données nommés eds. Le poids statistique de chaque individu est fourni par la variable V005 qui doit au préalable être divisée par un million. Les grappes d’échantillonnage au premier degré sont fournies par la variable V021 (primary sample unit). Si elle n’est pas renseignée, on pourra utiliser le numéro de grappe V001. Enfin, le milieu de résidence (urbain / rural) est fourni par V025 et la région par V024. Pour rappel, l’échantillon a été stratifié à la fois par région et par milieu de résidence. Certaines enquêtes fournissent directement un numéro de strate via V022. Si tel est le cas, on pourra préciser le plan d’échantillonnage ainsi :\n\neds$poids &lt;- eds$V005/1000000\nt_eds &lt;- eds |&gt; \n  srvyr::as_survey_design(\n    ids = V021,\n    strata = V022,\n    weights = poids\n  )",
    "crumbs": [
      "**Données pondérées avec `survey`**",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Définir un plan d'échantillonnage</span>"
    ]
  },
  {
    "objectID": "donnees_ponderees/plan-echantillonnage.html#webin-r",
    "href": "donnees_ponderees/plan-echantillonnage.html#webin-r",
    "title": "28  Définir un plan d’échantillonnage",
    "section": "\n28.4 webin-R",
    "text": "28.4 webin-R\nLa statistique univariée est présentée dans le webin-R #10 (données pondérées, plan d’échantillonnage complexe & survey) sur YouTube.",
    "crumbs": [
      "**Données pondérées avec `survey`**",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Définir un plan d'échantillonnage</span>"
    ]
  },
  {
    "objectID": "donnees_ponderees/manipulation.html",
    "href": "donnees_ponderees/manipulation.html",
    "title": "29  Manipulation de données pondérées",
    "section": "",
    "text": "29.1 Utilisation de {srvyr}\nsrvyr fournit les verbes srvyr::select() et srvyr::filter() pour sélectionner respectivement des colonnes et des lignes.\nlibrary(srvyr)\n\n\nAttachement du package : 'srvyr'\n\n\nL'objet suivant est masqué depuis 'package:stats':\n\n    filter\n\nt_titanic |&gt; select(Sex, Age)\n\nIndependent Sampling design (with replacement)\nCalled via srvyr\nSampling variables:\n  - ids: `1` \n  - weights: n \nData variables: \n  - Sex (chr), Age (chr)\n\nt_titanic |&gt; filter(Sex == \"Female\")\n\nIndependent Sampling design (with replacement)\nCalled via srvyr\nSampling variables:\n  - ids: `1` \n  - weights: n \nData variables: \n  - Class (chr), Sex (chr), Age (chr), Survived (chr), n (dbl)\nOn peut aussi utiliser srvyr::pull() pour extraire le contenu d’une colonne ou srvyr::drop_na() pour supprimer les observations contenant des valeurs manquantes.\nsrvyr fournit également le verbe srvyr::summarize() permettant de calculer des statistiques sur l’ensemble du fichier ou par sous-groupe (en combinant summarize() avec group_by()). Afin de prendre en compte correctement la pondération et le plan d’échantillonnage, srvyr fournit des fonctions adaptées pour un usage au sein de summarize() : srvyr::survey_mean(), srvyr::survey_total(), srvyr::survey_prop(), srvyr::survey_ratio(), srvyr::survey_quantile() ou encore srvyr::survey_median().\nt_titanic |&gt; \n  group_by(Sex, Class, Survived) |&gt; \n  summarise(taux_survie = survey_prop()) |&gt; \n  filter(Survived == \"Yes\")\n\nWhen `proportion` is unspecified, `survey_prop()` now defaults to `proportion = TRUE`.\nℹ This should improve confidence interval coverage.\nThis message is displayed once per session.\n\n\nWarning: There were 24 warnings in `dplyr::summarise()`.\nThe first warning was:\nℹ In argument: `taux_survie = survey_prop()`.\nℹ In group 1: `Sex = \"Female\"`, `Class = \"1st\"`, `Survived = \"No\"`.\nCaused by warning in `summary.glm()`:\n! les observations de poids nul n'ont pas été utilisées pour le calcul de la dispersion\nℹ Run `dplyr::last_dplyr_warnings()` to see the 23 remaining warnings.\n\n\n# A tibble: 8 × 5\n# Groups:   Sex, Class [8]\n  Sex    Class Survived taux_survie taux_survie_se\n  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt;          &lt;dbl&gt;\n1 Female 1st   Yes            0.972         0.0384\n2 Female 2nd   Yes            0.877         0.145 \n3 Female 3rd   Yes            0.459         0.306 \n4 Female Crew  Yes            0.870         0.163 \n5 Male   1st   Yes            0.344         0.312 \n6 Male   2nd   Yes            0.140         0.150 \n7 Male   3rd   Yes            0.173         0.183 \n8 Male   Crew  Yes            0.223         0.249",
    "crumbs": [
      "**Données pondérées avec `survey`**",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Manipulation de données pondérées</span>"
    ]
  },
  {
    "objectID": "donnees_ponderees/manipulation.html#utilisation-de-srvyr",
    "href": "donnees_ponderees/manipulation.html#utilisation-de-srvyr",
    "title": "29  Manipulation de données pondérées",
    "section": "",
    "text": "Avertissement\n\n\n\nPar contre, le verbe arrange() (tri du tableau) ou encore les fonctions de jointures (telles que left_join()) ne sont pas implémentées car ce type d’opération entraînerait des modifications du plan d’échantillonnage. Il est donc préférable de réaliser ce type d’opérations avant la déclaration du plan d’échantillonnage (quand les données sont donc encore stockées dans un tableau de données classiques).",
    "crumbs": [
      "**Données pondérées avec `survey`**",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Manipulation de données pondérées</span>"
    ]
  },
  {
    "objectID": "donnees_ponderees/manipulation.html#lister-rechercher-des-variables",
    "href": "donnees_ponderees/manipulation.html#lister-rechercher-des-variables",
    "title": "29  Manipulation de données pondérées",
    "section": "\n29.2 Lister / Rechercher des variables",
    "text": "29.2 Lister / Rechercher des variables\nLa fonction labelled::look_for(), que nous avons déjà abordée (cf. Section 4.3), est compatible avec les objets survey et peut donc être utilisée pour lister ou rechercher des variables.\n\nt_titanic &lt;- titanic |&gt; \n  labelled::set_variable_labels(\n    Class = \"Class du passager\",\n    Sex = \"Sexe du passager\",\n    Age = \"Enfant ou adulte ?\",\n    Survived = \"A survécu au naufrage ?\",\n    n = \"Nombre d'observations\"\n  ) |&gt; \n  srvyr::as_survey_design(weights = n)\nt_titanic |&gt; labelled::look_for()\n\n pos variable label                   col_type missing values\n 1   Class    Class du passager       chr      0             \n 2   Sex      Sexe du passager        chr      0             \n 3   Age      Enfant ou adulte ?      chr      0             \n 4   Survived A survécu au naufrage ? chr      0             \n 5   n        Nombre d'observations   dbl      0             \n\nt_titanic |&gt; labelled::look_for(\"nau\")\n\n pos variable label                   col_type missing values\n 4   Survived A survécu au naufrage ? chr      0",
    "crumbs": [
      "**Données pondérées avec `survey`**",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Manipulation de données pondérées</span>"
    ]
  },
  {
    "objectID": "donnees_ponderees/manipulation.html#extraire-un-sous-échantillon",
    "href": "donnees_ponderees/manipulation.html#extraire-un-sous-échantillon",
    "title": "29  Manipulation de données pondérées",
    "section": "\n29.3 Extraire un sous-échantillon",
    "text": "29.3 Extraire un sous-échantillon\nSi l’on souhaite travailler sur un sous-échantillon de l’enquête, il importe de définir le plan d’échantillonnage sur l’ensemble du jeu de données avant de procéder à la sélection des observations.\nLa fonction classique pour sélectionner des lignes est subset(). Cependant, elle a un inconvénient lorsque nos données comportent des étiquettes de variables (cf. Chapitre 11) ou de valeurs ( Chapitre 12), car les étiquettes ne sont pas conservées après l’opération.\nOn préférera donc avoir recours à srvyr::filter() qui conservent les attributs associés aux colonnes du tableau de données.\n\nt_subset &lt;- t_titanic |&gt; subset(Sex == \"Female\")\nt_subset |&gt; labelled::look_for()\n\n pos variable label col_type missing values\n 1   Class    —     chr      0             \n 2   Sex      —     chr      0             \n 3   Age      —     chr      0             \n 4   Survived —     chr      0             \n 5   n        —     dbl      0             \n\nt_filter &lt;- t_titanic |&gt; filter(Sex == \"Female\")\nt_filter |&gt; labelled::look_for()\n\n pos variable label                   col_type missing values\n 1   Class    Class du passager       chr      0             \n 2   Sex      Sexe du passager        chr      0             \n 3   Age      Enfant ou adulte ?      chr      0             \n 4   Survived A survécu au naufrage ? chr      0             \n 5   n        Nombre d'observations   dbl      0",
    "crumbs": [
      "**Données pondérées avec `survey`**",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Manipulation de données pondérées</span>"
    ]
  },
  {
    "objectID": "donnees_ponderees/analyses-bivariees.html",
    "href": "donnees_ponderees/analyses-bivariees.html",
    "title": "30  Analyses uni- et bivariées pondérées",
    "section": "",
    "text": "30.1 La fonction tbl_svysummary()\nDans les chapitres sur la statistique univariée (cf. Chapitre 18) et la statistique bivariée (cf. Chapitre 19), nous avons abordé la fonction gtsummary::tbl_summary() qui permet de générer des tris à plats et des tableaux croisés prêts à être publiés.\nSon équivalent pour les objets survey existe : il s’agit de la fonction gtsummary::tbl_svysummary() qui fonctionne de manière similaire.\nPour illustrer son fonctionnement, nous allons utiliser le jeu de données fecondite fournit dans le package questionr. Ce jeu de données fournit un tableau de données femmes comportant une variable poids de pondération que nous allons utiliser. Les données catégorielles étant stockées sous forme de vecteurs numériques avec étiquettes de valeurs (cf. Chapitre 12), nous allons les convertir en facteurs avec labelled::unlabelled(). De même, certaines valeurs manquantes sont indiquées sous formes de user NAs (cf. Section 13.2) : nous allons les convertir en valeurs manquantes classiques (regular NAs) avec labelled::user_na_to_na().\ndata(\"fecondite\", package = \"questionr\")\nlibrary(srvyr)\n\n\nAttachement du package : 'srvyr'\n\n\nL'objet suivant est masqué depuis 'package:stats':\n\n    filter\n\ndp &lt;- femmes |&gt; \n  labelled::user_na_to_na() |&gt; \n  labelled::unlabelled() |&gt; \n  as_survey_design(weights = poids)\ndp\n\nIndependent Sampling design (with replacement)\nCalled via srvyr\nSampling variables:\n  - ids: `1` \n  - weights: poids \nData variables: \n  - id_femme (dbl), id_menage (dbl), poids (dbl), date_entretien (date),\n    date_naissance (date), age (dbl), milieu (fct), region (fct), educ (fct),\n    travail (fct), matri (fct), religion (fct), journal (fct), radio (fct), tv\n    (fct), nb_enf_ideal (dbl), test (fct)\nChargeons gtsummary et définissons le français comme langue de rendu des tableaux.\nlibrary(gtsummary)\ntheme_gtsummary_language(\n  language = \"fr\", \n  decimal.mark = \",\", \n  big.mark = \"\"\n)\n\nSetting theme \"language: fr\"\nPour réaliser un tableau croisé, il nous suffit d’appeler gtsummary::tbl_svysummary() de la même manière que l’on aurait procédé avec gtsummary::tbl_summary(). En arrière plan, gtsummary::tbl_svysummary() appellera les différentes fonctions statistiques de survey : la pondération ainsi que les spécificités du plan d’échantillonnage seront donc correctement prises en compte.\ndp |&gt; \n  tbl_svysummary(\n    by = milieu,\n    include = c(age, educ, travail)\n  ) |&gt; \n  add_overall(last = TRUE) |&gt; \n  bold_labels()\n\nWarning in svymean.survey.design2(data, design[byfactor %in% byfactor[i], :\nSample size greater than population size: are weights correctly scaled?\nWarning in svymean.survey.design2(data, design[byfactor %in% byfactor[i], :\nSample size greater than population size: are weights correctly scaled?\nWarning in svymean.survey.design2(data, design[byfactor %in% byfactor[i], :\nSample size greater than population size: are weights correctly scaled?\nWarning in svymean.survey.design2(data, design[byfactor %in% byfactor[i], :\nSample size greater than population size: are weights correctly scaled?\nWarning in svymean.survey.design2(data, design[byfactor %in% byfactor[i], :\nSample size greater than population size: are weights correctly scaled?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nurbain\nN = 1026\n1\n\n\nrural\nN = 1002\n1\n\n\nOverall\nN = 2027\n1\n\n\n\n\nÂge révolu (en années) à la date de passation du questionnaire\n26 (20 – 33)\n28 (22 – 36)\n27 (21 – 35)\n\n\nNiveau d'éducation\n\n\n\n\n\n    aucun\n414 (40%)\n681 (68%)\n1095 (54%)\n\n\n    primaire\n251 (24%)\n257 (26%)\n507 (25%)\n\n\n    secondaire\n303 (30%)\n61 (6,1%)\n364 (18%)\n\n\n    supérieur\n58 (5,7%)\n3 (0,3%)\n61 (3,0%)\n\n\nA un emploi ?\n\n\n\n\n\n    non\n401 (39%)\n269 (27%)\n670 (33%)\n\n\n    oui\n621 (61%)\n731 (73%)\n1351 (67%)\n\n\n    Manquant\n5\n1\n6\n\n\n\n\n1\nMédiane (Q1 – Q3); n (%)\n\n\n\n\n\n\n\n\nTable 30.1: Tableau croisé sur des données pondérées",
    "crumbs": [
      "**Données pondérées avec `survey`**",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Analyses uni- et bivariées pondérées</span>"
    ]
  },
  {
    "objectID": "donnees_ponderees/analyses-bivariees.html#la-fonction-tbl_svysummary",
    "href": "donnees_ponderees/analyses-bivariees.html#la-fonction-tbl_svysummary",
    "title": "30  Analyses uni- et bivariées pondérées",
    "section": "",
    "text": "Important\n\n\n\nPar défaut, les effectifs (ainsi que les pourcentages et autres statistiques) affichés sont pondérés. Il est important de bien comprendre ce que représentent ces effectifs pondérés pour les interpréter correctement. Pour cela, il faut savoir comment les poids de l’enquête ont été calculés.\nDans certains cas, lorsque la population totale est connue, la somme des poids est égale à cette population totale dans laquelle l’échantillon a été tiré au sort. Les effectifs pondérés représentent donc une estimation des effectifs dans la population totale et ne représentent en rien le nombre d’observations dans l’enquête.\nDans d’autres enquêtes, les poids sont générés de telle manière que la somme des poids correspondent au nombre total de personnes enquêtées. Dans ce genre de situation, on a souvent tendance, à tort, à interpréter les effectifs pondérés comme un nombre d’observations. Or, il peut y avoir un écart important entre le nombre d’observations dans l’enquête et les effectifs pondérés.\nOn pourra éventuellement présenter séparément le nombre d’observations (i.e. les effectifs non pondérés) et les proportions pondérées. gtsummary::tbl_svysummary() fournit justement à la fois ces données pondérées et non pondérées. Il est vrai que cela nécessite quand même quelques manipulations. Pour les cellules, on précisera le type d’effectifs à afficher avec l’argument statistic. Pour personnaliser l’affiche du nombre de valeurs manquantes, cela doit se faire à un niveau plus global via gtsummary::set_gtsummary_theme(). Enfin, on passera par gtsummary::modify_header() pour personnaliser les en-têtes de colonne.\n\nset_gtsummary_theme(\n  list(\"tbl_summary-str:missing_stat\" = \"{N_miss_unweighted} obs.\")\n)\ndp |&gt; \n  tbl_svysummary(\n    by = milieu,\n    include = c(educ, travail),\n    statistic = all_categorical() ~ \"{p}% ({n_unweighted} obs.)\",\n    digits = all_categorical() ~ c(1, 0)\n  ) |&gt; \n  modify_header(\n    all_stat_cols() ~ \"**{level}** ({n_unweighted} obs.)\"\n  ) |&gt; \n  bold_labels()\n\nWarning in svymean.survey.design2(data, design[byfactor %in% byfactor[i], :\nSample size greater than population size: are weights correctly scaled?\nWarning in svymean.survey.design2(data, design[byfactor %in% byfactor[i], :\nSample size greater than population size: are weights correctly scaled?\nWarning in svymean.survey.design2(data, design[byfactor %in% byfactor[i], :\nSample size greater than population size: are weights correctly scaled?\nWarning in svymean.survey.design2(data, design[byfactor %in% byfactor[i], :\nSample size greater than population size: are weights correctly scaled?\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nurbain (912 obs.)\n1\n\n\nrural (1088 obs.)\n1\n\n\n\n\nNiveau d'éducation\n\n\n\n\n    aucun\n40,3% (375 obs.)\n68,0% (763 obs.)\n\n\n    primaire\n24,4% (213 obs.)\n25,6% (247 obs.)\n\n\n    secondaire\n29,5% (275 obs.)\n6,1% (73 obs.)\n\n\n    supérieur\n5,7% (49 obs.)\n0,3% (5 obs.)\n\n\nA un emploi ?\n\n\n\n\n    non\n39,2% (370 obs.)\n26,9% (296 obs.)\n\n\n    oui\n60,8% (537 obs.)\n73,1% (790 obs.)\n\n\n    Manquant\n5\n1\n\n\n\n1\n\n\n\n\n\n\nIl faut noter qu’une modification du thème impactera tous les tableaux suivants, jusqu’à ce que le thème soit à nouveau modifié ou bien que l’on fasse appel à gtsummary::reset_gtsummary_theme().",
    "crumbs": [
      "**Données pondérées avec `survey`**",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Analyses uni- et bivariées pondérées</span>"
    ]
  },
  {
    "objectID": "donnees_ponderees/analyses-bivariees.html#calcul-manuel-avec-survey",
    "href": "donnees_ponderees/analyses-bivariees.html#calcul-manuel-avec-survey",
    "title": "30  Analyses uni- et bivariées pondérées",
    "section": "\n30.2 Calcul manuel avec {survey}\n",
    "text": "30.2 Calcul manuel avec {survey}\n\nLorsque l’on travail avec un plan d’échantillonnage, on ne peut utiliser les fonctions statistiques classiques de R. On aura recours à leurs équivalents fournis par survey :\n\nsurvey::svymean(), survey::svyvar(), survey::svytotal(), survey::svyquantile() : moyenne, variance, total, quantiles\nsurvey::svytable() : tri à plat et tableau croisé\nsurvey::svychisq() : test du χ²\nsurvey::svyby() : statistiques selon un facteur\nsurvey::svyttest() : test t de Student de comparaison de moyennes\nsurvey::svyciprop() : intervalle de confiance d’une proportion\nsurvey::svyratio() : ratio de deux variables continues\n\nCes fonctions prennent leurs arguments sous forme de formules pour spécifier les variables d’intérêt.\n\nsurvey::svymean(~ age, dp)\n\n      mean     SE\nage 28.468 0.2697\n\nsurvey::svymean(~ age, dp) |&gt; confint()\n\n       2.5 %   97.5 %\nage 27.93931 28.99653\n\nsurvey::svyquantile(~age, dp, quantile = c(0.25, 0.5, 0.75), ci = TRUE)\n\n$age\n     quantile ci.2.5 ci.97.5        se\n0.25       21     21      22 0.2549523\n0.5        27     27      28 0.2549523\n0.75       35     35      37 0.5099045\n\nattr(,\"hasci\")\n[1] TRUE\nattr(,\"class\")\n[1] \"newsvyquantile\"\n\n\nLes tris à plat se déclarent en passant comme argument le nom de la variable précédé d’un tilde (~), tandis que les tableaux croisés utilisent les noms des deux variables séparés par un signe plus (+) et précédés par un tilde (~)1.\n1 Cette syntaxe est similaire à celle de xtabs().\nsurvey::svytable(~region, dp)\n\nregion\n    Nord      Est      Sud    Ouest \n611.0924 175.7404 329.2220 911.2197 \n\nsurvey::svytable(~milieu + educ, dp)\n\n        educ\nmilieu        aucun   primaire secondaire  supérieur\n  urbain 413.608780 250.665214 303.058978  58.412688\n  rural  681.131096 256.694363  61.023980   2.679392\n\n\nLa fonction questionr::freq() peut être utilisée si on lui passe en argument non pas la variable elle-même, mais son tri à plat obtenu avec survey::svytable() :\n\nsurvey::svytable(~region, dp) |&gt; \n  questionr::freq(total = TRUE)\n\n           n     %  val%\nNord   611.1  30.1  30.1\nEst    175.7   8.7   8.7\nSud    329.2  16.2  16.2\nOuest  911.2  44.9  44.9\nTotal 2027.3 100.0 100.0\n\n\nLes fonctions questionr::rprop() et questionr::cprop() peuvent être utilisées pour calculer les pourcentages en ligne ou en colonne.\n\nsurvey::svytable(~milieu + educ, dp) |&gt; \n  questionr::cprop()\n\n        educ\nmilieu   aucun primaire secondaire supérieur Ensemble\n  urbain  37.8  49.4     83.2       95.6      50.6   \n  rural   62.2  50.6     16.8        4.4      49.4   \n  Total  100.0 100.0    100.0      100.0     100.0   \n\n\nLe principe de la fonction survey::svyby() est similaire à celui de tapply() (cf. Section 19.2.3). Elle permet de calculer des statistiques selon plusieurs sous-groupes définis par un facteur.\n\nsurvey::svyby(~age, ~region, dp, survey::svymean)\n\n      region      age        se\nNord    Nord 29.03299 0.4753268\nEst      Est 27.54455 0.5261669\nSud      Sud 28.96830 0.6148223\nOuest  Ouest 28.08626 0.4458201",
    "crumbs": [
      "**Données pondérées avec `survey`**",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Analyses uni- et bivariées pondérées</span>"
    ]
  },
  {
    "objectID": "donnees_ponderees/analyses-bivariees.html#intervalles-de-confiance-et-tests-statistiques",
    "href": "donnees_ponderees/analyses-bivariees.html#intervalles-de-confiance-et-tests-statistiques",
    "title": "30  Analyses uni- et bivariées pondérées",
    "section": "\n30.3 Intervalles de confiance et tests statistiques",
    "text": "30.3 Intervalles de confiance et tests statistiques\nLa fonction gtsummary::add_ci() peut être appliquée à des tableaux produits avec gtsummary::tbl_svysummary()2. Les méthodes utilisées sont adaptées à la prise en compte d’un plan d’échantillonnage. On se référera à la document de la fonction pour plus de détails sur les méthodes statistiques utilisées. Rappel : pour les variables continues, on sera vigilant à ce que la statistique affichée (médiane par défaut) corresponde au type d’intervalle de confiance calculé (moyenne par défaut).\n2 Cela requiert une version récente (≥1.7.0) de gtsummary.\ndp |&gt; \n  tbl_svysummary(\n    include = c(age, region),\n    statistic = all_continuous() ~ \"{mean} ({sd})\"\n  ) |&gt; \n  add_ci() |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 2027\n1\n\n\n95% IC\n2\n\n\n\n\nÂge révolu (en années) à la date de passation du questionnaire\n28 (9)\n28, 29\n\n\nRégion de résidence\n\n\n\n\n    Nord\n611 (30%)\n28%, 33%\n\n\n    Est\n176 (8,7%)\n7,7%, 9,8%\n\n\n    Sud\n329 (16%)\n14%, 18%\n\n\n    Ouest\n911 (45%)\n42%, 48%\n\n\n\n\n\n1\nMoyenne (ET); n (%)\n\n\n\n\n2\nIC = intervalle de confiance\n\n\n\n\n\n\n\n\n\nTable 30.2: Intervalles de confiance avec prise en compte du plan d’échantillonnage\n\n\n\nDe même, on peut aisément effectuer des tests de comparaison avec gtsummary::add_p(). Là aussi, les tests utilisés sont des adaptations des tests classiques avec différentes corrections pour tenir compte à la fois de la pondération et du plan d’échantillonnage.\n\ndp |&gt; \n  tbl_svysummary(\n    include = c(age, region),\n    by = milieu\n  ) |&gt; \n  add_p() |&gt; \n  bold_labels()\n\nWarning in svymean.survey.design2(data, design[byfactor %in% byfactor[i], :\nSample size greater than population size: are weights correctly scaled?\nWarning in svymean.survey.design2(data, design[byfactor %in% byfactor[i], :\nSample size greater than population size: are weights correctly scaled?\nWarning in svymean.survey.design2(data, design[byfactor %in% byfactor[i], :\nSample size greater than population size: are weights correctly scaled?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nurbain\nN = 1026\n1\n\n\nrural\nN = 1002\n1\n\n\np-valeur\n2\n\n\n\n\nÂge révolu (en années) à la date de passation du questionnaire\n26 (20 – 33)\n28 (22 – 36)\n&lt;0,001\n\n\nRégion de résidence\n\n\n&lt;0,001\n\n\n    Nord\n265 (26%)\n346 (35%)\n\n\n\n    Est\n48 (4,7%)\n128 (13%)\n\n\n\n    Sud\n79 (7,7%)\n250 (25%)\n\n\n\n    Ouest\n633 (62%)\n278 (28%)\n\n\n\n\n\n\n1\nMédiane (Q1 – Q3); n (%)\n\n\n\n\n2\nDesign-based KruskalWallis test; Pearson’s X^2: Rao & Scott adjustment\n\n\n\n\n\n\n\n\n\nTable 30.3: Tests de comparaison avec prise en compte du plan d’échantillonnage",
    "crumbs": [
      "**Données pondérées avec `survey`**",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Analyses uni- et bivariées pondérées</span>"
    ]
  },
  {
    "objectID": "donnees_ponderees/analyses-bivariees.html#calcul-manuel-avec-srvyr",
    "href": "donnees_ponderees/analyses-bivariees.html#calcul-manuel-avec-srvyr",
    "title": "30  Analyses uni- et bivariées pondérées",
    "section": "\n30.4 Calcul manuel avec {srvyr}\n",
    "text": "30.4 Calcul manuel avec {srvyr}\n\nOn peut avoir besoin de calculer des moyennes et/ou des proportions par sous-groupe, avec leurs intervalles de confiance, de manière manuelle, par exemple en amont d’un graphique à représenter avec ggplot2. Dans ce cas de figure, les fonctions natives de survey ne sont pas toujours très facile d’emploi et l’on pourra avantageusement recourir à srvyr pour bénéficier d’une syntaxe à la dplyr.\nPar exemple, pour calculer l’âge moyen des femmes par région, on combinera srvyr::survey_mean() avec srvyr::group_by() et srvyr::summarise()  :\n\ndp |&gt; \n  group_by(region) |&gt; \n  summarise(moy = survey_mean())\n\n# A tibble: 4 × 3\n  region    moy  moy_se\n  &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 Nord   0.301  0.0127 \n2 Est    0.0867 0.00544\n3 Sud    0.162  0.0102 \n4 Ouest  0.449  0.0147 \n\n\nPar défaut, cela renvoie les moyennes et les erreurs standards. Pour les intervalles de confiance, on précisera simplement vartype = \"ci\".\n\ndp |&gt; \n  group_by(region) |&gt; \n  summarise(moy = survey_mean(vartype = \"ci\"))\n\n# A tibble: 4 × 4\n  region    moy moy_low moy_upp\n  &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 Nord   0.301   0.277   0.326 \n2 Est    0.0867  0.0760  0.0974\n3 Sud    0.162   0.142   0.182 \n4 Ouest  0.449   0.421   0.478 \n\n\nPour des proportions, on aura recours à srvyr::survey_prop(). Par exemple, pour un tri à plat du niveau d’éducation :\n\ndp |&gt; \n  group_by(educ) |&gt; \n  summarise(prop = survey_prop())\n\nWhen `proportion` is unspecified, `survey_prop()` now defaults to `proportion = TRUE`.\nℹ This should improve confidence interval coverage.\nThis message is displayed once per session.\n\n\n# A tibble: 4 × 3\n  educ         prop prop_se\n  &lt;fct&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n1 aucun      0.540  0.0144 \n2 primaire   0.250  0.0127 \n3 secondaire 0.180  0.0110 \n4 supérieur  0.0301 0.00487\n\n\nLà encore, on peut passer l’option vartpe = \"ci\" pour obtenir les intervalles de confiance3.\n3 Par défaut, les intervalles de confiance sont calculés avec survey::svymean() et peuvent générer des valeurs inférieures à 0 ou supérieures à 1. Pour un calcul plus précis reposant sur survey::svyciprop(), on précisera proportion = TRUE. Plusieurs méthodes existent pour ce calcul, voir l’aide de survey::svyciprop().Si l’on passe plusieurs variables dans le group_by(), les proportions sont calculées pour la dernière variable pour chaque combinaison des autres variables. Par exemple, pour la distribution du niveau d’éducation par milieu de résidence (i.e. la somme des proportions est de 100% pour le milieu urbain et de 100% pour celles du milieu rural, soit 200% au total) :\n\ndp |&gt; \n  group_by(milieu, educ) |&gt; \n  summarise(prop = survey_prop(vartype = \"ci\", proportion = TRUE))\n\n# A tibble: 8 × 5\n# Groups:   milieu [2]\n  milieu educ          prop prop_low prop_upp\n  &lt;fct&gt;  &lt;fct&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 urbain aucun      0.403    0.364    0.444  \n2 urbain primaire   0.244    0.210    0.282  \n3 urbain secondaire 0.295    0.260    0.334  \n4 urbain supérieur  0.0569   0.0410   0.0785 \n5 rural  aucun      0.680    0.643    0.715  \n6 rural  primaire   0.256    0.223    0.292  \n7 rural  secondaire 0.0609   0.0454   0.0813 \n8 rural  supérieur  0.00268  0.00108  0.00660\n\n\nSi l’on souhaite les pourcentages que représentent chaque combinaison au sein de l’ensemble de l’échantillon (i.e. que la somme de toutes les proportions soit de 100%), on aura recours à srvyr::interact().\n\ndp |&gt; \n  group_by(interact(milieu, educ)) |&gt; \n  summarise(prop = survey_prop(vartype = \"ci\", proportion = TRUE))\n\n# A tibble: 8 × 5\n  milieu educ          prop prop_low prop_upp\n  &lt;fct&gt;  &lt;fct&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 urbain aucun      0.204   0.182     0.228  \n2 urbain primaire   0.124   0.105     0.145  \n3 urbain secondaire 0.149   0.130     0.171  \n4 urbain supérieur  0.0288  0.0207    0.0400 \n5 rural  aucun      0.336   0.310     0.363  \n6 rural  primaire   0.127   0.109     0.146  \n7 rural  secondaire 0.0301  0.0224    0.0404 \n8 rural  supérieur  0.00132 0.000535  0.00326",
    "crumbs": [
      "**Données pondérées avec `survey`**",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Analyses uni- et bivariées pondérées</span>"
    ]
  },
  {
    "objectID": "donnees_ponderees/analyses-bivariees.html#impact-du-plan-déchantillonnage",
    "href": "donnees_ponderees/analyses-bivariees.html#impact-du-plan-déchantillonnage",
    "title": "30  Analyses uni- et bivariées pondérées",
    "section": "\n30.5 Impact du plan d’échantillonnage",
    "text": "30.5 Impact du plan d’échantillonnage\nLorsque l’on calcul des proportions, moyennes ou médianes pondérées, seuls les poids entrent en ligne de compte. Le plan d’échantillonnage (strates et/ou grappes) n’a de son côté pas d’effet. Par contre, le plan d’échantillonnage a un impact important sur le calcul des variances et, par extension, sur le calcul des intervalles de confiance et des tests de comparaison.\nPour illustrer cela, nous allons considérer un même jeu de données, avec la même variable de poids, mais en faisant varier la présence de strates et de grappes.\nCommençons par regarder le jeu de données apistrat fourni par survey.\n\ndata(\"api\", package = \"survey\")\nnrow(apistrat)\n\n[1] 200\n\nsummary(apistrat$pw)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  15.10   19.05   32.28   30.97   44.21   44.21 \n\nsum(apistrat$pw)\n\n[1] 6194\n\n\nNous avons ici un tableau de données de 200 lignes, avec des poids variant entre 15 et 44. Nous pouvons définir une pondération simple et croiser deux variables.\n\nd_ponderation_simple &lt;- apistrat |&gt; \n  as_survey_design(weights = pw)\ntbl &lt;- survey::svytable(~ awards + yr.rnd, design = d_ponderation_simple)\ntbl\n\n      yr.rnd\nawards      No     Yes\n   No  2068.34  168.09\n   Yes 3274.06  683.51\n\n\nRéalisons un test du Chi² entre ces deux variables. Si nous appliquions la fonction classique chisq.test() sur ce tableau, cette fonction considérait que nous avons 6194 observations (somme des poids) et dès lors nous obtiendrions une p-valeur très faible.\n\ntbl |&gt; chisq.test()\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  tbl\nX-squared = 113.84, df = 1, p-value &lt; 2.2e-16\n\n\nLe calcul précédent ne tient pas compte que nous n’avons que 200 observations dans notre échantillon. Refaisons le calcul survey::svychisq() qui est adaptée aux plans d’échantillonnage.\n\nsurvey::svychisq(~ awards + yr.rnd, design = d_ponderation_simple)\n\n\n    Pearson's X^2: Rao & Scott adjustment\n\ndata:  NextMethod()\nF = 2.9162, ndf = 1, ddf = 199, p-value = 0.08926\n\n\nLe résultat est ici tout autre et notre test n’est plus significatif au seuil de 5% ! Ici, les corrections de Rao & Scott permettent justement de tenir compte que nous avons un échantillon de seulement 200 observations.\nRegardons maintenant si, à poids égal, il y a une différence entre une enquête stratifiée et une enquête en grappes.\n\n# Pondération simple\nsurvey::svytable(~ awards + yr.rnd, design = d_ponderation_simple)\n\n      yr.rnd\nawards      No     Yes\n   No  2068.34  168.09\n   Yes 3274.06  683.51\n\nsurvey::svychisq(~ awards + yr.rnd, design = d_ponderation_simple)\n\n\n    Pearson's X^2: Rao & Scott adjustment\n\ndata:  NextMethod()\nF = 2.9162, ndf = 1, ddf = 199, p-value = 0.08926\n\n# Enquête stratifiée\nd_strates &lt;- apistrat |&gt; \n  as_survey_design(weights = pw, strata = stype)\nsurvey::svytable(~ awards + yr.rnd, design = d_strates)\n\n      yr.rnd\nawards      No     Yes\n   No  2068.34  168.09\n   Yes 3274.06  683.51\n\nsurvey::svychisq(~ awards + yr.rnd, design = d_strates)\n\n\n    Pearson's X^2: Rao & Scott adjustment\n\ndata:  NextMethod()\nF = 2.9007, ndf = 1, ddf = 197, p-value = 0.09012\n\n# Enquête en grappes\nd_grappes &lt;- apistrat |&gt; \n  as_survey_design(weights = pw, ids = dnum)\nsurvey::svytable(~ awards + yr.rnd, design = d_grappes)\n\n      yr.rnd\nawards      No     Yes\n   No  2068.34  168.09\n   Yes 3274.06  683.51\n\nsurvey::svychisq(~ awards + yr.rnd, design = d_grappes)\n\n\n    Pearson's X^2: Rao & Scott adjustment\n\ndata:  NextMethod()\nF = 3.1393, ndf = 1, ddf = 134, p-value = 0.0787\n\n\nOn le constate : dans les trois cas les tableaux croisés sont identiques, mais pour autant les trois p-valeurs diffèrent.\nDès lors qu’un calcul de variance est impliqué, la simple prise en compte des poids est insuffisante : il faut appliquer des corrections en fonction du plan d’échantillonnage !\nPas d’inquiétude, survey s’en occupe pour vous, dès lors que le plan d’échantillonnage a correctement été défini.",
    "crumbs": [
      "**Données pondérées avec `survey`**",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Analyses uni- et bivariées pondérées</span>"
    ]
  },
  {
    "objectID": "donnees_ponderees/graphiques-ponderes.html",
    "href": "donnees_ponderees/graphiques-ponderes.html",
    "title": "31  Graphiques pondérés",
    "section": "",
    "text": "Le package ggplot2 n’est compatible directement avec les objets survey. Cependant, il accepte une esthétique weight qui permet de définir une variable de pondération.\n\n\n\n\n\n\nAvertissement\n\n\n\nATTENTION : les graphiques obtenus ne sont corrects qu’à la condition que seuls les poids soient nécessaires pour les construire, ce qui est le cas d’un nuage de points ou d’un diagramme en barres.\nPar contre, si le calcul du graphique implique le calcul de variances, la représentation sera incorrecte. Par exemple, avec ggplot2::geom_smooth(), les intervalles de confiance affichés ne prendront pas correctement en compte le plan d’échantillonnage.\n\n\nReprenons le jeu de données fecondite que nous avons abordé dans le chapitre sur les analyses bivariées pondérées, cf. Chapitre 30. Les poids d’enquête y sont indiqués dans la colonne poids. Pour rappel, les données catégorielles étant stockées sous forme de vecteurs numériques avec étiquettes de valeurs (cf. Chapitre 12), nous allons les convertir en facteurs avec labelled::unlabelled().\n\ndata(\"fecondite\", package = \"questionr\")\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nd &lt;- labelled::unlabelled(femmes)\n\nPour réaliser un graphique, nous pouvons reprendre ce que nous avons vu dans notre chapitre introductif sur ggplot2, cf. Chapitre 17, en spécifiant simplement l’esthétique weight.\n\nggplot(d) +\n  aes(x = region, fill = test, weight = poids) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\nFigure 31.1: Un graphique en barres pondéré\n\n\n\n\nSi l’on a déjà créé un objet survey, on peut obtenir les poids des observations avec la fonction weights(). Les données sont quant à elle accessibles via le sous-élément nommé variables.\n\nlibrary(srvyr)\n\n\nAttachement du package : 'srvyr'\n\n\nL'objet suivant est masqué depuis 'package:stats':\n\n    filter\n\ndp &lt;- femmes |&gt; \n  labelled::unlabelled() |&gt; \n  as_survey_design(weights = poids)\n\n\nggplot(dp$variables) +\n  aes(x = region, fill = test, weight = weights(dp)) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\nFigure 31.2: Un graphique en barres pondéré\n\n\n\n\nPour se faciliter les choses, on peut avoir directement recours à la fonction ggstats::ggsurvey(), que l’on utilisera à la place de ggplot2::ggplot(), et qui fait exactement la même chose que dans notre exemple précédent : on lui passe un objet de type survey et la fonction en extrait le sous-élément variables pour le passer à ggplot2::ggplot() et les poids qui sont automatiquement associés à l’esthétique weight.\nAinsi, le code de notre graphique précédent s’écrit tout simplement1 :\n1 Notez que les poids ont déjà été associés à la bonne esthétique et qu’il n’est donc pas nécessaire de le refaire dans l’appel à aes().\nggstats::ggsurvey(dp) +\n  aes(x = region, fill = test) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\nFigure 31.3: Un graphique en barres pondéré\n\n\n\n\n\n\n\nFigure 31.1: Un graphique en barres pondéré\nFigure 31.2: Un graphique en barres pondéré\nFigure 31.3: Un graphique en barres pondéré",
    "crumbs": [
      "**Données pondérées avec `survey`**",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Graphiques pondérés</span>"
    ]
  },
  {
    "objectID": "donnees_ponderees/regression-logistique-binaire-ponderee.html",
    "href": "donnees_ponderees/regression-logistique-binaire-ponderee.html",
    "title": "32  Régression logistique binaire pondérée",
    "section": "",
    "text": "32.1 Données des exemples\nNous allons reprendre les même données issues de l’enquête Histoire de vie 2003, mais en tenant compte cette fois-ci des poids de pondération fourni dans la variable poids.\nlibrary(tidyverse)\nlibrary(labelled)\ndata(hdv2003, package = \"questionr\")\nd &lt;-\n  hdv2003 |&gt; \n  mutate(\n    sexe = sexe |&gt; fct_relevel(\"Femme\"),\n    groupe_ages = age |&gt;\n      cut(\n        c(18, 25, 45, 65, 99),\n        right = FALSE,\n        include.lowest = TRUE,\n        labels = c(\"18-24 ans\", \"25-44 ans\",\n                   \"45-64 ans\", \"65 ans et plus\")\n      ),\n    etudes = nivetud |&gt; \n      fct_recode(\n        \"Primaire\" = \"N'a jamais fait d'etudes\",\n        \"Primaire\" = \"A arrete ses etudes, avant la derniere annee d'etudes primaires\",\n        \"Primaire\" = \"Derniere annee d'etudes primaires\",\n        \"Secondaire\" = \"1er cycle\",\n        \"Secondaire\" = \"2eme cycle\",\n        \"Technique / Professionnel\" = \"Enseignement technique ou professionnel court\",\n        \"Technique / Professionnel\" = \"Enseignement technique ou professionnel long\",\n        \"Supérieur\" = \"Enseignement superieur y compris technique superieur\"\n    ) |&gt; \n    fct_na_value_to_level(\"Non documenté\")  \n  ) |&gt; \n  set_variable_labels(\n    sport = \"Pratique un sport ?\",\n    sexe = \"Sexe\",\n    groupe_ages = \"Groupe d'âges\",\n    etudes = \"Niveau d'études\",\n    relig = \"Rapport à la religion\",\n    heures.tv = \"Heures de télévision / jour\",\n    poids = \"Pondération de l'enquête\"\n  )\nIl ne nous reste qu’à définir notre objet survey en spécifiant la pondération fournie avec l’enquête. La documentation ne mentionne ni strates ni grappes.\nlibrary(srvyr)\nlibrary(survey)\ndp &lt;- d |&gt; \n  as_survey_design(weights = poids)",
    "crumbs": [
      "**Données pondérées avec `survey`**",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Régression logistique binaire pondérée</span>"
    ]
  },
  {
    "objectID": "donnees_ponderees/regression-logistique-binaire-ponderee.html#calcul-de-la-régression-logistique-binaire",
    "href": "donnees_ponderees/regression-logistique-binaire-ponderee.html#calcul-de-la-régression-logistique-binaire",
    "title": "32  Régression logistique binaire pondérée",
    "section": "\n32.2 Calcul de la régression logistique binaire",
    "text": "32.2 Calcul de la régression logistique binaire\nLa syntaxe de survey::svyglm() est similaire à celle de glm() sauf qu’elle a un argument design au lieu de data.\nLa plupart du temps, les poids de pondération ne sont pas des nombres entiers, mais des nombres décimaux. Or, la famille de modèles binomiaux repose sur des nombres entiers de succès et d’échecs. Avec une version récente1 de R, cela n’est pas problématique. Nous aurons simplement un avertissement.\n1 Si vous utilisez une version ancienne de R, cela n’était tout simplement pas possible. Vous obteniez un message d’erreur et le modèle n’était pas calculé. Si c’est votre cas, optez pour un modèle quasi-binomial ou bien mettez à jour R.\nmod_binomial &lt;- svyglm(\n  sport ~ sexe + groupe_ages + etudes + relig + heures.tv,\n  family = binomial,\n  design = dp\n)\n\nWarning in eval(family$initialize): nombre de succès non entier dans un glm\nbinomial !\n\n\nUne alternative consiste à avoir recours à la famille quasi-binomiale, que l’on spécifie avec family = quasibinomial et qui constitue une extension de la famille binomiale pouvant gérer des poids non entiers. La distribution quasi-binomiale, bien que similaire à la distribution binomiale, possède un paramètre supplémentaire 𝜙 qui tente de décrire une variance supplémentaire dans les données qui ne peut être expliquée par une distribution binomiale seule (on parle alors de surdispersion). Les coefficients obtenus sont les mêmes, mais les intervalles de confiance peuvent être un peu plus large.\n\nmod_quasi &lt;- svyglm(\n  sport ~ sexe + groupe_ages + etudes + relig + heures.tv,\n  family = quasibinomial,\n  design = dp\n)\n\nSimple, non ?",
    "crumbs": [
      "**Données pondérées avec `survey`**",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Régression logistique binaire pondérée</span>"
    ]
  },
  {
    "objectID": "donnees_ponderees/regression-logistique-binaire-ponderee.html#sélection-de-modèle",
    "href": "donnees_ponderees/regression-logistique-binaire-ponderee.html#sélection-de-modèle",
    "title": "32  Régression logistique binaire pondérée",
    "section": "\n32.3 Sélection de modèle",
    "text": "32.3 Sélection de modèle\nComme précédemment (cf. Chapitre 23), il est possible de procéder à une sélection de modèle pas à pas, par minimisation de l’AIC, avec step().\n\nmod_quasi2 &lt;- step(mod_quasi)\n\nStart:  AIC=2309.89\nsport ~ sexe + groupe_ages + etudes + relig + heures.tv\n\n              Df Deviance    AIC\n- relig        5   2266.3 2302.2\n&lt;none&gt;             2263.9 2309.9\n- heures.tv    1   2276.2 2320.2\n- sexe         1   2276.4 2320.4\n- groupe_ages  3   2313.9 2353.8\n- etudes       4   2383.5 2421.2\n\nStep:  AIC=2296.28\nsport ~ sexe + groupe_ages + etudes + heures.tv\n\n              Df Deviance    AIC\n&lt;none&gt;             2266.3 2296.3\n- heures.tv    1   2278.4 2306.4\n- sexe         1   2279.0 2307.0\n- groupe_ages  3   2318.3 2342.1\n- etudes       4   2387.2 2408.8\n\n\n\n\n\n\n\n\nSélection pas à pas et valeurs manquantes\n\n\n\nNous avons abordé dans le chapitre sur la sélection de modèle pas à pas la problématique des valeurs manquantes lors d’une sélection pas à pas descendante par minimisation de l’AIC (cf. Section 23.8). La même approche peut être appliquée avec des données pondérées. Cependant, la fonction step_with_na() que nous avons présenté n’est pas compatible avec les modèles survey::svyglm() puisqu’ils prennent en entrée un argument design et non data.\nOn pourra essayer la variante step_with_na_survey() ci-dessous qui nécessite qu’on lui passe également l’objet survey ayant servi au calcul du modèle.\n\nstep_with_na_survey &lt;- function(model, design, ...) {\n  # list of variables\n  variables &lt;- broom.helpers::model_list_variables(\n    model,\n    only_variable = TRUE\n  )\n  # design with no na\n  design_no_na &lt;- design |&gt; \n    srvyr::drop_na(dplyr::any_of(variables))\n  # refit the model without NAs\n  model_no_na &lt;- update(model, data = design_no_na)  \n  # apply step()\n  model_simplified &lt;- step(model_no_na, ...)\n  # recompute simplified model using full data\n  update(model, formula = terms(model_simplified))\n}\n\n\nmod2_binomial &lt;- step_with_na_survey(mod_binomial, dp)",
    "crumbs": [
      "**Données pondérées avec `survey`**",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Régression logistique binaire pondérée</span>"
    ]
  },
  {
    "objectID": "donnees_ponderees/regression-logistique-binaire-ponderee.html#affichage-des-résultats",
    "href": "donnees_ponderees/regression-logistique-binaire-ponderee.html#affichage-des-résultats",
    "title": "32  Régression logistique binaire pondérée",
    "section": "\n32.4 Affichage des résultats",
    "text": "32.4 Affichage des résultats\nNous pouvons tout à fait utiliser gtsumarry::tbl_regression() avec ce type de modèles. De même, on peut utiliser gtsummary::add_global_p() pour calculer les p-valeurs globales des variables ou encore gtsummary::add_vif() pour vérifier la multicolinéarité (cf. Chapitre 27).\n\nlibrary(gtsummary)\ntheme_gtsummary_language(\"fr\", decimal.mark = \",\", big.mark = \" \")\n\n\nmod_quasi2 |&gt; \n  tbl_regression(exponentiate = TRUE) |&gt; \n  add_global_p(keep = TRUE) |&gt; \n  add_vif() |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nOR\n1\n\n\n95% IC\n1\n\np-valeur\n\nGVIF\n1\n\n\nAdjusted GVIF\n2,1\n\n\n\n\nSexe\n\n\n0,005\n1,0\n1,0\n\n\n    Femme\n—\n—\n\n\n\n\n\n    Homme\n1,44\n1,12 – 1,87\n0,005\n\n\n\n\nGroupe d'âges\n\n\n&lt;0,001\n2,1\n1,1\n\n\n    18-24 ans\n—\n—\n\n\n\n\n\n    25-44 ans\n0,85\n0,48 – 1,51\n0,6\n\n\n\n\n    45-64 ans\n0,40\n0,22 – 0,73\n0,003\n\n\n\n\n    65 ans et plus\n0,37\n0,19 – 0,72\n0,004\n\n\n\n\nNiveau d'études\n\n\n&lt;0,001\n2,2\n1,1\n\n\n    Primaire\n—\n—\n\n\n\n\n\n    Secondaire\n2,66\n1,62 – 4,38\n&lt;0,001\n\n\n\n\n    Technique / Professionnel\n3,09\n1,90 – 5,00\n&lt;0,001\n\n\n\n\n    Supérieur\n6,54\n3,99 – 10,7\n&lt;0,001\n\n\n\n\n    Non documenté\n10,3\n4,60 – 23,0\n&lt;0,001\n\n\n\n\nHeures de télévision / jour\n0,89\n0,82 – 0,97\n0,006\n1,1\n1,0\n\n\n\n\n\n1\nOR = rapport de cotes, IC = intervalle de confiance, GVIF = Generalized Variance Inflation Factor\n\n\n\n\n2\nGVIF2\n\n\n\n\n2 1/(2*df)\n\n\n\n\nTable 32.1: Facteurs associés à la pratique d’un sport (régression logistique pondérée)\n\n\n\nPour un graphique des coefficients, nous pouvons utiliser ggstats::ggcoef_model().\n\nmod_quasi2 |&gt; \n  ggstats::ggcoef_model(exponentiate = TRUE)\n\n\n\n\n\n\nFigure 32.1: Facteurs associés à la pratique d’un sport (régression logistique pondérée)",
    "crumbs": [
      "**Données pondérées avec `survey`**",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Régression logistique binaire pondérée</span>"
    ]
  },
  {
    "objectID": "donnees_ponderees/regression-logistique-binaire-ponderee.html#prédictions-marginales",
    "href": "donnees_ponderees/regression-logistique-binaire-ponderee.html#prédictions-marginales",
    "title": "32  Régression logistique binaire pondérée",
    "section": "\n32.5 Prédictions marginales",
    "text": "32.5 Prédictions marginales\nPour visualiser les prédictions marginales moyennes du modèle (cf. Section 24.3), nous pouvons utiliser broom.helpers::plot_marginal_predictions().\n\nmod_quasi2 |&gt; \n  broom.helpers::plot_marginal_predictions(type = \"response\") |&gt; \n  patchwork::wrap_plots() &\n  scale_y_continuous(\n    limits = c(0, .8),\n    labels = scales::label_percent()\n  )\n\nWarning: With models of this class, it is normally good practice to specify\nweights using the `wts` argument. Otherwise, weights will be ignored in the\ncomputation of quantities of interest.\nWarning: With models of this class, it is normally good practice to specify\nweights using the `wts` argument. Otherwise, weights will be ignored in the\ncomputation of quantities of interest.\nWarning: With models of this class, it is normally good practice to specify\nweights using the `wts` argument. Otherwise, weights will be ignored in the\ncomputation of quantities of interest.\nWarning: With models of this class, it is normally good practice to specify\nweights using the `wts` argument. Otherwise, weights will be ignored in the\ncomputation of quantities of interest.\n\n\n\n\n\n\n\nFigure 32.2: Prédictions marginales moyennes du modèle pondéré\n\n\n\n\n\n\n\nFigure 32.1: Facteurs associés à la pratique d’un sport (régression logistique pondérée)\nFigure 32.2: Prédictions marginales moyennes du modèle pondéré",
    "crumbs": [
      "**Données pondérées avec `survey`**",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Régression logistique binaire pondérée</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/fusion-tables.html",
    "href": "manipulation_avancee/fusion-tables.html",
    "title": "33  Fusion de tables",
    "section": "",
    "text": "33.1 Jointures avec dplyr\nLe jeu de données nycflights13 est un exemple de données réparties en plusieurs tables. Ici on en a trois : les informations sur les vols, celles sur les aéroports et celles sur les compagnies aériennes sont dans trois tables distinctes.\ndplyr propose différentes fonctions permettant de travailler avec des données structurées de cette manière.\nlibrary(tidyverse)\nlibrary(nycflights13)\ndata(flights)\ndata(airports)\ndata(airlines)",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Fusion de tables</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/fusion-tables.html#jointures-avec-dplyr",
    "href": "manipulation_avancee/fusion-tables.html#jointures-avec-dplyr",
    "title": "33  Fusion de tables",
    "section": "",
    "text": "33.1.1 Clés implicites\nLorsque les données sont réparties dans plusieurs tables différentes, il est essentiel de repérer les identifiants permettant de naviguer d’une table à l’autre. Dans notre exemple, on peut voir que la table flights contient le code de la compagnie aérienne du vol dans la variable carrier :\n\nflights |&gt; labelled::look_for()\n\n pos variable       label col_type missing values\n 1   year           —     int      0             \n 2   month          —     int      0             \n 3   day            —     int      0             \n 4   dep_time       —     int      8255          \n 5   sched_dep_time —     int      0             \n 6   dep_delay      —     dbl      8255          \n 7   arr_time       —     int      8713          \n 8   sched_arr_time —     int      0             \n 9   arr_delay      —     dbl      9430          \n 10  carrier        —     chr      0             \n 11  flight         —     int      0             \n 12  tailnum        —     chr      2512          \n 13  origin         —     chr      0             \n 14  dest           —     chr      0             \n 15  air_time       —     dbl      9430          \n 16  distance       —     dbl      0             \n 17  hour           —     dbl      0             \n 18  minute         —     dbl      0             \n 19  time_hour      —     dttm     0             \n\n\nEt que par ailleurs la table airlines contient une information supplémentaire relative à ces compagnies, à savoir le nom complet.\n\nairlines |&gt; labelled::look_for()\n\n pos variable label col_type missing values\n 1   carrier  —     chr      0             \n 2   name     —     chr      0             \n\n\nIl est donc naturel de vouloir associer les deux, en l’occurrence pour ajouter les noms complets des compagnies à la table flights. Dans ce cas on va faire une jointure : les lignes d’une table seront associées à une autre en se basant non pas sur leur position, mais sur les valeurs d’une ou plusieurs colonnes. Ces colonnes sont appelées des clés.\nPour faire une jointure de ce type, on va utiliser la fonction dplyr::left_join() :\n\nfusion &lt;- flights |&gt; left_join(airlines)\n\nJoining with `by = join_by(carrier)`\n\n\nPour faciliter la lecture, on va afficher seulement certaines colonnes du résultat et les premières lignes de la table :\n\nfusion |&gt; \n  select(month, day, carrier, name) |&gt; \n  head(10)\n\n# A tibble: 10 × 4\n   month   day carrier name                    \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;                   \n 1     1     1 UA      United Air Lines Inc.   \n 2     1     1 UA      United Air Lines Inc.   \n 3     1     1 AA      American Airlines Inc.  \n 4     1     1 B6      JetBlue Airways         \n 5     1     1 DL      Delta Air Lines Inc.    \n 6     1     1 UA      United Air Lines Inc.   \n 7     1     1 B6      JetBlue Airways         \n 8     1     1 EV      ExpressJet Airlines Inc.\n 9     1     1 B6      JetBlue Airways         \n10     1     1 AA      American Airlines Inc.  \n\n\nOn voit que la table obtenue est bien la fusion des deux tables d’origine selon les valeurs des deux colonnes clés carrier. On est parti de la table flights, et pour chaque ligne on a ajouté les colonnes de airlines pour lesquelles la valeur de carrier est la même. On a donc bien une nouvelle colonne name dans notre table résultat, avec le nom complet de la compagnie aérienne.\n\n\n\n\n\n\nNote\n\n\n\nNous sommes ici dans le cas le plus simple concernant les clés de jointure : les deux clés sont uniques et portent le même nom dans les deux tables. Par défaut, si on ne lui spécifie pas explicitement les clés, dplyr fusionne en utilisant l’ensemble des colonnes communes aux deux tables. On peut d’ailleurs voir dans cet exemple qu’un message a été affiché précisant que la jointure s’est faite sur la variable carrier.\n\n\n\n33.1.2 Clés explicites\nLa table airports, elle, contient des informations supplémentaires sur les aéroports : nom complet, altitude, position géographique, etc. Chaque aéroport est identifié par un code contenu dans la colonne faa.\nSi on regarde la table flights, on voit que le code d’identification des aéroports apparaît à deux endroits différents : pour l’aéroport de départ dans la colonne origin, et pour celui d’arrivée dans la colonne dest. On a donc deux clés de jointures possibles, et qui portent un nom différent de la clé de airports.\nOn va commencer par fusionner les données concernant l’aéroport de départ. Pour simplifier l’affichage des résultats, on va se contenter d’un sous-ensemble des deux tables :\n\nflights_ex &lt;- flights |&gt; select(month, day, origin, dest)\nairports_ex &lt;- airports |&gt; select(faa, alt, name)\n\nSi on se contente d’un dplyr::left_join() comme à l’étape précédente, on obtient un message d’erreur car aucune colonne commune ne peut être identifiée comme clé de jointure :\n\nflights_ex |&gt; left_join(airports_ex)\n\nError in `left_join()`:\n! `by` must be supplied when `x` and `y` have no common variables.\nℹ Use `cross_join()` to perform a cross-join.\n\n\nOn doit donc spécifier explicitement les clés avec l’argument by de dplyr::left_join(). Ici la clé est nommée origin dans la première table, et faa dans la seconde. La syntaxe est donc la suivante :\n\nflights_ex |&gt; \n  left_join(airports_ex, by = c(\"origin\" = \"faa\")) |&gt; \n  head(10)\n\n# A tibble: 10 × 6\n   month   day origin dest    alt name               \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;              \n 1     1     1 EWR    IAH      18 Newark Liberty Intl\n 2     1     1 LGA    IAH      22 La Guardia         \n 3     1     1 JFK    MIA      13 John F Kennedy Intl\n 4     1     1 JFK    BQN      13 John F Kennedy Intl\n 5     1     1 LGA    ATL      22 La Guardia         \n 6     1     1 EWR    ORD      18 Newark Liberty Intl\n 7     1     1 EWR    FLL      18 Newark Liberty Intl\n 8     1     1 LGA    IAD      22 La Guardia         \n 9     1     1 JFK    MCO      13 John F Kennedy Intl\n10     1     1 LGA    ORD      22 La Guardia         \n\n\nOn constate que les deux nouvelles colonnes name et alt contiennent bien les données correspondant à l’aéroport de départ.\nOn va stocker le résultat de cette jointure dans flights_ex :\n\nflights_ex &lt;- flights_ex |&gt; \n  left_join(airports_ex, by = c(\"origin\" = \"faa\"))\n\nSupposons qu’on souhaite maintenant fusionner à nouveau les informations de la table airports, mais cette fois pour les aéroports d’arrivée de notre nouvelle table flights_ex. Les deux clés sont donc désormais dest dans la première table, et faa dans la deuxième. La syntaxe est donc la suivante :\n\nflights_ex |&gt; \n  left_join(airports_ex, by=c(\"dest\" = \"faa\")) |&gt; \n  head(10)\n\n# A tibble: 10 × 8\n   month   day origin dest  alt.x name.x              alt.y name.y              \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;               \n 1     1     1 EWR    IAH      18 Newark Liberty Intl    97 George Bush Interco…\n 2     1     1 LGA    IAH      22 La Guardia             97 George Bush Interco…\n 3     1     1 JFK    MIA      13 John F Kennedy Intl     8 Miami Intl          \n 4     1     1 JFK    BQN      13 John F Kennedy Intl    NA &lt;NA&gt;                \n 5     1     1 LGA    ATL      22 La Guardia           1026 Hartsfield Jackson …\n 6     1     1 EWR    ORD      18 Newark Liberty Intl   668 Chicago Ohare Intl  \n 7     1     1 EWR    FLL      18 Newark Liberty Intl     9 Fort Lauderdale Hol…\n 8     1     1 LGA    IAD      22 La Guardia            313 Washington Dulles I…\n 9     1     1 JFK    MCO      13 John F Kennedy Intl    96 Orlando Intl        \n10     1     1 LGA    ORD      22 La Guardia            668 Chicago Ohare Intl  \n\n\nCela fonctionne, les informations de l’aéroport d’arrivée ont bien été ajoutées, mais on constate que les colonnes ont été renommées. En effet, ici les deux tables fusionnées contenaient toutes les deux des colonnes name et alt. Comme on ne peut pas avoir deux colonnes avec le même nom dans un tableau, dplyr a renommé les colonnes de la première table en name.x et alt.x, et celles de la deuxième en name.y et alt.y.\nC’est pratique, mais pas forcément très parlant. On pourrait renommer manuellement les colonnes pour avoir des intitulés plus explicites avec dplyr::rename(), mais on peut aussi utiliser l’argument suffix de dplyr::left_join(), qui permet d’indiquer les suffixes à ajouter aux colonnes. Ainsi, on peut faire :\n\nflights_ex |&gt; \n  left_join(\n    airports_ex, \n    by = c(\"dest\" = \"faa\"), \n    suffix = c(\"_depart\", \"_arrivee\")\n  ) |&gt; \n  head(10)\n\n# A tibble: 10 × 8\n   month   day origin dest  alt_depart name_depart      alt_arrivee name_arrivee\n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;  &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                  &lt;dbl&gt; &lt;chr&gt;       \n 1     1     1 EWR    IAH           18 Newark Liberty …          97 George Bush…\n 2     1     1 LGA    IAH           22 La Guardia                97 George Bush…\n 3     1     1 JFK    MIA           13 John F Kennedy …           8 Miami Intl  \n 4     1     1 JFK    BQN           13 John F Kennedy …          NA &lt;NA&gt;        \n 5     1     1 LGA    ATL           22 La Guardia              1026 Hartsfield …\n 6     1     1 EWR    ORD           18 Newark Liberty …         668 Chicago Oha…\n 7     1     1 EWR    FLL           18 Newark Liberty …           9 Fort Lauder…\n 8     1     1 LGA    IAD           22 La Guardia               313 Washington …\n 9     1     1 JFK    MCO           13 John F Kennedy …          96 Orlando Intl\n10     1     1 LGA    ORD           22 La Guardia               668 Chicago Oha…\n\n\nOn obtient ainsi directement des noms de colonnes nettement plus clairs.\n\n33.1.3 Types de jointures\nJusqu’à présent nous avons utilisé la fonction dplyr::left_join(), mais il existe plusieurs types de jointures.\nPartons de deux tables d’exemple, personnes et voitures :\n\npersonnes &lt;- tibble(\n  nom = c(\"Sylvie\", \"Sylvie\", \"Monique\", \"Gunter\", \"Rayan\", \"Rayan\"),\n  voiture = c(\"Twingo\", \"Ferrari\", \"Scenic\", \"Lada\", \"Twingo\", \"Clio\")\n)\npersonnes\n\n# A tibble: 6 × 2\n  nom     voiture\n  &lt;chr&gt;   &lt;chr&gt;  \n1 Sylvie  Twingo \n2 Sylvie  Ferrari\n3 Monique Scenic \n4 Gunter  Lada   \n5 Rayan   Twingo \n6 Rayan   Clio   \n\n\n\nvoitures &lt;- tibble(\n  voiture = c(\"Twingo\", \"Ferrari\", \"Clio\", \"Lada\", \"208\"),\n  vitesse = c(\"140\", \"280\", \"160\", \"85\", \"160\")\n)\nvoitures\n\n# A tibble: 5 × 2\n  voiture vitesse\n  &lt;chr&gt;   &lt;chr&gt;  \n1 Twingo  140    \n2 Ferrari 280    \n3 Clio    160    \n4 Lada    85     \n5 208     160    \n\n\n\n33.1.3.1 left_join()\n\nSi on fait un dplyr::left_join() de voitures sur personnes :\n\npersonnes |&gt; left_join(voitures, by = \"voiture\")\n\n# A tibble: 6 × 3\n  nom     voiture vitesse\n  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n1 Sylvie  Twingo  140    \n2 Sylvie  Ferrari 280    \n3 Monique Scenic  &lt;NA&gt;   \n4 Gunter  Lada    85     \n5 Rayan   Twingo  140    \n6 Rayan   Clio    160    \n\n\nOn voit que chaque ligne de personnes est bien présente, et qu’on lui a ajouté une ligne de voitures correspondante si elle existe. Dans le cas du Scenic, il n’y a avait pas de ligne dans voitures, donc vitesse a été peuplée avec la valeur manquante NA. Dans le cas de la 208, présente dans voitures mais pas dans personnes, la ligne n’apparaît pas.\nLa clé de fusion étant unique dans la table de droite, le nombre de lignes de la table de gauche est donc bien préservée.\n\npersonnes |&gt; nrow()\n\n[1] 6\n\npersonnes |&gt; left_join(voitures, by = \"voiture\") |&gt; nrow()\n\n[1] 6\n\n\nSi on fait un dplyr::left_join() cette fois de personnes sur voitures, c’est l’inverse :\n\nvoitures |&gt; left_join(personnes, by = \"voiture\")\n\n# A tibble: 6 × 3\n  voiture vitesse nom   \n  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt; \n1 Twingo  140     Sylvie\n2 Twingo  140     Rayan \n3 Ferrari 280     Sylvie\n4 Clio    160     Rayan \n5 Lada    85      Gunter\n6 208     160     &lt;NA&gt;  \n\n\nLa ligne 208 est bien là avec la variable nom remplie avec une valeur manquante NA. Par contre Monique est absente.\n\n\n\n\n\n\nImportant\n\n\n\nOn remarquera que la ligne Twingo, présente deux fois dans personnes, a été dupliquée pour être associée aux deux lignes de données de Sylvie et Rayan. Autrement dit, si la clé de fusion n’est pas unique dans la table de droite, certaines de lignes de la table de gauche seront dupliquées.\nEn résumé, quand on fait un left_join(x, y), toutes les lignes de x sont présentes, et dupliquées si nécessaire quand elles apparaissent plusieurs fois dans y. Les lignes de y non présentes dans x disparaissent. Les lignes de x non présentes dans y se voient attribuer des valeurs manquantes NA pour les nouvelles colonnes.\n\n\nIntuitivement, on pourrait considérer que left_join(x, y) signifie ramener l’information de la table y sur la table x.\nEn général, dplyr::left_join() sera le type de jointures le plus fréquemment utilisé.\n\n33.1.3.2 right_join()\n\nLa jointure dplyr::right_join() est l’exacte symétrique de dplyr::left_join(), c’est-à dire que x |&gt; right_join(y) est équivalent1 à y |&gt; left_join(x) :\n1 À l’exception de l’ordre des variables dans le tableau final.\npersonnes |&gt; right_join(voitures, by = \"voiture\")\n\n# A tibble: 6 × 3\n  nom    voiture vitesse\n  &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;  \n1 Sylvie Twingo  140    \n2 Sylvie Ferrari 280    \n3 Gunter Lada    85     \n4 Rayan  Twingo  140    \n5 Rayan  Clio    160    \n6 &lt;NA&gt;   208     160    \n\nvoitures |&gt; left_join(personnes, by = \"voiture\")\n\n# A tibble: 6 × 3\n  voiture vitesse nom   \n  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt; \n1 Twingo  140     Sylvie\n2 Twingo  140     Rayan \n3 Ferrari 280     Sylvie\n4 Clio    160     Rayan \n5 Lada    85      Gunter\n6 208     160     &lt;NA&gt;  \n\n\n\n33.1.3.3 inner_join()\n\nDans le cas de dplyr::inner_join(), seules les lignes présentes à la fois dans x et y sont présentes (et si nécessaire dupliquées) dans la table résultat :\n\npersonnes |&gt; inner_join(voitures, by = \"voiture\")\n\n# A tibble: 5 × 3\n  nom    voiture vitesse\n  &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;  \n1 Sylvie Twingo  140    \n2 Sylvie Ferrari 280    \n3 Gunter Lada    85     \n4 Rayan  Twingo  140    \n5 Rayan  Clio    160    \n\n\nIci la ligne 208 est absente, ainsi que la ligne Monique, qui dans le cas d’un dplyr::left_join() avait été conservée et s’était vue attribuer NA à vitesse.\n\n33.1.3.4 full_join()\n\nDans le cas de dplyr::full_join(), toutes les lignes de x et toutes les lignes de y sont conservées (avec des NA ajoutés si nécessaire) même si elles sont absentes de l’autre table :\n\npersonnes |&gt; full_join(voitures, by = \"voiture\")\n\n# A tibble: 7 × 3\n  nom     voiture vitesse\n  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n1 Sylvie  Twingo  140    \n2 Sylvie  Ferrari 280    \n3 Monique Scenic  &lt;NA&gt;   \n4 Gunter  Lada    85     \n5 Rayan   Twingo  140    \n6 Rayan   Clio    160    \n7 &lt;NA&gt;    208     160    \n\n\n\n33.1.3.5 semi_join() et anti_join()\n\ndplyr::semi_join() et dplyr::anti_join() sont des jointures filtrantes, c’est-à-dire qu’elles sélectionnent les lignes de x sans ajouter les colonnes de y.\nAinsi, dplyr::semi_join() ne conservera que les lignes de x pour lesquelles une ligne de y existe également, et supprimera les autres. Dans notre exemple, la ligne Monique est donc supprimée :\n\npersonnes |&gt; semi_join(voitures, by = \"voiture\")\n\n# A tibble: 5 × 2\n  nom    voiture\n  &lt;chr&gt;  &lt;chr&gt;  \n1 Sylvie Twingo \n2 Sylvie Ferrari\n3 Gunter Lada   \n4 Rayan  Twingo \n5 Rayan  Clio   \n\n\nUn dplyr::anti_join() fait l’inverse, il ne conserve que les lignes de x absentes de y. Dans notre exemple, on ne garde donc que la ligne Monique :\n\npersonnes |&gt; anti_join(voitures, by = \"voiture\")\n\n# A tibble: 1 × 2\n  nom     voiture\n  &lt;chr&gt;   &lt;chr&gt;  \n1 Monique Scenic",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Fusion de tables</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/fusion-tables.html#jointures-avec-merge",
    "href": "manipulation_avancee/fusion-tables.html#jointures-avec-merge",
    "title": "33  Fusion de tables",
    "section": "\n33.2 Jointures avec merge()\n",
    "text": "33.2 Jointures avec merge()\n\nLa fonction merge() est la fonction de R base pour fusionner des tables entre elles.\nPar défaut, elle réalise un inner join, c’est-à-dire qu’elle ne garde que les observations dont la clé est retrouvée dans les deux tableaux fusionnés\n\nmerge(personnes, voitures, by = \"voiture\")\n\n  voiture    nom vitesse\n1    Clio  Rayan     160\n2 Ferrari Sylvie     280\n3    Lada Gunter      85\n4  Twingo Sylvie     140\n5  Twingo  Rayan     140\n\n\nLes paramètres all.x et all.y permettent de réaliser fusions à gauche, à droite ou complète. L’équivalent de dplyr::left_join() sera obtenu avec all.x = TRUE, celui de dplyr::right_join() avec all.y = TRUE et celui de dplyr::full_join() avec all.x = TRUE, all.y = TRUE.\n\nmerge(personnes, voitures, by = \"voiture\", all.x = TRUE)\n\n  voiture     nom vitesse\n1    Clio   Rayan     160\n2 Ferrari  Sylvie     280\n3    Lada  Gunter      85\n4  Scenic Monique    &lt;NA&gt;\n5  Twingo  Sylvie     140\n6  Twingo   Rayan     140\n\npersonnes |&gt; left_join(voitures)\n\nJoining with `by = join_by(voiture)`\n\n\n# A tibble: 6 × 3\n  nom     voiture vitesse\n  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n1 Sylvie  Twingo  140    \n2 Sylvie  Ferrari 280    \n3 Monique Scenic  &lt;NA&gt;   \n4 Gunter  Lada    85     \n5 Rayan   Twingo  140    \n6 Rayan   Clio    160",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Fusion de tables</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/fusion-tables.html#ajouter-des-observations-avec-bind_rows",
    "href": "manipulation_avancee/fusion-tables.html#ajouter-des-observations-avec-bind_rows",
    "title": "33  Fusion de tables",
    "section": "\n33.3 Ajouter des observations avec bind_rows()\n",
    "text": "33.3 Ajouter des observations avec bind_rows()\n\n\nLa fonction base::rbind(), fournie nativement avec R pour ajouter des observations à un tableau, doit être évitée car elle générera des résultats non pertinents si les tableaux que l’on concatènent n’ont pas exactement les mêmes colonnes dans le même ordre.\n\nLa fonction dplyr::bind_rows() de dplyr permet d’ajouter des lignes à une table à partir d’une ou plusieurs autres tables.\nL’exemple suivant (certes très artificiel) montre l’utilisation de dplyr::bind_rows(). On commence par créer trois tableaux t1, t2 et t3 :\n\nt1 &lt;- airports |&gt; \n  select(faa, name, lat, lon) |&gt; \n  slice(1:2)\nt1\n\n# A tibble: 2 × 4\n  faa   name                            lat   lon\n  &lt;chr&gt; &lt;chr&gt;                         &lt;dbl&gt; &lt;dbl&gt;\n1 04G   Lansdowne Airport              41.1 -80.6\n2 06A   Moton Field Municipal Airport  32.5 -85.7\n\n\n\nt2 &lt;- airports |&gt; \n  select(name, faa, lon, lat) |&gt; \n  slice(5:6)\n\nt2\n\n# A tibble: 2 × 4\n  name                           faa     lon   lat\n  &lt;chr&gt;                          &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Jekyll Island Airport          09J   -81.4  31.1\n2 Elizabethton Municipal Airport 0A9   -82.2  36.4\n\n\n\nt3 &lt;- airports |&gt; \n  select(faa, name) |&gt; \n  slice(100:101)\nt3\n\n# A tibble: 2 × 2\n  faa   name             \n  &lt;chr&gt; &lt;chr&gt;            \n1 ADW   Andrews Afb      \n2 AET   Allakaket Airport\n\n\nOn concatène ensuite les trois tables avec dplyr::bind_rows() :\n\nbind_rows(t1, t2, t3)\n\n# A tibble: 6 × 4\n  faa   name                             lat   lon\n  &lt;chr&gt; &lt;chr&gt;                          &lt;dbl&gt; &lt;dbl&gt;\n1 04G   Lansdowne Airport               41.1 -80.6\n2 06A   Moton Field Municipal Airport   32.5 -85.7\n3 09J   Jekyll Island Airport           31.1 -81.4\n4 0A9   Elizabethton Municipal Airport  36.4 -82.2\n5 ADW   Andrews Afb                     NA    NA  \n6 AET   Allakaket Airport               NA    NA  \n\n\nOn remarquera que si des colonnes sont manquantes pour certaines tables, comme les colonnes lat et lon de t3, des valeurs manquantes NA sont automatiquement insérées.\nDe plus, peu importe l’ordre des variables entre les différentes tables, dplyr::bind_rows() les ré-associera en considérant que deux colonnes ayant le même nom dans deux tableaux correspondent à la même variable.\nIl peut être utile, quand on concatène des lignes, de garder une trace du tableau d’origine de chacune des lignes dans le tableau final. C’est possible grâce à l’argument .id de dplyr::bind_rows(). On passe à cet argument le nom d’une colonne qui contiendra l’indicateur d’origine des lignes :\n\nbind_rows(t1, t2, t3, .id = \"source\")\n\n# A tibble: 6 × 5\n  source faa   name                             lat   lon\n  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;                          &lt;dbl&gt; &lt;dbl&gt;\n1 1      04G   Lansdowne Airport               41.1 -80.6\n2 1      06A   Moton Field Municipal Airport   32.5 -85.7\n3 2      09J   Jekyll Island Airport           31.1 -81.4\n4 2      0A9   Elizabethton Municipal Airport  36.4 -82.2\n5 3      ADW   Andrews Afb                     NA    NA  \n6 3      AET   Allakaket Airport               NA    NA  \n\n\nPar défaut la colonne .id ne contient qu’un nombre, différent pour chaque tableau. On peut lui spécifier des valeurs plus explicites en “nommant” les tables dans dplyr::bind_rows() de la manière suivante :\n\nbind_rows(table1 = t1, table2 = t2, table3 = t3, .id = \"source\")\n\n# A tibble: 6 × 5\n  source faa   name                             lat   lon\n  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;                          &lt;dbl&gt; &lt;dbl&gt;\n1 table1 04G   Lansdowne Airport               41.1 -80.6\n2 table1 06A   Moton Field Municipal Airport   32.5 -85.7\n3 table2 09J   Jekyll Island Airport           31.1 -81.4\n4 table2 0A9   Elizabethton Municipal Airport  36.4 -82.2\n5 table3 ADW   Andrews Afb                     NA    NA  \n6 table3 AET   Allakaket Airport               NA    NA  \n\n\n\nUne alternative à dplyr::bind_rows() est la fonction plyr::rbind.fill() de l’extension plyr qui fonctionne de manière similaire.",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Fusion de tables</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/dates.html",
    "href": "manipulation_avancee/dates.html",
    "title": "34  Dates avec lubridate",
    "section": "",
    "text": "34.1 Création de dates / de dates-heures\nIl existe trois types de variables pour représenter des dates et des heures :\nLes classes Date et POSIXct sont gérées nativement par R tandis que la classe hms est fournies par le package homonyme hms. Cette dernière classe est d’un usage plus spécifique. Dans cette section, nous allons nous concentrer sur les dates et les dates-heures.\nIl est toujours préférable d’utiliser la classe la plus simple. Si vous gérez uniquement des dates, privilégiez la classe Date. La classe POSIXct, plus complexe, permet d’ajouter une heure associée à un fuseau horaire.\nPour obtenir la date ou la date-heure courante, vous pouvez appeler today() ou now() :\ntoday()\n\n[1] \"2024-08-26\"\n\nnow()\n\n[1] \"2024-08-26 18:00:33 CEST\"",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Dates avec `lubridate`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/dates.html#création-de-dates-de-dates-heures",
    "href": "manipulation_avancee/dates.html#création-de-dates-de-dates-heures",
    "title": "34  Dates avec lubridate",
    "section": "",
    "text": "une date, de la classe Date et représentée dans un tibble avec &lt;date&gt;\nune heure, de la classe hms et représentée dans un tibble avec &lt;time&gt;\nune date-heure, de la classe POSIXct et représentée dans un tibble avec &lt;dttm&gt;\n\n\n\n\n\n\n34.1.1 lors de l’import d’un fichier CSV\nSi le fichier CSV contient des dates ou des dates-heures au format ISO8601, readr::read_csv() saura les reconnaître automatiquement :\n\ncsv &lt;- \"\n  date,datetime\n  2022-01-02,2022-01-02 05:12\n\"\nread_csv(csv)\n\n# A tibble: 1 × 2\n  date       datetime           \n  &lt;date&gt;     &lt;dttm&gt;             \n1 2022-01-02 2022-01-02 05:12:00\n\n\n\n\n\n\n\n\nAstuce\n\n\n\nLe format ISO8601 est un standard international pour l’écriture de dates1 sous la forme AAAA-MM-JJ afin d’éviter la confusion entre les habitudes de différents pays, par exemple JJ/MM/AAAA en France ou MM/JJ/AA dans les pays anglo-saxons.\n\n\n1 https://xkcd.com/1179/2 La spécification complète est décrite dans l’aide de la fonction strptime().Pour les autres formats, non standards, il sera nécessaire d’utiliser col_types avec col_date() pour spécifier comme lire et interpréter les chaînes de caractères. readr comprend la spécification POSIX qui permet de décrire une format de date2. Il s’agit de codes commençant par le symbole % et indiquant un composant d’une date. Par exemple, %Y-%m-%d correspond au format ISO8601, par exemple 2023-10-03 pour le 3 octobre 2023. Le tableau Table 34.1 liste les principales options.\n\n\n\n\n\n\n\n\n\n\nType\nCode\nSignification\nExemple\n\n\n\nAnnée\n%Y\nannée sur 4 chiffres\n2021\n\n\n\n%y\nannée sur 2 chiffres\n21\n\n\nMois\n%m\nnuméro du mois\n2\n\n\n\n%b\nnom abrégé\nFeb\n\n\n\n%B\nnom complet\nFebruary\n\n\nJour\n%d\njour sur 2 chiffres\n02\n\n\n\n%e\njour sur 1 ou 2 chiffres\n2\n\n\nHeure\n%H\nheure sur 24 heures\n13\n\n\n\n%I\nheure sur 12 heures\n1\n\n\n\n%p\nAM ou PM\npm\n\n\nMinute\n%M\nminutes\n35\n\n\nSeconde\n%S\nsecondes\n45\n\n\n\n%OS\nsecondes avec une composante décimale\n45.35\n\n\nFuseau horaire\n%Z\nnom du fuseau\nAmerica/Chicago\n\n\n\n%z\ndécalage du fuseau par rapport au temps universel UTC\n+0800\n\n\nAutre\n%.\nsauter un caractère (autre qu’un chiffre)\n:\n\n\n\n%*\nsauter un nombre quelconque de caractères (autres qu’un chiffre)\n\n\n\n\n\n\nTable 34.1: Les formats de dates compris par readr\n\n\nEt voici un exemple de code induisant une lecture différente d’une date ambiguë.\n\ncsv &lt;- \"\n  date\n  01/02/15\n\"\n\nread_csv(csv, col_types = cols(date = col_date(\"%m/%d/%y\")))\n\n# A tibble: 1 × 1\n  date      \n  &lt;date&gt;    \n1 2015-01-02\n\nread_csv(csv, col_types = cols(date = col_date(\"%d/%m/%y\")))\n\n# A tibble: 1 × 1\n  date      \n  &lt;date&gt;    \n1 2015-02-01\n\nread_csv(csv, col_types = cols(date = col_date(\"%y/%m/%d\")))\n\n# A tibble: 1 × 1\n  date      \n  &lt;date&gt;    \n1 2001-02-15\n\n\nQuel que soit le format original, les dates importées seront toujours affichées par R au format ISO.\n\n\n\n\n\n\nAstuce\n\n\n\nSi vous utilisez %b ou %B, il est essentiel de spécifier la langue utilisée avec le paramètre local de col_date(). Pour voir l’ensemble des langues couvertes, vous pouvez appelez readr::date_names_langs() et pour voir les chaînes de langues correspondantes readr::date_names_lang(). Si vos données n’utilise pas des noms standards, vous pouvez créer votre propre jeu de correspondance avec readr::date_names().\n\ndate_names_langs()\n\n  [1] \"af\"  \"agq\" \"ak\"  \"am\"  \"ar\"  \"as\"  \"asa\" \"az\"  \"bas\" \"be\"  \"bem\" \"bez\"\n [13] \"bg\"  \"bm\"  \"bn\"  \"bo\"  \"br\"  \"brx\" \"bs\"  \"ca\"  \"cgg\" \"chr\" \"cs\"  \"cy\" \n [25] \"da\"  \"dav\" \"de\"  \"dje\" \"dsb\" \"dua\" \"dyo\" \"dz\"  \"ebu\" \"ee\"  \"el\"  \"en\" \n [37] \"eo\"  \"es\"  \"et\"  \"eu\"  \"ewo\" \"fa\"  \"ff\"  \"fi\"  \"fil\" \"fo\"  \"fr\"  \"fur\"\n [49] \"fy\"  \"ga\"  \"gd\"  \"gl\"  \"gsw\" \"gu\"  \"guz\" \"gv\"  \"ha\"  \"haw\" \"he\"  \"hi\" \n [61] \"hr\"  \"hsb\" \"hu\"  \"hy\"  \"id\"  \"ig\"  \"ii\"  \"is\"  \"it\"  \"ja\"  \"jgo\" \"jmc\"\n [73] \"ka\"  \"kab\" \"kam\" \"kde\" \"kea\" \"khq\" \"ki\"  \"kk\"  \"kkj\" \"kl\"  \"kln\" \"km\" \n [85] \"kn\"  \"ko\"  \"kok\" \"ks\"  \"ksb\" \"ksf\" \"ksh\" \"kw\"  \"ky\"  \"lag\" \"lb\"  \"lg\" \n [97] \"lkt\" \"ln\"  \"lo\"  \"lt\"  \"lu\"  \"luo\" \"luy\" \"lv\"  \"mas\" \"mer\" \"mfe\" \"mg\" \n[109] \"mgh\" \"mgo\" \"mk\"  \"ml\"  \"mn\"  \"mr\"  \"ms\"  \"mt\"  \"mua\" \"my\"  \"naq\" \"nb\" \n[121] \"nd\"  \"ne\"  \"nl\"  \"nmg\" \"nn\"  \"nnh\" \"nus\" \"nyn\" \"om\"  \"or\"  \"os\"  \"pa\" \n[133] \"pl\"  \"ps\"  \"pt\"  \"qu\"  \"rm\"  \"rn\"  \"ro\"  \"rof\" \"ru\"  \"rw\"  \"rwk\" \"sah\"\n[145] \"saq\" \"sbp\" \"se\"  \"seh\" \"ses\" \"sg\"  \"shi\" \"si\"  \"sk\"  \"sl\"  \"smn\" \"sn\" \n[157] \"so\"  \"sq\"  \"sr\"  \"sv\"  \"sw\"  \"ta\"  \"te\"  \"teo\" \"th\"  \"ti\"  \"to\"  \"tr\" \n[169] \"twq\" \"tzm\" \"ug\"  \"uk\"  \"ur\"  \"uz\"  \"vai\" \"vi\"  \"vun\" \"wae\" \"xog\" \"yav\"\n[181] \"yi\"  \"yo\"  \"zgh\" \"zh\"  \"zu\" \n\ndate_names_lang(\"fr\")\n\n&lt;date_names&gt;\nDays:   dimanche (dim.), lundi (lun.), mardi (mar.), mercredi (mer.), jeudi\n        (jeu.), vendredi (ven.), samedi (sam.)\nMonths: janvier (janv.), février (févr.), mars (mars), avril (avr.), mai (mai),\n        juin (juin), juillet (juil.), août (août), septembre (sept.),\n        octobre (oct.), novembre (nov.), décembre (déc.)\nAM/PM:  AM/PM\n\ndate_names_lang(\"en\")\n\n&lt;date_names&gt;\nDays:   Sunday (Sun), Monday (Mon), Tuesday (Tue), Wednesday (Wed), Thursday\n        (Thu), Friday (Fri), Saturday (Sat)\nMonths: January (Jan), February (Feb), March (Mar), April (Apr), May (May),\n        June (Jun), July (Jul), August (Aug), September (Sep), October\n        (Oct), November (Nov), December (Dec)\nAM/PM:  AM/PM\n\ncsv &lt;- \"date\n3 de febrero de 2001\"\n\nread_csv(\n  csv,\n  col_types = cols(date = col_date(\"%d de %B de %Y\")),\n  locale = locale(\"es\")\n)\n\n# A tibble: 1 × 1\n  date      \n  &lt;date&gt;    \n1 2001-02-03\n\n\n\n\n\n34.1.2 à partir d’une chaîne de caractères\nLe langage de spécification de la date et du temps est puissant, mais il nécessite une analyse minutieuse du format de la date. Une autre approche consiste à utiliser les fonctions de lubridate qui tentent de déterminer automatiquement le format une fois que vous avez spécifié l’ordre des composants. Pour les utiliser, identifiez l’ordre dans lequel l’année, le mois et le jour apparaissent dans vos dates, puis placez “y”, “m” et “d” dans le même ordre. Cela vous donne le nom de la fonction lubridate qui analysera votre date. Par exemple :\n\nymd(\"2017-01-31\")\n\n[1] \"2017-01-31\"\n\nmdy(\"January 31st, 2017\")\n\n[1] \"2017-01-31\"\n\ndmy(\"31-Jan-2017\")\n\n[1] \"2017-01-31\"\n\n\nymd() et ses sœurs créent des dates. Pour des dates-heures, ajoutez un tiret bas et les lettres “h”, “m” et/ou “s” :\n\nymd_hms(\"2017-01-31 20:11:59\")\n\n[1] \"2017-01-31 20:11:59 UTC\"\n\nmdy_hm(\"01/31/2017 08:01\")\n\n[1] \"2017-01-31 08:01:00 UTC\"\n\n\n\n34.1.3 à partir des composants\nParfois, les différentes composantes d’une date (jour, mois, année…) sont stockées dans des colonnes séparées. C’est le cas par exemple dans la table flights issue du package nycflights13.\n\nflights |&gt; \n  select(year, month, day, hour, minute) |&gt; \n  head()\n\n# A tibble: 6 × 5\n   year month   day  hour minute\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1  2013     1     1     5     15\n2  2013     1     1     5     29\n3  2013     1     1     5     40\n4  2013     1     1     5     45\n5  2013     1     1     6      0\n6  2013     1     1     5     58\n\n\nPour créer une date ou une date-heure à partir de colonnes séparées, il suffit d’utiliser lubridate::make_date() pour les dates et lubridate::make_datetime() pour les dates-heures :\n\nflights |&gt; \n  select(year, month, day, hour, minute) |&gt; \n  mutate(\n    departure = make_datetime(year, month, day, hour, minute),\n    departure_date = make_date(year, month, day)\n  ) |&gt; \n  head()\n\n# A tibble: 6 × 7\n   year month   day  hour minute departure           departure_date\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dttm&gt;              &lt;date&gt;        \n1  2013     1     1     5     15 2013-01-01 05:15:00 2013-01-01    \n2  2013     1     1     5     29 2013-01-01 05:29:00 2013-01-01    \n3  2013     1     1     5     40 2013-01-01 05:40:00 2013-01-01    \n4  2013     1     1     5     45 2013-01-01 05:45:00 2013-01-01    \n5  2013     1     1     6      0 2013-01-01 06:00:00 2013-01-01    \n6  2013     1     1     5     58 2013-01-01 05:58:00 2013-01-01    \n\n\n\n34.1.4 conversion\nPour convertir une date en date-heure, ou l’inverse, utilisez lubridate::as_datetime() ou lubridate::as_date() :\n\nas_datetime(today())\n\n[1] \"2024-08-26 UTC\"\n\nas_date(now())\n\n[1] \"2024-08-26\"",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Dates avec `lubridate`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/dates.html#manipuler-les-composants-dune-datedate-heure",
    "href": "manipulation_avancee/dates.html#manipuler-les-composants-dune-datedate-heure",
    "title": "34  Dates avec lubridate",
    "section": "\n34.2 Manipuler les composants d’une date/date-heure",
    "text": "34.2 Manipuler les composants d’une date/date-heure\n\n34.2.1 Extraire un composant\nPour extraire un composant d’une date ou d’une date-heure, il suffit d’utiliser l’une des fonctions suivantes : year() (année), month() (mois), mday() (jour du mois), yday() (jours de l’année), wday() (jour de la semaine), hour() (heure), minute() (minute), ou second() (seconde).\n\ndatetime &lt;- ymd_hms(\"2026-07-08 12:34:56\")\n\nyear(datetime)\n\n[1] 2026\n\nmonth(datetime)\n\n[1] 7\n\nmday(datetime)\n\n[1] 8\n\nyday(datetime)\n\n[1] 189\n\nwday(datetime)\n\n[1] 4\n\n\nPour month() et wday(), vous pouvez indiquer label = TRUE pour récupérer le nom abrégé du mois ou du jours de la semaine. Ajoutez abbr = FALSE pour le nom complet.\n\nmonth(datetime, label = TRUE)\n\n[1] juil\n12 Levels: janv &lt; févr &lt; mars &lt; avr &lt; mai &lt; juin &lt; juil &lt; août &lt; ... &lt; déc\n\nwday(datetime, label = TRUE, abbr = FALSE)\n\n[1] mercredi\n7 Levels: dimanche &lt; lundi &lt; mardi &lt; mercredi &lt; jeudi &lt; ... &lt; samedi\n\n\nLes noms sont affichés dans la langue de votre ordinateur. On peut utiliser le paramètre locale pour changer la langue. Attention : le code peut varier selon votre système d’exploitation. Vous pouvez essayer déjà de simplement indiquer le code à 2 lettres de la langue visée, par exemple \"de\" pour l’allemand. Si cela ne fonctionne pas, essayez \"de_DE\" (allemand utilisé en Allemagne), \"de_DE.UTF-8\" (format utilisé par MacOS et plusieurs distributions Linux), la variante \"de_DE.utf8\" (utilisée par certaines distributions Linux) ou bien encore \"German.UTF-8\" (utilisé par Windows).\n\nmonth(datetime, label = TRUE, abbr = FALSE, locale = \"en\")\n\n[1] July\n12 Levels: January &lt; February &lt; March &lt; April &lt; May &lt; June &lt; ... &lt; December\n\nmonth(datetime, label = TRUE, abbr = FALSE, locale = \"es_ES.utf8\")\n\n[1] julio\n12 Levels: enero &lt; febrero &lt; marzo &lt; abril &lt; mayo &lt; junio &lt; ... &lt; diciembre\n\nmonth(datetime, label = TRUE, abbr = FALSE, locale = \"German.UTF-8\")\n\n[1] Juli\n12 Levels: Januar &lt; Februar &lt; März &lt; April &lt; Mai &lt; Juni &lt; Juli &lt; ... &lt; Dezember\n\n\n\n34.2.2 Arrondis\nLes fonctions lubridate::round_date(), lubridate::floor_date() et lubridate::ceiling_date() permettent d’arrondir une date à l’unité la plus proche, inférieure ou supérieure. On devra préciser avec unit l’unité utilisée pour arrondir. Les valeurs acceptées sont \"second\", \"minute\", \"hour\", \"day\", \"week\", \"month\", \"bimonth\" (bimestre, i.e. période de 2 mois), \"quarter\" (trimestre), season (saison), halfyear (semestre) et year, ou un multiple de ces valeurs.\n\nd &lt;- ymd(\"2022-05-14\")\nfloor_date(d, unit = \"week\")\n\n[1] \"2022-05-08\"\n\nfloor_date(d, unit = \"month\")\n\n[1] \"2022-05-01\"\n\nfloor_date(d, unit = \"3 months\")\n\n[1] \"2022-04-01\"\n\nfloor_date(d, unit = \"year\")\n\n[1] \"2022-01-01\"\n\n\n\n34.2.3 Modifier un composant\nLes mêmes fonctions peuvent être utilisées pour modifier un composant particulier d’une date-heure.\n\ndatetime &lt;- ymd_hms(\"2026-07-08 12:34:56\")\n\nyear(datetime) &lt;- 2030\ndatetime\n\n[1] \"2030-07-08 12:34:56 UTC\"\n\nmonth(datetime) &lt;- 01\ndatetime\n\n[1] \"2030-01-08 12:34:56 UTC\"\n\nhour(datetime) &lt;- hour(datetime) + 1\ndatetime\n\n[1] \"2030-01-08 13:34:56 UTC\"\n\n\nUne alternative, plutôt que de modifier une date-heure, consiste à créer une copie modifiée avec lubridate::update(). Cela permet également de modifier plusieurs éléments à la fois :\n\nupdate(datetime, year = 2030, month = 2, mday = 2, hour = 2)\n\n[1] \"2030-02-02 02:34:56 UTC\"\n\n\nSi les valeurs sont trop importantes (trop de jours par exemple), la fonction ajoutera les unités en trop pour générer une date valide :\n\nupdate(ymd(\"2023-02-01\"), mday = 30)\n\n[1] \"2023-03-02\"\n\nupdate(ymd(\"2023-02-01\"), hour = 400)\n\n[1] \"2023-02-17 16:00:00 UTC\"",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Dates avec `lubridate`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/dates.html#durées-périodes-intervalles-arithmétique",
    "href": "manipulation_avancee/dates.html#durées-périodes-intervalles-arithmétique",
    "title": "34  Dates avec lubridate",
    "section": "\n34.3 Durées, périodes, intervalles & Arithmétique",
    "text": "34.3 Durées, périodes, intervalles & Arithmétique\nIl existe plusieurs manières de représenter les intervalles de temps entre deux dates :\n\nles durées (Duration), qui représentent un nombre exact de secondes ;\nles périodes (Periods), qui représentent une durée sous la forme d’unités de temps telles que des semaines ou des mois ;\nles intervalles (Intervals), qui sont définis par une date-heure de début et une date-heure de fin.\n\n\n34.3.1 Durées (Duration)\nAvec R, lorsque l’on soustrait deux dates, on obtient un objet de la classe difftime.\n\ndiff &lt;- ymd(\"2021-06-30\") - ymd(\"1979-10-14\")\ndiff\n\nTime difference of 15235 days\n\n\nUn objet difftime enregistre une durée sous la forme d’un nombre de secondes, de minutes, d’heures, de jours ou de semaines. Du fait de variations de l’unité d’un objet à l’autre, ils ne sont pas toujours faciles à manipuler. Pour lever toute ambiguïté, on préférera les objets de la classe Duration qui stockent les durées sous la forme d’un nombre de secondes. La conversion peut se faire avec lubridate::as.duration().\n\nas.duration(diff)\n\n[1] \"1316304000s (~41.71 years)\"\n\n\nIl est possible de créer facilement des durées avec une série de fonctions dédiées dont le nom commence par \"d\"\n\ndseconds(15)\n\n[1] \"15s\"\n\ndminutes(10)\n\n[1] \"600s (~10 minutes)\"\n\ndhours(c(12, 24))\n\n[1] \"43200s (~12 hours)\" \"86400s (~1 days)\"  \n\nddays(0:5)\n\n[1] \"0s\"                \"86400s (~1 days)\"  \"172800s (~2 days)\"\n[4] \"259200s (~3 days)\" \"345600s (~4 days)\" \"432000s (~5 days)\"\n\ndweeks(3)\n\n[1] \"1814400s (~3 weeks)\"\n\ndyears(1)\n\n[1] \"31557600s (~1 years)\"\n\n\nLes durées sont toujours exprimées en secondes. Des unités plus grandes sont créées en convertissant les minutes, les heures, les jours, les semaines et les années en secondes : 60 secondes dans une minute, 60 minutes dans une heure, 24 heures dans un jour et 7 jours dans une semaine. Les unités de temps plus grandes posent davantage de problèmes. Une année utilise le nombre « moyen » de jours dans une année, c’est-à-dire 365,25. Il n’existe aucun moyen de convertir un mois en durée, car les variations sont trop importantes.\nIl est possible d’additionner et de multiplier les durées :\n\n2 * dyears(1)\n\n[1] \"63115200s (~2 years)\"\n\ndyears(1) + dweeks(12) + dhours(15)\n\n[1] \"38869200s (~1.23 years)\"\n\n\nOn peut ajouter ou soustraire des durées à une date.\n\ndemain &lt;- today() + ddays(1)\nil_y_a_un_an &lt;- today() - dyears(1)\n\nCependant, comme les durées représentent un nombre exact de secondes, vous pouvez parfois obtenir un résultat inattendu :\n\none_am &lt;- ymd_hms(\"2026-03-08 01:00:00\", tz = \"America/New_York\")\n\none_am\n\n[1] \"2026-03-08 01:00:00 EST\"\n\none_am + ddays(1)\n\n[1] \"2026-03-09 02:00:00 EDT\"\n\n\nPourquoi lorsqu’on ajoute un jour, on passe de 1 heure du matin à 2 heures du matin ? Si vous regardez attentivement la date, vous remarquerez que le fuseau a changé. Le 8 mars 2026 n’aura que 23 heures aux États-Unis en raison du passage à l’heure d’été. En ajoutant une durée de 1 jour, nous avons ajouté exactement 24 heures. Le même type de phénomène peut s’observer en ajoutant une durée d’une année, car on considère que cela représente en moyenne 365.25 jours.\n\n34.3.2 Périodes (Period)\nPour résoudre ce problème, lubridate a introduit les périodes (de classe Period) qui représentent une durée en nombre de secondes, minutes, heures, jours, mois et années, sans préciser la durée exacte de chaque mois ou année. Cela permet de faire des calculs plus intuitifs :\n\none_am\n\n[1] \"2026-03-08 01:00:00 EST\"\n\none_am + days(1)\n\n[1] \"2026-03-09 01:00:00 EDT\"\n\n\nComme pour les durées, on peut créer facilement des périodes avec des fonctions dédiées (notez ici le pluriel des noms de fonction, alors que celles permettant d’extraire un composant d’une date étaient au singulier) :\n\nhours(c(12, 24))\n\n[1] \"12H 0M 0S\" \"24H 0M 0S\"\n\ndays(7)\n\n[1] \"7d 0H 0M 0S\"\n\nmonths(1:6)\n\n[1] \"1m 0d 0H 0M 0S\" \"2m 0d 0H 0M 0S\" \"3m 0d 0H 0M 0S\" \"4m 0d 0H 0M 0S\"\n[5] \"5m 0d 0H 0M 0S\" \"6m 0d 0H 0M 0S\"\n\n\nOn peut ajouter, soustraire et multiplier les périodes entre elles.\n\n10 * (months(6) + days(1))\n\n[1] \"60m 10d 0H 0M 0S\"\n\ndays(50) + hours(25) + minutes(2)\n\n[1] \"50d 25H 2M 0S\"\n\n\nBien sûr, on peut ajouter ou soustraire une période à une date :\n\n# Exemple avec une année bissextile\nymd(\"2024-01-01\") + dyears(1)\n\n[1] \"2024-12-31 06:00:00 UTC\"\n\nymd(\"2024-01-01\") + years(1)\n\n[1] \"2025-01-01\"\n\n# Exemple avec un passage à l'heure d'été\none_am + ddays(1)\n\n[1] \"2026-03-09 02:00:00 EDT\"\n\none_am + days(1)\n\n[1] \"2026-03-09 01:00:00 EDT\"\n\n\nRestent malgré tout quelques cas problématiques. Essayons d’ajouter 1 mois à la date du 31 janvier 2021.\n\nymd(\"2021-01-31\") + months(1)\n\n[1] NA\n\n\nCe calcul a jouté 1 au mois, sans toucher à l’année ni au jour, produisant la date du 31 février 2021 qui n’existe pas, produisant ainsi NA. Pour du calcul impliquant des dates et des périodes, il est préférable d’utiliser les opérateurs dédiés %m+% pour l’addition et %m-% pour la soustraction.\n\nymd(\"2021-01-31\") %m+% months(1)\n\n[1] \"2021-02-28\"\n\n\nLorsque le résultat produit une date inexistante, cela renvoie la dernière date correcte, ici le 28 février 2021, ce qui correspond bien à la fin du mois considéré.\n\n34.3.3 Intervalles (Interval)\nQuelle est la durée réelle d’une année ? En 2015, il s’agissait de 365 jours alors qu’en 2016 on en comptait 366. Quand on s’intéresse aux mois, la situation est encore plus compliquée car il y a une grande variation du nombre de jours d’un mois à l’autre.\nPour des calculs précis entre deux dates, les durées et les intervalles sont souvent insuffisants. On pourra alors avoir recours aux intervalles (de la classe Interval) qui sont définis avec une date de début et une date de fin.\nOn peut créer un intervalle avec la fonction lubridate::interval() :\n\ninterval(ymd(\"2022-05-13\"), ymd(\"2022-08-15\"))\n\n[1] 2022-05-13 UTC--2022-08-15 UTC\n\n\nOn peut également utiliser l’opérateur %--% :\n\ny2023 &lt;- ymd(\"2023-01-01\") %--% ymd(\"2024-01-01\")\ny2024 &lt;- ymd(\"2024-01-01\") %--% ymd(\"2025-01-01\")\n\ny2023\n\n[1] 2023-01-01 UTC--2024-01-01 UTC\n\ny2024\n\n[1] 2024-01-01 UTC--2025-01-01 UTC\n\n\nOn peut tester si une date est située dans un intervalle donné avec l’opérateur %within%.\n\nint &lt;- interval(ymd(\"2001-01-01\"), ymd(\"2002-01-01\"))\nymd(\"2001-05-03\") %within% int\n\n[1] TRUE\n\n\nOn peut même tester si un intervalle est situé à l’intérieur d’un intervalle :\n\nint2 &lt;- interval(ymd(\"2001-06-01\"), ymd(\"2001-11-11\"))\nint2 %within% int\n\n[1] TRUE\n\n\nCela n’est valable que si l’ensemble du premier intervalle est situé à l’intérieur du second intervalle.\n\nint3 &lt;- interval(ymd(\"2001-06-01\"), ymd(\"2002-06-01\"))\nint3 %within% int\n\n[1] FALSE\n\n\nPour tester si deux intervalles ont une partie en commun, on pourra utiliser lubridate::int_overlaps(). La fonction intersect() renvoie la partie partagée par les deux intervalles.\n\nint_overlaps(int3, int)\n\n[1] TRUE\n\nintersect(int3, int)\n\n[1] 2001-06-01 UTC--2002-01-01 UTC\n\n\nlubridate fournie plusieurs fonctions, de la forme int_*(), pour manipuler les intervalles.\n\nint\n\n[1] 2001-01-01 UTC--2002-01-01 UTC\n\nint_start(int)\n\n[1] \"2001-01-01 UTC\"\n\nint_end(int)\n\n[1] \"2002-01-01 UTC\"\n\nint_flip(int)\n\n[1] 2002-01-01 UTC--2001-01-01 UTC\n\n\nOn peut calculer facilement la durée d’un intervalle avec la fonction lubridate::time_length() :\n\ntime_length(int) # en seconde par défaut\n\n[1] 31536000\n\ntime_length(int, unit = \"weeks\")\n\n[1] 52.14286\n\ntime_length(int, unit = \"days\")\n\n[1] 365\n\n\nLa fonction time_length() permet notamment de calculer correctement un âge.",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Dates avec `lubridate`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/dates.html#sec-calcul-age",
    "href": "manipulation_avancee/dates.html#sec-calcul-age",
    "title": "34  Dates avec lubridate",
    "section": "\n34.4 Calcul d’un âge",
    "text": "34.4 Calcul d’un âge\nEn tant que démographe, je suis toujours attentif au calcul des âges. Les démographes distinguent l’âge exact, exprimé en années avec une partie décimale, et qui correspond à la durée entre la date considérée et la date de naissance ; l’âge révolu, qui correspond à l’âge au dernier anniversaire et exprimé avec un nombre entier d’années (c’est l’âge que nous utilisons dans notre vie quotidienne)·; et l’âge atteint ou âge par différence de millésimes, qui correspond à la différence entre l’année en cours et l’année de naissance (c’est l’âge que l’on aura cette année le jour de son anniversaire).\nPour calculer un âge exact en années, nous ne pouvons pendre la durée en jours entre les deux dates et diviser par 365 puisqu’il y a des années bissextiles. Une approche correcte est déjà de considérer l’âge au dernière anniversaire pour la partie entière, puis de calculer la partie décimale comme étant le ratio entre la durée depuis le dernière anniversaire et la durée entre le dernier et le prochain anniversaire. C’est exactement ce que fait lubridate::time_length().\n\nnaiss &lt;- ymd(\"1979-11-28\")\nevt &lt;- ymd(\"2022-07-14\")\nage_exact &lt;- time_length(naiss %--% evt, unit = \"years\")\nage_exact\n\n[1] 42.62466\n\n\nPour un âge révolu, il suffit de ne garder que la partie entière de l’âge exact avec trunc().\n\nage_revolu &lt;- trunc(age_exact)\nage_revolu\n\n[1] 42\n\n\nEnfin, pour un âge atteint ou un âge par différence de millésimes, nous extrairons les deux années avant d’en faire la soustraction.\n\nage_atteint &lt;- year(evt) - year(naiss)\nage_atteint\n\n[1] 43\n\n\n\n\n\n\n\n\nAstuce\n\n\n\nLe calcul d’un âge moyen s’effectue normalement à partir d’âges exacts. Il arrive fréquemment que l’on ne dispose dans les données d’enquêtes que de l’âge révolu. Auquel cas, il faut bien penser à rajouter 0,5 au résultat obtenu. En effet, un âge révolu peut être vu comme une classe d’âges exacts : les individus ayant 20 ans révolus ont entre 20 et 21 ans exacts, soit en moyenne 20,5 ans !",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Dates avec `lubridate`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/dates.html#fuseaux-horaires",
    "href": "manipulation_avancee/dates.html#fuseaux-horaires",
    "title": "34  Dates avec lubridate",
    "section": "\n34.5 Fuseaux horaires",
    "text": "34.5 Fuseaux horaires\nLes fuseaux horaires sont un sujet extrêmement complexe en raison de leur interaction avec les entités géopolitiques. Heureusement, nous n’avons pas besoin d’entrer dans tous les détails, car ils ne sont pas tous importants pour l’analyse des données, mais il y a quelques défis que nous devrons relever.\nLe premier défi est que les noms courants des fuseaux horaires ont tendance à être ambigus. Par exemple, si vous êtes américain, vous connaissez probablement l’EST (Eastern Standard Time). Cependant, l’Australie et le Canada ont également une heure normale de l’Est ! Pour éviter toute confusion, R utilise les fuseaux horaires standard internationaux de l’IANA. Ceux-ci utilisent un schéma de dénomination cohérent {zone}/{lieu}, généralement sous la forme {continent}/{ville} ou {océan}/{ville}. Parmi les exemples, citons \"America/New_York\", “Europe/Paris” et “Pacific/Auckland”.\nOn peut se demander pourquoi le fuseau horaire utilise une ville, alors que l’on pense généralement que les fuseaux horaires sont associés à un pays ou à une région à l’intérieur d’un pays. La raison en est que la base de données de l’IANA doit enregistrer des dizaines d’années de règles relatives aux fuseaux horaires. Au fil des décennies, les pays changent de nom (ou se séparent) assez fréquemment, mais les noms de villes ont tendance à rester inchangés. Un autre problème réside dans le fait que le nom doit refléter non seulement le comportement actuel, mais aussi l’ensemble de l’histoire. Par exemple, il existe des fuseaux horaires pour \"America/New_York\" et \"America/Detroit\". Cela vaut la peine de lire la base de données brute des fuseaux horaires (disponible à l’adresse https://www.iana.org/time-zones) rien que pour lire certaines de ces histoires !\nVous pouvez découvrir ce que R pense être votre fuseau horaire actuel avec Sys.timezone() :\n\nSys.timezone()\n\n[1] \"Europe/Paris\"\n\n\nLa liste complète des fuseaux horaires est disponible avec OlsonNames():\n\nlength(OlsonNames())\n\n[1] 596\n\nhead(OlsonNames())\n\n[1] \"Africa/Abidjan\"     \"Africa/Accra\"       \"Africa/Addis_Ababa\"\n[4] \"Africa/Algiers\"     \"Africa/Asmara\"      \"Africa/Asmera\"     \n\n\nDans R, le fuseau horaire est un attribut de la date-heure qui ne contrôle que l’affichage. Par exemple, ces trois objets représentent le même instant dans le temps :\n\nx1 &lt;- ymd_hms(\"2024-06-01 12:00:00\", tz = \"America/New_York\")\nx1\n\n[1] \"2024-06-01 12:00:00 EDT\"\n\nx2 &lt;- ymd_hms(\"2024-06-01 18:00:00\", tz = \"Europe/Copenhagen\")\nx2\n\n[1] \"2024-06-01 18:00:00 CEST\"\n\nx3 &lt;- ymd_hms(\"2024-06-02 04:00:00\", tz = \"Pacific/Auckland\")\nx3\n\n[1] \"2024-06-02 04:00:00 NZST\"\n\n\nSauf indication contraire, lubridate utilise toujours l’heure UTC. UTC (Temps universel coordonné, compromis entre l’anglais CUT Coordinated universal time et le français TUC Temps universel coordonné) est le fuseau horaire standard utilisé par la communauté scientifique et est à peu près équivalent à GMT (Greenwich Mean Time). Il n’y a pas d’heure d’été, ce qui en fait une représentation pratique pour les calculs. Les opérations qui combinent des dates-heure, comme c(), ne tiennent souvent pas compte du fuseau horaire. Dans ce cas, les dates-heure s’afficheront dans le fuseau horaire du premier élément :\n\nx4 &lt;- c(x1, x2, x3)\nx4\n\n[1] \"2024-06-01 12:00:00 EDT\" \"2024-06-01 12:00:00 EDT\"\n[3] \"2024-06-01 12:00:00 EDT\"\n\n\nVous pouvez modifier le fuseau horaire de deux manières :\n\n\nConserver le même instant dans le temps, mais modifier la façon dont il est affiché. Utilisez cette option lorsque l’instant est correct, mais que vous souhaitez un affichage plus naturel.\n\nx4a &lt;- with_tz(x4, tzone = \"Australia/Lord_Howe\")\nx4a\n\n[1] \"2024-06-02 02:30:00 +1030\" \"2024-06-02 02:30:00 +1030\"\n[3] \"2024-06-02 02:30:00 +1030\"\n\nx4a - x4\n\nTime differences in secs\n[1] 0 0 0\n\n\n\n\nModifier l’instant sous-jacent dans le temps. Utilisez cette option lorsqu’un instant a été étiqueté avec un fuseau horaire incorrect et que vous devez le corriger.\n\nx4b &lt;- force_tz(x4, tzone = \"Australia/Lord_Howe\")\nx4b\n\n[1] \"2024-06-01 12:00:00 +1030\" \"2024-06-01 12:00:00 +1030\"\n[3] \"2024-06-01 12:00:00 +1030\"\n\nx4b - x4\n\nTime differences in hours\n[1] -14.5 -14.5 -14.5",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Dates avec `lubridate`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/dates.html#pour-aller-plus-loin",
    "href": "manipulation_avancee/dates.html#pour-aller-plus-loin",
    "title": "34  Dates avec lubridate",
    "section": "\n34.6 Pour aller plus loin",
    "text": "34.6 Pour aller plus loin\n\nle chapitre Dates and times de l’ouvrage R for Data Science (2e édition)\nla documentation du package lubridate : https://lubridate.tidyverse.org/",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Dates avec `lubridate`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/stringr.html",
    "href": "manipulation_avancee/stringr.html",
    "title": "35  Chaînes de texte avec stringr",
    "section": "",
    "text": "35.1 Concaténer des chaînes\nLa première opération de base consiste à concaténer des chaînes de caractères entre elles. On peut le faire avec la fonction paste().\nPar exemple, si on veut concaténer l’adresse et la ville :\npaste(d$adresse, d$ville)\n\n[1] \"3 rue des Fleurs Nouméa\"              \n[2] \"47 ave de la Libération Marseille\"    \n[3] \"12 rue du 17 octobre 1961 Vénissieux\" \n[4] \"221 avenue de la Libération Marseille\"\nPar défaut, paste() concatène en ajoutant un espace entre les différentes chaînes. On peut spécifier un autre séparateur avec son argument sep :\npaste(d$adresse, d$ville, sep = \" - \")\n\n[1] \"3 rue des Fleurs - Nouméa\"              \n[2] \"47 ave de la Libération - Marseille\"    \n[3] \"12 rue du 17 octobre 1961 - Vénissieux\" \n[4] \"221 avenue de la Libération - Marseille\"\nIl existe une variante, paste0(), qui concatène sans mettre de séparateur, et qui est légèrement plus rapide :\npaste0(d$adresse, d$ville)\n\n[1] \"3 rue des FleursNouméa\"              \n[2] \"47 ave de la LibérationMarseille\"    \n[3] \"12 rue du 17 octobre 1961Vénissieux\" \n[4] \"221 avenue de la LibérationMarseille\"\nParfois on cherche à concaténer les différents éléments d’un vecteur non pas avec ceux d’un autre vecteur, comme on l’a fait précédemment, mais entre eux. Dans ce cas paste() seule ne fera rien :\npaste(d$ville)\n\n[1] \"Nouméa\"     \"Marseille\"  \"Vénissieux\" \"Marseille\"\nIl faut lui ajouter un argument collapse, avec comme valeur la chaîne à utiliser pour concaténer les éléments :\nd$ville |&gt; paste(collapse = \", \")\n\n[1] \"Nouméa, Marseille, Vénissieux, Marseille\"",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Chaînes de texte avec `stringr`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/stringr.html#concaténer-des-chaînes",
    "href": "manipulation_avancee/stringr.html#concaténer-des-chaînes",
    "title": "35  Chaînes de texte avec stringr",
    "section": "",
    "text": "Note\n\n\n\nÀ noter que paste() et paste0() sont des fonctions R de base. L’équivalent pour stringr se nomme stringr::str_c().",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Chaînes de texte avec `stringr`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/stringr.html#convertir-en-majuscules-minuscules",
    "href": "manipulation_avancee/stringr.html#convertir-en-majuscules-minuscules",
    "title": "35  Chaînes de texte avec stringr",
    "section": "\n35.2 Convertir en majuscules / minuscules",
    "text": "35.2 Convertir en majuscules / minuscules\nLes fonctions stringr::str_to_lower(), stringr::str_to_upper() et stringr::str_to_title() permettent respectivement de mettre en minuscules, mettre en majuscules, ou de capitaliser les éléments d’un vecteur de chaînes de caractères :\n\nd$nom |&gt; str_to_lower()\n\n[1] \"mr félicien machin\"  \"mme raymonde bidule\" \"m. martial truc\"    \n[4] \"mme huguette chose\" \n\n\n\nd$nom |&gt; str_to_upper()\n\n[1] \"MR FÉLICIEN MACHIN\"  \"MME RAYMONDE BIDULE\" \"M. MARTIAL TRUC\"    \n[4] \"MME HUGUETTE CHOSE\" \n\n\n\nd$nom |&gt; str_to_title()\n\n[1] \"Mr Félicien Machin\"  \"Mme Raymonde Bidule\" \"M. Martial Truc\"    \n[4] \"Mme Huguette Chose\"",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Chaînes de texte avec `stringr`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/stringr.html#découper-des-chaînes",
    "href": "manipulation_avancee/stringr.html#découper-des-chaînes",
    "title": "35  Chaînes de texte avec stringr",
    "section": "\n35.3 Découper des chaînes",
    "text": "35.3 Découper des chaînes\nLa fonction stringr::str_split() permet de “découper” une chaîne de caractère en fonction d’un délimiteur. On passe la chaîne en premier argument, et le délimiteur en second :\n\n\"un-deux-trois\" |&gt; \n  str_split(\"-\") \n\n[[1]]\n[1] \"un\"    \"deux\"  \"trois\"\n\n\nOn peut appliquer la fonction à un vecteur, dans ce cas le résultat sera une liste :\n\nstr_split(d$nom, \" \")\n\n[[1]]\n[1] \"Mr\"       \"Félicien\" \"Machin\"  \n\n[[2]]\n[1] \"Mme\"      \"Raymonde\" \"Bidule\"  \n\n[[3]]\n[1] \"M.\"      \"Martial\" \"Truc\"   \n\n[[4]]\n[1] \"Mme\"      \"Huguette\" \"Chose\"   \n\n\nOu un tableau (plus précisément une matrice) si on ajoute simplify = TRUE.\n\nd$nom |&gt; \n  str_split(\" \", simplify = TRUE)\n\n     [,1]  [,2]       [,3]    \n[1,] \"Mr\"  \"Félicien\" \"Machin\"\n[2,] \"Mme\" \"Raymonde\" \"Bidule\"\n[3,] \"M.\"  \"Martial\"  \"Truc\"  \n[4,] \"Mme\" \"Huguette\" \"Chose\" \n\n\nSi on souhaite créer de nouvelles colonnes dans un tableau de données en découpant une colonne de type texte, on pourra utiliser la fonction tidyr::separate() de l’extension tidyr (cf. Section 36.5).\nVoici juste un exemple de son utilisation :\n\nd |&gt; \n  tidyr::separate(\n    col = nom,\n    into = c(\"genre\", \"prenom\", \"nom\")\n)\n\nWarning: Expected 3 pieces. Additional pieces discarded in 1 rows [1].\n\n\n# A tibble: 4 × 5\n  genre prenom   nom    adresse                     ville     \n  &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;                       &lt;chr&gt;     \n1 Mr    F        licien 3 rue des Fleurs            Nouméa    \n2 Mme   Raymonde Bidule 47 ave de la Libération     Marseille \n3 M     Martial  Truc   12 rue du 17 octobre 1961   Vénissieux\n4 Mme   Huguette Chose  221 avenue de la Libération Marseille",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Chaînes de texte avec `stringr`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/stringr.html#extraire-des-sous-chaînes-par-position",
    "href": "manipulation_avancee/stringr.html#extraire-des-sous-chaînes-par-position",
    "title": "35  Chaînes de texte avec stringr",
    "section": "\n35.4 Extraire des sous-chaînes par position",
    "text": "35.4 Extraire des sous-chaînes par position\nLa fonction stringr::str_sub() permet d’extraire des sous-chaînes par position, en indiquant simplement les positions des premier et dernier caractères :\n\nd$ville |&gt; str_sub(1, 3)\n\n[1] \"Nou\" \"Mar\" \"Vén\" \"Mar\"",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Chaînes de texte avec `stringr`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/stringr.html#str_detect",
    "href": "manipulation_avancee/stringr.html#str_detect",
    "title": "35  Chaînes de texte avec stringr",
    "section": "\n35.5 Détecter des motifs",
    "text": "35.5 Détecter des motifs\nstringr::str_detect() permet de détecter la présence d’un motif parmi les éléments d’un vecteur. Par exemple, si on souhaite identifier toutes les adresses contenant Libération :\n\nd$adresse |&gt; str_detect(\"Libération\")\n\n[1] FALSE  TRUE FALSE  TRUE\n\n\nstringr::str_detect() renvoi un vecteur de valeurs logiques et peut donc être utilisée, par exemple, avec le verbe dplyr::filter() pour extraire des sous-populations.\n\nd |&gt; \n  filter(adresse |&gt;  str_detect(\"Libération\"))\n\n# A tibble: 2 × 3\n  nom                 adresse                     ville    \n  &lt;chr&gt;               &lt;chr&gt;                       &lt;chr&gt;    \n1 Mme Raymonde Bidule 47 ave de la Libération     Marseille\n2 Mme Huguette Chose  221 avenue de la Libération Marseille\n\n\nUne variante, stringr::str_count(), compte le nombre d’occurrences d’une chaîne pour chaque élément d’un vecteur :\n\nd$ville\n\n[1] \"Nouméa\"     \"Marseille\"  \"Vénissieux\" \"Marseille\" \n\nd$ville |&gt; str_count(\"s\")\n\n[1] 0 1 2 1\n\n\n\n\n\n\n\n\nImportant\n\n\n\nAttention, les fonctions de stringr étant prévues pour fonctionner avec des expressions régulières, certains caractères n’auront pas le sens habituel dans la chaîne indiquant le motif à rechercher. Par exemple, le . ne sera pas un point mais le symbole représentant n’importe quel caractère.\nLa section sur les modificateurs de motifs explique comment utiliser des chaîne classiques au lieu d’expressions régulières.\n\n\nOn peut aussi utiliser stringr::str_subset() pour ne garder d’un vecteur que les éléments correspondant au motif :\n\nd$adresse |&gt; str_subset(\"Libération\")\n\n[1] \"47 ave de la Libération\"     \"221 avenue de la Libération\"",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Chaînes de texte avec `stringr`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/stringr.html#expressions-régulières",
    "href": "manipulation_avancee/stringr.html#expressions-régulières",
    "title": "35  Chaînes de texte avec stringr",
    "section": "\n35.6 Expressions régulières",
    "text": "35.6 Expressions régulières\nLes fonctions présentées ici sont pour la plupart prévues pour fonctionner avec des expressions régulières. Celles-ci constituent un mini-langage, qui peut paraître assez cryptique, mais qui est très puissant pour spécifier des motifs de chaînes de caractères.\nElles permettent par exemple de sélectionner le dernier mot avant la fin d’une chaîne, l’ensemble des suites alphanumériques commençant par une majuscule, des nombres de 3 ou 4 chiffres situés en début de chaîne, et beaucoup beaucoup d’autres choses encore bien plus complexes.\nPour donner un exemple concret, l’expression régulière suivante permet de détecter une adresse de courrier électronique1 :\n1 Il s’agit en fait d’une version très simplifiée, la véritable expression permettant de tester si une adresse mail est valide fait plus de 80 lignes…[\\w\\d+.-_]+@[\\w\\d.-]+\\.[a-zA-Z]{2,}\nLes exemples donnés dans ce chapitre ont utilisés autant que possible de simples chaînes de texte, sans expression régulière. Mais si vous pensez manipuler des données textuelles, il peut être très utile de s’intéresser à cette syntaxe.",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Chaînes de texte avec `stringr`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/stringr.html#extraire-des-motifs",
    "href": "manipulation_avancee/stringr.html#extraire-des-motifs",
    "title": "35  Chaînes de texte avec stringr",
    "section": "\n35.7 Extraire des motifs",
    "text": "35.7 Extraire des motifs\nstringr::str_extract() permet d’extraire les valeurs correspondant à un motif. Si on lui passe comme motif une chaîne de caractère, cela aura peu d’intérêt :\n\nd$adresse |&gt; \n  str_extract(\"Libération\")\n\n[1] NA           \"Libération\" NA           \"Libération\"\n\n\nC’est tout de suite plus intéressant si on utilise des expressions régulières. Par exemple la commande suivante permet d’isoler les numéros de rue.\n\nd$adresse |&gt; str_extract(\"^\\\\d+\")\n\n[1] \"3\"   \"47\"  \"12\"  \"221\"\n\n\nstringr::str_extract() ne récupère que la première occurrence du motif. Si on veut toutes les extraire on peut utiliser stringr::str_extract_all(). Ainsi, si on veut extraire l’ensemble des nombres présents dans les adresses :\n\nd$adresse |&gt; str_extract_all(\"\\\\d+\")\n\n[[1]]\n[1] \"3\"\n\n[[2]]\n[1] \"47\"\n\n[[3]]\n[1] \"12\"   \"17\"   \"1961\"\n\n[[4]]\n[1] \"221\"\n\n\n\nSi on veut faire de l’extraction de groupes dans des expressions régulières (identifiés avec des parenthèses), on pourra utiliser str_match.\n\nÀ noter que si on souhaite extraire des valeurs d’une colonne texte d’un tableau de données pour créer de nouvelles variables, on pourra plutôt utiliser la fonction tidyr::extract() de l’extension tidyr (cf. Section 36.8).\nPar exemple :\n\nd |&gt;\n  tidyr::extract(\n    col = adresse,\n    into = \"type_rue\",\n    regex = \"^\\\\d+ (.*?) \",\n    remove = FALSE\n  )\n\n# A tibble: 4 × 4\n  nom                 adresse                     type_rue ville     \n  &lt;chr&gt;               &lt;chr&gt;                       &lt;chr&gt;    &lt;chr&gt;     \n1 Mr Félicien Machin  3 rue des Fleurs            rue      Nouméa    \n2 Mme Raymonde Bidule 47 ave de la Libération     ave      Marseille \n3 M. Martial Truc     12 rue du 17 octobre 1961   rue      Vénissieux\n4 Mme Huguette Chose  221 avenue de la Libération avenue   Marseille",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Chaînes de texte avec `stringr`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/stringr.html#remplacer-des-motifs",
    "href": "manipulation_avancee/stringr.html#remplacer-des-motifs",
    "title": "35  Chaînes de texte avec stringr",
    "section": "\n35.8 Remplacer des motifs",
    "text": "35.8 Remplacer des motifs\nLa fonction stringr::str_replace() permet de remplacer une chaîne ou un motif par une autre.\nPar exemple, on peut remplace les occurrence de “Mr” par “M.” dans les noms de notre tableau :\n\nd$nom |&gt; \n  str_replace(\"Mr\", \"M.\")\n\n[1] \"M. Félicien Machin\"  \"Mme Raymonde Bidule\" \"M. Martial Truc\"    \n[4] \"Mme Huguette Chose\" \n\n\nLa variante stringr::str_replace_all() permet de spécifier plusieurs remplacements d’un coup :\n\nd$adresse |&gt; \n  str_replace_all(\n    c(\n      \"avenue\"=\"Avenue\",\n      \"ave\"=\"Avenue\",\n      \"rue\"=\"Rue\"\n    )\n  )\n\n[1] \"3 Rue des Fleurs\"            \"47 Avenue de la Libération\" \n[3] \"12 Rue du 17 octobre 1961\"   \"221 Avenue de la Libération\"",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Chaînes de texte avec `stringr`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/stringr.html#modificateurs",
    "href": "manipulation_avancee/stringr.html#modificateurs",
    "title": "35  Chaînes de texte avec stringr",
    "section": "\n35.9 Modificateurs de motifs",
    "text": "35.9 Modificateurs de motifs\nPar défaut, les motifs passés aux fonctions comme stringr::str_detect(), stringr::str_extract() ou stringr::str_replace() sont des expressions régulières classiques.\nOn peut spécifier qu’un motif n’est pas une expression régulière mais une chaîne de caractères normale en lui appliquant la fonction stringr::fixed(). Par exemple, si on veut compter le nombre de points dans les noms de notre tableau, le paramétrage par défaut ne fonctionnera pas car dans une expression régulière le . est un symbole signifiant n’importe quel caractère :\n\nd$nom |&gt; str_count(\".\")\n\n[1] 18 19 15 18\n\n\nIl faut donc spécifier que notre point est bien un point avec stringr::fixed() :\n\nd$nom |&gt; str_count(fixed(\".\"))\n\n[1] 0 0 1 0\n\n\nOn peut aussi modifier le comportement des expressions régulières à l’aide de la fonction stringr::regex(). On peut ainsi rendre les motifs insensibles à la casse avec ignore_case :\n\nd$nom |&gt; str_detect(\"mme\")\n\n[1] FALSE FALSE FALSE FALSE\n\n\n\nd$nom |&gt; \n  str_detect(regex(\"mme\", ignore_case = TRUE))\n\n[1] FALSE  TRUE FALSE  TRUE\n\n\nOn peut également permettre aux expressions régulières d’être multilignes avec l’option multiline = TRUE, etc.",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Chaînes de texte avec `stringr`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/stringr.html#insérer-une-variable-dans-une-chaîne-de-caractères",
    "href": "manipulation_avancee/stringr.html#insérer-une-variable-dans-une-chaîne-de-caractères",
    "title": "35  Chaînes de texte avec stringr",
    "section": "\n35.10 Insérer une variable dans une chaîne de caractères",
    "text": "35.10 Insérer une variable dans une chaîne de caractères\nLa fonction stringr::str_glue() repose sur l’extension glue. Elle permet, à l’aide d’une syntaxe un peu spécifique, de pouvoir insérer facilement les valeurs d’une ou plusieurs variables dans une chaîne de caractères. Prenons un exemple :\n\nprenom &lt;- \"Fred\"\nage &lt;- 28\nanniversaire &lt;- as.Date(\"1991-10-12\")\nstr_glue(\n  \"Je m'appelle {prenom}. \",\n  \"L'année prochaine j'aurai {age + 1} ans, \",\n  \"car je suis né le {format(anniversaire, '%A %d %B %Y')}.\"\n)\n\nJe m'appelle Fred. L'année prochaine j'aurai 29 ans, car je suis né le samedi 12 octobre 1991.\n\n\nSa variante stringr::str_glue_data() est adaptée lorsque l’on travaille sur un tableau de données.\n\nd |&gt; str_glue_data(\"{nom} habite à {ville}.\")\n\nMr Félicien Machin habite à Nouméa.\nMme Raymonde Bidule habite à Marseille.\nM. Martial Truc habite à Vénissieux.\nMme Huguette Chose habite à Marseille.",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Chaînes de texte avec `stringr`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/stringr.html#ressources",
    "href": "manipulation_avancee/stringr.html#ressources",
    "title": "35  Chaînes de texte avec stringr",
    "section": "\n35.11 Ressources",
    "text": "35.11 Ressources\nL’ouvrage R for Data Science, accessible en ligne, contient un chapitre entier sur les chaînes de caractères et les expressions régulières (en anglais).\nLe site officiel de stringr contient une liste des fonctions et les pages d’aide associées, ainsi qu’un article dédié aux expressions régulières.\nPour des besoins plus pointus, on pourra aussi utiliser le package stringi sur lequel est basé stringr.",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Chaînes de texte avec `stringr`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/tidyr.html",
    "href": "manipulation_avancee/tidyr.html",
    "title": "36  Réorganisation avec tidyr",
    "section": "",
    "text": "36.1 Tidy data\nComme indiqué dans le chapitre sur les tibbles (cf. Chapitre 5), les extensions du tidyverse comme dplyr ou ggplot2 partent du principe que les données sont “bien rangées” sous forme de tidy data.\nPrenons un exemple avec les données suivantes, qui indique la population de trois pays pour quatre années différentes :\ncountry\n1992\n1997\n2002\n2007\n\n\n\nBelgium\n10045622\n10199787\n10311970\n10392226\n\n\nFrance\n57374179\n58623428\n59925035\n61083916\n\n\nGermany\n80597764\n82011073\n82350671\n82400996\nImaginons qu’on souhaite représenter avec ggplot2 l’évolution de la population pour chaque pays sous forme de lignes : c’est impossible avec les données sous ce format. On a besoin d’arranger le tableau de la manière suivante :\ncountry\nyear\npopulation\n\n\n\nBelgium\n1992\n10045622\n\n\nBelgium\n1997\n10199787\n\n\nBelgium\n2002\n10311970\n\n\nBelgium\n2007\n10392226\n\n\nFrance\n1992\n57374179\n\n\nFrance\n1997\n58623428\n\n\nFrance\n2002\n59925035\n\n\nFrance\n2007\n61083916\n\n\nGermany\n1992\n80597764\n\n\nGermany\n1997\n82011073\n\n\nGermany\n2002\n82350671\n\n\nGermany\n2007\n82400996\nC’est seulement avec les données dans ce format qu’on peut réaliser le graphique :\nlibrary(tidyverse)\nggplot(d) + \n  aes(x = year, y = population, color = country) +\n  geom_line() +\n  scale_x_continuous(breaks = unique(d$year)) +\n  scale_y_continuous(\n    labels = scales::label_number(\n      scale = 10^-6,\n      suffix = \" millions\"\n    )\n  )\nC’est la même chose pour dplyr, par exemple si on voulait calculer la population minimale pour chaque pays avec dplyr::summarise() :\nd |&gt; \n  group_by(country) |&gt;  \n  summarise(pop_min = min(population))\n\n# A tibble: 3 × 2\n  country  pop_min\n  &lt;fct&gt;      &lt;int&gt;\n1 Belgium 10045622\n2 France  57374179\n3 Germany 80597764",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Réorganisation avec `tidyr`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/tidyr.html#trois-règles-pour-des-données-bien-rangées",
    "href": "manipulation_avancee/tidyr.html#trois-règles-pour-des-données-bien-rangées",
    "title": "36  Réorganisation avec tidyr",
    "section": "\n36.2 Trois règles pour des données bien rangées",
    "text": "36.2 Trois règles pour des données bien rangées\nLe concept de tidy data repose sur trois règles interdépendantes. Des données sont considérées comme tidy si :\n\nchaque ligne correspond à une observation\nchaque colonne correspond à une variable\nchaque valeur est présente dans une unique case de la table ou, de manière équivalente, si des unités d’observations différentes sont présentes dans des tables différentes\n\nCes règles ne sont pas forcément très intuitives. De plus, il y a une infinité de manières pour un tableau de données de ne pas être tidy.\nPrenons par exemple les règles 1 et 2 et le tableau de notre premier exemple :\n\n\n\n\ncountry\n1992\n1997\n2002\n2007\n\n\n\nBelgium\n10045622\n10199787\n10311970\n10392226\n\n\nFrance\n57374179\n58623428\n59925035\n61083916\n\n\nGermany\n80597764\n82011073\n82350671\n82400996\n\n\n\n\n\nPourquoi ce tableau n’est pas tidy ? Parce que si l’on essaie d’identifier les variables mesurées dans le tableau, il y en a trois : le pays, l’année et la population. Or elles ne correspondent pas aux colonnes de la table. C’est le cas par contre pour la table transformée :\n\n\n\n\ncountry\nannee\npopulation\n\n\n\nBelgium\n1992\n10045622\n\n\nFrance\n1992\n57374179\n\n\nGermany\n1992\n80597764\n\n\nBelgium\n1997\n10199787\n\n\nFrance\n1997\n58623428\n\n\nGermany\n1997\n82011073\n\n\nBelgium\n2002\n10311970\n\n\nFrance\n2002\n59925035\n\n\nGermany\n2002\n82350671\n\n\nBelgium\n2007\n10392226\n\n\nFrance\n2007\n61083916\n\n\nGermany\n2007\n82400996\n\n\n\n\n\nOn peut remarquer qu’en modifiant notre table pour satisfaire à la deuxième règle, on a aussi réglé la première : chaque ligne correspond désormais à une observation, en l’occurrence l’observation de trois pays à plusieurs moments dans le temps. Dans notre table d’origine, chaque ligne comportait en réalité quatre observations différentes.\nCe point permet d’illustrer le fait que les règles sont interdépendantes.\nAutre exemple, généré depuis le jeu de données nycflights13, permettant cette fois d’illustrer la troisième règle :\n\n\n\n\n\n\n\n\n\n\n\n\n\nyear\nmonth\nday\ndep_time\ncarrier\nname\nflights_per_year\n\n\n\n2013\n1\n1\n517\nUA\nUnited Air Lines Inc.\n58665\n\n\n2013\n1\n1\n533\nUA\nUnited Air Lines Inc.\n58665\n\n\n2013\n1\n1\n542\nAA\nAmerican Airlines Inc.\n32729\n\n\n2013\n1\n1\n554\nUA\nUnited Air Lines Inc.\n58665\n\n\n2013\n1\n1\n558\nAA\nAmerican Airlines Inc.\n32729\n\n\n2013\n1\n1\n558\nUA\nUnited Air Lines Inc.\n58665\n\n\n2013\n1\n1\n558\nUA\nUnited Air Lines Inc.\n58665\n\n\n2013\n1\n1\n559\nAA\nAmerican Airlines Inc.\n32729\n\n\n\n\n\nDans ce tableau on a bien une observation par ligne (un vol), et une variable par colonne. Mais on a une “infraction” à la troisième règle, qui est que chaque valeur doit être présente dans une unique case : si on regarde la colonne name, on a en effet une duplication de l’information concernant le nom des compagnies aériennes. Notre tableau mêle en fait deux types d’observations différents : des observations sur les vols, et des observations sur les compagnies aériennes.\nPour “arranger” ce tableau, il faut séparer les deux types d’observations en deux tables différentes :\n\n\n\n\nyear\nmonth\nday\ndep_time\ncarrier\n\n\n\n2013\n1\n1\n517\nUA\n\n\n2013\n1\n1\n533\nUA\n\n\n2013\n1\n1\n542\nAA\n\n\n2013\n1\n1\n554\nUA\n\n\n2013\n1\n1\n558\nAA\n\n\n2013\n1\n1\n558\nUA\n\n\n2013\n1\n1\n558\nUA\n\n\n2013\n1\n1\n559\nAA\n\n\n\n\n\n\n\n\n\ncarrier\nname\nflights_per_year\n\n\n\nUA\nUnited Air Lines Inc.\n58665\n\n\nAA\nAmerican Airlines Inc.\n32729\n\n\n\n\n\nOn a désormais deux tables distinctes, l’information n’est pas dupliquée, et on peut facilement faire une jointure si on a besoin de récupérer l’information d’une table dans une autre.\nL’objectif de tidyr est de fournir des fonctions pour arranger ses données et les convertir dans un format tidy. Ces fonctions prennent la forme de verbes qui viennent compléter ceux de dplyr et s’intègrent parfaitement dans les séries de pipes (|&gt;, cf. Chapitre 7), les pipelines, permettant d’enchaîner les opérations.",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Réorganisation avec `tidyr`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/tidyr.html#pivot_longer-rassembler-des-colonnes",
    "href": "manipulation_avancee/tidyr.html#pivot_longer-rassembler-des-colonnes",
    "title": "36  Réorganisation avec tidyr",
    "section": "\n36.3 pivot_longer() : rassembler des colonnes",
    "text": "36.3 pivot_longer() : rassembler des colonnes\nPrenons le tableau d suivant, qui liste la population de 4 pays en 2002 et 2007 :\n\n\n\n\ncountry\n2002\n2007\n\n\n\nBelgium\n10311970\n10392226\n\n\nFrance\n59925035\n61083916\n\n\nGermany\n82350671\n82400996\n\n\nSpain\n40152517\n40448191\n\n\n\n\n\nDans ce tableau, une même variable (la population) est répartie sur plusieurs colonnes, chacune représentant une observation à un moment différent. On souhaite que la variable ne représente plus qu’une seule colonne, et que les observations soient réparties sur plusieurs lignes.\nPour cela on va utiliser la fonction tidyr::pivot_longer() :\n\nd |&gt;\n  pivot_longer(\n    cols = c(`2002`,`2007`),\n    names_to = \"annee\",\n    values_to = \"population\"\n  )\n\n# A tibble: 8 × 3\n  country annee population\n  &lt;fct&gt;   &lt;chr&gt;      &lt;int&gt;\n1 Belgium 2002    10311970\n2 Belgium 2007    10392226\n3 France  2002    59925035\n4 France  2007    61083916\n5 Germany 2002    82350671\n6 Germany 2007    82400996\n7 Spain   2002    40152517\n8 Spain   2007    40448191\n\n\nLa fonction tidyr::pivot_longer() prend comme arguments la liste des colonnes à rassembler (on peut également y utiliser les différentes fonctions de sélection de variables utilisables avec dplyr::select()), ainsi que deux arguments names_to et values_to :\n\n\nnames_to est le nom de la colonne qui va contenir les “noms” des colonnes originelles, c’est-à-dire les identifiants des différentes observations\n\nvalues_to est le nom de la colonne qui va contenir la valeur des observations\n\nParfois il est plus rapide d’indiquer à tidyr::pivot_longer() les colonnes qu’on ne souhaite pas rassembler. On peut le faire avec la syntaxe suivante :\n\nd |&gt;\n  pivot_longer(\n    -country,\n    names_to = \"annee\",\n    values_to = \"population\"\n  )\n\n# A tibble: 8 × 3\n  country annee population\n  &lt;fct&gt;   &lt;chr&gt;      &lt;int&gt;\n1 Belgium 2002    10311970\n2 Belgium 2007    10392226\n3 France  2002    59925035\n4 France  2007    61083916\n5 Germany 2002    82350671\n6 Germany 2007    82400996\n7 Spain   2002    40152517\n8 Spain   2007    40448191",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Réorganisation avec `tidyr`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/tidyr.html#pivot_wider-disperser-des-lignes",
    "href": "manipulation_avancee/tidyr.html#pivot_wider-disperser-des-lignes",
    "title": "36  Réorganisation avec tidyr",
    "section": "\n36.4 pivot_wider() : disperser des lignes",
    "text": "36.4 pivot_wider() : disperser des lignes\nLa fonction tidyr::pivot_wider() est l’inverse de tidyr::pivot_longer().\nSoit le tableau d suivant :\n\n\n\n\ncountry\ncontinent\nyear\nvariable\nvalue\n\n\n\nBelgium\nEurope\n2002\nlifeExp\n78.320\n\n\nBelgium\nEurope\n2007\nlifeExp\n79.441\n\n\nFrance\nEurope\n2002\nlifeExp\n79.590\n\n\nFrance\nEurope\n2007\nlifeExp\n80.657\n\n\nGermany\nEurope\n2002\nlifeExp\n78.670\n\n\nGermany\nEurope\n2007\nlifeExp\n79.406\n\n\nBelgium\nEurope\n2002\npop\n10311970.000\n\n\nBelgium\nEurope\n2007\npop\n10392226.000\n\n\nFrance\nEurope\n2002\npop\n59925035.000\n\n\nFrance\nEurope\n2007\npop\n61083916.000\n\n\nGermany\nEurope\n2002\npop\n82350671.000\n\n\nGermany\nEurope\n2007\npop\n82400996.000\n\n\n\n\n\nCe tableau a le problème inverse du précédent : on a deux variables, lifeExp et pop qui, plutôt que d’être réparties en deux colonnes, sont réparties entre plusieurs lignes.\nOn va donc utiliser tidyr::pivot_wider() pour disperser ces lignes dans deux colonnes différentes :\n\nd |&gt;\n  pivot_wider(\n    names_from = variable,\n    values_from = value\n  )\n\n# A tibble: 6 × 5\n  country continent  year lifeExp      pop\n  &lt;fct&gt;   &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 Belgium Europe     2002    78.3 10311970\n2 Belgium Europe     2007    79.4 10392226\n3 France  Europe     2002    79.6 59925035\n4 France  Europe     2007    80.7 61083916\n5 Germany Europe     2002    78.7 82350671\n6 Germany Europe     2007    79.4 82400996\n\n\ntidyr::pivot_wider() prend deux arguments principaux :\n\n\nnames_from indique la colonne contenant les noms des nouvelles variables à créer\n\nvalues_from indique la colonne contenant les valeurs de ces variables\n\nIl peut arriver que certaines variables soient absentes pour certaines observations. Dans ce cas l’argument values_fill permet de spécifier la valeur à utiliser pour ces données manquantes (par défaut, les valeurs manquantes sont indiquées avec NA).\nExemple avec le tableau d suivant :\n\n\n\n\ncountry\ncontinent\nyear\nvariable\nvalue\n\n\n\nBelgium\nEurope\n2002\nlifeExp\n78.320\n\n\nBelgium\nEurope\n2007\nlifeExp\n79.441\n\n\nFrance\nEurope\n2002\nlifeExp\n79.590\n\n\nFrance\nEurope\n2007\nlifeExp\n80.657\n\n\nGermany\nEurope\n2002\nlifeExp\n78.670\n\n\nGermany\nEurope\n2007\nlifeExp\n79.406\n\n\nBelgium\nEurope\n2002\npop\n10311970.000\n\n\nBelgium\nEurope\n2007\npop\n10392226.000\n\n\nFrance\nEurope\n2002\npop\n59925035.000\n\n\nFrance\nEurope\n2007\npop\n61083916.000\n\n\nGermany\nEurope\n2002\npop\n82350671.000\n\n\nGermany\nEurope\n2007\npop\n82400996.000\n\n\nFrance\nEurope\n2002\ndensity\n94.000\n\n\n\n\n\n\nd |&gt; \n  pivot_wider(\n    names_from =  variable,\n    values_from = value\n  )\n\n# A tibble: 6 × 6\n  country continent  year lifeExp      pop density\n  &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1 Belgium Europe     2002    78.3 10311970      NA\n2 Belgium Europe     2007    79.4 10392226      NA\n3 France  Europe     2002    79.6 59925035      94\n4 France  Europe     2007    80.7 61083916      NA\n5 Germany Europe     2002    78.7 82350671      NA\n6 Germany Europe     2007    79.4 82400996      NA\n\n\n\nd |&gt; \n  pivot_wider(\n    names_from =  variable,\n    values_from = value,\n    values_fill = list(value = 0)\n  )\n\n# A tibble: 6 × 6\n  country continent  year lifeExp      pop density\n  &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1 Belgium Europe     2002    78.3 10311970       0\n2 Belgium Europe     2007    79.4 10392226       0\n3 France  Europe     2002    79.6 59925035      94\n4 France  Europe     2007    80.7 61083916       0\n5 Germany Europe     2002    78.7 82350671       0\n6 Germany Europe     2007    79.4 82400996       0",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Réorganisation avec `tidyr`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/tidyr.html#sec-separate",
    "href": "manipulation_avancee/tidyr.html#sec-separate",
    "title": "36  Réorganisation avec tidyr",
    "section": "\n36.5 separate() : séparer une colonne en plusieurs colonnes",
    "text": "36.5 separate() : séparer une colonne en plusieurs colonnes\nParfois on a plusieurs informations réunies en une seule colonne et on souhaite les séparer. Soit le tableau d’exemple caricatural suivant, nommé df :\n\ndf &lt;- tibble(\n  eleve = c(\"Alex Petit\", \"Bertrand Dupont\", \"Corinne Durand\"),\n  note = c(\"5/20\", \"6/10\", \"87/100\")\n)\ndf\n\n# A tibble: 3 × 2\n  eleve           note  \n  &lt;chr&gt;           &lt;chr&gt; \n1 Alex Petit      5/20  \n2 Bertrand Dupont 6/10  \n3 Corinne Durand  87/100\n\n\ntidyr::separate() permet de séparer la colonne note en deux nouvelles colonnes note et note_sur :\n\ndf |&gt;\n  separate(note, c(\"note\", \"note_sur\"))\n\n# A tibble: 3 × 3\n  eleve           note  note_sur\n  &lt;chr&gt;           &lt;chr&gt; &lt;chr&gt;   \n1 Alex Petit      5     20      \n2 Bertrand Dupont 6     10      \n3 Corinne Durand  87    100     \n\n\ntidyr::separate() prend deux arguments principaux, le nom de la colonne à séparer et un vecteur indiquant les noms des nouvelles variables à créer. Par défaut tidyr::separate() sépare au niveau des caractères non-alphanumérique (espace, symbole, etc.). On peut lui indiquer explicitement le caractère sur lequel séparer avec l’argument sep :\n\ndf |&gt;\n  tidyr::separate(\n    eleve,\n    c(\"prenom\", \"nom\"),\n    sep = \" \"\n  )\n\n# A tibble: 3 × 3\n  prenom   nom    note  \n  &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt; \n1 Alex     Petit  5/20  \n2 Bertrand Dupont 6/10  \n3 Corinne  Durand 87/100",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Réorganisation avec `tidyr`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/tidyr.html#separate_rows-séparer-une-colonne-en-plusieurs-lignes",
    "href": "manipulation_avancee/tidyr.html#separate_rows-séparer-une-colonne-en-plusieurs-lignes",
    "title": "36  Réorganisation avec tidyr",
    "section": "\n36.6 separate_rows() : séparer une colonne en plusieurs lignes",
    "text": "36.6 separate_rows() : séparer une colonne en plusieurs lignes\nLa fonction tidyr::separate_rows() est utile lorsque plusieurs valeurs sont contenues dans la même variable. Mais, alors que tidyr::separate() permet de répartir ces différentes valeurs dans plusieurs colonnes, tidyr::separate_rows() va créé une ligne pour chaque valeur. Prenons cet exemple trivial où les différentes notes de chaque élève sont contenues dans la colonne notes.\n\ndf &lt;- tibble(\n  eleve = c(\"Alex Petit\", \"Bertrand Dupont\", \"Corinne Durand\"),\n  notes = c(\"10,15,16\", \"18,12,14\", \"16,17\")\n)\ndf\n\n# A tibble: 3 × 2\n  eleve           notes   \n  &lt;chr&gt;           &lt;chr&gt;   \n1 Alex Petit      10,15,16\n2 Bertrand Dupont 18,12,14\n3 Corinne Durand  16,17   \n\n\nAppliquons tidyr::separate_rows().\n\ndf |&gt; \n  separate_rows(notes) |&gt; \n  rename(note = notes)\n\n# A tibble: 8 × 2\n  eleve           note \n  &lt;chr&gt;           &lt;chr&gt;\n1 Alex Petit      10   \n2 Alex Petit      15   \n3 Alex Petit      16   \n4 Bertrand Dupont 18   \n5 Bertrand Dupont 12   \n6 Bertrand Dupont 14   \n7 Corinne Durand  16   \n8 Corinne Durand  17   \n\n\nPar défaut tidyr::separate_rows() sépare les valeurs dès qu’elle trouve un caractère qui ne soit ni un chiffre ni une lettre, mais on peut spécifier le séparateur à l’aide de l’argument sep (qui accepte une chaîne de caractère ou même une expression régulière) :\n\ndf |&gt; \n  separate_rows(notes, sep = \",\") |&gt; \n  rename(note = notes)\n\n# A tibble: 8 × 2\n  eleve           note \n  &lt;chr&gt;           &lt;chr&gt;\n1 Alex Petit      10   \n2 Alex Petit      15   \n3 Alex Petit      16   \n4 Bertrand Dupont 18   \n5 Bertrand Dupont 12   \n6 Bertrand Dupont 14   \n7 Corinne Durand  16   \n8 Corinne Durand  17",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Réorganisation avec `tidyr`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/tidyr.html#unite-regrouper-plusieurs-colonnes-en-une-seule",
    "href": "manipulation_avancee/tidyr.html#unite-regrouper-plusieurs-colonnes-en-une-seule",
    "title": "36  Réorganisation avec tidyr",
    "section": "\n36.7 unite() : regrouper plusieurs colonnes en une seule",
    "text": "36.7 unite() : regrouper plusieurs colonnes en une seule\ntidyr::unite() est l’opération inverse de tidyr::separate(). Elle permet de regrouper plusieurs colonnes en une seule. Imaginons qu’on obtient le tableau d suivant :\n\n\n\n\ncode_departement\ncode_commune\ncommune\npop_tot\n\n\n\n01\n004\nAmbérieu-en-Bugey\n14233\n\n\n01\n007\nAmbronay\n2437\n\n\n01\n014\nArbent\n3440\n\n\n01\n024\nAttignat\n3110\n\n\n01\n025\nBâgé-la-Ville\n3130\n\n\n01\n027\nBalan\n2785\n\n\n\n\n\nOn souhaite reconstruire une colonne code_insee qui indique le code INSEE de la commune, et qui s’obtient en concaténant le code du département et celui de la commune. On peut utiliser tidyr::unite() pour cela on indique d’abord le nom de la nouvelle variable puis la liste des variables à concaténer :\n\nd |&gt;\n  unite(code_insee, code_departement, code_commune)\n\n# A tibble: 6 × 3\n  code_insee commune           pop_tot\n  &lt;chr&gt;      &lt;chr&gt;               &lt;int&gt;\n1 01_004     Ambérieu-en-Bugey   14233\n2 01_007     Ambronay             2437\n3 01_014     Arbent               3440\n4 01_024     Attignat             3110\n5 01_025     Bâgé-la-Ville        3130\n6 01_027     Balan                2785\n\n\nLe résultat n’est pas idéal : par défaut tidyr::unite() ajoute un caractère _ entre les deux valeurs concaténées, alors qu’on ne veut aucun séparateur. De plus, on souhaite conserver nos deux colonnes d’origine, qui peuvent nous être utiles. On peut résoudre ces deux problèmes à l’aide des arguments sep et remove :\n\nd |&gt; \n  unite(\n    code_insee,\n    code_departement,\n    code_commune, \n    sep = \"\",\n    remove = FALSE\n  )\n\n# A tibble: 6 × 5\n  code_insee code_departement code_commune commune           pop_tot\n  &lt;chr&gt;      &lt;chr&gt;            &lt;chr&gt;        &lt;chr&gt;               &lt;int&gt;\n1 01004      01               004          Ambérieu-en-Bugey   14233\n2 01007      01               007          Ambronay             2437\n3 01014      01               014          Arbent               3440\n4 01024      01               024          Attignat             3110\n5 01025      01               025          Bâgé-la-Ville        3130\n6 01027      01               027          Balan                2785",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Réorganisation avec `tidyr`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/tidyr.html#sec-extract",
    "href": "manipulation_avancee/tidyr.html#sec-extract",
    "title": "36  Réorganisation avec tidyr",
    "section": "\n36.8 extract() : créer de nouvelles colonnes à partir d’une colonne de texte",
    "text": "36.8 extract() : créer de nouvelles colonnes à partir d’une colonne de texte\ntidyr::extract() permet de créer de nouvelles colonnes à partir de sous-chaînes d’une colonne de texte existante, identifiées par des groupes dans une expression régulière.\nPar exemple, à partir du tableau suivant :\n\n\n\n\neleve\nnote\n\n\n\nAlex Petit\n5/20\n\n\nBertrand Dupont\n6/10\n\n\nCorinne Durand\n87/100\n\n\n\n\n\nOn peut extraire les noms et prénoms dans deux nouvelles colonnes avec :\n\ndf |&gt;\n  extract(\n    eleve,\n    c(\"prenom\", \"nom\"),\n    \"^(.*) (.*)$\"\n  )\n\n# A tibble: 3 × 3\n  prenom   nom    note  \n  &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt; \n1 Alex     Petit  5/20  \n2 Bertrand Dupont 6/10  \n3 Corinne  Durand 87/100\n\n\nOn passe donc à tidyr::extract() trois arguments :\n\nla colonne d’où on doit extraire les valeurs,\nun vecteur avec les noms des nouvelles colonnes à créer,\net une expression régulière comportant autant de groupes (identifiés par des parenthèses) que de nouvelles colonnes.\n\nPar défaut la colonne d’origine n’est pas conservée dans la table résultat. On peut modifier ce comportement avec l’argument remove = FALSE. Ainsi, le code suivant extrait les initiales du prénom et du nom mais conserve la colonne d’origine :\n\ndf |&gt;\n  tidyr::extract(\n    eleve, \n    c(\"initiale_prenom\", \"initiale_nom\"), \n    \"^(.).* (.).*$\", \n    remove = FALSE\n  )\n\n# A tibble: 3 × 4\n  eleve           initiale_prenom initiale_nom note  \n  &lt;chr&gt;           &lt;chr&gt;           &lt;chr&gt;        &lt;chr&gt; \n1 Alex Petit      A               P            5/20  \n2 Bertrand Dupont B               D            6/10  \n3 Corinne Durand  C               D            87/100",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Réorganisation avec `tidyr`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/tidyr.html#complete-compléter-des-combinaisons-de-variables-manquantes",
    "href": "manipulation_avancee/tidyr.html#complete-compléter-des-combinaisons-de-variables-manquantes",
    "title": "36  Réorganisation avec tidyr",
    "section": "\n36.9 complete() : compléter des combinaisons de variables manquantes",
    "text": "36.9 complete() : compléter des combinaisons de variables manquantes\nImaginons qu’on ait le tableau de résultats suivants :\n\n\n\n\neleve\nmatiere\nnote\n\n\n\nAlain\nMaths\n16\n\n\nAlain\nFrançais\n9\n\n\nBarnabé\nMaths\n17\n\n\nChantal\nFrançais\n11\n\n\n\n\n\nLes élèves Barnabé et Chantal n’ont pas de notes dans toutes les matières. Supposons que c’est parce qu’ils étaient absents et que leur note est en fait un 0. Si on veut calculer les moyennes des élèves, on doit compléter ces notes manquantes.\nLa fonction tidyr::complete() est prévue pour ce cas de figure : elle permet de compléter des combinaisons manquantes de valeurs de plusieurs colonnes.\nOn peut l’utiliser de cette manière :\n\ndf |&gt;\n  complete(eleve, matiere)\n\n# A tibble: 6 × 3\n  eleve   matiere   note\n  &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt;\n1 Alain   Français     9\n2 Alain   Maths       16\n3 Barnabé Français    NA\n4 Barnabé Maths       17\n5 Chantal Français    11\n6 Chantal Maths       NA\n\n\nOn voit que les combinaisons manquante “Barnabé - Français” et “Chantal - Maths” ont bien été ajoutées par tidyr::complete().\nPar défaut les lignes insérées récupèrent des valeurs manquantes NA pour les colonnes restantes. On peut néanmoins choisir une autre valeur avec l’argument fill, qui prend la forme d’une liste nommée :\n\ndf |&gt;\n  complete(\n    eleve,\n    matiere,\n    fill = list(note = 0)\n  )\n\n# A tibble: 6 × 3\n  eleve   matiere   note\n  &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt;\n1 Alain   Français     9\n2 Alain   Maths       16\n3 Barnabé Français     0\n4 Barnabé Maths       17\n5 Chantal Français    11\n6 Chantal Maths        0\n\n\nParfois on ne souhaite pas inclure toutes les colonnes dans le calcul des combinaisons de valeurs. Par exemple, supposons qu’on rajoute dans notre tableau une colonne avec les identifiants de chaque élève :\n\n\n\n\nid\neleve\nmatiere\nnote\n\n\n\n1001001\nAlain\nMaths\n16\n\n\n1001001\nAlain\nFrançais\n9\n\n\n1001002\nBarnabé\nMaths\n17\n\n\n1001003\nChantal\nFrançais\n11\n\n\n\n\n\nSi on applique tidyr::complete() comme précédemment, le résultat n’est pas bon car il génère des valeurs manquantes pour id.\n\ndf |&gt;\n  complete(eleve, matiere)\n\n# A tibble: 6 × 4\n  eleve   matiere       id  note\n  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 Alain   Français 1001001     9\n2 Alain   Maths    1001001    16\n3 Barnabé Français      NA    NA\n4 Barnabé Maths    1001002    17\n5 Chantal Français 1001003    11\n6 Chantal Maths         NA    NA\n\n\nEt si nous ajoutons id dans l’appel de la fonction, nous obtenons toutes les combinaisons de id, eleve et matiere.\n\ndf |&gt;\n  complete(id, eleve, matiere)\n\n# A tibble: 18 × 4\n        id eleve   matiere   note\n     &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt;\n 1 1001001 Alain   Français     9\n 2 1001001 Alain   Maths       16\n 3 1001001 Barnabé Français    NA\n 4 1001001 Barnabé Maths       NA\n 5 1001001 Chantal Français    NA\n 6 1001001 Chantal Maths       NA\n 7 1001002 Alain   Français    NA\n 8 1001002 Alain   Maths       NA\n 9 1001002 Barnabé Français    NA\n10 1001002 Barnabé Maths       17\n11 1001002 Chantal Français    NA\n12 1001002 Chantal Maths       NA\n13 1001003 Alain   Français    NA\n14 1001003 Alain   Maths       NA\n15 1001003 Barnabé Français    NA\n16 1001003 Barnabé Maths       NA\n17 1001003 Chantal Français    11\n18 1001003 Chantal Maths       NA\n\n\nDans ce cas, pour signifier à tidyr::complete() que id et eleve sont deux attributs d’un même individu et ne doivent pas être combinés entre eux, on doit les placer dans une fonction tidyr::nesting() :\n\ndf |&gt;\n  complete(\n    nesting(id, eleve),\n    matiere\n  )\n\n# A tibble: 6 × 4\n       id eleve   matiere   note\n    &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt;\n1 1001001 Alain   Français     9\n2 1001001 Alain   Maths       16\n3 1001002 Barnabé Français    NA\n4 1001002 Barnabé Maths       17\n5 1001003 Chantal Français    11\n6 1001003 Chantal Maths       NA",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Réorganisation avec `tidyr`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/tidyr.html#ressources",
    "href": "manipulation_avancee/tidyr.html#ressources",
    "title": "36  Réorganisation avec tidyr",
    "section": "\n36.10 Ressources",
    "text": "36.10 Ressources\nChaque jeu de données est différent, et le travail de remise en forme est souvent long et plus ou moins compliqué. On n’a donné ici que les exemples les plus simples, et c’est souvent en combinant différentes opérations qu’on finit par obtenir le résultat souhaité.\nLe livre R for data science, librement accessible en ligne, contient un chapitre complet sur la remise en forme des données.\nL’article Tidy data, publié en 2014 dans le Journal of Statistical Software (doi: 10.18637/jss.v059.i10), présente de manière détaillée le concept éponyme (mais il utilise des extensions désormais obsolètes qui ont depuis été remplacées par dplyr ettidyr).\nLe site de l’extension est accessible à l’adresse : http://tidyr.tidyverse.org/ et contient une liste des fonctions et les pages d’aide associées.\nEn particulier, on pourra se référer à la vignette dédiée à tidyr::pivot_wider() et tidyr::pivot_longer() pour des exemples avancés de réorganisation des données.\nPour des usages avancés, il est possible avec tidyr de gérer des données nichées (nested data), c’est-à-dire des tableaux de données dans des tableaux de données. Ces fonctionnalités, réservées aux utilisateurs avancés, sont décrites dans une vignette spécifique.",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Réorganisation avec `tidyr`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/tidyr.html#fichiers-volumineux",
    "href": "manipulation_avancee/tidyr.html#fichiers-volumineux",
    "title": "36  Réorganisation avec tidyr",
    "section": "\n36.11 Fichiers volumineux",
    "text": "36.11 Fichiers volumineux\nSi l’on a des tableaux de données particulièrement volumineux (plusieurs Go), les fonctions de tidyr ne sont pas les plus performantes.\nOn aura alors intérêt à regarder du côté des fonctions data.table::melt() et data.table::dcast() de l’extension data.table développées pour optimiser la performance sur les grands tableaux de données.\nPour plus de détails, voir la vignette dédiée : https://rdatatable.gitlab.io/data.table/articles/datatable-reshape.html",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Réorganisation avec `tidyr`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/tidyr.html#webin-r",
    "href": "manipulation_avancee/tidyr.html#webin-r",
    "title": "36  Réorganisation avec tidyr",
    "section": "\n36.12 webin-R",
    "text": "36.12 webin-R\nLe package tidyr est évoqué sur YouTube dans le webin-R #13 (exemples de graphiques avancés) et le le webin-R #17 (trajectoires de soins : un exemple de données longitudinales).",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Réorganisation avec `tidyr`</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/conditions-logiques.html",
    "href": "manipulation_avancee/conditions-logiques.html",
    "title": "37  Conditions logiques",
    "section": "",
    "text": "37.1 Opérateurs de comparaison\nUne manière commune de créer un vecteur logique consiste à utiliser l’un des opérateurs de comparaison suivants : &lt; (strictement inférieur), &lt;= (inférieur ou égal), &gt; (strictement supérieur), &gt;= (supérieur ou égal), == (est égal à), != (est différent de).\nOn peut comparer un vecteur de plusieurs valeurs avec une valeur unique.\nx &lt;- c(1, 5, 2, 8)\nx &lt; 3\n\n[1]  TRUE FALSE  TRUE FALSE\nSi l’on prend deux vecteurs de même longueur, la comparaison se fera ligne à ligne.\ny &lt;- c(3, 5, 1, 7)\ny &gt;= x\n\n[1]  TRUE  TRUE FALSE FALSE\n\ny == x\n\n[1] FALSE  TRUE FALSE FALSE\n\ny != x\n\n[1]  TRUE FALSE  TRUE  TRUE\nOn peut ainsi facilement sélectionner des lignes d’un tableau de données à partir d’une condition sur certaines variables.\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndata(\"hdv2003\", package = \"questionr\")\nhdv2003 |&gt; nrow()\n\n[1] 2000\n\nhdv2003 |&gt;\n  filter(sexe == \"Femme\") |&gt; \n  nrow()\n\n[1] 1101\n\nhdv2003 |&gt; \n  filter(age &lt; 25) |&gt; \n  nrow()\n\n[1] 169",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Conditions logiques</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/conditions-logiques.html#opérateurs-de-comparaison",
    "href": "manipulation_avancee/conditions-logiques.html#opérateurs-de-comparaison",
    "title": "37  Conditions logiques",
    "section": "",
    "text": "Tester l’égalité d’une valeur décimale\n\n\n\nLorsque l’on effectue un test d’égalité avec des valeurs décimales, le test échouera si les deux valeurs ne sont pas parfaitement identique.\nPrenons un exemple :\n\nx &lt;- 1 / 49 * 49\nx\n\n[1] 1\n\nx == 1\n\n[1] FALSE\n\n\nPourquoi ce test échoue-t-il ? Le nombre de décimales stockées par l’ordinateur est limité et, de ce fait, il peut y avoir quelques écarts d’arrondis. Ainsi, x n’est pas tout à fait égal à 1, ce qui devient visible si on l’affiche avec un nombre élevé de décimales.\n\nprint(x, digits = 16)\n\n[1] 0.9999999999999999\n\n\nDans ce cas là, on pourra avoir recours à dplyr::near() qui prendra en compte la précision de l’ordinateur dans la comparaison.\n\nnear(x, 1)\n\n[1] TRUE\n\n\nOn peut aussi utiliser cette fonction en personnalisant le niveau de tolérance pour la comparaison.\n\nnear(c(2.1, 3.4), 2, tol = 1)\n\n[1]  TRUE FALSE",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Conditions logiques</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/conditions-logiques.html#sec-comparaison-valeurs-manquantes",
    "href": "manipulation_avancee/conditions-logiques.html#sec-comparaison-valeurs-manquantes",
    "title": "37  Conditions logiques",
    "section": "\n37.2 Comparaison et valeurs manquantes",
    "text": "37.2 Comparaison et valeurs manquantes\nLes valeurs manquantes (NA) peuvent être parfois problématiques lors d’une comparaison car elles renvoient systématique une valeur manquante.\n\n2 &lt; NA\n\n[1] NA\n\nNA == 6\n\n[1] NA\n\n\nLorsque l’on sélectionne des observations avec la syntaxe des crochets ([], voir Chapitre 4), cela va générer des lignes vides / manquantes.\n\nd &lt;- tibble(\n  a = c(1, NA, 3, 4),\n  b = c(\"x\", \"y\", \"x\", \"y\")\n)\nd[d$a &gt; 2, ]\n\n# A tibble: 3 × 2\n      a b    \n  &lt;dbl&gt; &lt;chr&gt;\n1    NA &lt;NA&gt; \n2     3 x    \n3     4 y    \n\n\nLe recours à dplyr::filter() est plus sûr car les lignes pour lesquelles la condition renvoie NA ne sont pas sélectionnées.\n\nd |&gt; filter(a &gt; 2)\n\n# A tibble: 2 × 2\n      a b    \n  &lt;dbl&gt; &lt;chr&gt;\n1     3 x    \n2     4 y    \n\n\nL’opérateur == ne peut pas être utilisé pour tester si une valeur est manquante. On utilisera à la place la fonction is.na().\n\nd$a == NA\n\n[1] NA NA NA NA\n\nis.na(d$a)\n\n[1] FALSE  TRUE FALSE FALSE\n\n\n\n\n\n\n\n\nAstuce\n\n\n\nVoici deux petites fonctions permettant de tester si deux valeurs sont identiques ou différentes, en tenant compte des NA comme l’un des valeurs possibles (deux NA seront alors considérés comme égaux).\n\nis_different &lt;- function(x, y) {\n  (x != y & !is.na(x) & !is.na(y)) | xor(is.na(x), is.na(y))\n}\n\nis_equal &lt;- function(x, y) {\n  (x == y & !is.na(x) & !is.na(y)) | (is.na(x) & is.na(y))\n}\n\nv &lt;- c(1, NA, NA, 2)\nw &lt;- c(1, 2, NA, 3)\n\nv == w\n\n[1]  TRUE    NA    NA FALSE\n\nis_equal(v, w)\n\n[1]  TRUE FALSE  TRUE FALSE\n\nv != w\n\n[1] FALSE    NA    NA  TRUE\n\nis_different(v, w)\n\n[1] FALSE  TRUE FALSE  TRUE",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Conditions logiques</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/conditions-logiques.html#opérateurs-logiques-algèbre-booléenne",
    "href": "manipulation_avancee/conditions-logiques.html#opérateurs-logiques-algèbre-booléenne",
    "title": "37  Conditions logiques",
    "section": "\n37.3 Opérateurs logiques (algèbre booléenne)",
    "text": "37.3 Opérateurs logiques (algèbre booléenne)\nLes opérateurs logiques permettent de combiner ensemble plusieurs vecteurs logiques :\n\n& : opérateur et (x & y est vrai si à la fois x et y sont vrais) ;\n| : opérateur ou (x | y est vrai si x ou y ou les deux sont vrais) ;\nxor() : opérateur ou exclusif (xor(x, y) est vrai si seulement x ou seulement y est vrai, mais pas les deux) ;\n! : opérateur non (!x est vrai si x est faux).\n\n\n\nReprésentation graphique de l’ensemble des opérations logiques. Le cercle de gauche représente x et celui de droite y. La région colorée représente le résultat de l’opération.\n\nIls permettent de combiner plusieurs conditions entre elles.\n\nhdv2003 |&gt;\n  filter(sexe == \"Femme\" & age &lt; 25) |&gt; \n  nrow()\n\n[1] 93\n\nhdv2003 |&gt;\n  filter(sexe == \"Femme\" | age &lt; 25) |&gt; \n  nrow()\n\n[1] 1177\n\n\nPour des conditions complexes, on utilisera des parenthèses pour indiquer dans quel ordre effectuer les opérations.\n\n# sélectionne les jeunes femmes et les hommes âgés\nhdv2003 |&gt;\n  filter(\n    (sexe == \"Femme\" & age &lt; 25) | \n      (sexe == \"Homme\" & age &gt; 60)) |&gt; \n  nrow()\n\n[1] 315\n\n\n\n37.3.1 Opérations logiques et Valeurs manquantes\nOn sera vigilant·e avec les valeurs manquantes. Cela peut paraître un peu obscur au premier abord, mais est en fait parfaitement logique.\n\ndf &lt;- tibble(x = c(TRUE, FALSE, NA))\n\ndf |&gt; \n  mutate(\n    et_na = x & NA,\n    ou_na = x | NA\n  )\n\n# A tibble: 3 × 3\n  x     et_na ou_na\n  &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt;\n1 TRUE  NA    TRUE \n2 FALSE FALSE NA   \n3 NA    NA    NA   \n\n\nTRUE | NA vaut TRUE car la condition reste vrai quelle que soit la valeur du deuxième paramètre, tandis que FALSE | NA renvoie NA car le résultat est indéterminé (il dépend du deuxième paramètre).\n\n37.3.2 L’opérateur %in%\n\nIl est fréquent de vouloir tester simultanément plusieurs égalités. Par exemple :\n\nx &lt;- c(\"a\", \"b\", \"c\", \"d\")\nx == \"a\" | x == \"b\"\n\n[1]  TRUE  TRUE FALSE FALSE\n\n\nOn aura alors avantageusement recours à l’opérateur %in% que l’on peut traduire par appartient à et qui teste si les éléments appartiennent à un certain ensemble.\n\nx %in% c(\"a\", \"b\")\n\n[1]  TRUE  TRUE FALSE FALSE",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Conditions logiques</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/conditions-logiques.html#aggrégation",
    "href": "manipulation_avancee/conditions-logiques.html#aggrégation",
    "title": "37  Conditions logiques",
    "section": "\n37.4 Aggrégation",
    "text": "37.4 Aggrégation\nPour résumer un ensemble de valeurs logiques en une seule, on utilisera les fonction all() et any() qui teste si toutes les valeurs / au moins une valeur est vrai. Ces deux fonctions acceptent un argument na.rm permettant de ne pas tenir compte des valeurs manquantes.\n\nx &lt;- c(TRUE, NA, FALSE, FALSE)\nany(x)\n\n[1] TRUE\n\nall(x)\n\n[1] FALSE\n\n\nUn vecteur logique peut-être vu comme un vecteur de valeur binaire (0 si FALSE, 1 si TRUE). On peut dès lors effectuer des opérations comme la somme ou la moyenne.\n\nsum(x, na.rm = TRUE)\n\n[1] 1\n\nmean(x, na.rm = TRUE)\n\n[1] 0.3333333",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Conditions logiques</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/conditions-logiques.html#programmation",
    "href": "manipulation_avancee/conditions-logiques.html#programmation",
    "title": "37  Conditions logiques",
    "section": "\n37.5 Programmation",
    "text": "37.5 Programmation\nLorsque l’on programme avec R, notamment avec des structures conditionnelles telles que if ... else ..., on a besoin d’écrire des conditions qui ne renvoient qu’une et une seule valeur logique.\nLes opérateurs & et | s’appliquent sur des vecteurs et donc renvoient potentiellement plusieurs valeurs. On privilégiera alors les variantes && et || qui ne renvoient qu’une seule valeur et produise une erreur sinon.\nDe même, pour vérifier qu’un objet est bien égal à TRUE ou à FALSE, n’est pas nul, n’est pas manquant et est de longueur 1, on utilisera isTRUE() et isFALSE().\n\nisTRUE(TRUE)\n\n[1] TRUE\n\nisTRUE(NA)\n\n[1] FALSE\n\nisTRUE(NULL)\n\n[1] FALSE\n\nisTRUE(c(TRUE, TRUE))\n\n[1] FALSE\n\n\n\n\n\nReprésentation graphique de l’ensemble des opérations logiques. Le cercle de gauche représente x et celui de droite y. La région colorée représente le résultat de l’opération.",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Conditions logiques</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/fonctions-a-fenetre.html",
    "href": "manipulation_avancee/fonctions-a-fenetre.html",
    "title": "38  Fonctions à fenêtre",
    "section": "",
    "text": "38.1 Rappels à propos du tri\nLa fonction dplyr::arange() permet de trier les valeurs d’un tableau de données. Par exemple, pour trier sur la longueur des pétales :\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\niris |&gt;\n  arrange(Petal.Length) |&gt; \n  head()\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          4.6         3.6          1.0         0.2  setosa\n2          4.3         3.0          1.1         0.1  setosa\n3          5.8         4.0          1.2         0.2  setosa\n4          5.0         3.2          1.2         0.2  setosa\n5          4.7         3.2          1.3         0.2  setosa\n6          5.4         3.9          1.3         0.4  setosa\nPour un tri décroissant, on utilisera dplyr::desc().\niris |&gt;\n  arrange(desc(Petal.Length)) |&gt; \n  head()\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n1          7.7         2.6          6.9         2.3 virginica\n2          7.7         3.8          6.7         2.2 virginica\n3          7.7         2.8          6.7         2.0 virginica\n4          7.6         3.0          6.6         2.1 virginica\n5          7.9         3.8          6.4         2.0 virginica\n6          7.3         2.9          6.3         1.8 virginica\nIl est possible de fournir plusieurs variables de tri. Par exemple, pour trier sur l’espèce puis, pour les observations d’une même espace, selon la longueur du sépale de manière décroissante :\niris |&gt;\n  arrange(Species, desc(Sepal.Length)) |&gt; \n  head()\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.8         4.0          1.2         0.2  setosa\n2          5.7         4.4          1.5         0.4  setosa\n3          5.7         3.8          1.7         0.3  setosa\n4          5.5         4.2          1.4         0.2  setosa\n5          5.5         3.5          1.3         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\nPar défaut, arrange() ne tient pas compte des variables de groupement quand elles existent.\niris |&gt; \n  group_by(Species) |&gt; \n  arrange(desc(Sepal.Length))\n\n# A tibble: 150 × 5\n# Groups:   Species [3]\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species  \n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;    \n 1          7.9         3.8          6.4         2   virginica\n 2          7.7         3.8          6.7         2.2 virginica\n 3          7.7         2.6          6.9         2.3 virginica\n 4          7.7         2.8          6.7         2   virginica\n 5          7.7         3            6.1         2.3 virginica\n 6          7.6         3            6.6         2.1 virginica\n 7          7.4         2.8          6.1         1.9 virginica\n 8          7.3         2.9          6.3         1.8 virginica\n 9          7.2         3.6          6.1         2.5 virginica\n10          7.2         3.2          6           1.8 virginica\n# ℹ 140 more rows\nPour inclure les variables de groupement dans le tri, il faut préciser .by_group = TRUE.\niris |&gt; \n  group_by(Species) |&gt; \n  arrange(desc(Sepal.Length), .by_group = TRUE)\n\n# A tibble: 150 × 5\n# Groups:   Species [3]\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n 1          5.8         4            1.2         0.2 setosa \n 2          5.7         4.4          1.5         0.4 setosa \n 3          5.7         3.8          1.7         0.3 setosa \n 4          5.5         4.2          1.4         0.2 setosa \n 5          5.5         3.5          1.3         0.2 setosa \n 6          5.4         3.9          1.7         0.4 setosa \n 7          5.4         3.7          1.5         0.2 setosa \n 8          5.4         3.9          1.3         0.4 setosa \n 9          5.4         3.4          1.7         0.2 setosa \n10          5.4         3.4          1.5         0.4 setosa \n# ℹ 140 more rows",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Fonctions à fenêtre</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/fonctions-a-fenetre.html#valeurs-précédentes-et-suivantes",
    "href": "manipulation_avancee/fonctions-a-fenetre.html#valeurs-précédentes-et-suivantes",
    "title": "38  Fonctions à fenêtre",
    "section": "\n38.2 Valeurs précédentes et suivantes",
    "text": "38.2 Valeurs précédentes et suivantes\nLa fonction dplyr::lag() permet d’accéder à la valeur précédente d’un vecteur et la fonction dplyr::lead() à la valeur suivante. Il est donc prudent de toujours bien trier son tableau en amont. L’argument n permet d’accéder à la seconde valeur suivante, ou la troisième, etc.\n\nd &lt;- tibble(\n  nom = c(\"marc\", \"marie\", \"antoine\", \"dominique\", \"michelle\"),\n  score = c(122, 182, 144, 167, 144),\n  groupe = c(\"a\", \"a\", \"a\", \"b\", \"b\")\n)\n\nd |&gt; \n  arrange(desc(score)) |&gt; \n  mutate(\n    precedent = lag(nom),\n    suivant = lead(nom),\n    sur_suivant = lead(nom, n = 2)\n  )\n\n# A tibble: 5 × 6\n  nom       score groupe precedent suivant   sur_suivant\n  &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;      \n1 marie       182 a      &lt;NA&gt;      dominique antoine    \n2 dominique   167 b      marie     antoine   michelle   \n3 antoine     144 a      dominique michelle  marc       \n4 michelle    144 b      antoine   marc      &lt;NA&gt;       \n5 marc        122 a      michelle  &lt;NA&gt;      &lt;NA&gt;       \n\n\nÀ noter, cela génère des valeurs manquantes (NA) au début ou à la fin de la nouvelle variable.",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Fonctions à fenêtre</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/fonctions-a-fenetre.html#fonctions-de-rang",
    "href": "manipulation_avancee/fonctions-a-fenetre.html#fonctions-de-rang",
    "title": "38  Fonctions à fenêtre",
    "section": "\n38.3 Fonctions de rang",
    "text": "38.3 Fonctions de rang\nLes fonctions de rang vise à calculer le rang d’un individu, c’est-à-dire sa position quand le vecteur est trié d’une certaine manière. La fonction de base sous R est rank() qui propose plusieurs options. Mais l’on pourra se référer plus facilement aux différentes fonctions disponibles dans dplyr.\nLa première est dplyr::row_number() qui par défaut va numéroter les lignes du tableau selon le tri actuel.\n\nd |&gt; mutate(rang = row_number())\n\n# A tibble: 5 × 4\n  nom       score groupe  rang\n  &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;int&gt;\n1 marc        122 a          1\n2 marie       182 a          2\n3 antoine     144 a          3\n4 dominique   167 b          4\n5 michelle    144 b          5\n\n\nOn peut optionnellement lui passer une variable de tri pour le calcul du rang.\n\nd |&gt; mutate(rang = row_number(desc(score)))\n\n# A tibble: 5 × 4\n  nom       score groupe  rang\n  &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;int&gt;\n1 marc        122 a          5\n2 marie       182 a          1\n3 antoine     144 a          3\n4 dominique   167 b          2\n5 michelle    144 b          4\n\n\nOu encore trier notre tableau en amont.\n\nd |&gt; \n  arrange(desc(score)) |&gt; \n  mutate(rang = row_number())\n\n# A tibble: 5 × 4\n  nom       score groupe  rang\n  &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;int&gt;\n1 marie       182 a          1\n2 dominique   167 b          2\n3 antoine     144 a          3\n4 michelle    144 b          4\n5 marc        122 a          5\n\n\nChaque rang est ici unique. En cas d’égalité, les individus sont classés selon l’ordre du tableau. Mais dans cet exemple, il semble injuste de classer Michelle derrière Antoine dans la mesure où ils ont eu le même score. On pourra alors utiliser dplyr::min_rank() qui attribue aux observations égales le premier rang. Ici, Michelle et Antoine seront tous les deux classés 3e et Marc classé 5e.\n\nd |&gt; \n  arrange(desc(score)) |&gt; \n  mutate(rang = min_rank(desc(score)))\n\n# A tibble: 5 × 4\n  nom       score groupe  rang\n  &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;int&gt;\n1 marie       182 a          1\n2 dominique   167 b          2\n3 antoine     144 a          3\n4 michelle    144 b          3\n5 marc        122 a          5\n\n\nPour éviter la présence de sauts dans le classement et considéré Marc comme 4e, on utilisera dplyr::dense_rank().\n\nd |&gt; \n  arrange(desc(score)) |&gt; \n  mutate(rang = dense_rank(desc(score)))\n\n# A tibble: 5 × 4\n  nom       score groupe  rang\n  &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;int&gt;\n1 marie       182 a          1\n2 dominique   167 b          2\n3 antoine     144 a          3\n4 michelle    144 b          3\n5 marc        122 a          4\n\n\nPour plus d’options, on aura recours à rank(), qui par défaut attribue un rang moyen.\n\nd |&gt; \n  arrange(desc(score)) |&gt; \n  mutate(rang = rank(desc(score)))\n\n# A tibble: 5 × 4\n  nom       score groupe  rang\n  &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;\n1 marie       182 a        1  \n2 dominique   167 b        2  \n3 antoine     144 a        3.5\n4 michelle    144 b        3.5\n5 marc        122 a        5  \n\n\nMais il est possible d’indiquer d’autres méthodes de traitement des égalités, par exemple l’utilisation du rang maximum (l’inverse de min_rank()).\n\nd |&gt; \n  arrange(desc(score)) |&gt; \n  mutate(rang = rank(desc(score), ties.method = \"max\"))\n\n# A tibble: 5 × 4\n  nom       score groupe  rang\n  &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;int&gt;\n1 marie       182 a          1\n2 dominique   167 b          2\n3 antoine     144 a          4\n4 michelle    144 b          4\n5 marc        122 a          5\n\n\nLa fonction dplyr::percent_risk() renvoie un rang en pourcentage, c’est-à-dire une valeur numérique entre 0 et 1 où 0 représente le plus petit rang et 1 le plus grand.\n\nd |&gt; \n  arrange(desc(score)) |&gt; \n  mutate(rang = percent_rank(desc(score)))\n\n# A tibble: 5 × 4\n  nom       score groupe  rang\n  &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;\n1 marie       182 a       0   \n2 dominique   167 b       0.25\n3 antoine     144 a       0.5 \n4 michelle    144 b       0.5 \n5 marc        122 a       1   \n\n\nEnfin, les rangs peuvent être calculés par groupe.\n\nd |&gt; \n  group_by(groupe) |&gt;  \n  mutate(rang = min_rank(desc(score))) |&gt; \n  arrange(groupe, rang)\n\n# A tibble: 5 × 4\n# Groups:   groupe [2]\n  nom       score groupe  rang\n  &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;int&gt;\n1 marie       182 a          1\n2 antoine     144 a          2\n3 marc        122 a          3\n4 dominique   167 b          1\n5 michelle    144 b          2",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Fonctions à fenêtre</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/fonctions-a-fenetre.html#fonctions-cumulatives",
    "href": "manipulation_avancee/fonctions-a-fenetre.html#fonctions-cumulatives",
    "title": "38  Fonctions à fenêtre",
    "section": "\n38.4 Fonctions cumulatives",
    "text": "38.4 Fonctions cumulatives\nR propose nativement plusieurs fonctions cumulatives comme la somme (cumsum()), le minimum (cummin()), le maximum (cummax()) ou encore le produit (cumprod()). dplyr fournit la moyenne cumulée (dplyr::cummean()). Le calcul s’effectue à chaque fois sur les premières lignes du tableau jusqu’à la ligne considérée.\n\nd |&gt; \n  mutate(\n    sum = cumsum(score),\n    mean = cummean(score),\n    min = cummin(score),\n    max = cummax(score),\n    prod = cumprod(score)\n  )\n\n# A tibble: 5 × 8\n  nom       score groupe   sum  mean   min   max        prod\n  &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;\n1 marc        122 a        122  122    122   122         122\n2 marie       182 a        304  152    122   182       22204\n3 antoine     144 a        448  149.   122   182     3197376\n4 dominique   167 b        615  154.   122   182   533961792\n5 michelle    144 b        759  152.   122   182 76890498048\n\n\nLe résultat est de facto fortement dépendant du tri du tableau.\n\nd |&gt; \n  arrange(score) |&gt; \n  mutate(\n    sum = cumsum(score),\n    mean = cummean(score),\n    min = cummin(score),\n    max = cummax(score),\n    prod = cumprod(score)\n  )\n\n# A tibble: 5 × 8\n  nom       score groupe   sum  mean   min   max        prod\n  &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;\n1 marc        122 a        122  122    122   122         122\n2 antoine     144 a        266  133    122   144       17568\n3 michelle    144 b        410  137.   122   144     2529792\n4 dominique   167 b        577  144.   122   167   422475264\n5 marie       182 a        759  152.   122   182 76890498048\n\n\nPour des tests sur des valeurs conditions, on pourra avoir recours à dplyr::cumany() ou dplyr::cumall().\n\nd |&gt; \n  mutate(\n    cumany = cumany(score &gt; 150)\n  )\n\n# A tibble: 5 × 4\n  nom       score groupe cumany\n  &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;lgl&gt; \n1 marc        122 a      FALSE \n2 marie       182 a      TRUE  \n3 antoine     144 a      TRUE  \n4 dominique   167 b      TRUE  \n5 michelle    144 b      TRUE  \n\n\nOn peut, notamment dans des analyses longitudinales, avoir besoin de repérer chaque changement d’une certaine valeur. Dans le chapitre sur les conditions logiques, nous avions proposé une fonction is_different() permettant de comparer deux valeurs tout en tenant compte des valeurs manquantes (voir Section 37.2). Nous proposons ici une fonction cumdifferent() permettant de compter les changements de valeurs (et donc d’identifier les lignes continues ayant les mêmes valeurs).\n\nis_different &lt;- function(x, y) {\n  (x != y & !is.na(x) & !is.na(y)) | xor(is.na(x), is.na(y))\n}\ncumdifferent &lt;- function(x) {\n  cumsum(is_different(x, lag(x)))\n}\n\n\nd |&gt; \n  arrange(score) |&gt; \n  mutate(sous_groupe = cumdifferent(groupe))\n\n# A tibble: 5 × 4\n  nom       score groupe sous_groupe\n  &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;        &lt;int&gt;\n1 marc        122 a                1\n2 antoine     144 a                1\n3 michelle    144 b                2\n4 dominique   167 b                2\n5 marie       182 a                3",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Fonctions à fenêtre</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/transformations-multiples.html",
    "href": "manipulation_avancee/transformations-multiples.html",
    "title": "39  Transformations multiples",
    "section": "",
    "text": "39.1 Transformations multiples sur les colonnes\nIl est souvent utile d’effectuer la même opération sur plusieurs colonnes, mais le copier-coller est à la fois fastidieux et source d’erreurs :\ndf |&gt; \n  group_by(g1, g2) |&gt; \n  summarise(\n    a = mean(a),\n    b = mean(b),\n    c = mean(c),\n    d = mean(d)\n  )\nDans cette section, nous allons introduire dplyr::across() qui permets de réécrire la même commande de manière plus succincte.\ndf |&gt; \n  group_by(g1, g2) |&gt; \n  summarise(across(a:d, mean))",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Transformations multiples</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/transformations-multiples.html#transformations-multiples-sur-les-colonnes",
    "href": "manipulation_avancee/transformations-multiples.html#transformations-multiples-sur-les-colonnes",
    "title": "39  Transformations multiples",
    "section": "",
    "text": "39.1.1 Usage de base\ndplyr::across() a deux arguments principaux :\n\nle premier, .cols, permet de sélectionner les colonnes sur lesquelles on souhaite agir et accepte la même syntaxe de dplyr::select() ;\nle second, .fns, est une fonction (ou une liste de fonctions) à appliquer à chaque colonne sélectionnée.\n\nVoici quelques exemples avec dplyr::summarise().\nDans ce premier exemple, nous utilisons tidyselect::where() qui permet de sélectionner les colonnes en fonction de leur type (ici les colonnes textuelles car where() est utilisé en conjonction avec la fonction is.character()). Notez que l’on passe is.character() sans ajouter de parenthèse. En effet, is.character renvoie la fonction du même nom, tandis que is.character() appelle la fonction pour l’exécuter. La fonction dplyr::n_distinct(), quant à elle, compte le nombre de valeurs uniques. Le tableau ci-dessous renvoie donc, pour chaque variable textuelle, le nombre de valeurs uniques observées dans les données.\n\nlibrary(tidyverse)\nstarwars |&gt;  \n  summarise(across(where(is.character), n_distinct))\n\n# A tibble: 1 × 8\n   name hair_color skin_color eye_color   sex gender homeworld species\n  &lt;int&gt;      &lt;int&gt;      &lt;int&gt;     &lt;int&gt; &lt;int&gt;  &lt;int&gt;     &lt;int&gt;   &lt;int&gt;\n1    87         12         31        15     5      3        49      38\n\n\nDans ce second exemple, nous indiquons simplement la liste de nos variables d’intérêt.\n\nstarwars |&gt; \n  group_by(species) |&gt; \n  filter(n() &gt; 1) |&gt;  \n  summarise(across(c(sex, gender, homeworld), n_distinct))\n\n# A tibble: 9 × 4\n  species    sex gender homeworld\n  &lt;chr&gt;    &lt;int&gt;  &lt;int&gt;     &lt;int&gt;\n1 Droid        1      2         3\n2 Gungan       1      1         1\n3 Human        2      2        15\n4 Kaminoan     2      2         1\n5 Mirialan     1      1         1\n6 Twi'lek      2      2         1\n7 Wookiee      1      1         1\n8 Zabrak       1      1         2\n9 &lt;NA&gt;         1      1         3\n\n\nDans ce troisième exemple, nous allons calculer la moyenne pour chaque variable numérique.\n\nstarwars |&gt; \n  group_by(homeworld) |&gt;  \n  filter(n() &gt; 1) |&gt;  \n  summarise(across(where(is.numeric), mean))\n\n# A tibble: 10 × 4\n   homeworld height  mass birth_year\n   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;\n 1 Alderaan    176.  NA           NA\n 2 Corellia    175   78.5         25\n 3 Coruscant   174.  NA           NA\n 4 Kamino      208.  NA           NA\n 5 Kashyyyk    231  124           NA\n 6 Mirial      168   53.1         49\n 7 Naboo       177.  NA           NA\n 8 Ryloth      179   NA           NA\n 9 Tatooine    170.  NA           NA\n10 &lt;NA&gt;         NA   NA           NA\n\n\nIl y a beaucoup de valeurs manquantes. Nous devons donc passer na.rm = TRUE à mean(). Différentes approches sont possibles :\n\nécrire notre propre fonction ma_fonction() ;\nutiliser purrr::partial() qui permet de renvoyer une fonction avec des valeurs par défaut différentes ;\nla syntaxe native de R pour déclarer des fonctions anonymes avec le raccourci \\(arg) expr ;\nune formule définissant une fonction dans le style du package purrr, c’est-à-dire une formule commençant par ~ et dont le premier argument sera noté .x1.\n\n1 Cette syntaxe particulière n’est compatible que dans certaines fonctions du tidyverse. Ce n’est pas une syntaxe standard de R.\nma_fonction &lt;- function(x) {mean(x, na.rm = TRUE)}\nstarwars |&gt; \n  group_by(homeworld) |&gt;  \n  filter(n() &gt; 1) |&gt;  \n  summarise(across(where(is.numeric), ma_fonction))\n\n# A tibble: 10 × 4\n   homeworld height  mass birth_year\n   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;\n 1 Alderaan    176.  64         43  \n 2 Corellia    175   78.5       25  \n 3 Coruscant   174.  50         91  \n 4 Kamino      208.  83.1       31.5\n 5 Kashyyyk    231  124        200  \n 6 Mirial      168   53.1       49  \n 7 Naboo       177.  64.2       55  \n 8 Ryloth      179   55         48  \n 9 Tatooine    170.  85.4       54.6\n10 &lt;NA&gt;        139.  82        334. \n\nstarwars |&gt; \n  group_by(homeworld) |&gt;  \n  filter(n() &gt; 1) |&gt;  \n  summarise(across(where(is.numeric), purrr::partial(mean, na.rm = TRUE)))\n\n# A tibble: 10 × 4\n   homeworld height  mass birth_year\n   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;\n 1 Alderaan    176.  64         43  \n 2 Corellia    175   78.5       25  \n 3 Coruscant   174.  50         91  \n 4 Kamino      208.  83.1       31.5\n 5 Kashyyyk    231  124        200  \n 6 Mirial      168   53.1       49  \n 7 Naboo       177.  64.2       55  \n 8 Ryloth      179   55         48  \n 9 Tatooine    170.  85.4       54.6\n10 &lt;NA&gt;        139.  82        334. \n\nstarwars |&gt; \n  group_by(homeworld) |&gt;  \n  filter(n() &gt; 1) |&gt;  \n  summarise(across(where(is.numeric), \\(x) {mean(x, na.rm = TRUE)}))\n\n# A tibble: 10 × 4\n   homeworld height  mass birth_year\n   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;\n 1 Alderaan    176.  64         43  \n 2 Corellia    175   78.5       25  \n 3 Coruscant   174.  50         91  \n 4 Kamino      208.  83.1       31.5\n 5 Kashyyyk    231  124        200  \n 6 Mirial      168   53.1       49  \n 7 Naboo       177.  64.2       55  \n 8 Ryloth      179   55         48  \n 9 Tatooine    170.  85.4       54.6\n10 &lt;NA&gt;        139.  82        334. \n\nstarwars |&gt; \n  group_by(homeworld) |&gt;  \n  filter(n() &gt; 1) |&gt;  \n  summarise(across(where(is.numeric), ~ mean(.x, na.rm = TRUE)))\n\n# A tibble: 10 × 4\n   homeworld height  mass birth_year\n   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;\n 1 Alderaan    176.  64         43  \n 2 Corellia    175   78.5       25  \n 3 Coruscant   174.  50         91  \n 4 Kamino      208.  83.1       31.5\n 5 Kashyyyk    231  124        200  \n 6 Mirial      168   53.1       49  \n 7 Naboo       177.  64.2       55  \n 8 Ryloth      179   55         48  \n 9 Tatooine    170.  85.4       54.6\n10 &lt;NA&gt;        139.  82        334. \n\n\nComme dplyr::across() est souvent utilisée au sein de dplyr::mutate() ou de dplyr::summarise(), les variables de groupement ne sont jamais sélectionnée par dplyr::across() pour éviter tout accident.\n\ndf &lt;- data.frame(\n  g = c(1, 1, 2),\n  x = c(-1, 1, 3),\n  y = c(-1, -4, -9)\n)\ndf |&gt; \n  group_by(g) |&gt; \n  summarise(across(where(is.numeric), sum))\n\n# A tibble: 2 × 3\n      g     x     y\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     0    -5\n2     2     3    -9\n\n\n\n39.1.2 Fonctions multiples\nVous pouvez transformer chaque variable avec plus d’une fonction en fournissant une liste nommée de fonctions dans le deuxième argument :\n\nmin_max &lt;- list(\n  min = \\(x) min(x, na.rm = TRUE), \n  max = \\(x) max(x, na.rm = TRUE)\n)\nstarwars |&gt; \n  summarise(across(where(is.numeric), min_max))\n\n# A tibble: 1 × 6\n  height_min height_max mass_min mass_max birth_year_min birth_year_max\n       &lt;int&gt;      &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;\n1         66        264       15     1358              8            896\n\n\nOn peut contrôler le nom des variables produites avec l’option .names qui prend une chaîne de caractère au format du package glue.\n\nstarwars |&gt; \n  summarise(\n    across(\n      where(is.numeric),\n      min_max,\n      .names = \"{.fn}.{.col}\"\n    )\n  )\n\n# A tibble: 1 × 6\n  min.height max.height min.mass max.mass min.birth_year max.birth_year\n       &lt;int&gt;      &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;\n1         66        264       15     1358              8            896\n\n\n\n39.1.3 Accéder à la colonne courante\nSi vous en avez besoin, vous pouvez accéder au nom de la colonne courante à l’intérieur d’une fonction en appelant dplyr::cur_column(). Cela peut être utile si vous voulez effectuer une sorte de transformation dépendante du contexte qui est déjà encodée dans un vecteur :\n\ndf &lt;- tibble(x = 1:3, y = 3:5, z = 5:7)\nmult &lt;- list(x = 1, y = 10, z = 100)\n\ndf |&gt; \n  mutate(\n    across(\n      all_of(names(mult)), \n      ~ .x * mult[[cur_column()]]\n    )\n  )\n\n# A tibble: 3 × 3\n      x     y     z\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1    30   500\n2     2    40   600\n3     3    50   700\n\n\nJusqu’à présent, nous nous sommes concentrés sur l’utilisation de across() avec summarise(), mais cela fonctionne avec n’importe quel autre verbe dplyr qui utilise le masquage de données.\nPar exemple, nous pouvons rééchelonner toutes les variables numériques pour se situer entre 0 et 1.\n\nrescale01 &lt;- function(x) {\n  rng &lt;- range(x, na.rm = TRUE)\n  (x - rng[1]) / (rng[2] - rng[1])\n}\ndf &lt;- tibble(x = 1:4, y = rnorm(4))\ndf |&gt; \n  mutate(across(where(is.numeric), rescale01))\n\n# A tibble: 4 × 2\n      x     y\n  &lt;dbl&gt; &lt;dbl&gt;\n1 0     1    \n2 0.333 0    \n3 0.667 0.136\n4 1     0.261\n\n\n\n39.1.4 pick()\nPour certains verbes, comme dplyr::group_by(), dplyr::count() et dplyr::distinct(), il n’est pas nécessaire de fournir une fonction de résumé, mais il peut être utile de pouvoir sélectionner dynamiquement un ensemble de colonnes.\nDans ce cas, nous recommandons d’utiliser le complément de dplyr::across(), dplyr::pick(), qui fonctionne comme across() mais n’applique aucune fonction et renvoie à la place un cadre de données contenant les colonnes sélectionnées.\n\nstarwars |&gt; \n  distinct(pick(contains(\"color\")))\n\n# A tibble: 67 × 3\n   hair_color    skin_color  eye_color\n   &lt;chr&gt;         &lt;chr&gt;       &lt;chr&gt;    \n 1 blond         fair        blue     \n 2 &lt;NA&gt;          gold        yellow   \n 3 &lt;NA&gt;          white, blue red      \n 4 none          white       yellow   \n 5 brown         light       brown    \n 6 brown, grey   light       blue     \n 7 brown         light       blue     \n 8 &lt;NA&gt;          white, red  red      \n 9 black         light       brown    \n10 auburn, white fair        blue-gray\n# ℹ 57 more rows\n\nstarwars |&gt; \n  count(pick(contains(\"color\")), sort = TRUE)\n\n# A tibble: 67 × 4\n   hair_color skin_color eye_color     n\n   &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;     &lt;int&gt;\n 1 brown      light      brown         6\n 2 brown      fair       blue          4\n 3 none       grey       black         4\n 4 black      dark       brown         3\n 5 blond      fair       blue          3\n 6 black      fair       brown         2\n 7 black      tan        brown         2\n 8 black      yellow     blue          2\n 9 brown      fair       brown         2\n10 none       white      yellow        2\n# ℹ 57 more rows\n\n\ndplyr::across() ne fonctionne pas avec dplyr::select() ou dplyr::rename() parce qu’ils utilisent déjà une syntaxe de sélection dynamique. Si vous voulez transformer les noms de colonnes avec une fonction, vous pouvez utiliser dplyr::rename_with().",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Transformations multiples</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/transformations-multiples.html#sélection-de-lignes-à-partir-dune-sélection-de-colonnes",
    "href": "manipulation_avancee/transformations-multiples.html#sélection-de-lignes-à-partir-dune-sélection-de-colonnes",
    "title": "39  Transformations multiples",
    "section": "\n39.2 Sélection de lignes à partir d’une sélection de colonnes",
    "text": "39.2 Sélection de lignes à partir d’une sélection de colonnes\nNous ne pouvons pas utiliser directement across() dans dplyr::filter() car nous avons besoin d’une étape supplémentaire pour combiner les résultats. À cette fin, filter() dispose de deux fonctions complémentaires spéciales :\ndplyr::if_any() conserve les lignes pour lesquelles le prédicat est vrai pour au moins une colonne sélectionnée :\n\nstarwars |&gt; \n  filter(if_any(everything(), ~ !is.na(.x)))\n\n# A tibble: 87 × 14\n   name     height  mass hair_color skin_color eye_color birth_year sex   gender\n   &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n 1 Luke Sk…    172    77 blond      fair       blue            19   male  mascu…\n 2 C-3PO       167    75 &lt;NA&gt;       gold       yellow         112   none  mascu…\n 3 R2-D2        96    32 &lt;NA&gt;       white, bl… red             33   none  mascu…\n 4 Darth V…    202   136 none       white      yellow          41.9 male  mascu…\n 5 Leia Or…    150    49 brown      light      brown           19   fema… femin…\n 6 Owen La…    178   120 brown, gr… light      blue            52   male  mascu…\n 7 Beru Wh…    165    75 brown      light      blue            47   fema… femin…\n 8 R5-D4        97    32 &lt;NA&gt;       white, red red             NA   none  mascu…\n 9 Biggs D…    183    84 black      light      brown           24   male  mascu…\n10 Obi-Wan…    182    77 auburn, w… fair       blue-gray       57   male  mascu…\n# ℹ 77 more rows\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;\n\n\ndplyr::if_all() sélectionne les lignes pour lesquelles le prédicat est vrai pour toutes les colonnes sélectionnées :\n\nstarwars |&gt;  \n  filter(if_all(everything(), ~ !is.na(.x)))\n\n# A tibble: 29 × 14\n   name     height  mass hair_color skin_color eye_color birth_year sex   gender\n   &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n 1 Luke Sk…    172    77 blond      fair       blue            19   male  mascu…\n 2 Darth V…    202   136 none       white      yellow          41.9 male  mascu…\n 3 Leia Or…    150    49 brown      light      brown           19   fema… femin…\n 4 Owen La…    178   120 brown, gr… light      blue            52   male  mascu…\n 5 Beru Wh…    165    75 brown      light      blue            47   fema… femin…\n 6 Biggs D…    183    84 black      light      brown           24   male  mascu…\n 7 Obi-Wan…    182    77 auburn, w… fair       blue-gray       57   male  mascu…\n 8 Anakin …    188    84 blond      fair       blue            41.9 male  mascu…\n 9 Chewbac…    228   112 brown      unknown    blue           200   male  mascu…\n10 Han Solo    180    80 brown      fair       brown           29   male  mascu…\n# ℹ 19 more rows\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Transformations multiples</span>"
    ]
  },
  {
    "objectID": "manipulation_avancee/transformations-multiples.html#transformations-multiples-sur-les-lignes",
    "href": "manipulation_avancee/transformations-multiples.html#transformations-multiples-sur-les-lignes",
    "title": "39  Transformations multiples",
    "section": "\n39.3 Transformations multiples sur les lignes",
    "text": "39.3 Transformations multiples sur les lignes\ndplyr, et R de manière générale, sont particulièrement bien adaptés à l’exécution d’opérations sur les colonnes, alors que l’exécution d’opérations sur les lignes est beaucoup plus difficile. Ici, nous verrons comment réaliser des calculs ligne par ligne avec dplyr::rowwise().\n\n39.3.1 Création\nLes opérations par ligne requièrent un type spécial de regroupement où chaque groupe est constitué d’une seule ligne. Vous créez ce type de groupe avec dplyr::rowwise() :\n\ndf &lt;- tibble(x = 1:2, y = 3:4, z = 5:6)\ndf |&gt; rowwise()\n\n# A tibble: 2 × 3\n# Rowwise: \n      x     y     z\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     1     3     5\n2     2     4     6\n\n\nComme group_by(), rowwise() ne fait rien en soi ; elle modifie simplement le fonctionnement des autres verbes. Par exemple, comparez les résultats de mutate() dans le code suivant :\n\ndf |&gt; \n  mutate(m = mean(c(x, y, z)))\n\n# A tibble: 2 × 4\n      x     y     z     m\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n1     1     3     5   3.5\n2     2     4     6   3.5\n\ndf |&gt; \n  rowwise() |&gt; \n  mutate(m = mean(c(x, y, z)))\n\n# A tibble: 2 × 4\n# Rowwise: \n      x     y     z     m\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n1     1     3     5     3\n2     2     4     6     4\n\n\nSi vous utilisez mutate() avec un tableau de données classique, il calcule la moyenne de x, y et z sur toutes les lignes. Si vous l’appliquez à un tableau de données row-wise, il calcule la moyenne séparément pour chaque ligne.\nVous pouvez optionnellement fournir des variables identifiantes dans votre appel à rowwise(). Ces variables sont conservées lorsque vous appelez summarise(), de sorte qu’elles se comportent de manière similaire aux variables de regroupement passées à group_by():\n\ndf &lt;- tibble(\n  name = c(\"Mara\", \"Hadley\"),\n  x = 1:2,\n  y = 3:4,\n  z = 5:6\n)\n\ndf |&gt; \n  rowwise() |&gt; \n  summarise(m = mean(c(x, y, z)))\n\n# A tibble: 2 × 1\n      m\n  &lt;dbl&gt;\n1     3\n2     4\n\ndf |&gt; \n  rowwise(name) |&gt; \n  summarise(m = mean(c(x, y, z)))\n\n`summarise()` has grouped output by 'name'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 2 × 2\n# Groups:   name [2]\n  name       m\n  &lt;chr&gt;  &lt;dbl&gt;\n1 Mara       3\n2 Hadley     4\n\n\nrowwise() n’est qu’une forme spéciale de regroupement : donc si vous voulez enlever sa déclaration, appelez simplement ungroup().\n\n39.3.2 Statistiques ligne par ligne\ndplyr::summarise() permet de résumer facilement les valeurs d’une ligne à l’autre à l’intérieur d’une colonne. Combinée à rowwise(), elle permet également de résumer les valeurs de plusieurs colonnes à l’intérieur d’une même ligne. Pour voir comment, commençons par créer un petit jeu de données :\n\ndf &lt;- tibble(\n  id = 1:6,\n  w = 10:15,\n  x = 20:25,\n  y = 30:35,\n  z = 40:45\n)\ndf\n\n# A tibble: 6 × 5\n     id     w     x     y     z\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     1    10    20    30    40\n2     2    11    21    31    41\n3     3    12    22    32    42\n4     4    13    23    33    43\n5     5    14    24    34    44\n6     6    15    25    35    45\n\n\nSupposons que nous voulions calculer la somme de w, x, y et z pour chaque ligne. Nous pouvons utiliser mutate() pour ajouter une nouvelle colonne ou summarise() pour renvoyer ce seul résumé :\n\ndf |&gt; \n  rowwise(id) |&gt; \n  mutate(total = sum(c(w, x, y, z)))\n\n# A tibble: 6 × 6\n# Rowwise:  id\n     id     w     x     y     z total\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     1    10    20    30    40   100\n2     2    11    21    31    41   104\n3     3    12    22    32    42   108\n4     4    13    23    33    43   112\n5     5    14    24    34    44   116\n6     6    15    25    35    45   120\n\ndf |&gt; \n  rowwise(id) |&gt; \n  summarise(total = sum(c(w, x, y, z)))\n\n`summarise()` has grouped output by 'id'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 6 × 2\n# Groups:   id [6]\n     id total\n  &lt;int&gt; &lt;int&gt;\n1     1   100\n2     2   104\n3     3   108\n4     4   112\n5     5   116\n6     6   120\n\n\nBien sûr, si vous avez beaucoup de variables, il sera fastidieux de taper chaque nom de variable. Au lieu de cela, vous pouvez utiliser dplyr::c_across() qui utilise une syntaxe tidy selection afin de sélectionner succinctement de nombreuses variables :\n\ndf |&gt; \n  rowwise(id) |&gt; \n  mutate(total = sum(c_across(w:z)))\n\n# A tibble: 6 × 6\n# Rowwise:  id\n     id     w     x     y     z total\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     1    10    20    30    40   100\n2     2    11    21    31    41   104\n3     3    12    22    32    42   108\n4     4    13    23    33    43   112\n5     5    14    24    34    44   116\n6     6    15    25    35    45   120\n\ndf |&gt; \n  rowwise(id) |&gt; \n  mutate(total = sum(c_across(where(is.numeric))))\n\n# A tibble: 6 × 6\n# Rowwise:  id\n     id     w     x     y     z total\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     1    10    20    30    40   100\n2     2    11    21    31    41   104\n3     3    12    22    32    42   108\n4     4    13    23    33    43   112\n5     5    14    24    34    44   116\n6     6    15    25    35    45   120\n\n\nVous pouvez combiner cela avec des opérations par colonne (voir la section précédente) pour calculer la proportion du total pour chaque colonne :\n\ndf |&gt; \n  rowwise(id) |&gt; \n  mutate(total = sum(c_across(w:z))) |&gt; \n  ungroup() |&gt; \n  mutate(across(w:z, ~ . / total))\n\n# A tibble: 6 × 6\n     id     w     x     y     z total\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1     1 0.1   0.2   0.3   0.4     100\n2     2 0.106 0.202 0.298 0.394   104\n3     3 0.111 0.204 0.296 0.389   108\n4     4 0.116 0.205 0.295 0.384   112\n5     5 0.121 0.207 0.293 0.379   116\n6     6 0.125 0.208 0.292 0.375   120\n\n\n\n\n\n\n\n\nImportant\n\n\n\nL’approche rowwise() fonctionne pour n’importe quelle fonction de résumé. Mais si vous avez besoin d’une plus grande rapidité, il est préférable de rechercher une variante intégrée de votre fonction de résumé. Celles-ci sont plus efficaces car elles opèrent sur l’ensemble du cadre de données ; elles ne le divisent pas en lignes, ne calculent pas le résumé et ne joignent pas à nouveau les résultats.\nPar exemple, R fournit nativement les fonctions rowSums() et rowMeans() pour calculer des sommes et des moyennes par ligne. Elles sont de fait bien plus efficaces.\n\ndf  |&gt; \n  mutate(total = rowSums(pick(where(is.numeric), -id)))\n\n# A tibble: 6 × 6\n     id     w     x     y     z total\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n1     1    10    20    30    40   100\n2     2    11    21    31    41   104\n3     3    12    22    32    42   108\n4     4    13    23    33    43   112\n5     5    14    24    34    44   116\n6     6    15    25    35    45   120\n\ndf |&gt; \n  mutate(mean = rowMeans(pick(where(is.numeric), -id)))\n\n# A tibble: 6 × 6\n     id     w     x     y     z  mean\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n1     1    10    20    30    40    25\n2     2    11    21    31    41    26\n3     3    12    22    32    42    27\n4     4    13    23    33    43    28\n5     5    14    24    34    44    29\n6     6    15    25    35    45    30",
    "crumbs": [
      "**Manipulation avancée**",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Transformations multiples</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/analyse-factorielle.html",
    "href": "analyses_avancees/analyse-factorielle.html",
    "title": "40  Analyse factorielle",
    "section": "",
    "text": "40.1 Principe général\nL’analyse des correspondances multiples est une technique descriptive visant à résumer l’information contenu dans un grand nombre de variables afin de faciliter l’interprétation des corrélations existantes entre ces différentes variables. On cherche à savoir quelles sont les modalités corrélées entre elles.\nL’idée générale est la suivante. L’ensemble des individus peut être représenté dans un espace à plusieurs dimensions où chaque axe représente les différentes variables utilisées pour décrire chaque individu. Plus précisément, pour chaque variable qualitative, il y a autant d’axes que de modalités moins un. Ainsi il faut trois axes pour décrire une variable à quatre modalités. Un tel nuage de points est aussi difficile à interpréter que de lire directement le fichier de données. On ne voit pas les corrélations qu’il peut y avoir entre modalités, par exemple qu’aller au cinéma est plus fréquent chez les personnes habitant en milieu urbain. Afin de mieux représenter ce nuage de points, on va procéder à un changement de systèmes de coordonnées. Les individus seront dès lors projetés et représentés sur un nouveau système d’axe. Ce nouveau système d’axes est choisis de telle manière que la majorité des variations soit concentrées sur les premiers axes. Les deux-trois premiers axes permettront d’expliquer la majorité des différences observées dans l’échantillon, les autres axes n’apportant qu’une faible part additionnelle d’information. Dès lors, l’analyse pourra se concentrer sur ses premiers axes qui constitueront un bon résumé des variations observables dans l’échantillon.",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Analyse factorielle</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/analyse-factorielle.html#principe-général",
    "href": "analyses_avancees/analyse-factorielle.html#principe-général",
    "title": "40  Analyse factorielle",
    "section": "",
    "text": "Important\n\n\n\nAvant toute analyse factorielle, il est indispensable de réaliser une analyse préliminaire de chaque variable, afin de voir si toutes les classes sont aussi bien représentées ou s’il existe un déséquilibre. L’analyse factorielle est sensible aux petits effectifs. Aussi il peut être préférable de regrouper les classes peu représentées le cas échéant.\nDe même, il peut être tentant de mettre toutes les variables disponibles dans son jeu de données directement dans une analyse factorielle pour voir ce que ça donne. Il est préférable de réfléchir en amont aux questions que l’on veut poser et de choisir ensuite un jeu de variables en fonction.",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Analyse factorielle</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/analyse-factorielle.html#première-illustration-acm-sur-les-loisirs",
    "href": "analyses_avancees/analyse-factorielle.html#première-illustration-acm-sur-les-loisirs",
    "title": "40  Analyse factorielle",
    "section": "\n40.2 Première illustration : ACM sur les loisirs",
    "text": "40.2 Première illustration : ACM sur les loisirs\nPour ce premier exemple, nous allons considérer le jeu de données hdv2003 fourni dans le package questionr et correspondant à un extrait de l’enquête Histoire de Vie réalisée par l’Insee en 2003.\nNous allons considérer 7 variables binaires (oui/non) portant sur la pratique de différents loisirs (écouter du hard rock, lire des bandes dessinées, pratiquer la pêche ou la chasse, cuisiner, bricoler ou pratiquer un sport). Pour le moment, nous n’allons pas intégrer à l’analyse de variable socio-démographique, car nous souhaitons explorer comment ces activités se corrèlent entre elles, indépendamment de toute autre considération.\nNotons, avec questionr::freq.na() ou avec labelled::look_for(), qu’il n’y a pas de valeurs manquantes dans nos données.\n\nlibrary(tidyverse)\ndata(\"hdv2003\", package = \"questionr\")\nd &lt;- hdv2003 |&gt; \n  select(hard.rock:sport)\nd |&gt; questionr::freq.na()\n\n             missing %\nhard.rock          0 0\nlecture.bd         0 0\npeche.chasse       0 0\ncuisine            0 0\nbricol             0 0\ncinema             0 0\nsport              0 0\n\nd |&gt; labelled::look_for()\n\n pos variable     label col_type missing values\n 1   hard.rock    —     fct      0       Non   \n                                         Oui   \n 2   lecture.bd   —     fct      0       Non   \n                                         Oui   \n 3   peche.chasse —     fct      0       Non   \n                                         Oui   \n 4   cuisine      —     fct      0       Non   \n                                         Oui   \n 5   bricol       —     fct      0       Non   \n                                         Oui   \n 6   cinema       —     fct      0       Non   \n                                         Oui   \n 7   sport        —     fct      0       Non   \n                                         Oui   \n\n\nComme l’ensemble de nos variables sont catégorielles nous allons réaliser une analyse des correspondances multiples (ACM).\n\n40.2.1 Calcul de l’ACM\nAvec ade4, l’ACM s’obtient à l’aide la fonction ade4::dudi.acm(). Par défaut, si l’on exécute seulement ade4::dudi.acm(d), la fonction va afficher un graphique indiquant la variance expliquée par chaque axe et une invite dans la console va demander le nombre d’axes à conserver pour l’analyse. Une invite de commande n’est pas vraiment adaptée dans le cadre d’un script que l’on souhaite pouvoir exécuter car cela implique une intervention manuelle. On pourra désactiver cette invitation avec scannf = FALSE et indiquer le nombre d’axes à conserver avec l’argument nf (nf = Inf permet de conserver l’ensemble des axes).\n\nacm1_ad &lt;- d |&gt;\n  ade4::dudi.acm(scannf = FALSE, nf = Inf)\n\nAvec FactoMineR, l’ACM s’obtient avec FactoMineR::MCA(). Par défaut, seuls les 5 premiers axes sont conservés, ce qui est modifiable avec l’argument ncp. De plus, la fonction affiche par défaut un graphique des résultats avant de renvoyer les résultats de l’ACM. Ce graphique peut être désactivé avec graph = FALSE.\n\nacm1_fm &lt;- d |&gt; \n  FactoMineR::MCA(ncp = Inf, graph = FALSE)\n\nLes deux ACM sont ici identiques. Par contre, les deux objets renvoyés ne sont pas structurés de la même manière.\n\n40.2.2 Exploration graphique interactive\nLe package explor permets d’explorer les résultats de manière interactive. Il fonctionne à la fois avec les analyses factorielles produites avec FactoMineR et celles réalisées avec ade4.\nPour lancer l’exploration interactive, il suffit de passer les résultats de l’ACM à la fonction explor::explor().\n\nacm1_ad |&gt; explor::explor()\n\n\n\n\n\n\nFigure 40.1: Capture d’écran de l’interface d’explor\n\n\nLes graphiques réalisés avec explor::explor() peuvent être exportés en fichier image SVG (via le bouton dédié en bas à gauche dans l’interface). De même, il est possible d’obtenir un code R que l’on pourra copier dans un script pour reproduire le graphique (ATTENTION : le graphique produit est interactif et donc utilisable uniquement dans document web).\n\nres &lt;- explor::prepare_results(acm1_ad)\np &lt;- explor::MCA_var_plot(\n  res,\n  xax = 1,\n  yax = 2,\n  var_sup = FALSE,\n  var_sup_choice = ,\n  var_lab_min_contrib = 0,\n  col_var = \"Variable\",\n  symbol_var = \"Variable\",\n  size_var = \"Contrib\",\n  size_range = c(52.5, 700),\n  labels_size = 12,\n  point_size = 56,\n  transitions = FALSE,\n  labels_positions = \"auto\",\n  labels_prepend_var = TRUE,\n  xlim = c(-2.58, 1.69),\n  ylim = c(-1.33, 2.94)\n)\n\n\n\nExemple de figure exportée à partir de explor\n\n\n40.2.3 Représentations graphiques\nÀ la fois ade4 et FactoMineR disposent de leurs propres fonctions graphiques dédiées. Elles sont cependant spécifiques à chaque package. Les fonctions graphiques de ade4 ne peuvent pas être utilisées avec un objet FactoMineR et inversement.\nLe package factoextra permet de palier à ce problème. Ces fonctions graphiques sont en effet compatibles avec les deux packages et reposent sur ggplot2, ce qui permet facilement de personnaliser les graphiques obtenus.\n\n40.2.4 Variance expliquée et valeurs propres\nLes valeurs propres (eigen values en anglais) correspondent à la quantité de variance capturée par chaque axe (on parle également d’inertie). On peut les obtenir aisément avec la fonction factoextra::get_eigenvalue().\n\nacm1_ad |&gt;\n  factoextra::get_eigenvalue()\n\n      eigenvalue variance.percent cumulative.variance.percent\nDim.1  0.2121854         21.21854                    21.21854\nDim.2  0.1542803         15.42803                    36.64657\nDim.3  0.1468192         14.68192                    51.32849\nDim.4  0.1387719         13.87719                    65.20568\nDim.5  0.1349671         13.49671                    78.70239\nDim.6  0.1192865         11.92865                    90.63104\nDim.7  0.0936896          9.36896                   100.00000\n\n\nOn notera que les axes sont ordonnées en fonction de la quantité de variation qu’ils capturent. Le premier axe est toujours celui qui capture le plus de variance, suivi du deuxième, etc.\nLa somme totale des valeurs propres indique la variation totale des données. Souvent, les valeurs propres sont exprimées en pourcentage du total. Dans notre exemple, l’axe 1 capture 21,2 % de la variance et l’axe 2 en capture 15,4 %. Ainsi, le plan factoriel composé des deux premiers axes permet de capturer à lui seul plus du tiers (36,6 %) de la variance totale.\nUne représentation graphique des valeurs propres s’obtient avec factoextra::fviz_screeplot().\n\nacm1_ad |&gt;\n  factoextra::fviz_screeplot()\n\n\n\n\n\n\nFigure 40.2: Représentation graphique de la variance expliquée par les différents axes de l’ACM\n\n\n\n\nIl n’y a pas de règle absolue concernant le nombre d’axes à explorer pour l’analyse et l’interprétation des résultats. L’objectif d’une analyse factorielle étant justement de réduire le nombre de dimension considérée pour ce concentrer sur les principales associations entre modalités, il est fréquent de se limiter aux deux premiers ou aux trois premiers axes.\nUne approche fréquente consiste à regarder s’il y a un coude, un saut plus marqué qu’un autre dans le graphique des valeurs propres. Dans notre exemple, qui ne comporte qu’un petit nombre de variable, on voit un saut marqué entre le premier axe et les autres, suggérant de se focaliser en particulier sur ce premier axe.\n\n40.2.5 Contribution aux axes\nLa fonction factoextra::fviz_contrib() permet de visualiser la contribution des différentes modalités à un axe donnée. Regardons le premier axe.\n\nacm1_ad |&gt;\n  factoextra::fviz_contrib(choice = \"var\", axes = 1)\n\n\n\n\n\n\nFigure 40.3: Contribution des modalités au premier axe\n\n\n\n\nLa ligne en pointillés rouges indique la contribution attendue de chaque modalité si la répartition était uniforme. Nous constatons ici que le premier axe est surtout déterminé par la pratique d’une activité sportive et le fait d’aller au cinéma.\n\nacm1_ad |&gt;\n  factoextra::fviz_contrib(choice = \"var\", axes = 2)\n\n\n\n\n\n\nFigure 40.4: Contribution des modalités au deuxième axe\n\n\n\n\nLe deuxième axe, quant à lui, est surtout marqué par la pratique de la pêche ou de la chasse et, dans une moindre mesure, par le fait de bricoler.\n\n40.2.6 Représentation des modalités dans le plan factoriel\nPour représenter les modalités dans le plan factoriel, on aura recours à factoextra::fviz_mca_var(). En termes de visualisation, c’est moins ergonomique que ce que propose explor. On aura donc tout intérêt à profiter de ce dernier. Si l’on a réalisé un autre type d’analyse factorielle, il faudra choisir la fonction correspondante, par exemple factoextra::fviz_famd_var() pour une analyse sur données mixtes. La liste complète est visible sur le site de documentation du package.\n\nacm1_ad |&gt;\n  factoextra::fviz_mca_var()\n\n\n\n\n\n\nFigure 40.5: Projection des modalités dans le plan factoriel\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSi l’on réalise le même graphique à partir de l’ACM réalisée avec FactoMineR, nous aurons à première vue un résultat différent.\n\nacm1_fm |&gt;\n  factoextra::fviz_mca_var()\n\n\n\n\n\n\n\nSi l’on regarde plus attentivement, les valeurs sont inversées sur l’axe 1 : les valeurs positives sont devenues négatives et inversement. Ceci est du à de légères différences dans les algorithmes de calcul des deux packages. Pour autant, les résultats sont bien strictement équivalents, le sens des axes n’ayant pas de signification en soi.\n\n\n\n40.2.7 Représentation des individus dans le plan factoriel\nPour projeter les individus (i.e. les observations) dans le plan factoriel, nous aurons recours à factoextra::fviz_mca_ind().\n\nacm1_ad |&gt;\n  factoextra::fviz_mca_ind()\n\n\n\n\n\n\nFigure 40.6: Projection des individus dans le plan factoriel\n\n\n\n\nLe graphique sera un peu plus lisible en n’affichant que les points avec un effet de transparence (pour les points superposés).\n\nacm1_ad |&gt;\n  factoextra::fviz_mca_ind(\n    geom.ind = \"point\",\n    alpha.ind = 0.1\n  )\n\n\n\n\n\n\nFigure 40.7: Projection des individus dans le plan factoriel\n\n\n\n\nIl est souvent intéressant de colorier les individus selon une variable catégorielle tierce, que ce soit une des variables ayant contribué ou non à l’ACM. Par exemple, nous allons regarder la répartition des individus dans le plan factoriel selon leur pratique d’un sport, puisque cette variable contribuait fortement au premier axe.\nNous indiquerons la variable considérée à factoextra::fviz_mca_in() via l’argument habillage. L’option addEllipses = TRUE permet de dessiner des ellipses autour des observations.\n\nacm1_ad |&gt;\n  factoextra::fviz_mca_ind(\n    habillage = d$sport,\n    addEllipses = TRUE,\n    geom.ind = \"point\",\n    alpha.ind = 0.1\n  )\n\n\n\n\n\n\nFigure 40.8: Projection des individus dans le plan factoriel selon la pratique d’un sport\n\n\n\n\n\n\n\n\n\n\nAstuce\n\n\n\nSi l’on a réalisé l’ACM avec ade4, nous pouvons utiliser la fonction ade4::scatter() pour réaliser ce même type de graphique avec l’ensemble des variables inclues dans l’ACM. Afin de rendre le graphique plus lisible, nous passons à la fonction une palette de couleur obtenue avec khroma::colour() (cf. Section 16.3.2).\n\nacm1_ad |&gt;\n  ade4::scatter(col = khroma::colour(\"bright\")(2))\n\n\n\n\n\n\n\n\n\n\n40.2.8 Récupérer les coordonnées des individus / des variables\nDans certaines situations (par exemple pour créer un score à partir de la position sur le premier axe), on peut avoir besoin de récupérer les données brutes de l’analyse factorielle.\nOn pourra utiliser les fonctions get_*() de factoextra. Par exemple, pour les individus dans le cadre d’une ACM, on utilisera factoextra::get_mca_ind().\n\nres &lt;- acm1_ad |&gt;\n  factoextra::get_mca_ind()\nprint(res)\n\nMultiple Correspondence Analysis Results for individuals\n ===================================================\n  Name       Description                       \n1 \"$coord\"   \"Coordinates for the individuals\" \n2 \"$cos2\"    \"Cos2 for the individuals\"        \n3 \"$contrib\" \"contributions of the individuals\"\n\n\nLe résultat obtenu est une liste avec trois tableaux de données. Pour accéder aux coordonnées des individus, il suffit donc d’exécuter la commande ci-dessous.\n\nas_tibble(res$coord)\n\n# A tibble: 2,000 × 7\n     Dim.1   Dim.2    Dim.3   Dim.4  Dim.5   Dim.6   Dim.7\n     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1  0.380  -0.0481 -0.130   -0.0757 -0.554 -0.118  -0.0382\n 2 -0.301  -0.512   0.0125   0.221   0.421 -0.340  -0.0402\n 3  0.146  -0.261   0.0784   0.152   0.279 -0.252  -0.578 \n 4 -0.842  -0.0612  0.00886  0.247  -0.232  0.149  -0.0297\n 5  0.614  -0.149   0.0190  -0.0259  0.139 -0.0253 -0.0474\n 6 -0.301  -0.512   0.0125   0.221   0.421 -0.340  -0.0402\n 7  0.270   0.905  -0.214   -0.198  -0.267 -0.732   0.144 \n 8 -0.0369  1.26   -0.0688  -0.122  -0.227 -0.150   0.146 \n 9  0.167  -0.400  -0.0469   0.0425  0.282 -0.114   0.490 \n10 -0.301  -0.512   0.0125   0.221   0.421 -0.340  -0.0402\n# ℹ 1,990 more rows",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Analyse factorielle</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/analyse-factorielle.html#ajout-de-variables-dobservations-additionnelles",
    "href": "analyses_avancees/analyse-factorielle.html#ajout-de-variables-dobservations-additionnelles",
    "title": "40  Analyse factorielle",
    "section": "\n40.3 Ajout de variables / d’observations additionnelles",
    "text": "40.3 Ajout de variables / d’observations additionnelles\nDans le cadre d’une analyse factorielle, on peut souhaiter ajouter des variables ou des observations additionnelles, qui ne participeront donc pas au calcul de l’analyse factorielle (et seront donc sans effet sur les axes de l’analyse). Ces variables / observations additionnelles seront simplement projetées dans le nouvel espace factoriel.\nReprenons notre exemple et calculons des groupes d’âges.\n\nhdv2003 &lt;- hdv2003 |&gt; \n  mutate(\n    groupe_ages = age |&gt;\n      cut(\n        c(18, 25, 45, 65, 99),\n        right = FALSE,\n        include.lowest = TRUE,\n        labels = c(\"18-24 ans\", \"25-44 ans\",\n                   \"45-64 ans\", \"65 ans et plus\")\n      )\n  )\n\nAjoutons maintenant le sexe, le groupe d’âges et le niveau d’étude comme variables additionnelles.\nAvec FactoMineR, cela se fait directement au moment du calcul de l’ACM, en indiquant l’index (ordre de la colonne dans le tableau) des variables supplémentaires à quali.sup pour les variables catégorielles et à quanti.sup pour les variables continues. De même, ind.sup peut-être utilisé pour indiquer les observations additionnelles.\n\nd2 &lt;- hdv2003 |&gt; \n  select(sexe, groupe_ages, nivetud, hard.rock:sport)\nacm2_fm &lt;- d2 |&gt; \n  FactoMineR::MCA(\n    ncp = Inf,\n    graph = FALSE,\n    quali.sup = 1:3\n  )\n\nAvec ade4, la manipulation est légèrement différente. Le calcul de l’ACM se fait comme précédemment, uniquement avec les variables et les observations inclues dans l’analyse, puis on pourra projeter dans l’espace factoriel les variables / observations additionnelles à l’aide de ade4::supcol() et ade4::suprow(). Si pour ajouter des observations additionnelles il suffit de passer l’ACM de base et un tableau de données des observations additionnelles à ade4::suprow(), c’est un peu plus compliqué pour des variables additionnelles. Il faut déjà réaliser une ACM sur ces variables additionnelles, en extraire le sous objet $tab et passer ce dernier à ade4::supcol().\n\nacm_add &lt;- hdv2003 |&gt;\n  select(sexe, groupe_ages, nivetud) |&gt; \n  ade4::dudi.acm(scannf = FALSE, nf = Inf)\n\nacm_supp &lt;- ade4::supcol(\n  acm1_ad,\n  acm_add$tab\n)\n\nSi l’on veut pouvoir utiliser explor::explor() avec ces variables additionnelles, il faudra enregistrer le résultat de ade4::supcol() dans un sous-objet $supv de l’ACM principale.\n\nacm2_ad &lt;- acm1_ad\nacm2_ad$supv &lt;- acm_supp\n\nPour des représentations graphiques avec factoextra, on privilégiera ici le calcul avec FactoMineR (les variables additionnelles calculées avec ade4 n’étant pas gérées par factoextra). En effet, si l’ACM a été calculée avec {FactoMineR}, factoextra::fviz_mca_var() affiche par défaut les variables ad\n\nacm2_fm |&gt;\n  factoextra::fviz_mca_var(repel = TRUE, labelsize = 2)\n\n\n\n\n\n\nFigure 40.9: Projection des modalités dans le plan factoriel (incluant les variables additionnelles)",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Analyse factorielle</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/analyse-factorielle.html#gestion-des-valeurs-manquantes",
    "href": "analyses_avancees/analyse-factorielle.html#gestion-des-valeurs-manquantes",
    "title": "40  Analyse factorielle",
    "section": "\n40.4 Gestion des valeurs manquantes",
    "text": "40.4 Gestion des valeurs manquantes\nPour ce troisième exemple, nous allons maintenant inclure les variables sexe, groupe d’âges et niveau d’étude dans l’ACM, non pas comme variables additionnelles mais comme variables de l’ACM (qui vont donc contribuer au calcul des axes).\n\nd3 &lt;- hdv2003 |&gt; \n  select(sexe, groupe_ages, nivetud, hard.rock:sport)\n\nCalculons maintenant l’ACM avec ade4 et FactoMineR.\n\nacm3_ad &lt;- d3 |&gt;\n  ade4::dudi.acm(scannf = FALSE, nf = Inf)\nacm3_fm &lt;- d3 |&gt; \n  FactoMineR::MCA(ncp = Inf, graph = FALSE)\n\nRegardons les valeurs propres et l’inertie expliquée et positionnons les deux graphiques côte à côte (cf. Section 17.6 sur la combinaison de graphiques).\n\np_ad &lt;- acm3_ad |&gt; \n  factoextra::fviz_screeplot(choice = \"eigenvalue\") +\n  ggplot2::ggtitle(\"ACM3 avec ade4\")\np_fm&lt;- acm3_fm |&gt; \n  factoextra::fviz_screeplot(choice = \"eigenvalue\") +\n  ggplot2::ggtitle(\"ACM3 avec FactoMineR\")\npatchwork::wrap_plots(p_ad, p_fm) &\n  ggplot2::ylim(0, .3)\n\n\n\n\n\n\nFigure 40.10: Inertie expliquée par axe (comparaison des ACM réalisées avec ade4 et FactoMineR)\n\n\n\n\nComme nous pouvons le voir, cette fois-ci, l’inertie expliquée par axe diffère entre les deux ACM. Cela est du à la présence de valeurs manquantes pour la variable nivetud.\n\nd3 |&gt; questionr::freq.na()\n\n             missing %\nnivetud          112 6\nsexe               0 0\ngroupe_ages        0 0\nhard.rock          0 0\nlecture.bd         0 0\npeche.chasse       0 0\ncuisine            0 0\nbricol             0 0\ncinema             0 0\nsport              0 0\n\n\nOr, les deux packages ne traitent pas les valeurs manquantes de la même manière : ade4 exclue les valeurs manquantes tandis que FactoMineR les considère comme une modalité additionnelle.\nPour éviter toute ambiguïté, il est préférable de traiter soi-même les valeurs manquantes (NA) en amont des deux fonctions.\nPour convertir les valeurs manquantes d’un facteur en une modalité en soi, on utilisera forcats::fct_na_value_to_level(). Il est possible d’appliquer cette fonction à tous les facteurs d’un tableau de données avec dplyr::across() (cf. Chapitre 39).\n\nd3_modalite_manquant &lt;- d3 |&gt; \n  mutate(\n    across(\n      where(is.factor),\n      fct_na_value_to_level,\n      level = \"(manquant)\"\n    )\n  )\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(where(is.factor), fct_na_value_to_level, level =\n  \"(manquant)\")`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\nd3_modalite_manquant |&gt; nrow()\n\n[1] 2000\n\nd3_modalite_manquant |&gt; questionr::freq.na()\n\n             missing %\nsexe               0 0\ngroupe_ages        0 0\nnivetud            0 0\nhard.rock          0 0\nlecture.bd         0 0\npeche.chasse       0 0\ncuisine            0 0\nbricol             0 0\ncinema             0 0\nsport              0 0\n\n\nPour ne conserver que l’ensemble des observations complètes (i.e. sans valeur manquante), on pourra avoir recours tidyr::drop_na().\n\nd3_obs_completes &lt;- d3 |&gt; \n  tidyr::drop_na()\nd3_obs_completes |&gt; nrow()\n\n[1] 1888\n\nd3_obs_completes |&gt; questionr::freq.na()\n\n             missing %\nsexe               0 0\ngroupe_ages        0 0\nnivetud            0 0\nhard.rock          0 0\nlecture.bd         0 0\npeche.chasse       0 0\ncuisine            0 0\nbricol             0 0\ncinema             0 0\nsport              0 0\n\n\nUne alternative est offerte par le package GDAtools qui implémente une ACM spécifique permettant de neutraliser certaines modalités dans la construction de l’espace factoriel, tout en conservant l’ensemble des individus. Les valeurs manquantes sont automatiquement considérées comme des modalités à ne pas tenir compte. Mais il est également possible d’indiquer d’autres modalités à ignorer (voir le tutoriel du package).\n\nacm3_spe &lt;- GDAtools::speMCA(d3)\n\nSi les fonctions de {factorextra} ne sont pas compatibles avec GDAtools, on peut tout à fait utiliser explor. De plus, GDAtools fournit directement plusieurs outils de visualisation avancée et d’aide à l’interprétation des résultats.",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Analyse factorielle</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/analyse-factorielle.html#webin-r",
    "href": "analyses_avancees/analyse-factorielle.html#webin-r",
    "title": "40  Analyse factorielle",
    "section": "\n40.5 webin-R",
    "text": "40.5 webin-R\nL’analyse factorielle est présentée sur YouTube dans le webin-R #11 (Analyse des Correspondances Multiples (ACM)).",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Analyse factorielle</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/analyse-factorielle.html#lectures-additionnelles",
    "href": "analyses_avancees/analyse-factorielle.html#lectures-additionnelles",
    "title": "40  Analyse factorielle",
    "section": "\n40.6 Lectures additionnelles",
    "text": "40.6 Lectures additionnelles\n\n\nVisualiser une analyse géométrique des données avec ggplot2 (R/RStudio) par Anton Perdoncin\n\nExploration interactive de résultats d’ACP/ACM avec explor par Julien Barnier\n\nAnalyse des correspondances multiples (ACM ou AFCM) avec FactoMineR (Vidéo YouTube) par François Husson (l’un des auteurs de FactoMineR)\n\nL’analyse géométrique des données avec GDAtools par Nicolas Robette\n\nTuto@Mate #32 : Les Analyses Factorielles Multiples (AFM) par Maelle Amand\n\n\n\n\nFigure 40.1: Capture d’écran de l’interface d’explor\nExemple de figure exportée à partir de explor\nFigure 40.2: Représentation graphique de la variance expliquée par les différents axes de l’ACM\nFigure 40.3: Contribution des modalités au premier axe\nFigure 40.4: Contribution des modalités au deuxième axe\nFigure 40.5: Projection des modalités dans le plan factoriel\nFigure 40.6: Projection des individus dans le plan factoriel\nFigure 40.7: Projection des individus dans le plan factoriel\nFigure 40.8: Projection des individus dans le plan factoriel selon la pratique d’un sport\nFigure 40.9: Projection des modalités dans le plan factoriel (incluant les variables additionnelles)\nFigure 40.10: Inertie expliquée par axe (comparaison des ACM réalisées avec ade4 et FactoMineR)",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Analyse factorielle</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/classification-ascendante-hierarchique.html",
    "href": "analyses_avancees/classification-ascendante-hierarchique.html",
    "title": "41  Classification ascendante hiérarchique",
    "section": "",
    "text": "41.1 Calculer une matrice des distances\nLa notion de ressemblance entre observations est évaluée par une distance entre individus. Plusieurs type de distances existent selon les données utilisées.\nIl existe de nombreuses distances mathématiques pour les variables quantitatives (euclidiennes, Manhattan…) que nous n’aborderons pas ici1. La plupart peuvent être calculées avec la fonction stats::dist().\nUsuellement, pour un ensemble de variables qualitatives, on aura recours à la distance du Φ² qui est celle utilisée pour l’analyse des correspondances multiples (cf. Chapitre 40). Avec l’extension ade4, la distance du Φ² s’obtient avec la fonction ade4::dist.dudi()2. Le cas particulier de la CAH avec l’extension FactoMineR sera abordée un peu plus loin.\nNous évoquerons également la distance de Gower qui peut s’appliquer à un ensemble de variables à la fois qualitatives et quantitatives et qui se calcule avec la fonction cluster::daisy() de l’extension cluster.\nIl existe bien entendu d’autres types de distance. Par exemple, dans le chapitre sur l’analyse de séquences, nous verrons comment calculer une distance entre séquences, permettant ainsi de réaliser une classification ascendante hiérarchique.",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Classification ascendante hiérarchique</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/classification-ascendante-hierarchique.html#calculer-une-matrice-des-distances",
    "href": "analyses_avancees/classification-ascendante-hierarchique.html#calculer-une-matrice-des-distances",
    "title": "41  Classification ascendante hiérarchique",
    "section": "",
    "text": "1 Pour une présentation des propriétés mathématiques des distances et des distances les lus courantes, on pourra se référer à la page Wikipedia correspondance.2 Cette même fonction peut aussi être utilisée pour calculer une distance après une analyse en composantes principales ou une analyse mixte de Hill et Smith.\n\n\n\n41.1.1 Distance de Gower\nEn 1971, Gower a proposé un indice de similarité qui porte son nom3. L’objectif de cet indice consiste à mesurer dans quelle mesure deux individus sont semblables. L’indice de Gower varie entre 0 et 1. Si l’indice vaut 1, les deux individus sont identiques. À l’opposé, s’il vaut 0, les deux individus considérés n’ont pas de point commun. Si l’on note \\(S_g\\) l’indice de similarité de Gower, la distance de Gower \\(D_g\\) s’obtient simplement de la manière suivante : \\(D_g = 1 - S_g\\). Ainsi, la distance sera nulle entre deux individus identiques et elle sera égale à 1 entre deux individus totalement différents. Cette distance s’obtient sous R avec la fonction cluster::daisy() du package cluster.\n3 Voir Gower, J. (1971). A General Coefficient of Similarity and Some of Its Properties. Biometrics, 27(4), 857-871. doi:10.2307/2528823 (http://www.jstor.org/stable/2528823).L’indice de similarité de Gower entre deux individus x1 et x2 se calcule de la manière suivante :\n\\[\nS_{g}(x_{1},x_{2})=\\frac{1}{p}\\sum_{j=1}^{p}s_{12j}\n\\]\n\\(p\\) représente le nombre total de caractères (ou de variables) descriptifs utilisés pour comparer les deux individus4. \\(s_{ 12j}\\) représente la similarité partielle entre les individus 1 et 2 concernant le descripteur \\(j\\). Cette similarité partielle se calcule différemment s’il s’agit d’une variable qualitative ou quantitative :\n4 Pour une description mathématique plus détaillée de cette fonction, notamment en cas de valeur manquante, se référer à l’article original de Gower précédemment cité.\n\nvariable qualitative : \\(s_{ 12j}\\) vaut 1 si la variable \\(j\\) prend la même valeur pour les individus 1 et 2, et vaut 0 sinon. Par exemple, si 1 et 2 sont tous les deux « grand », alors \\(s_{12j}\\) vaudra 1. Si 1 est « grand » et 2 « petit », \\(s_{12j}\\) vaudra 0.\n\nvariable quantitative : la différence absolue entre les valeurs des deux variables est tout d’abord calculée, soit \\(|y_{1j} - y_{2j}|\\). Puis l’écart maximum observé sur l’ensemble du fichier est déterminé et noté \\(R_j\\). Dès lors, la similarité partielle vaut \\(s_{12j} = 1 - |y_{1j} - y_{2j}| / R_j\\).\n\nDans le cas où l’on n’a que des variables qualitatives, la valeur de l’indice de Gower correspond à la proportion de caractères en commun. Supposons des individus 1 et 2 décris ainsi :\n\nhomme / grand / blond / étudiant / urbain\nfemme / grande / brune / étudiante / rurale\n\nSur les 5 variables utilisées pour les décrire, 1 et 2 ont deux caractéristiques communes : ils sont grand(e)s et étudiant(e)s. Dès lors, l’indice de similarité de Gower entre 1 et 2 vaut 2/5 = 0,4 (soit une distance de 1 − 0,4 = 0,6).\nPlusieurs approches peuvent être retenues pour traiter les valeurs manquantes :\n\nsupprimer tout individu n’étant pas renseigné pour toutes les variables de l’analyse ;\nconsidérer les valeurs manquantes comme une modalité en tant que telle ;\ngarder les valeurs manquantes en tant que valeurs manquantes.\n\nLe choix retenu modifiera les distances de Gower calculées. Supposons que l’on ait :\n\nhomme / grand / blond / étudiant / urbain\nfemme / grande / brune / étudiante / manquant\n\nSi l’on supprime les individus ayant des valeurs manquantes, 2 est retirée du fichier d’observations et aucune distance n’est calculée.\nSi l’on traite les valeurs manquantes comme une modalité particulière, 1 et 2 partagent alors 2 caractères sur les 5 analysés, la distance de Gower entre eux est alors de 1 − 2/5 =1 − 0,4 = 0,6.\nSi on garde les valeurs manquantes, l’indice de Gower est dès lors calculé sur les seuls descripteurs renseignés à la fois pour 1 et 2. La distance de Gower sera calculée dans le cas présent uniquement sur les 4 caractères renseignés et vaudra 1 − 2/4 = 0,5.\n\n41.1.2 Distance du Φ²\nIl s’agit de la distance utilisée dans les analyses de correspondance multiples (ACM). C’est une variante de la distance du χ². Nous considérons ici que nous avons Q questions (soit Q variables initiales de type facteur). À chaque individu est associé un patron c’est-à-dire une certaine combinaison de réponses aux Q questions. La distance entre deux individus correspond à la distance entre leurs deux patrons. Si les deux individus présentent le même patron, leur distance sera nulle. La distance du Φ² peut s’exprimer ainsi :\n\\[\nd_{\\Phi^2}^2(L_i,L_j)=\\frac{1}{Q}\\sum_{k}\\frac{(\\delta_{ik}-\\delta_{jk})^2}{f_k}\n\\]\noù \\(L_i\\) et \\(L_j\\) sont deux patrons, \\(Q\\) le nombre total de questions. \\(\\delta_{ik}\\) vaut 1 si la modalité \\(k\\) est présente dans le patron \\(L_i\\), 0 sinon. \\(f_k\\)est la fréquence de la modalité \\(k\\) dans l’ensemble de la population.\nExprimé plus simplement, on fait la somme de l’inverse des fréquences des modalités non communes aux deux patrons, puis on divise par le nombre total de question. Si nous reprenons notre exemple précédent :\n\nhomme / grand / blond / étudiant / urbain\nfemme / grande / brune / étudiante / rurale\n\nPour calculer la distance entre 1 et 2, il nous faut connaître la proportion des différentes modalités dans l’ensemble de la population étudiée. En l’occurrence :\n\nhommes : 52 % / femmes : 48 %\ngrand : 30 % / moyen : 45 % / petit : 25 %\nblond : 15 % / châtain : 45 % / brun : 30 % / blanc : 10 %\nétudiant : 20 % / salariés : 65 % / retraités : 15 %\nurbain : 80 % / rural : 20 %\n\nLes modalités non communes entre les profils de 1 et 2 sont : homme, femme, blond, brun, urbain et rural. La distance du Φ² entre 1 et 2 est donc la suivante :\n\\[\nd_{\\Phi^2}^2(L_1,L_2)=\\frac{1}{5}(\\frac{1}{0,52}+\\frac{1}{0,48}+\\frac{1}{0,15}+\\frac{1}{0,30}+\\frac{1}{0,80}+\\frac{1}{0,20})=4,05\n\\]\nCette distance, bien que moins intuitive que la distance de Gower évoquée précédemment, est la plus employée pour l’analyse d’enquêtes en sciences sociales. Il faut retenir que la distance entre deux profils est dépendante de la distribution globale de chaque modalité dans la population étudiée. Ainsi, si l’on recalcule les distances entre individus à partir d’un sous-échantillon, le résultat obtenu sera différent. De manière générale, les individus présentant des caractéristiques rares dans la population vont se retrouver éloignés des individus présentant des caractéristiques fortement représentées.\n\n41.1.3 Illustration\nNous allons reprendre l’exemple utilisé au chapitre précédent sur l’analyse factorielle (cf. Chapitre 40) et portant sur les loisirs pratiqués par les répondants à l’enquête histoire de vie de 2003.\n\nlibrary(tidyverse)\ndata(\"hdv2003\", package = \"questionr\")\nd &lt;- hdv2003 |&gt; \n  select(hard.rock:sport)\n\nCalculons maintenant une matrice de distances. Il s’agit d’une grande matrice carrée, avec autant de lignes et de colonnes que d’observations et indiquant la distance entre chaque individus pris deux à deux.\nLa distance de Gower se calcule avec cluster::daisy().\n\nmd_gower &lt;- d |&gt; \n  cluster::daisy(metric = \"gower\")\n\nPour la distance du Φ², nous allons d’abord réaliser une ACM avec ade4::dudi.cm() puis appeler ade4::dist.dudi().\n\nacm_ad &lt;- d |&gt;\n  ade4::dudi.acm(scannf = FALSE)\nmd_phi2 &lt;- acm_ad |&gt; \n  ade4::dist.dudi()\n\n\n\n\n\n\n\nAstuce\n\n\n\nLa distance du Φ² peut être calculée entre les observations (ce que nous venons de faire) afin de créer ensuite une typologie d’individus, mais il est également possible de calculer une distance du Φ² entre les modalités des variables afin de créer une typologie de variables. Dans ce cas-là, on appellera ade4::dist.dudi() avec l’option amongrow = FALSE.",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Classification ascendante hiérarchique</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/classification-ascendante-hierarchique.html#calcul-du-dendrogramme",
    "href": "analyses_avancees/classification-ascendante-hierarchique.html#calcul-du-dendrogramme",
    "title": "41  Classification ascendante hiérarchique",
    "section": "\n41.2 Calcul du dendrogramme",
    "text": "41.2 Calcul du dendrogramme\nIl faut ensuite choisir une méthode d’agrégation pour construire le dendrogramme. De nombreuses solutions existent (saut minimum, distance maximum, moyenne, méthode de Ward…). Chacune d’elle produira un dendrogramme différent. Nous ne détaillerons pas ici ces différentes techniques5.\n5 Les méthodes single, complete, centroid, average et Ward sont présentées succinctement dans le document Hierarchical Clustering par Fatih Karabiber.6 Ward, J. (1963). Hierarchical Grouping to Optimize an Objective Function. Journal of the American Statistical Association, 58(301), 236-244. doi:10.2307/2282967. (http://www.jstor.org/stable/2282967)7 Voir par exemple la discussion, en anglais, sur Wikipedia concernant la page présentant la méthode Ward : https://en.wikipedia.org/wiki/Talk:Ward%27s_methodCependant, à l’usage, on privilégiera le plus souvent la méthode de Ward6. De manière simplifiée, cette méthode cherche à minimiser l’inertie intra-classe et à maximiser l’inertie inter-classe afin d’obtenir des classes les plus homogènes possibles. Cette méthode est souvent incorrectement présentée comme une méthode de minimisation de la variance alors qu’au sens strict Ward vise l’augmentation minimum de la somme des carrés (“minimum increase of sum-of-squares (of errors)”)7.\nEn raison de la variété des distances possibles et de la variété des techniques d’agrégation, on pourra être amené à réaliser plusieurs dendrogrammes différents sur un même jeu de données jusqu’à obtenir une classification qui fait « sens ».\nLa fonction de base pour le calcul d’un dendrogramme est stats::hclust() en précisant le critère d’agrégation avec method. Dans notre cas, nous allons opter pour la méthode de Ward appliquée au carré des distances (ce qu’on indique avec method = \"ward.D2\"8) :\n8 L’option method = \"ward.D\" correspondant à la méthode de Ward sur la matrice des distances simples (i.e. sans la passer au carré). Mais il est à noter que la méthode décrite par Ward dans son article de 1963 correspond bien à method = \"ward.D2\".\narbre_phi2 &lt;- md_phi2 |&gt; \n  hclust(method = \"ward.D2\")\n\n\n\n\n\n\n\nAstuce\n\n\n\nLe temps de calcul d’un dendrogramme peut être particulièrement important sur un gros fichier de données. Le package fastcluster permet de réduire significativement ce temps de calcul. Elle propose une version optimisée de hclust() (les arguments sont identiques).\nIl suffira donc de charger fastcluster pour surcharger la fonction hclust(), ou bien d’appeler explicitement fastcluster::hclust().\n\narbre_gower &lt;- md_gower |&gt; \n  fastcluster::hclust(method = \"ward.D2\")\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nLe dendrogramme peut également être calculé avec la fonction cluster::agnes(). Cependant, à l’usage, le temps de calcul peut être plus long qu’avec hclust().\nLes noms des arguments sont légèrement différents. Pour la méthode de Ward appliquée au carré de la matrice des distance, on précisera à cluster::agnes() l’option method = \"ward\".\nLe résultat obtenu n’est pas au même format que celui de stats::hclust(). Il est possible de transformer un objet cluster::agnes() au format stats::hclust() avec cluster::as.hclust().\n\n\n\n41.2.1 Représentation graphique du dendrogramme\nPour une représentation graphique rapide du dendrogramme, on peut directement plot(). Lorsque le nombre d’individus est important, il peut être utile de ne pas afficher les étiquettes des individus avec labels = FALSE.\n\narbre_gower |&gt; \n  plot(labels = FALSE, main = \"Dendrogramme (distance de Gower)\")\n\n\n\n\n\n\nFigure 41.1: Représentation graphique du dendrogramme avec plot()\n\n\n\n\nPour une représentation graphique un peu plus propre (et avec plus d’options que nous verrons plus loin), nous pouvons avoir recours à factoextra::fviz_dend() du package factoextra. Le temps de calcul du graphique est par contre sensible plus long.\n\narbre_gower |&gt; \n  factoextra::fviz_dend(show_labels = FALSE) +\n  ggplot2::ggtitle(\"Dendrogramme (distance de Gower)\")\n\n\n\n\n\n\nFigure 41.2: Représentation graphique du dendrogramme avec fviz_dend()\n\n\n\n\nIl existe d’autres packages offrant des visualisations avancées pour les dendrogrammes. Citons notamment le package ggdendro et surtout dendextend qui est très complet.",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Classification ascendante hiérarchique</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/classification-ascendante-hierarchique.html#découper-le-dendrogramme",
    "href": "analyses_avancees/classification-ascendante-hierarchique.html#découper-le-dendrogramme",
    "title": "41  Classification ascendante hiérarchique",
    "section": "\n41.3 Découper le dendrogramme",
    "text": "41.3 Découper le dendrogramme\nPour obtenir une partition de la population, il suffit de découper le dendrogramme obtenu à une certaine hauteur. Cela aura pour effet de découper l’échantillon en plusieurs groupes, i.e. en plusieurs classes.\n\n41.3.1 Classes obtenues avec la distance de Gower\nEn premier lieu, il est toujours bon de prendre le temps d’observer de la forme des branches du dendrogramme. Reprenons le dendrogramme obtenu avec la distance de Gower (Figure 41.2). Nous recherchons des branches qui se distinguent clairement, c’est-à-dire avec un saut marqué sous la branche. Ici, nous avons tout d’abord deux groupes bien distincts qui apparaissent. Chacune des deux premières branches se sépare ensuite en deux branches bien visibles, suggérant une possible classification en 4 groupes.\nNous pouvons l’impact d’un découpage avec factoextra::fviz_dend() en précisant k = 4 pour lui indiquer de colorer un découpage en 4 classes. On peut optionnellement ajouter rect = TRUE pour dessiner des rectangles autour de chaque classe.\n\narbre_gower |&gt; \n  factoextra::fviz_dend(\n    show_labels = FALSE,\n    k = 4,\n    rect = TRUE\n  ) +\n  ggplot2::ggtitle(\"Dendrogramme découpé en 4 classes (distance de Gowver)\")\n\n\n\n\n\n\nFigure 41.3: Représentation graphique du dendrogramme avec fviz_dend()\n\n\n\n\nPour nous aider dans l’analyse du dendrogramme, il est possible de représenter graphiquement les sauts d’inertie (i.e. de la hauteur des branches) au fur-et-à-mesure que l’on découpe l’arbre en un nombre de classes plus important. Nous pouvons également considérer la perte absolue d’inertie (l’écart de hauteur entre le découpage précédent et le découpage considéré) voire la perte relative (i.e. la perte absolue exprimée en pourcentage de la hauteur précédente). FactoMineR (que nous aborderons un peu plus loin) suggère par défaut la partition correspondant à la plus grande perte relative d’inertie (the one with the higher relative loss of inertia).\nPour faciliter les choses, voici deux petites fonctions que vous pouvez recopier / adapter dans vos scripts. get_inertia_from_tree() calcule l’inertie à chaque niveau, ainsi que les pertes absolues et relatives. plot_inertia_from_tree() en propose une représentation graphique.\n\nget_inertia_from_tree &lt;- function(tree, k_max = 15) {\n  if (inherits(tree, \"HCPC\"))\n    tree &lt;- tree$call$t$tree\n  if (!inherits(tree, \"hclust\"))\n    tree &lt;- as.hclust(tree)\n  inertia &lt;- tree$height |&gt; \n    sort(decreasing = TRUE) |&gt; \n    head(k_max)\n  prev_inertia &lt;- dplyr::lag(inertia)\n  dplyr::tibble(\n    k = seq_along(inertia),\n    inertia = inertia,\n    absolute_loss = inertia - prev_inertia,\n    relative_loss = (inertia - prev_inertia) / prev_inertia\n  )\n}\n\nplot_inertia_from_tree &lt;- function(tree, k_max = 15) {\n  d &lt;- get_inertia_from_tree(tree, k_max)\n  p_inertia &lt;- \n    ggplot2::ggplot(d) +\n    ggplot2::aes(x = k, y = inertia) +\n    ggplot2::geom_step() +\n    ggplot2::ylab(\"Inertia\")\n  p_absolute &lt;-\n    ggplot2::ggplot(d) +\n    ggplot2::aes(x = k, y = absolute_loss) +\n    ggplot2::geom_bar(stat = \"identity\", fill = \"#4477AA\") +\n    ggplot2::ylab(\"Absolute loss\")\n  p_relative &lt;-\n    ggplot2::ggplot(d) +\n    ggplot2::aes(x = k, y = relative_loss) +\n    ggplot2::geom_line(color = \"#AA3377\") +\n    ggplot2::geom_point(size = 3, color = \"#AA3377\") +\n    ggplot2::scale_y_continuous(label = scales::percent) +\n    ggplot2::ylab(\"Relative loss\")\n  patchwork::wrap_plots(\n    p_inertia,\n    p_absolute,\n    p_relative,\n    ncol = 1\n  ) &\n    ggplot2::theme_light() &\n    ggplot2::xlab(\"Number of clusters\") &\n    ggplot2::scale_x_continuous(\n      breaks = d$k,\n      minor_breaks = NULL,\n      limits = c(1, k_max)\n    )\n}\n\nVoyons ce qu’on obtient.\n\narbre_gower |&gt; \n  plot_inertia_from_tree()\n\n\n\n\n\n\nFigure 41.4: Inertie, perte absolue et perte relative d’inertie pour différents découpages en classes (distance de Gower)\n\n\n\n\nDans cet exemple, nous pouvons voir qu’un découpage en deux classes maximise la perte absolue et la perte relative d’inertie. Mais, pour les besoins de l’analyse, nous pouvons souhaiter un nombre de classe un peu plus élevé (plus de classes permet une analyse plus fine, trop de classes rend l’interprétation des résultats compliqués). Un découpage en 4 classes apparaît sur ce graphique comme une bonne alternative, voir un découpage en 6 classes (une lecture du dendrogramme nous permet de voir que, dans cet exemple, un découpage en 6 classes reviendrait à couper en deux les 2 classes les plus larges du découpage en 4 classes).\nPour découper notre dendrogramme et récupérer la classification, nous appliquerons la fonction cutree() au dendrogramme, en indiquant le nombre de classes souhaitées9.\n9 Ici, nous pouvons ajouter le résultat obtenu directement à notre tableau de données hdv2003 dans la mesure où, depuis le début de l’analyse, l’ordre des lignes n’a jamais changé à aucune étape de l’analyse.\nhdv2003$typo_gower_4classes &lt;- arbre_gower |&gt; \n  cutree(4)\n\nNous pouvons rapidement faire un tri à plat avec gtsummary::tbl_summary().\n\nlibrary(gtsummary)\ntheme_gtsummary_language(\"fr\", decimal.mark = \",\")\n\n\nhdv2003 |&gt; \n  tbl_summary(include = typo_gower_4classes)\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 2 000\n1\n\n\n\n\ntypo_gower_4classes\n\n\n\n    1\n837 (42%)\n\n\n    2\n636 (32%)\n\n\n    3\n172 (8,6%)\n\n\n    4\n355 (18%)\n\n\n\n\n1\nn (%)\n\n\n\n\n\n\n\n\nTable 41.1: Distribution de la typologie en 4 classes obtenues à partir de la distance de Gower\n\n\n\nNous obtenons deux classes principales regroupant chacune plus du tiers de l’échantillon, une troisième classe regroupant presque un cinquième et une dernière classe avec un peu moins de 9 % des individus.\n\n41.3.2 Classes obtenues à partir de l’ACM (distance du Φ²)\nPour découper l’arbre obtenu à partir de l’ACM, nous allons procéder de la même manière. D’abord, jetons un œil au dendrogramme.\n\narbre_phi2 |&gt; \n  factoextra::fviz_dend(show_labels = FALSE) +\n  ggplot2::ggtitle(\"Dendrogramme (distance du Phi²)\")\n\n\n\n\n\n\nFigure 41.5: Représentation graphique du dendrogramme issu de l’ACM\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nLe dendrogramme obtenu est ici bien différent. Cela est lié au fait que les deux distances traitent différemment les modalités atypiques. En effet, la distance du Φ² prend en compte la fréquence de chaque modalité dans l’ensemble de l’échantillon. De fait, les modalités très peu représentées dans l’échantillon se retrouvent très éloignées des autres et la CAH aura tendance à isoler les individus atypiques. À l’inverse, la distance de Gower est indépendante de la fréquence de chaque modalité dans l’échantillon. De fait, plutôt que d’isoler les individus atypiques, une CAH basée sur la distance de Gower aura plutôt tendance à les associer aux autres à partir de leurs autres caractéristiques, aboutissant à des classes plus équilibrées.\nIl n’y a pas une approche meilleure que l’autre. Tout dépend des questions de recherche que l’on se posent et de ce que l’on souhaite faire émerger.\n\n\nComme nous pouvons le voir, dès le début du dendrogramme, l’arbre se divise rapidement en 5 branches puis il y a un saut relativement marqué. Nous pouvons confirmer cela avec plot_inertia_from_tree().\n\narbre_phi2 |&gt; \n  plot_inertia_from_tree()\n\n\n\n\n\n\nFigure 41.6: Inertie, perte absolue et perte relative d’inertie pour différents découpages en classes (distance de Phi²)\n\n\n\n\nCela confirme un découpage optimal en 5 classes. Regardons la distribution de cette typologie.\n\nhdv2003$typo_phi2_5classes &lt;- arbre_phi2 |&gt; \n  cutree(5)\n\n\nhdv2003 |&gt; \n  tbl_summary(include = typo_phi2_5classes)\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 2 000\n1\n\n\n\n\ntypo_phi2_5classes\n\n\n\n    1\n1 010 (51%)\n\n\n    2\n713 (36%)\n\n\n    3\n216 (11%)\n\n\n    4\n14 (0,7%)\n\n\n    5\n47 (2,4%)\n\n\n\n\n1\nn (%)\n\n\n\n\n\n\n\n\nTable 41.2: Distribution de la typologie en 5 classes obtenues à partir de la distance du Phi²\n\n\n\nSur les 5 classes, deux sont très atypiques puisqu’elles ne réunissent que 0,7 % et 2,4 % de l’échantillon. À voir si cela est problématique pour la suite de l’analyse. Au besoin, nous pourrions envisager de fusionner les classes 4 et 5 avec la classe 2 avec laquelle elles sont plus proches selon le dendrogramme.\nIl est possible de visualiser la répartition de la typologie dans le plan factoriel avec factoextra::fviz_mca_ind() et en passant la typologie à habillage.\n\nacm_ad |&gt;\n  factoextra::fviz_mca_ind(\n    habillage = hdv2003$typo_phi2_5classes,\n    addEllipses = TRUE,\n    geom.ind = \"point\",\n    alpha.ind = 0.1\n  )\n\n\n\n\n\n\nFigure 41.7: Projection de la typologie dans le plan factoriel de l’ACM\n\n\n\n\nNous voyons que les classes 1, 2 et 3 séparent bien les individus au niveau du plan factoriel. Les deux classes atypiques 4 et 5, quant à elles, sont diffuses sur les deux premiers axes, suggérant qu’elles capturent des différences observables sur des axes de niveau supérieur.\n\n\n\n\n\n\nNote\n\n\n\nIl existe de multiples autres indicateurs statistiques cherchant à mesurer la qualité de chaque partition. Pour cela, on pourra par exemple avoir recours à la fonction WeightedCluster::as.clustrange() de l’extension WeightedCluster.\nPour plus d’informations, voir le manuel de la librairie WeightedCluster, chapitre 7.\n\nWeightedCluster::as.clustrange(arbre_phi2, md_phi2) |&gt; plot()\n\nRegistered S3 method overwritten by 'vegan':\n  method     from      \n  rev.hclust dendextend\n\n\n\n\n\n\n\n\nOn pourra également lire Determining The Optimal Number Of Clusters: 3 Must Know Methods par Alboukadel Kassambara, l’un des auteurs du package factoextra.",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Classification ascendante hiérarchique</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/classification-ascendante-hierarchique.html#calcul-de-lacm-et-de-la-cah-avec-factominer",
    "href": "analyses_avancees/classification-ascendante-hierarchique.html#calcul-de-lacm-et-de-la-cah-avec-factominer",
    "title": "41  Classification ascendante hiérarchique",
    "section": "\n41.4 Calcul de l’ACM et de la CAH avec FactoMineR\n",
    "text": "41.4 Calcul de l’ACM et de la CAH avec FactoMineR\n\nLe package FactoMineR permet lui aussi de réaliser une CAH à partir d’une ACM via la fonction FactoMineR::HCPC() qui réalise les différentes opérations en une seule fois.\nFactoMineR::HCPC() réalise à la fois le calcul de la matrice des distances, du dendrogramme et le partitionnement de la population en classes. Par défaut, FactoMineR::HCPC() calcule le dendrogramme à partir du carré des distances du Φ² et avec la méthode de Ward. Si l’on ne précise rien, FactoMineR::HCPC() détermine une partition optimale selon le critère de la plus perte relative d’inertie évoqué plus haut10. La fonction prend en entrée une analyse factorielle réalisée avec FactoMineR. Le paramètre min permet d’indiquer un nombre minimum de classes.\n10 Plus précisément si graph = FALSE ou si nb.clust = -1. Si graph = TRUE et nb.clust = 0 (valeurs par défaut), la fonction affichera un dendrogramme interactif et l’utilisateur devra cliquer au niveau de la hauteur où il souhaite réaliser la découpe.\nacm_fm &lt;- FactoMineR::MCA(d, graph = FALSE)\ncah_fm &lt;- FactoMineR::HCPC(acm_fm, graph = FALSE, min = 3)\n\nNous pouvons directement passer le résultat de FactoMineR::HCPC() à factoextra::fviz_dend() pour visualiser le dendrogramme, qui sera d’ailleurs automatiquement colorié à partir de la partition recommandée par FactoMineR::HCPC().\n\ncah_fm |&gt; \n  factoextra::fviz_dend(show_labels = FALSE)\n\n\n\n\n\n\nFigure 41.8: Représentation graphique du dendrogramme issu de l’ACM réalisée avec FactoMineR\n\n\n\n\nNous obtenons ici un découpage en 6 classes qui correspond bien à la plus grand perte relative d’inertie comme nous pouvons le vérifier avec plot_inertia_from_tree() qui accepte également en entrée un objet produit par FactoMineR::HCPC().\n\ncah_fm |&gt; \n  plot_inertia_from_tree()\n\n\n\n\n\n\nFigure 41.9: Inertie, perte absolue et perte relative d’inertie pour différents découpages en classes à partir du résultat de HCPC()\n\n\n\n\nPar contre, le dendrogramme obtenu diffère de celui que nous avions eu précédemment avec ade4 (cf. Figure 41.5). Cela est dû au fait que FactoMineR::HCPC() procède différemment pour calculer la matrice des distances en ne prenant en compte que les axes retenus dans le cadre de l’ACM.\nPour rappel, par défaut, FactoMineR::MCA() ne retient que les 5 premiers axes de l’espace factoriel. FactoMineR::HCPC() n’a donc pris en compte que ces 5 premiers axes pour calculer les distances entre les individus, considérant que les autres axes n’apportent que du « bruit » rendant la classification instable. Comme le montre summary(acm_fm), nos cinq premiers axes n’expliquent que 78 % de la variance. On considère usuellement préférable de garder un plus grande nombre d’axes afin de couvrir au moins 80 à 90 % de la variance.\nDe son côté, ade4::dist.dudi() prends en compte l’ensemble des axes pour calculer la matrice des distances. On peut reproduire cela avec FactoMineR en indiquant ncp = Inf lors du calcul de l’ACM.\n\nacm_fm2 &lt;- FactoMineR::MCA(d, graph = FALSE, ncp = Inf)\ncah_fm2 &lt;- FactoMineR::HCPC(acm_fm2, graph = FALSE, min = 3)\n\n\ncah_fm2 |&gt; \n  factoextra::fviz_dend(show_labels = FALSE)\n\n\n\n\n\n\nFigure 41.10: Représentation graphique du dendrogramme issu de l’ACM réalisée avec FactoMineR avec prise en compte de l’ensemble des axes\n\n\n\n\nNous retrouvons alors le même résultat que celui obtenu avec ade4 et un découpage en 5 classes.\nÀ noter que FactoMineR propose une visualisation en 3 dimensions du dendrogramme projeté sur le plan factoriel.\n\ncah_fm2 |&gt; \n  plot()\n\n\n\n\n\n\nFigure 41.11: Représentation en 3 dimensions du dendrogramme sur le plan factoriel\n\n\n\n\nNotons également l’option choice = \"tree\" qui propose une représentation du dendrogramme, avec des rectangles indiquant le découpage optimal et une vignette présentant l’inertie à chaque découpage.\n\ncah_fm2 |&gt; \n  plot(choice = \"tree\")\n\n\n\n\n\n\nFigure 41.12: Représentation du dendrogramme et de l’inertie\n\n\n\n\nPour récupérer la classification, on pourra récupérer la colonne $clust du sous-objet $data.clust du résultat renvoyé par FactoMineR::HCPC().\n\nhdv2003$typo_cah_fm2 &lt;- cah_fm2$data.clust$clust\n\nSi l’on a besoin de découper le dendrogramme à un autre endroit, nous pouvons récupérer le dendrogramme via le sous-objet $call$t$tree puis lui appliquer cutree().\n\nhdv2003$typo_alternative &lt;-\n  cah_fm2$call$t$tree |&gt;\n  cutree(3)",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Classification ascendante hiérarchique</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/classification-ascendante-hierarchique.html#caractériser-la-typologie",
    "href": "analyses_avancees/classification-ascendante-hierarchique.html#caractériser-la-typologie",
    "title": "41  Classification ascendante hiérarchique",
    "section": "\n41.5 Caractériser la typologie",
    "text": "41.5 Caractériser la typologie\nReste le travail le plus important (et parfois le plus difficile) qui consiste à catégoriser la typologie obtenue et le cas échéant à nommer les classes.\nEn premier lieu, on peut croiser la typologie obtenue avec les différentes variables inclues dans l’ACM. Le plus simple est d’avoir recours à gtsummary::tbl_summary(). Par exemple, pour la typologie obtenue avec la distance de Gower.\n\nhdv2003 |&gt;\n  tbl_summary(\n    include = hard.rock:sport,\n    by = typo_gower_4classes\n  ) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\n1\nN = 837\n1\n\n\n2\nN = 636\n1\n\n\n3\nN = 172\n1\n\n\n4\nN = 355\n1\n\n\n\n\nhard.rock\n\n\n\n\n\n\n    Non\n837 (100%)\n632 (99%)\n171 (99%)\n346 (97%)\n\n\n    Oui\n0 (0%)\n4 (0,6%)\n1 (0,6%)\n9 (2,5%)\n\n\nlecture.bd\n\n\n\n\n\n\n    Non\n813 (97%)\n613 (96%)\n172 (100%)\n355 (100%)\n\n\n    Oui\n24 (2,9%)\n23 (3,6%)\n0 (0%)\n0 (0%)\n\n\npeche.chasse\n\n\n\n\n\n\n    Non\n806 (96%)\n633 (100%)\n0 (0%)\n337 (95%)\n\n\n    Oui\n31 (3,7%)\n3 (0,5%)\n172 (100%)\n18 (5,1%)\n\n\ncuisine\n\n\n\n\n\n\n    Non\n532 (64%)\n316 (50%)\n79 (46%)\n192 (54%)\n\n\n    Oui\n305 (36%)\n320 (50%)\n93 (54%)\n163 (46%)\n\n\nbricol\n\n\n\n\n\n\n    Non\n570 (68%)\n317 (50%)\n47 (27%)\n213 (60%)\n\n\n    Oui\n267 (32%)\n319 (50%)\n125 (73%)\n142 (40%)\n\n\ncinema\n\n\n\n\n\n\n    Non\n831 (99%)\n226 (36%)\n115 (67%)\n2 (0,6%)\n\n\n    Oui\n6 (0,7%)\n410 (64%)\n57 (33%)\n353 (99%)\n\n\nsport\n\n\n\n\n\n\n    Non\n834 (100%)\n2 (0,3%)\n86 (50%)\n355 (100%)\n\n\n    Oui\n3 (0,4%)\n634 (100%)\n86 (50%)\n0 (0%)\n\n\n\n\n1\nn (%)\n\n\n\n\n\n\n\n\nTable 41.3: Description de la typologie en 4 classes à partir de la distance de Gower\n\n\n\nPour une représentation plus visuelle, on peut également avoir recours à GGally::ggtable() de GGally pour représenter les résidus du Chi² et mieux repérer les différences. La couleur bleue indique que la modalité est sur-représentée et la couleur rouge qu’elle est sous-représentée.\n\nlibrary(GGally)\nhdv2003$typo_gower_4classes &lt;- factor(hdv2003$typo_gower_4classes)\nggtable(\n  hdv2003, \n  columnsX = \"typo_gower_4classes\", \n  columnsY = names(d),\n  cells = \"col.prop\",\n  fill = \"std.resid\"\n) + \n  labs(fill = \"Résidus standardizés du Chi²\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\nFigure 41.13: Distribution de la typologie en 4 classes et résidus du Chi²\n\n\n\n\nUne première lecture nous indique que :\n\nla première classe rassemble des individus qui n’ont pas (ou peu) de loisirs ;\nla seconde classe réunit des personnes pratiquant un sport et ayant souvent une autre activité telle que le cinéma, la bricolage ou la cuisine ;\nla troisième classe réunit spécifiquement les individus pratiquant la chasse ou la pêche ;\nla quatrième classe correspond à des personnes ne pratiquant pas de sport mais allant au cinéma.\n\nBien sûr, l’interprétation fine des catégories nécessite un peu plus d’analyse, de croiser avec la littérature et les hypothèses des questions de recherche posées, et de croiser la typologie avec d’autres variables de l’enquête.\nPour la typologie réalisée à partir d’une ACM, nous pourrons procéder de la même manière. Cependant, si la CAH a été réalisée avec FactoMineR::HCPC(), l’objet retourné contient directement un sous-objet $desc.var donnant une description de la typologie obtenue.\n\ncah_fm2$desc.var\n\n\nLink between the cluster variable and the categorical variables (chi-square test)\n=================================================================================\n                  p.value df\nhard.rock    0.000000e+00  4\nlecture.bd   0.000000e+00  4\npeche.chasse 0.000000e+00  4\ncinema       0.000000e+00  4\nsport        1.122743e-38  4\nbricol       4.121835e-11  4\ncuisine      8.681152e-04  4\n\nDescription of each cluster by the categories\n=============================================\n$`1`\n                               Cla/Mod   Mod/Cla Global      p.value     v.test\ncinema=cinema_Non             86.03066 100.00000  58.70 0.000000e+00        Inf\npeche.chasse=peche.chasse_Non 56.86937 100.00000  88.80 2.188843e-75  18.372312\nsport=sport_Non               61.39389  77.62376  63.85 6.009360e-39  13.054257\nlecture.bd=lecture.bd_Non     51.71531 100.00000  97.65 2.518852e-15   7.912690\nbricol=bricol_Non             57.10549  64.85149  57.35 6.993497e-12   6.857788\ncuisine=cuisine_Non           54.60232  60.49505  55.95 3.566198e-05   4.133925\nhard.rock=hard.rock_Non       50.85599 100.00000  99.30 5.060286e-05   4.052825\nhard.rock=hard.rock_Oui        0.00000   0.00000   0.70 5.060286e-05  -4.052825\ncuisine=cuisine_Oui           45.28944  39.50495  44.05 3.566198e-05  -4.133925\nbricol=bricol_Oui             41.61782  35.14851  42.65 6.993497e-12  -6.857788\nlecture.bd=lecture.bd_Oui      0.00000   0.00000   2.35 2.518852e-15  -7.912690\nsport=sport_Oui               31.25864  22.37624  36.15 6.009360e-39 -13.054257\npeche.chasse=peche.chasse_Oui  0.00000   0.00000  11.20 2.188843e-75 -18.372312\ncinema=cinema_Oui              0.00000   0.00000  41.30 0.000000e+00       -Inf\n\n$`2`\n                                Cla/Mod   Mod/Cla Global       p.value\npeche.chasse=peche.chasse_Oui 96.428571 100.00000  11.20 2.257673e-282\nbricol=bricol_Oui             14.536928  57.40741  42.65  4.149911e-06\nlecture.bd=lecture.bd_Non     11.059908 100.00000  97.65  4.347616e-03\ncinema=cinema_Non             12.265758  66.66667  58.70  1.129267e-02\ncinema=cinema_Oui              8.716707  33.33333  41.30  1.129267e-02\nlecture.bd=lecture.bd_Oui      0.000000   0.00000   2.35  4.347616e-03\nbricol=bricol_Non              8.020924  42.59259  57.35  4.149911e-06\npeche.chasse=peche.chasse_Non  0.000000   0.00000  88.80 2.257673e-282\n                                  v.test\npeche.chasse=peche.chasse_Oui  35.908415\nbricol=bricol_Oui               4.603730\nlecture.bd=lecture.bd_Non       2.851773\ncinema=cinema_Non               2.533509\ncinema=cinema_Oui              -2.533509\nlecture.bd=lecture.bd_Oui      -2.851773\nbricol=bricol_Non              -4.603730\npeche.chasse=peche.chasse_Non -35.908415\n\n$`3`\n                               Cla/Mod   Mod/Cla Global      p.value     v.test\ncinema=cinema_Oui             86.31961 100.00000  41.30 0.000000e+00        Inf\npeche.chasse=peche.chasse_Non 40.14640 100.00000  88.80 6.154083e-47  14.388011\nsport=sport_Oui               52.97372  53.71669  36.15 1.222033e-33  12.088015\nlecture.bd=lecture.bd_Non     36.50794 100.00000  97.65 7.397824e-10   6.157337\nbricol=bricol_Oui             40.21102  48.10659  42.65 2.493205e-04   3.662957\ncuisine=cuisine_Oui           39.38706  48.66760  44.05 2.003812e-03   3.089667\nhard.rock=hard.rock_Non       35.90131 100.00000  99.30 2.035491e-03   3.085005\nhard.rock=hard.rock_Oui        0.00000   0.00000   0.70 2.035491e-03  -3.085005\ncuisine=cuisine_Non           32.70777  51.33240  55.95 2.003812e-03  -3.089667\nbricol=bricol_Non             32.25806  51.89341  57.35 2.493205e-04  -3.662957\nlecture.bd=lecture.bd_Oui      0.00000   0.00000   2.35 7.397824e-10  -6.157337\nsport=sport_Non               25.84182  46.28331  63.85 1.222033e-33 -12.088015\npeche.chasse=peche.chasse_Oui  0.00000   0.00000  11.20 6.154083e-47 -14.388011\ncinema=cinema_Non              0.00000   0.00000  58.70 0.000000e+00       -Inf\n\n$`4`\n                             Cla/Mod   Mod/Cla Global      p.value     v.test\nlecture.bd=lecture.bd_Oui 100.000000 100.00000   2.35 3.168360e-96  20.814956\ncinema=cinema_Oui           3.510896  61.70213  41.30 4.803168e-03   2.819946\nsport=sport_Oui             3.319502  51.06383  36.15 3.601926e-02   2.096710\nsport=sport_Non             1.801096  48.93617  63.85 3.601926e-02  -2.096710\ncinema=cinema_Non           1.533220  38.29787  58.70 4.803168e-03  -2.819946\nlecture.bd=lecture.bd_Non   0.000000   0.00000  97.65 3.168360e-96 -20.814956\n\n$`5`\n                            Cla/Mod   Mod/Cla Global      p.value     v.test\nhard.rock=hard.rock_Oui 100.0000000 100.00000    0.7 5.569208e-36  12.523271\ncinema=cinema_Oui         1.4527845  85.71429   41.3 9.122223e-04   3.316287\ncinema=cinema_Non         0.1703578  14.28571   58.7 9.122223e-04  -3.316287\nhard.rock=hard.rock_Non   0.0000000   0.00000   99.3 5.569208e-36 -12.523271\n\n\nUne représentation graphique indiquant les modalités contribuant le plus à chaque axe est même directement disponible. La couleur bleue indique que la modalité est sous-représentée dans la classe et la couleur rouge qu’elle est sur-représentée11.\n11 Attention à l’interprétation : ce code couleur est l’inverse de celui utilisé par GGally::ggtable().\ncah_fm2$desc.var |&gt; plot()\n\n\n\n\n\n\nFigure 41.14: Représentation graphique des modalités contribuant le plus",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Classification ascendante hiérarchique</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/classification-ascendante-hierarchique.html#webin-r",
    "href": "analyses_avancees/classification-ascendante-hierarchique.html#webin-r",
    "title": "41  Classification ascendante hiérarchique",
    "section": "\n41.6 webin-R",
    "text": "41.6 webin-R\nLa CAH est présentée sur YouTube dans le webin-R #12 (Classification Ascendante Hiérarchique).\n\n\n\n\nFigure 41.1: Représentation graphique du dendrogramme avec plot()\nFigure 41.2: Représentation graphique du dendrogramme avec fviz_dend()\nFigure 41.3: Représentation graphique du dendrogramme avec fviz_dend()\nFigure 41.4: Inertie, perte absolue et perte relative d’inertie pour différents découpages en classes (distance de Gower)\nFigure 41.5: Représentation graphique du dendrogramme issu de l’ACM\nFigure 41.6: Inertie, perte absolue et perte relative d’inertie pour différents découpages en classes (distance de Phi²)\nFigure 41.7: Projection de la typologie dans le plan factoriel de l’ACM\nFigure 41.8: Représentation graphique du dendrogramme issu de l’ACM réalisée avec FactoMineR\nFigure 41.9: Inertie, perte absolue et perte relative d’inertie pour différents découpages en classes à partir du résultat de HCPC()\nFigure 41.10: Représentation graphique du dendrogramme issu de l’ACM réalisée avec FactoMineR avec prise en compte de l’ensemble des axes\nFigure 41.11: Représentation en 3 dimensions du dendrogramme sur le plan factoriel\nFigure 41.12: Représentation du dendrogramme et de l’inertie\nFigure 41.13: Distribution de la typologie en 4 classes et résidus du Chi²\nFigure 41.14: Représentation graphique des modalités contribuant le plus",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Classification ascendante hiérarchique</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/analyse-survie.html",
    "href": "analyses_avancees/analyse-survie.html",
    "title": "42  Analyse de survie",
    "section": "",
    "text": "42.1 Données de l’exemple\nNous allons utiliser le jeu de données gtsummary::trial qui fournit des observations sur 200 patients atteints d’un cancer. La variable death indique si la personne est décédée (1) ou toujours en vie (1) et la variable ttdeath indique en mois la durée entre le diagnostic et le décès ou la censure à droite. Les données sont donc déjà codées de manière à être utilisée dans une analyse de survie.\nLa variable catégorielle trt indique si le patient a reçu le traitement A ou le traitement B. La variable catégorielle stage correspond au stade du cancer au moment du diagnostic : plus il est élevé plus le cancer est grave et avancé. Enfin, la variable continue age correspond à l’âge révolu du patient au moment du diagnostic.",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Analyse de survie</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/analyse-survie.html#analyse-univariée-courbe-de-kaplan-meier",
    "href": "analyses_avancees/analyse-survie.html#analyse-univariée-courbe-de-kaplan-meier",
    "title": "42  Analyse de survie",
    "section": "\n42.2 Analyse univariée (courbe de Kaplan-Meier)",
    "text": "42.2 Analyse univariée (courbe de Kaplan-Meier)\nLa courbe de survie de Kaplan-Meier permet de décrire la probabilité de survie au cours du temps tout en tenant compte des éventuelles censures à droite.\nElle se calcule avec la fonction survival::survfit() à laquelle nous allons décrire notre outcome à l’aide de survival::Surv() en lui indiquant d’abord la variable temps puis la variable évènement.\n\nlibrary(gtsummary)\nlibrary(survival)\nkm &lt;- survfit(Surv(ttdeath, death) ~ 1, data = trial)\n\nPour un graphique rapide, on peut utiliser plot().\n\nkm |&gt; plot()\n\n\n\n\n\n\n\nCependant, il est préférable d’avoir recours au package {ggsurvfit}, développé par le même auteur que gtsummary, et sa fonction homonyme ggsurvfit::ggsurvfit().\n\nlibrary(ggsurvfit)\n\nLoading required package: ggplot2\n\nkm |&gt; ggsurvfit()\n\n\n\n\n\n\n\nLe package fournit de multiples options :\n\n\nggsurvfit::add_confidence_interval() pour ajouter les intervalles de confiance de la courbe,\n\nggsurvfit::add_risk_table() pour ajouter une table avec le nombre de personnes encore à risque à chaque pas de temps et le nombre d’évènements,\n\nggsurvfit::add_quantile() pour ajouter des lignes indiquant un certain quantile (par exemple à quel moment la moitié de la population a connu l’évènement),\n\nggsurvfit::add_censor_mark() pour ajouter des marques indiquant les censures à droite.\n\nLe graphique renvoyé est un objet ggplot2 et l’on peut appliquer toute fonction graphique additionnelle.\n\nlibrary(ggplot2)\nkm |&gt; \n  ggsurvfit() +\n  add_confidence_interval() +\n  add_risktable(\n    stats_label = list(\n      \"n.risk\" = \"Personnes à risque\",\n      \"cum.event\" = \"Nombre de décès\"\n    )\n  ) +\n  add_quantile(\n    y_value = 0.5, \n    color = \"gray50\", \n    linewidth = 0.75\n  ) +\n  scale_x_continuous(breaks = 0:4*6) +\n  scale_y_continuous(labels = scales::percent) +\n  xlab(\"Mois depuis le diagnostic\") +\n  ylab(\"Proportion toujours en vie\")\n\n\n\n\n\n\n\nIl est également possible de représenter la proportion de personnes ayant vécu l’évènement plutôt que celle ne l’ayant toujours pas vécu.\n\nkm |&gt; \n  ggsurvfit(type = \"risk\") +\n  add_confidence_interval() +\n  scale_ggsurvfit() +\n  xlab(\"Mois depuis le diagnostic\") +\n  ylab(\"Proportion décédée\")\n\n\n\n\n\n\n\nPour un tableau des résultats, on fera appel à gtsummary::tbl_survfit() à laquelle on indiquera soit des points dans le temps, soit une série de quantiles. Par défaut, cela affiche la valeur de la courbe et les intervalles de confiance à 95%.\n\n# affichage des résultats en français\ntheme_gtsummary_language(\"fr\", decimal.mark = \",\")\n\nSetting theme \"language: fr\"\n\nkm |&gt; \n  tbl_survfit(\n    times = c(6, 12, 18, 24),\n    label_header = \"**Mois {time}**\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\nMois 6\nMois 12\nMois 18\nMois 24\n\n\nTotal\n99% (98%, 100%)\n89% (84%, 93%)\n65% (59%, 72%)\n44% (38%, 51%)\n\n\n\n\n\nkm |&gt; \n  tbl_survfit(\n    probs = c(.25, .5, .75)\n  ) |&gt; \n  modify_spanning_header(\n    all_stat_cols() ~ \"**Proportion décédée**\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\n\nProportion décédée\n\n\n\n25% Percentile\n50% Percentile\n75% Percentile\n\n\n\nTotal\n16 (15, 17)\n22 (21, —)\n— (—, —)",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Analyse de survie</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/analyse-survie.html#analyse-bivariée-kaplan-meier",
    "href": "analyses_avancees/analyse-survie.html#analyse-bivariée-kaplan-meier",
    "title": "42  Analyse de survie",
    "section": "\n42.3 Analyse bivariée (Kaplan-Meier)",
    "text": "42.3 Analyse bivariée (Kaplan-Meier)\nIl est possible de calculer des courbes de Kaplan-Meier selon une variable catégorielle (analyse stratifiée). Par exemple, pour voir comment varie la survie en fonction du stade au diagnostic.\n\nkm_stade &lt;- survfit(\n  Surv(ttdeath, death) ~ stage,\n  data = trial\n)\nkm_stade |&gt; ggsurvfit()\n\n\n\n\n\n\n\nNous pouvons facilement améliorer le rendu du graphique en utilisant ggsurvfit::surfit2() à la place de survival::survfit(). Les deux fonctions sont équivalentes à l’exception du fait que la version fournie par ggsurvfit concerne certaines informations, comme les étiquettes de variables, afin d’améliorer le rendu visuel par défaut du graphique.\n\nkm_stade &lt;- survfit2(\n  Surv(ttdeath, death) ~ stage,\n  data = trial\n)\nkm_stade |&gt; \n  ggsurvfit() +\n  scale_ggsurvfit()\n\n\n\n\n\n\n\nIl est possible de faire un test statistique pour déterminer si les courbes de survie diffèrent selon les stades avec la fonction survival::survdiff() qui implémente le test du log-rank ou de Mantel-Haenszel (par défaut).\n\nsurvdiff(\n  Surv(ttdeath, death) ~ stage,\n  data = trial\n)\n\nCall:\nsurvdiff(formula = Surv(ttdeath, death) ~ stage, data = trial)\n\n          N Observed Expected (O-E)^2/E (O-E)^2/V\nstage=T1 53       24     33.3     2.613      3.73\nstage=T2 54       27     31.9     0.750      1.05\nstage=T3 43       22     24.8     0.319      0.41\nstage=T4 50       39     22.0    13.223     16.56\n\n Chisq= 17  on 3 degrees of freedom, p= 7e-04 \n\n\nIl est possible de calculer et d’afficher directement ce résultat sur le graphique (en bas à droite) avec ggsurvfit::add_pvalue().\n\nkm_stade |&gt; \n  ggsurvfit() +\n  add_confidence_interval() +\n  add_pvalue() +\n  scale_ggsurvfit()\n\n\n\n\n\n\n\nDans un tableau, on aura recours à gtsummary::add_p().\n\nkm_stade |&gt; \n  tbl_survfit(times = c(12, 24)) |&gt; \n  add_p() |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\nTemps 12\nTemps 24\n\np-valeur\n1\n\n\n\n\nT Stage\n\n\n&lt;0,001\n\n\n    T1\n94% (88%, 100%)\n55% (43%, 70%)\n\n\n\n    T2\n89% (81%, 98%)\n50% (38%, 65%)\n\n\n\n    T3\n91% (82%, 100%)\n49% (36%, 66%)\n\n\n\n    T4\n80% (70%, 92%)\n22% (13%, 37%)\n\n\n\n\n\n1\nLog-rank test\n\n\n\n\n\n\n\nIl est possible de réaliser simultanément plusieurs analyses de survie bivariées avec tbl_survfit(). La syntaxe est juste un peu différente. Au lieu de passer un objet survfit() à tbl_survfit(), on lui passera le jeu de données et on utilisera y et include pour indiquer comment calculer les courbes de survies.\n\ntrial |&gt; \n  tbl_survfit(\n    y = Surv(ttdeath, death),\n    include = c(stage, trt),\n    times = c(12, 24)\n  ) |&gt; \n  add_p() |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\nTemps 12\nTemps 24\n\np-valeur\n1\n\n\n\n\nT Stage\n\n\n&lt;0,001\n\n\n    T1\n94% (88%, 100%)\n55% (43%, 70%)\n\n\n\n    T2\n89% (81%, 98%)\n50% (38%, 65%)\n\n\n\n    T3\n91% (82%, 100%)\n49% (36%, 66%)\n\n\n\n    T4\n80% (70%, 92%)\n22% (13%, 37%)\n\n\n\nChemotherapy Treatment\n\n\n0,2\n\n\n    Drug A\n91% (85%, 97%)\n47% (38%, 58%)\n\n\n\n    Drug B\n86% (80%, 93%)\n41% (33%, 52%)\n\n\n\n\n\n1\nLog-rank test",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Analyse de survie</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/analyse-survie.html#analyse-multivariable-modèle-de-cox",
    "href": "analyses_avancees/analyse-survie.html#analyse-multivariable-modèle-de-cox",
    "title": "42  Analyse de survie",
    "section": "\n42.4 Analyse multivariable (modèle de Cox)",
    "text": "42.4 Analyse multivariable (modèle de Cox)\nPour une analyse multivariable, on aura recours à un modèle de Cox. Il est tout à fait possible d’inclure des variables continues, par exemple l’âge des patients. Ici, nous n’abordons qu’un modèle avec des variables fixes au cours du temps. Mais il est possible de calculer un modèle de Cox avec des variables explicatives pouvant changer au cours du temps.\nLe modèle de Cox se calcule avec survival::coxph().\n\nmod &lt;- coxph(\n  Surv(ttdeath, death) ~ stage + trt + age,\n  data = trial\n)\n\n\n42.4.1 Visualisation des résultats\nComme pour la régression logistique (cf. Chapitre 22), nous pouvons utiliser gtsummary::tbl_regression(), ggstats::ggcoef_model() et ggstats::ggcoef_table() pour afficher les coefficients du modèle.\nIl est pertinent d’afficher l’exponentielle des coefficients car il s’interprètent comme des risque relatifs ou hazard ratios.\n\nmod |&gt; \n  tbl_regression(exponentiate = TRUE) |&gt; \n  add_global_p(keep = TRUE) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nHR\n1\n\n\n95% IC\n1\n\np-valeur\n\n\n\nT Stage\n\n\n0,002\n\n\n    T1\n—\n—\n\n\n\n    T2\n1,31\n0,74 – 2,30\n0,4\n\n\n    T3\n1,18\n0,64 – 2,16\n0,6\n\n\n    T4\n2,72\n1,58 – 4,68\n&lt;0,001\n\n\nChemotherapy Treatment\n\n\n0,12\n\n\n    Drug A\n—\n—\n\n\n\n    Drug B\n1,37\n0,93 – 2,02\n0,12\n\n\nAge\n1,01\n1,00 – 1,02\n0,15\n\n\n\n\n1\nHR = rapport de risques instantanés, IC = intervalle de confiance\n\n\n\n\n\n\n\n\nlibrary(ggstats)\nmod |&gt; \n  ggcoef_model(exponentiate = TRUE)\n\n\n\n\n\n\n\n\nmod |&gt; \n  ggcoef_table(exponentiate = TRUE)\n\n\n\n\n\n\n\nLe risque relatif correspond au rapport des risques instantanés. Il est par exemple de 2,7 pour les personnes au stade T4 par rapport à celles au stade T1. Cela signifie donc qu’à tout moment le risque de décéder est 2,7 fois plus important pour les personnes au stade 4 par rapport à celles au stade 1.\n\n42.4.2 Vérification des hypothèses\nLe modèle de Cox considère que, bien que le risque de décès évolue au cours du temps, les risques relatifs restent quant à eux identiques. Il s’agit de l’hypothèse de la proportionnalité des risques relatifs. Selon cette hypothèse les résidus de Schoenfeld ne dépendent pas du temps. Cette hypothèse peut être testée avec la fonction cox.zph().\n\nmod |&gt; cox.zph()\n\n       chisq df    p\nstage  0.983  3 0.81\ntrt    1.863  1 0.17\nage    0.159  1 0.69\nGLOBAL 2.969  5 0.70\n\n\nUn test est ici effectué globalement et pour chaque variable individuellement. Une valeur de p inférieure à 5% indique un problème potentiel en termes de proportionnalité des risques.\nLa fonction survminer::ggcoxzph() du package survminer permet de représenter les résidus de Schoenfeld et de visualiser si leur répartition est relativement stable au cours du temps (visuellement horizontale autour de 0) ou bien s’ils suivent une autre distribution.\n\nmod |&gt; cox.zph() |&gt; survminer::ggcoxzph()\n\n\n\n\n\n\n\n\n42.4.3 Représentation graphique d’une courbe de survie ajustée\nIl est possible de calculer, avec survfit2(), des courbes de survie ajustées à partir d’un modèle de Cox. Cependant, pour indiquer la variable de stratification des courbes, il est nécessaire de l’inclure avec strata() dans l’appel du modèle de Cox.\n\ntrial |&gt; \n  coxph(\n    Surv(ttdeath, death) ~ strata(stage) + trt + age,\n    data = _\n  ) |&gt; \n  survfit2() |&gt; \n  ggsurvfit()\n\n\n\n\n\n\n\n\n42.4.4 Sélection pas à pas d’un modèle réduit\nPour réduire le modèle (voir Chapitre 23), il est possible d’utiliser la fonction step().\n\nmod |&gt; step()\n\nStart:  AIC=1002.04\nSurv(ttdeath, death) ~ stage + trt + age\n\n\nError in drop1.default(fit, scope$drop, scale = scale, trace = trace, : le nombre de lignes utilisées a changé : supprimer les valeurs manquantes ?\n\n\nDans notre exemple, nous rencontrons une erreur liée à des valeurs manquantes pour l’une des variables explicatives. Comme abordé précédemment (cf. Section 23.8), nous pouvons avoir recours à la fonction step_with_na() de notre cru.\n\nstep_with_na &lt;- function(model,\n                         full_data = eval(model$call$data),\n                         ...) {\n  # data with no NAs\n  if (is.null(full_data)) {\n    ...data_no_na &lt;- model.frame(model)\n  } else {\n    ...data_no_na &lt;- get_all_vars(model, data = full_data) |&gt; na.omit()\n  }\n  \n  # assign ...data_no_na in parent.frame()\n  assign(\"...data_no_na\", ...data_no_na, envir = parent.frame())\n  \n  # refit the model without NAs\n  model_no_na &lt;- update(\n    model,\n    formula = terms(model),\n    data = ...data_no_na\n  )\n  \n  # apply step()\n  model_simplified &lt;- step(model_no_na, ...)\n  \n  # recompute simplified model using full data\n  if (is.null(full_data)) {\n    update(\n      model,\n      formula = terms(model_simplified)\n    )\n  } else {\n    update(\n      model,\n      formula = terms(model_simplified),\n      data = full_data\n    )\n  }\n}\n\nIl y a néanmoins une petite subtilité pour l’utiliser ici. En effet, elle a besoin de pouvoir reconstruire notre outcome qui est ici une variable composée créée avec Surv(). Deux possibilités. La première consiste à transmettre à step_with_na() le jeu de données complet.\n\nmod |&gt; step_with_na(full_data = trial)\n\nStart:  AIC=1002.04\nSurv(ttdeath, death) ~ stage + trt + age\n\n        Df    AIC\n&lt;none&gt;     1002.0\n- age    1 1002.1\n- trt    1 1002.5\n- stage  3 1011.2\n\n\nCall:\ncoxph(formula = Surv(ttdeath, death) ~ stage + trt + age, data = full_data)\n\n              coef exp(coef) se(coef)     z        p\nstageT2   0.268596  1.308126 0.287412 0.935 0.350028\nstageT3   0.164980  1.179370 0.309897 0.532 0.594468\nstageT4   1.000324  2.719163 0.276830 3.614 0.000302\ntrtDrug B 0.312336  1.366614 0.199005 1.569 0.116535\nage       0.010305  1.010358 0.007154 1.440 0.149753\n\nLikelihood ratio test=17.98  on 5 df, p=0.002975\nn= 189, number of events= 103 \n   (11 observations effacées parce que manquantes)\n\n\nLa seconde consiste à créer notre outcome en amont du calcul du modèle.\n\ntrial &lt;- trial |&gt; \n  mutate(survie = Surv(ttdeath, death))\nmod2 &lt;- coxph(\n  survie ~ stage + trt + age,\n  data = trial\n)\nmod2 |&gt; step_with_na()\n\nStart:  AIC=1002.04\nsurvie ~ stage + trt + age\n\n        Df    AIC\n&lt;none&gt;     1002.0\n- age    1 1002.1\n- trt    1 1002.5\n- stage  3 1011.2\n\n\nCall:\ncoxph(formula = survie ~ stage + trt + age, data = full_data)\n\n              coef exp(coef) se(coef)     z        p\nstageT2   0.268596  1.308126 0.287412 0.935 0.350028\nstageT3   0.164980  1.179370 0.309897 0.532 0.594468\nstageT4   1.000324  2.719163 0.276830 3.614 0.000302\ntrtDrug B 0.312336  1.366614 0.199005 1.569 0.116535\nage       0.010305  1.010358 0.007154 1.440 0.149753\n\nLikelihood ratio test=17.98  on 5 df, p=0.002975\nn= 189, number of events= 103 \n   (11 observations effacées parce que manquantes)\n\n\n\n42.4.5 Modèles de Cox univariables\nComme déjà abordé dans le chapitre sur la régression logistique binaire, il est possible d’effectuer en une fois plusieurs modèles univariables avec gtsummary::tbl_uvregression() (cf. Section 22.9).\n\ntrial |&gt; \n  tbl_uvregression(\n    method = coxph,\n    y = Surv(ttdeath, death),\n    include = c(stage, trt, age),\n    exponentiate = TRUE\n  ) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\nN\n\nHR\n1\n\n\n95% IC\n1\n\np-valeur\n\n\n\nT Stage\n200\n\n\n\n\n\n    T1\n\n—\n—\n\n\n\n    T2\n\n1,18\n0,68 – 2,04\n0,6\n\n\n    T3\n\n1,23\n0,69 – 2,20\n0,5\n\n\n    T4\n\n2,48\n1,49 – 4,14\n&lt;0,001\n\n\nChemotherapy Treatment\n200\n\n\n\n\n\n    Drug A\n\n—\n—\n\n\n\n    Drug B\n\n1,25\n0,86 – 1,81\n0,2\n\n\nAge\n189\n1,01\n0,99 – 1,02\n0,3\n\n\n\n\n1\nHR = rapport de risques instantanés, IC = intervalle de confiance",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Analyse de survie</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/analyse-survie.html#analyse-de-survie-pondérée",
    "href": "analyses_avancees/analyse-survie.html#analyse-de-survie-pondérée",
    "title": "42  Analyse de survie",
    "section": "\n42.5 Analyse de survie pondérée",
    "text": "42.5 Analyse de survie pondérée\nLorsque l’on travaille avec des données pondérées et un plan d’échantillonnage complexe, le plus pertinent est d’avoir recours au package survey (cf. Chapitre 28) qui propose des fonctions adaptées à l’analyse de survie.\nPour l’exemple, nous allons transformer le jeu de données en objet survey en indiquant simplement des poids uniformes égaux à 1.\n\nlibrary(survey)\n\nLe chargement a nécessité le package : grid\n\n\nLe chargement a nécessité le package : Matrix\n\n\n\nAttachement du package : 'survey'\n\n\nL'objet suivant est masqué depuis 'package:graphics':\n\n    dotchart\n\nstrial &lt;- svydesign(~ 1, data = trial)\n\nWarning in svydesign.default(~1, data = trial): No weights or probabilities\nsupplied, assuming equal probability\n\n\nPour le calcul d’une courbe de Kaplan-Meier, nous allons utiliser la fonction survey::svykm(). Il est préférable de préciser se = TRUE pour que les erreurs standards soient calculées, ce qui permettra plus tard de récupérer les intervalles de confiance.\n\nskm &lt;- svykm(\n  Surv(ttdeath, death) ~ 1,\n  design = strial,\n  se = TRUE\n)\nskm_trt &lt;- svykm(\n  Surv(ttdeath, death) ~ trt,\n  design = strial,\n  se = TRUE\n)\n\nMalheureusement, ggsurvfit::ggsurvfit() et gtsummary::tbl_survfit() ne sont pas (encore ?) compatibles avec les courbes de survies créées avec survey::svykm(). On devra donc avoir recours aux fonctions de bases.\nPour un graphique avec affichage des intervalles de confiance :\n\nskm |&gt;  plot(ci = TRUE)\n\n\n\n\n\n\n\n\nskm_trt |&gt; plot(\n  ci = TRUE,\n  pars = list(\n    col = c(\"red\", \"blue\")\n  ),\n  lwd = 2\n)\n\n\n\n\n\n\n\nOn pourra aussi avoir recours au package jskm et sa fonction homonyme jskm:jskm().\n\nlibrary(jskm)\nskm_trt |&gt; svyjskm()\n\n\n\n\n\n\n\n\nskm_trt |&gt; \n  svyjskm(\n    pval = TRUE,\n    xlabs = \"Mois depuis le diagnostic\",\n    ylabs = \"Probabilité de survie\",\n    surv.scale = \"percent\",\n    ci = TRUE,\n    table = TRUE,\n    label.nrisk = \"Personnes à risque\"\n  )\n\n\n\n\n\n\n\nPour récupérer la durée à laquelle certains quantiles sont atteints :\n\nskm |&gt;\n  quantile(\n    probs = c(1, .75, .5),\n    ci = TRUE\n  )\n\n    1  0.75   0.5 \n 3.53 16.07 22.41 \nattr(,\"ci\")\n     0.025 0.975\n1     3.53  7.27\n0.75 14.54 17.45\n0.5  20.62   Inf\n\n\nOn ne peut pas facilement accéder aux valeurs de la courbe de survie à certains points de temps. Mais la fonction suivante permets de la faire aisément. Il faut lui passer, via times, une liste de points de temps.\n\nsvykm_time_values &lt;- function(x, times, ci_level = .95) {\n  idx &lt;- sapply(\n    times,\n    function(t) max(which(x$time &lt;= t))\n  )\n  ci &lt;- confint(x, parm = times, level = ci_level)\n  dplyr::tibble(\n    time = times,\n    estimate = x$surv[idx],\n    conf.low = ci[, 1],\n    conf.high = ci[, 2]\n  )\n}\n\n\nskm |&gt; svykm_time_values(c(5, 10, 15, 20))\n\n# A tibble: 4 × 4\n   time estimate conf.low conf.high\n  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1     5    0.995    0.985     1    \n2    10    0.945    0.914     0.977\n3    15    0.791    0.736     0.849\n4    20    0.581    0.517     0.653\n\n\nPour le modèle de Cox, on aura recours à la fonction survey::svycoxph().\n\nmods &lt;- svycoxph(\n  Surv(ttdeath, death) ~ stage + trt + age,\n  design = strial\n)\n\nCette fois-ci, il est possible d’utiliser gtsummary::tbl_regression() ou ggstats::ggcoef_model() sans problème.\n\nmods |&gt; \n  tbl_regression(exponentiate = TRUE) |&gt; \n  bold_labels()\n\nIndependent Sampling design (with replacement)\nsvydesign(~1, data = trial)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nHR\n1\n\n\n95% IC\n1\n\np-valeur\n\n\n\nstage\n\n\n\n\n\n    T1\n—\n—\n\n\n\n    T2\n1,31\n0,75 – 2,28\n0,3\n\n\n    T3\n1,18\n0,64 – 2,19\n0,6\n\n\n    T4\n2,72\n1,60 – 4,63\n&lt;0,001\n\n\ntrt\n\n\n\n\n\n    Drug A\n—\n—\n\n\n\n    Drug B\n1,37\n0,93 – 2,01\n0,11\n\n\nage\n1,01\n1,00 – 1,03\n0,2\n\n\n\n\n1\nHR = rapport de risques instantanés, IC = intervalle de confiance\n\n\n\n\n\n\n\nEnfin, pour le test de l’hypothèse de proportionnalité des risques, on peut utiliser comme précédemment la fonction cox.zph().\n\nmods |&gt; cox.zph()\n\n          chisq df    p\nstage  0.004915  3 1.00\ntrt    0.009315  1 0.92\nage    0.000796  1 0.98\nGLOBAL 0.014845  5 1.00",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Analyse de survie</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/analyse-survie.html#webin-r",
    "href": "analyses_avancees/analyse-survie.html#webin-r",
    "title": "42  Analyse de survie",
    "section": "\n42.6 webin-R",
    "text": "42.6 webin-R\nL’analyse de survie est présentée sur YouTube dans le webin-R #15 (Analyse de survie).",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Analyse de survie</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/analyse-survie.html#lectures-complémentaires",
    "href": "analyses_avancees/analyse-survie.html#lectures-complémentaires",
    "title": "42  Analyse de survie",
    "section": "\n42.7 Lectures complémentaires",
    "text": "42.7 Lectures complémentaires\n\nIntroduction à l’analyse de survie, courbe de Kaplan-Meier et Introduction au modèle à risque proportionnel de Cox sur la chaîne YouTube “EpiMed Open Course”.\nIntroduction à l’analyse des durée de survie par Philippe Saint Pierre de l’université de Toulouse (cours assez technique avec formalisme mathématique)\nLes cours du Master 2 : Modélisation en pharmacologie clinique et épidémiologique de l’université de Nantes qui abordent des modèles plus complexes (modèles à risques compétitifs, modèles de fragilité, modèles additifs, variables dépendantes du temps, modèles mixtes…) avec des illustrations sous R.",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Analyse de survie</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/regression-logistique-multinomiale.html",
    "href": "analyses_avancees/regression-logistique-multinomiale.html",
    "title": "43  Régression logistique multinomiale",
    "section": "",
    "text": "43.1 Données d’illustration\nPour illustrer la régression logistique multinomiale, nous allons reprendre le jeu de données hdv2003 du package questionr et portant sur l’enquête histoires de vie 2003 de l’Insee.\nlibrary(tidyverse)\nlibrary(labelled)\ndata(\"hdv2003\", package = \"questionr\")\nd &lt;- hdv2003\nNous allons considérer comme variable d’intérêt la variable trav.satisf, à savoir la satisfaction ou l’insatisfaction au travail.\nquestionr::freq(d$trav.satisf)\n\n                 n    % val%\nSatisfaction   480 24.0 45.8\nInsatisfaction 117  5.9 11.2\nEquilibre      451 22.6 43.0\nNA             952 47.6   NA\nNous allons choisir comme modalité de référence la position intermédiaire, à savoir l’« équilibre », que nous allons donc définir comme la première modalité du facteur.\nd$trav.satisf &lt;- d$trav.satisf |&gt; fct_relevel(\"Equilibre\")\nNous allons aussi en profiter pour raccourcir les étiquettes de la variable trav.imp :\nlevels(d$trav.imp) &lt;- c(\"Le plus\", \"Aussi\", \"Moins\", \"Peu\")\nEnfin, procédons à quelques recodages additionnels :\nd &lt;- d |&gt; \n  mutate(\n    sexe = sexe |&gt; fct_relevel(\"Femme\"),\n    groupe_ages = age |&gt;\n      cut(\n        c(18, 25, 45, 99),\n        right = FALSE,\n        include.lowest = TRUE,\n        labels = c(\"18-24 ans\", \"25-44 ans\",\n                   \"45 et plus\")\n      ),\n    etudes = nivetud |&gt; \n      fct_recode(\n        \"Primaire\" = \"N'a jamais fait d'etudes\",\n        \"Primaire\" = \"A arrete ses etudes, avant la derniere annee d'etudes primaires\",\n        \"Primaire\" = \"Derniere annee d'etudes primaires\",\n        \"Secondaire\" = \"1er cycle\",\n        \"Secondaire\" = \"2eme cycle\",\n        \"Technique / Professionnel\" = \"Enseignement technique ou professionnel court\",\n        \"Technique / Professionnel\" = \"Enseignement technique ou professionnel long\",\n        \"Supérieur\" = \"Enseignement superieur y compris technique superieur\"\n    ) |&gt; \n    fct_na_value_to_level(\"Non documenté\")  \n  ) |&gt; \n  set_variable_labels(\n    trav.satisf = \"Satisfaction dans le travail\",\n    sexe = \"Sexe\",\n    groupe_ages = \"Groupe d'âges\",\n    etudes = \"Niveau d'études\",\n    trav.imp = \"Importance accordée au travail\"\n  )",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Régression logistique multinomiale</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/regression-logistique-multinomiale.html#calcul-du-modèle-multinomial",
    "href": "analyses_avancees/regression-logistique-multinomiale.html#calcul-du-modèle-multinomial",
    "title": "43  Régression logistique multinomiale",
    "section": "\n43.2 Calcul du modèle multinomial",
    "text": "43.2 Calcul du modèle multinomial\nPour calculer un modèle logistique multinomial, nous allons utiliser la fonction nnet::multinom() de l’extension nnet1. La syntaxe de nnet::multinom() est similaire à celle de glm(), le paramètre family en moins.\n1 Il existe plusieurs alternatives possibles : la fonction VGAM::vglm() avec family = VGAM::multinomial ou encore mlogit::mlogit(). Ces deux fonctions sont un peu plus complexes à mettre en œuvre. On se référera à la documentation de chaque package. Le support des modèles mlogit() et vglm() est aussi plus limité dans d’autres packages tels que broom.helpers, gtsummary, ggstats ou encore marginaleffects.\nreg &lt;- nnet::multinom(\n  trav.satisf ~ sexe + etudes + groupe_ages + trav.imp,\n  data = d\n)\n\n# weights:  36 (22 variable)\ninitial  value 1151.345679 \niter  10 value 977.985279\niter  20 value 971.187398\nfinal  value 971.113280 \nconverged\n\n\n\n\n\nComme pour la régression logistique binaire, il est possible de réaliser une sélection pas à pas descendante (cf. Chapitre 23) :\n\nreg2 &lt;- reg |&gt; step()\n\n\n\ntrying - sexe \ntrying - etudes \ntrying - groupe_ages \ntrying - trav.imp \ntrying - sexe \ntrying - etudes \ntrying - trav.imp \ntrying - etudes \ntrying - trav.imp",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Régression logistique multinomiale</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/regression-logistique-multinomiale.html#affichage-des-résultats-du-modèle",
    "href": "analyses_avancees/regression-logistique-multinomiale.html#affichage-des-résultats-du-modèle",
    "title": "43  Régression logistique multinomiale",
    "section": "\n43.3 Affichage des résultats du modèle",
    "text": "43.3 Affichage des résultats du modèle\nUne des particularités de la régression logistique multinomiale est qu’elle produit une série de coefficients pour chaque modalité de la variable d’intérêt (sauf la modalité de référence). Ici, nous aurons donc une série de coefficients pour celles et ceux qui sont satisfaits au travail (comparés à la modalité Équilibre) et une série de coefficients pour celles et ceux qui sont insatisfaits (comparés aux aussi à la modalité Équilibre).\nLa fonction gtsummary::tbl_regression() peut gérer ce type de modèles, et va afficher les deux séries de coefficients l’une au-dessus de l’autre. Nous allons indiquer exponentiate = TRUE car, comme pour la régression logistique binaire, l’exponentielle des coefficients peut s’interpréter comme des odds ratios.\n\nlibrary(gtsummary)\ntheme_gtsummary_language(\"fr\", decimal.mark = \",\")\n\n\ntbl &lt;- reg2 |&gt; \n  tbl_regression(exponentiate = TRUE)\n\nℹ Multinomial models have a different underlying structure than the models\n  gtsummary was designed for.\n• Functions designed to work with `tbl_regression()` objects may yield\n  unexpected results.\n\ntbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nOR\n1\n\n\n95% IC\n1\n\np-valeur\n\n\n\nSatisfaction\n\n\nNiveau d'études\n\n\n\n\n\n    Primaire\n—\n—\n\n\n\n    Secondaire\n1,05\n0,63 – 1,76\n0,9\n\n\n    Technique / Professionnel\n1,08\n0,67 – 1,73\n0,7\n\n\n    Supérieur\n2,01\n1,24 – 3,27\n0,005\n\n\n    Non documenté\n0,58\n0,18 – 1,86\n0,4\n\n\nImportance accordée au travail\n\n\n\n\n\n    Le plus\n—\n—\n\n\n\n    Aussi\n1,29\n0,56 – 2,98\n0,5\n\n\n    Moins\n0,84\n0,37 – 1,88\n0,7\n\n\n    Peu\n0,55\n0,18 – 1,64\n0,3\n\n\nInsatisfaction\n\n\nNiveau d'études\n\n\n\n\n\n    Primaire\n—\n—\n\n\n\n    Secondaire\n0,91\n0,41 – 1,99\n0,8\n\n\n    Technique / Professionnel\n1,09\n0,54 – 2,19\n0,8\n\n\n    Supérieur\n1,08\n0,51 – 2,29\n0,8\n\n\n    Non documenté\n0,96\n0,18 – 4,97\n&gt;0,9\n\n\nImportance accordée au travail\n\n\n\n\n\n    Le plus\n—\n—\n\n\n\n    Aussi\n0,80\n0,24 – 2,69\n0,7\n\n\n    Moins\n0,59\n0,18 – 1,88\n0,4\n\n\n    Peu\n3,82\n1,05 – 13,9\n0,042\n\n\n\n\n1\nOR = rapport de cotes, IC = intervalle de confiance\n\n\n\n\n\n\n\n\nTable 43.1: Tableau des odds ratio de la régression logistique multinomiale\n\n\n\nL’odds ratio du niveau d’étude supérieur pour la modalité satisfaction est de 2,01, indiquant que les personnes ayant un niveau d’étude supérieur ont plus de chances d’être satisfait au travail que d’être à l’équilibre que les personnes de niveau primaire. Par contre, l’OR est de seulement 1,08 (et non significatif) pour la modalité Insatisfait indiquant que ces personnes n’ont ni plus ni moins de chance d’être insatisfaite que d’être à l’équilibre.\nOn notera au passage un message d’avertissement de gtsummary sur le fait que les modèles multinomiaux n’ont pas la même structure que d’autres modèles et donc que certaines fonctionnalités ne sont pas disponibles. C’est le cas par exemple de gtsummary::add_global_p() pour le calcul des p-valeurs globales des variables. Pour tester l’effet globale d’une variable dans le modèle, on aura directement recours à car::Anova().\n\nreg2 |&gt; car::Anova()\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: trav.satisf\n         LR Chisq Df Pr(&gt;Chisq)    \netudes     24.211  8   0.002112 ** \ntrav.imp   48.934  6  7.687e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nAstuce\n\n\n\nLa fonction gtsummary::tbl_regression() affiche le tableau des coefficients dans un format long. Or, il est souvent plus lisible de présenter les coefficients dans un format large, avec les coefficients pour chaque modalité côte à côte.\nCela n’est pas possible nativement avec gtsummary mais on pourra éventuellement utiliser la fonction multinom_pivot_wider() proposée sur GitHub Gist. Voici son code à recopier dans son script.\n\nmultinom_pivot_wider &lt;- function(x) {\n  # check inputs match expectatations\n  if (!inherits(x, \"tbl_regression\") || !inherits(x$inputs$x, \"multinom\")) {\n    stop(\"`x=` must be class 'tbl_regression' summary of a `nnet::multinom()` model.\")\n  }\n  \n  # create tibble of results\n  df &lt;- tibble::tibble(outcome_level = unique(x$table_body$groupname_col))\n  df$tbl &lt;- \n    purrr::map(\n      df$outcome_level,\n      function(lvl) {\n        gtsummary::modify_table_body(\n          x, \n          ~dplyr::filter(.x, .data$groupname_col %in% lvl) %&gt;%\n            dplyr::ungroup() %&gt;%\n            dplyr::select(-.data$groupname_col)\n        )\n      }\n    )\n  \n  tbl_merge(df$tbl, tab_spanner = paste0(\"**\", df$outcome_level, \"**\"))\n}\n\nIl ne reste plus qu’à l’appliquer au tableau généré avec gtsummary::tbl_regression(). Attention : cette fonction n’est compatible qu’avec les modèles nnet::multinom().\n\ntbl |&gt; multinom_pivot_wider()\n\nWarning: Use of .data in tidyselect expressions was deprecated in tidyselect 1.2.0.\nℹ Please use `\"groupname_col\"` instead of `.data$groupname_col`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\n\nSatisfaction\n\n\n\nInsatisfaction\n\n\n\n\nOR\n1\n\n\n95% IC\n1\n\np-valeur\n\nOR\n1\n\n\n95% IC\n1\n\np-valeur\n\n\n\n\nNiveau d'études\n\n\n\n\n\n\n\n\n    Primaire\n—\n—\n\n—\n—\n\n\n\n    Secondaire\n1,05\n0,63 – 1,76\n0,9\n0,91\n0,41 – 1,99\n0,8\n\n\n    Technique / Professionnel\n1,08\n0,67 – 1,73\n0,7\n1,09\n0,54 – 2,19\n0,8\n\n\n    Supérieur\n2,01\n1,24 – 3,27\n0,005\n1,08\n0,51 – 2,29\n0,8\n\n\n    Non documenté\n0,58\n0,18 – 1,86\n0,4\n0,96\n0,18 – 4,97\n&gt;0,9\n\n\nImportance accordée au travail\n\n\n\n\n\n\n\n\n    Le plus\n—\n—\n\n—\n—\n\n\n\n    Aussi\n1,29\n0,56 – 2,98\n0,5\n0,80\n0,24 – 2,69\n0,7\n\n\n    Moins\n0,84\n0,37 – 1,88\n0,7\n0,59\n0,18 – 1,88\n0,4\n\n\n    Peu\n0,55\n0,18 – 1,64\n0,3\n3,82\n1,05 – 13,9\n0,042\n\n\n\n\n1\nOR = rapport de cotes, IC = intervalle de confiance\n\n\n\n\n\n\n\n\n\nPour un graphique des coefficients, on ne peut appeler directement ggstats::gcoef_model() en raison de la structure différente du modèle. Heureusement, ggstats propose une fonction spécifique ggstats::ggcoef_multinom() avec trois types de visualisation.\n\nreg2 |&gt; \n  ggstats::ggcoef_multinom(\n    exponentiate = TRUE\n  )\n\n\n\n\n\n\nFigure 43.1: Graphique des coefficients du modèle multinomial (type “dodged”)\n\n\n\n\n\nreg2 |&gt; \n  ggstats::ggcoef_multinom(\n    type = \"faceted\",\n    exponentiate = TRUE\n  )\n\n\n\n\n\n\nFigure 43.2: Graphique des coefficients du modèle multinomial (type “faceted”)\n\n\n\n\n\nreg2 |&gt; \n  ggstats::ggcoef_multinom(\n    type = \"table\",\n    exponentiate = TRUE\n  )\n\n\n\n\n\n\nFigure 43.3: Graphique des coefficients du modèle multinomial (type “table”)\n\n\n\n\nPour faciliter l’interprétation, on pourra représenter les prédictions marginales du modèle (cf. Chapitre 24) avec broom.helpers::plot_marginal_predictions().\n\nreg2 |&gt; \n  broom.helpers::plot_marginal_predictions() |&gt; \n  patchwork::wrap_plots(ncol = 1) &\n  scale_y_continuous(labels = scales::percent, limits = c(0, .8)) &\n  coord_flip()\n\n\n\n\n\n\nFigure 43.4: Prédictions marginales du modèle multinomial\n\n\n\n\n\n\n\n\n\n\nAstuce\n\n\n\nDans certaines situations, il peut être plus simple de réaliser plusieurs modèles logistiques binaires séparés plutôt qu’une régression multinomiale. Si la variable à expliquer a trois niveaux (A, B et C), on pourra réaliser un modèle binaire B vs A, et un modèle binaire C vs A. Cette approche est appelée approximation de Begg et Gray. On trouvera, en anglais, plus d’explications et des références bibliographiques sur StackOverflow.",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Régression logistique multinomiale</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/regression-logistique-multinomiale.html#données-pondérées",
    "href": "analyses_avancees/regression-logistique-multinomiale.html#données-pondérées",
    "title": "43  Régression logistique multinomiale",
    "section": "\n43.4 Données pondérées",
    "text": "43.4 Données pondérées\nL’extension survey (cf. Chapitre 28) ne fournit pas de fonction adaptée aux régressions multinomiales. Cependant, il est possible d’en réaliser une en ayant recours à des poids de réplication, comme suggéré par Thomas Lumley dans son ouvrage Complex Surveys: A Guide to Analysis Using R. Thomas Lumley est par ailleurs l’auteur de l’extension survey.\n\n43.4.1 avec svrepmisc::svymultinom()\n\nL’extension svrepmisc disponible sur GitHub fournit quelques fonctions facilitant l’utilisation des poids de réplication avec survey. Pour l’installer, on utilisera le code ci-dessous :\n\nremotes::install_github(\"carlganz/svrepmisc\")\n\nEn premier lieu, il faut définir le design de notre tableau de données puis calculer des poids de réplication.\n\nlibrary(survey)\nlibrary(srvyr)\ndw_rep &lt;- d |&gt;\n  as_survey(weights = poids) |&gt; \n  as_survey_rep(type = \"bootstrap\", replicates = 25)\n\nIl faut prévoir un nombre de replicates suffisant pour calculer ultérieurement les intervalles de confiance des coefficients. Plus ce nombre est élevé, plus précise sera l’estimation de la variance et donc des valeurs p et des intervalles de confiance. Cependant, plus ce nombre est élevé, plus le temps de calcul sera important. Pour gagner en temps de calcul, nous avons ici pris une valeur de 25, mais l’usage est de considérer au moins 1000 réplications.\nsvrepmisc fournit une fonction svrepmisc::svymultinom() pour le calcul d’une régression multinomiale avec des poids de réplication.\n\nlibrary(svrepmisc)\nregm &lt;- svymultinom(\n  trav.satisf ~ sexe + etudes + trav.imp,\n  design = dw_rep\n)\n\nsvrepmisc fournit également des méthodes svrepmisc::confint() et svrepmisc::tidy(). Nous pouvons donc calculer et afficher les odds ratio et leur intervalle de confiance.\n\nregm\n\n                                               Coefficient        SE t value\nSatisfaction.(Intercept)                         -0.116149  0.657889 -0.1765\nInsatisfaction.(Intercept)                       -1.547056  2.525954 -0.6125\nSatisfaction.sexeHomme                           -0.041405  0.151303 -0.2737\nInsatisfaction.sexeHomme                          0.221849  0.197419  1.1237\nSatisfaction.etudesSecondaire                     0.115722  0.223931  0.5168\nInsatisfaction.etudesSecondaire                   0.418476  0.728313  0.5746\nSatisfaction.etudesTechnique / Professionnel      0.220702  0.269653  0.8185\nInsatisfaction.etudesTechnique / Professionnel    0.529317  0.754102  0.7019\nSatisfaction.etudesSupérieur                      0.905852  0.287358  3.1524\nInsatisfaction.etudesSupérieur                    0.584499  0.715263  0.8172\nSatisfaction.etudesNon documenté                 -0.323293  1.809497 -0.1787\nInsatisfaction.etudesNon documenté                0.646168  4.349925  0.1485\nSatisfaction.trav.impAussi                       -0.027506  0.635968 -0.0433\nInsatisfaction.trav.impAussi                     -0.375642  2.262333 -0.1660\nSatisfaction.trav.impMoins                       -0.220703  0.591217 -0.3733\nInsatisfaction.trav.impMoins                     -0.694337  2.436413 -0.2850\nSatisfaction.trav.impPeu                         -0.069034  0.785088 -0.0879\nInsatisfaction.trav.impPeu                        1.584747  2.405920  0.6587\n                                               Pr(&gt;|t|)  \nSatisfaction.(Intercept)                         0.8649  \nInsatisfaction.(Intercept)                       0.5596  \nSatisfaction.sexeHomme                           0.7922  \nInsatisfaction.sexeHomme                         0.2982  \nSatisfaction.etudesSecondaire                    0.6212  \nInsatisfaction.etudesSecondaire                  0.5836  \nSatisfaction.etudesTechnique / Professionnel     0.4401  \nInsatisfaction.etudesTechnique / Professionnel   0.5054  \nSatisfaction.etudesSupérieur                     0.0161 *\nInsatisfaction.etudesSupérieur                   0.4407  \nSatisfaction.etudesNon documenté                 0.8633  \nInsatisfaction.etudesNon documenté               0.8861  \nSatisfaction.trav.impAussi                       0.9667  \nInsatisfaction.trav.impAussi                     0.8728  \nSatisfaction.trav.impMoins                       0.7200  \nInsatisfaction.trav.impMoins                     0.7839  \nSatisfaction.trav.impPeu                         0.9324  \nInsatisfaction.trav.impPeu                       0.5312  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nregm |&gt; confint()\n\n                                                    2.5 %     97.5 %\nSatisfaction.(Intercept)                       -1.6718106  1.4395121\nInsatisfaction.(Intercept)                     -7.5199876  4.4258748\nSatisfaction.sexeHomme                         -0.3991809  0.3163701\nInsatisfaction.sexeHomme                       -0.2449732  0.6886710\nSatisfaction.etudesSecondaire                  -0.4137898  0.6452346\nInsatisfaction.etudesSecondaire                -1.3037102  2.1406629\nSatisfaction.etudesTechnique / Professionnel   -0.4169250  0.8583298\nInsatisfaction.etudesTechnique / Professionnel -1.2538512  2.3124860\nSatisfaction.etudesSupérieur                    0.2263595  1.5853447\nInsatisfaction.etudesSupérieur                 -1.1068297  2.2758285\nSatisfaction.etudesNon documenté               -4.6020747  3.9554879\nInsatisfaction.etudesNon documenté             -9.6397715 10.9321069\nSatisfaction.trav.impAussi                     -1.5313324  1.4763202\nInsatisfaction.trav.impAussi                   -5.7252095  4.9739259\nSatisfaction.trav.impMoins                     -1.6187085  1.1773016\nInsatisfaction.trav.impMoins                   -6.4555389  5.0668650\nSatisfaction.trav.impPeu                       -1.9254717  1.7874030\nInsatisfaction.trav.impPeu                     -4.1043499  7.2738443\n\nregm |&gt;\n  broom::tidy(exponentiate = TRUE, conf.int = TRUE)\n\n                                             term  estimate std.error\n1                      Insatisfaction.(Intercept) 0.2128737 2.5259536\n2              Insatisfaction.etudesNon documenté 1.9082140 4.3499254\n3                 Insatisfaction.etudesSecondaire 1.5196444 0.7283130\n4                  Insatisfaction.etudesSupérieur 1.7940926 0.7152634\n5  Insatisfaction.etudesTechnique / Professionnel 1.6977731 0.7541023\n6                        Insatisfaction.sexeHomme 1.2483828 0.1974192\n7                    Insatisfaction.trav.impAussi 0.6868483 2.2623331\n8                    Insatisfaction.trav.impMoins 0.4994055 2.4364133\n9                      Insatisfaction.trav.impPeu 4.8780580 2.4059201\n10                       Satisfaction.(Intercept) 0.8903423 0.6578894\n11               Satisfaction.etudesNon documenté 0.7237615 1.8094974\n12                  Satisfaction.etudesSecondaire 1.1226842 0.2239308\n13                   Satisfaction.etudesSupérieur 2.4740390 0.2873575\n14   Satisfaction.etudesTechnique / Professionnel 1.2469523 0.2696527\n15                         Satisfaction.sexeHomme 0.9594401 0.1513033\n16                     Satisfaction.trav.impAussi 0.9728687 0.6359684\n17                     Satisfaction.trav.impMoins 0.8019545 0.5912166\n18                       Satisfaction.trav.impPeu 0.9332946 0.7850877\n     statistic    p.value     conf.low    conf.high\n1  -0.61246429 0.55959264 5.421393e-04    83.585899\n2   0.14854686 0.88609994 6.508793e-05 55944.026794\n3   0.57458315 0.58355864 2.715225e-01     8.505074\n4   0.81718065 0.44074721 3.306054e-01     9.735981\n5   0.70191727 0.50539212 2.854035e-01    10.099501\n6   1.12374565 0.29817640 7.827255e-01     1.991068\n7  -0.16604178 0.87281811 3.262670e-03   144.593434\n8  -0.28498324 0.78390420 1.571792e-03   158.676091\n9   0.65868653 0.53115785 1.650074e-02  1442.083604\n10 -0.17654827 0.86486257 1.879065e-01     4.218637\n11 -0.17866475 0.86326196 1.003100e-02    52.221168\n12  0.51677751 0.62123286 6.611399e-01     1.906434\n13  3.15235183 0.01609914 1.254026e+00     4.880973\n14  0.81846909 0.44005853 6.590704e-01     2.359217\n15 -0.27365839 0.79224593 6.708693e-01     1.372138\n16 -0.04325077 0.96670950 2.162473e-01     4.376810\n17 -0.37330388 0.71997060 1.981545e-01     3.245604\n18 -0.08793203 0.93239339 1.458070e-01     5.973918\n\n\nPar contre, le support de gtsummary::tbl_regression() et ggstats::ggcoef_model() est plus limité. Vous pourrez afficher un tableau basique des résultats et un graphiques des coefficients, mais sans les enrichissements usuels (identification des variables, étiquettes propres, identification des niveaux, etc.).\n\n43.4.2 avec svyVGAM::svy_glm()\n\nUne alternative possible pour le calcul de la régression logistique multinomiale avec des données pondérées est svyVGAM::svy_vglm() avec family = VGAM::multinomial.\nNous allons commencer par définir le plan d’échantillonnage.\n\nlibrary(survey)\nlibrary(srvyr)\ndw &lt;- d |&gt;\n  as_survey(weights = poids)\n\nPuis, on appelle svyVGAM::svy_vglm() en précisant family = VGAM::multinomial. Par défaut, VGAM::multinomial() utilise la dernière modalité de la variable d’intérêt comme modalité de référence. Cela est modifiable avec refLevel.\n\nregm2 &lt;- svyVGAM::svy_vglm(\n  trav.satisf ~ sexe + etudes + trav.imp,\n  family = VGAM::multinomial(refLevel = \"Equilibre\"),\n  design = dw\n)\nregm2 |&gt; summary()\n\nsvy_vglm.survey.design(trav.satisf ~ sexe + etudes + trav.imp, \n    family = VGAM::multinomial(refLevel = \"Equilibre\"), design = dw)\nIndependent Sampling design (with replacement)\nCalled via srvyr\nSampling variables:\n  - ids: `1` \n  - weights: poids \nData variables: \n  - id (int), age (int), sexe (fct), nivetud (fct), poids (dbl), occup (fct),\n    qualif (fct), freres.soeurs (int), clso (fct), relig (fct), trav.imp (fct),\n    trav.satisf (fct), hard.rock (fct), lecture.bd (fct), peche.chasse (fct),\n    cuisine (fct), bricol (fct), cinema (fct), sport (fct), heures.tv (dbl),\n    groupe_ages (fct), etudes (fct)\n                                       Coef        SE       z        p\n(Intercept):1                     -0.116117  0.553242 -0.2099 0.833757\n(Intercept):2                     -1.547693  0.876195 -1.7664 0.077332\nsexeHomme:1                       -0.041412  0.171351 -0.2417 0.809029\nsexeHomme:2                        0.221930  0.272669  0.8139 0.415693\netudesSecondaire:1                 0.115688  0.341830  0.3384 0.735034\netudesSecondaire:2                 0.418102  0.563205  0.7424 0.457868\netudesTechnique / Professionnel:1  0.220662  0.310123  0.7115 0.476754\netudesTechnique / Professionnel:2  0.529020  0.501080  1.0558 0.291079\netudesSupérieur:1                  0.905798  0.314513  2.8800 0.003977\netudesSupérieur:2                  0.584320  0.525633  1.1116 0.266289\netudesNon documenté:1             -0.323271  0.662511 -0.4879 0.625587\netudesNon documenté:2              0.646195  0.939745  0.6876 0.491687\ntrav.impAussi:1                   -0.027517  0.511636 -0.0538 0.957109\ntrav.impAussi:2                   -0.374881  0.825214 -0.4543 0.649625\ntrav.impMoins:1                   -0.220706  0.494951 -0.4459 0.655659\ntrav.impMoins:2                   -0.693571  0.792031 -0.8757 0.381200\ntrav.impPeu:1                     -0.069004  0.706959 -0.0976 0.922244\ntrav.impPeu:2                      1.585521  0.866529  1.8297 0.067289\n\n\nLà encore, le support de gtsummary::tbl_regression() et ggstats::ggcoef_model() sera limité (seulement des résultats bruts). Pour calculer les odds ratios avec leurs intervalles de confiance, on pourra avoir recours à broom.helpers::tidy_parameters().\n\nregm2 |&gt; broom.helpers::tidy_parameters(exponentiate = TRUE) \n\n                                term  estimate std.error conf.level   conf.low\n1                      (Intercept):1 0.8903708 0.4925908       0.95 0.30105802\n2                      (Intercept):2 0.2127382 0.1864002       0.95 0.03819678\n3                        sexeHomme:1 0.9594340 0.1643997       0.95 0.68574259\n4                        sexeHomme:2 1.2484837 0.3404228       0.95 0.73162172\n5                 etudesSecondaire:1 1.1226456 0.3837540       0.95 0.57448201\n6                 etudesSecondaire:2 1.5190753 0.8555505       0.95 0.50370762\n7  etudesTechnique / Professionnel:1 1.2469025 0.3866926       0.95 0.67897791\n8  etudesTechnique / Professionnel:2 1.6972676 0.8504673       0.95 0.63566751\n9                  etudesSupérieur:1 2.4739057 0.7780767       0.95 1.33557655\n10                 etudesSupérieur:2 1.7937708 0.9428657       0.95 0.64024629\n11             etudesNon documenté:1 0.7237778 0.4795111       0.95 0.19754885\n12             etudesNon documenté:2 1.9082659 1.7932841       0.95 0.30250055\n13                   trav.impAussi:1 0.9728582 0.4977496       0.95 0.35689786\n14                   trav.impAussi:2 0.6873710 0.5672279       0.95 0.13638549\n15                   trav.impMoins:1 0.8019528 0.3969271       0.95 0.30398071\n16                   trav.impMoins:2 0.4997879 0.3958473       0.95 0.10582985\n17                     trav.impPeu:1 0.9333229 0.6598208       0.95 0.23348961\n18                     trav.impPeu:2 4.8818349 4.2302506       0.95 0.89328990\n   conf.high   statistic df.error     p.value\n1   2.633247 -0.20988509      Inf 0.833757356\n2   1.184853 -1.76637893      Inf 0.077332298\n3   1.342360 -0.24167835      Inf 0.809029407\n4   2.130488  0.81391637      Inf 0.415692863\n5   2.193860  0.33843739      Inf 0.735033605\n6   4.581209  0.74236198      Inf 0.457868051\n7   2.289862  0.71153296      Inf 0.476754032\n8   4.531799  1.05575832      Inf 0.291078645\n9   4.582448  2.87999791      Inf 0.003976778\n10  5.025587  1.11164951      Inf 0.266288875\n11  2.651771 -0.48794745      Inf 0.625587062\n12 12.037925  0.68762767      Inf 0.491687277\n13  2.651888 -0.05378223      Inf 0.957108667\n14  3.464290 -0.45428375      Inf 0.649624613\n15  2.115688 -0.44591425      Inf 0.655659186\n16  2.360279 -0.87568771      Inf 0.381199829\n17  3.730751 -0.09760692      Inf 0.922244427\n18 26.679258  1.82973852      Inf 0.067289048",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Régression logistique multinomiale</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/regression-logistique-multinomiale.html#webin-r",
    "href": "analyses_avancees/regression-logistique-multinomiale.html#webin-r",
    "title": "43  Régression logistique multinomiale",
    "section": "\n43.5 webin-R",
    "text": "43.5 webin-R\nLa régression logistique multinomiale est abordée dans le webin-R #20 (trajectoires de soins : un exemple de données longitudinales (4)) sur YouTube.\n\n\n\n\nFigure 43.1: Graphique des coefficients du modèle multinomial (type “dodged”)\nFigure 43.2: Graphique des coefficients du modèle multinomial (type “faceted”)\nFigure 43.3: Graphique des coefficients du modèle multinomial (type “table”)\nFigure 43.4: Prédictions marginales du modèle multinomial",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Régression logistique multinomiale</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/regression-logistique-ordinale.html",
    "href": "analyses_avancees/regression-logistique-ordinale.html",
    "title": "44  Régression logistique ordinale",
    "section": "",
    "text": "44.1 Données d’illustration\nPour illustrer la régression logistique multinomiale, nous allons reprendre le jeu de données hdv2003 du package questionr et portant sur l’enquête histoires de vie 2003 de l’Insee et l’exemple utilisé dans le chapitre sur la régression logistique multinomiale (cf. Chapitre 43).\nlibrary(tidyverse)\nlibrary(labelled)\ndata(\"hdv2003\", package = \"questionr\")\nd &lt;- hdv2003\nNous allons considérer comme variable d’intérêt la variable trav.satisf, à savoir la satisfaction ou l’insatisfaction au travail.\nquestionr::freq(d$trav.satisf)\n\n                 n    % val%\nSatisfaction   480 24.0 45.8\nInsatisfaction 117  5.9 11.2\nEquilibre      451 22.6 43.0\nNA             952 47.6   NA\nNous allons devoir ordonner les modalités de la plus faible à la plus forte.\nd$trav.satisf &lt;- d$trav.satisf |&gt;\n  fct_relevel(\"Insatisfaction\", \"Equilibre\")\nEt nous allons indiquer qu’il s’agit d’un facteur ordonné.\nd$trav.satisf &lt;- d$trav.satisf |&gt;\n  as.ordered()\nNous allons aussi en profiter pour raccourcir les étiquettes de la variable trav.imp :\nlevels(d$trav.imp) &lt;- c(\"Le plus\", \"Aussi\", \"Moins\", \"Peu\")\nEnfin, procédons à quelques recodages additionnels :\nd &lt;- d |&gt; \n  mutate(\n    sexe = sexe |&gt; fct_relevel(\"Femme\"),\n    groupe_ages = age |&gt;\n      cut(\n        c(18, 25, 45, 99),\n        right = FALSE,\n        include.lowest = TRUE,\n        labels = c(\"18-24 ans\", \"25-44 ans\",\n                   \"45 et plus\")\n      ),\n    etudes = nivetud |&gt; \n      fct_recode(\n        \"Primaire\" = \"N'a jamais fait d'etudes\",\n        \"Primaire\" = \"A arrete ses etudes, avant la derniere annee d'etudes primaires\",\n        \"Primaire\" = \"Derniere annee d'etudes primaires\",\n        \"Secondaire\" = \"1er cycle\",\n        \"Secondaire\" = \"2eme cycle\",\n        \"Technique / Professionnel\" = \"Enseignement technique ou professionnel court\",\n        \"Technique / Professionnel\" = \"Enseignement technique ou professionnel long\",\n        \"Supérieur\" = \"Enseignement superieur y compris technique superieur\"\n    ) |&gt; \n    fct_na_value_to_level(\"Non documenté\")  \n  ) |&gt; \n  set_variable_labels(\n    trav.satisf = \"Satisfaction dans le travail\",\n    sexe = \"Sexe\",\n    groupe_ages = \"Groupe d'âges\",\n    etudes = \"Niveau d'études\",\n    trav.imp = \"Importance accordée au travail\"\n  )",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Régression logistique ordinale</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/regression-logistique-ordinale.html#calcul-du-modèle-ordinal",
    "href": "analyses_avancees/regression-logistique-ordinale.html#calcul-du-modèle-ordinal",
    "title": "44  Régression logistique ordinale",
    "section": "\n44.2 Calcul du modèle ordinal",
    "text": "44.2 Calcul du modèle ordinal\n\n44.2.1 avec MASS::polr()\nLe plus facile pour le calcul d’un modèle ordinal est d’avoir recours à la fonction MASS::polr().\n\nrego &lt;- MASS::polr(\n  trav.satisf ~ sexe + etudes + groupe_ages + trav.imp,\n  data = d\n)\n\nNous pouvons aisément simplifier le modèle avec step() (cf. Chapitre 23).\n\nrego2 &lt;- rego |&gt; step()\n\nStart:  AIC=1978.29\ntrav.satisf ~ sexe + etudes + groupe_ages + trav.imp\n\n              Df    AIC\n- groupe_ages  2 1977.2\n- sexe         1 1978.3\n&lt;none&gt;           1978.3\n- etudes       4 1991.5\n- trav.imp     3 2014.0\n\nStep:  AIC=1977.23\ntrav.satisf ~ sexe + etudes + trav.imp\n\n           Df    AIC\n- sexe      1 1977.0\n&lt;none&gt;        1977.2\n- etudes    4 1990.6\n- trav.imp  3 2013.2\n\nStep:  AIC=1976.97\ntrav.satisf ~ etudes + trav.imp\n\n           Df    AIC\n&lt;none&gt;        1977.0\n- etudes    4 1990.6\n- trav.imp  3 2011.6\n\n\n\n44.2.2 Fonctions alternatives\nUn package alternatif pour le calcul de régressions ordinales est le package dédié ordinal et sa fonction ordinal::clm(). Pour les utilisateurs avancés, ordinal permet également de traiter certains prédicteurs comme ayant un effet nominal (et donc avec un coefficient par niveau) via l’argument nominal. Il existe également une fonction ordinal::clmm() permet de définir des modèles mixtes avec variables à effet aléatoire.\n\nrego3 &lt;- ordinal::clm(\n  trav.satisf ~ sexe + etudes + groupe_ages + trav.imp,\n  data = d\n)\n\nLes modèles créés avec ordinal::clm() sont plutôt bien traités par des fonctions comme gtsummary::tbl_regression() ou ggstats::ggcoef_model().\nEnfin, on peut également citer la fonction VGAM::vgam() en spécifiant family = VGAM::cumulative(parallel = TRUE). Cette famille de modèles offre des options avancées (par exemple il est possible de calculer des modèles non parallèles, c’est-à-dire avec une série de coefficients pour chaque changement de niveau). Par contre, le support de gtsummary::tbl_regression() et ggstats::ggcoef_model() sera limité (seulement des résultats bruts).\n\nrego4 &lt;- VGAM::vgam(\n  trav.satisf ~ sexe + etudes + groupe_ages + trav.imp,\n  data = d,\n  family = VGAM::cumulative(parallel = TRUE)\n)\n\n\n\n\n\n\n\nImportant\n\n\n\nEn toute rigueur, il faudrait tester l’égalité des pentes. Laurent Rouvière propose un code permettant d’effectuer ce test sous R à partir d’un modèle réalisé avec VGAM::vglm(), voir la diapositive 33 sur 35 d’un de ses cours de janvier 2015 intitulé Quelques modèles logistiques polytomiques.",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Régression logistique ordinale</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/regression-logistique-ordinale.html#affichage-des-résultats-du-modèle",
    "href": "analyses_avancees/regression-logistique-ordinale.html#affichage-des-résultats-du-modèle",
    "title": "44  Régression logistique ordinale",
    "section": "\n44.3 Affichage des résultats du modèle",
    "text": "44.3 Affichage des résultats du modèle\nPour un tableau des coefficients, on peut tout simplement appeler gtsummary::tbl_regression(). Nous allons indiquer exponentiate = TRUE car, comme pour la régression logistique binaire, l’exponentielle des coefficients peut s’interpréter comme des odds ratios. Pour éviter certains messages d’information, nous allons préciser tidy_fun = broom.helpers::tidy_parameters (cela implique juste que le tableau des coefficients sera calculé avec le package parameters plutôt qu’avec le package broom). Nous pouvons calculer à la volée la p-valeur globale de chaque variable avec gtsummary::add_global_p().\n\nlibrary(gtsummary)\ntheme_gtsummary_language(\"fr\", decimal.mark = \",\")\n\n\nrego2 |&gt; \n  tbl_regression(\n    exponentiate = TRUE,\n    tidy_fun = broom.helpers::tidy_parameters\n  ) |&gt; \n  bold_labels() |&gt; \n  add_global_p(keep = TRUE)\n\n\nRéajustement pour obtenir le Hessien\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nOR\n1\n\n\n95% IC\n1\n\np-valeur\n\n\n\nNiveau d'études\n\n\n&lt;0,001\n\n\n    Primaire\n—\n—\n\n\n\n    Secondaire\n1,06\n0,67 – 1,67\n0,8\n\n\n    Technique / Professionnel\n1,01\n0,67 – 1,53\n&gt;0,9\n\n\n    Supérieur\n1,84\n1,20 – 2,83\n0,006\n\n\n    Non documenté\n0,66\n0,25 – 1,72\n0,4\n\n\nImportance accordée au travail\n\n\n&lt;0,001\n\n\n    Le plus\n—\n—\n\n\n\n    Aussi\n1,39\n0,65 – 2,97\n0,4\n\n\n    Moins\n1,03\n0,50 – 2,14\n&gt;0,9\n\n\n    Peu\n0,19\n0,08 – 0,48\n&lt;0,001\n\n\n\n\n1\nOR = rapport de cotes, IC = intervalle de confiance\n\n\n\n\n\n\n\n\nTable 44.1: Tableau des odds ratio de la régression logistique ordinale\n\n\n\nLa même commande fonctionne avec un modèle créé avec ordinal::clm().\nPour un graphique des coefficients, on va procéder de même avec ggstats::gcoef_model() ou ggstats::gcoef_table().\n\nrego2 |&gt; \n  ggstats::ggcoef_model(\n    exponentiate = TRUE,\n    tidy_fun = broom.helpers::tidy_parameters\n  )\n\n\n\n\n\n\nFigure 44.1: Graphique des coefficients du modèle ordinal\n\n\n\n\n\nrego2 |&gt; \n  ggstats::ggcoef_table(\n    exponentiate = TRUE,\n    tidy_fun = broom.helpers::tidy_parameters\n  )\n\n\n\n\n\n\nFigure 44.2: Graphique et table des coefficients du modèle ordinal\n\n\n\n\nPour faciliter l’interprétation, on pourra représenter les prédictions marginales du modèle (cf. Chapitre 24) avec broom.helpers::plot_marginal_predictions().\n\nrego2 |&gt; \n  broom.helpers::plot_marginal_predictions() |&gt; \n  patchwork::wrap_plots(ncol = 1) &\n  scale_y_continuous(labels = scales::percent, limits = c(0, .6)) &\n  coord_flip()\n\n\n\n\n\n\nFigure 44.3: Prédictions marginales du modèle ordinal",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Régression logistique ordinale</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/regression-logistique-ordinale.html#données-pondérées",
    "href": "analyses_avancees/regression-logistique-ordinale.html#données-pondérées",
    "title": "44  Régression logistique ordinale",
    "section": "\n44.4 Données pondérées",
    "text": "44.4 Données pondérées\n\n44.4.1 avec survey::svyolr()\n\nL’extension survey (cf. Chapitre 28) propose une fonction native survey::svyolr() pour le calcul d’une régression ordinale.\nNous allons commencer par définir le plan d’échantillonnage.\n\nlibrary(survey)\nlibrary(srvyr)\ndw &lt;- d |&gt;\n  as_survey(weights = poids)\n\nCalculons le modèle.\n\nrego5 &lt;- svyolr(\n  trav.satisf ~ sexe + etudes + groupe_ages + trav.imp,\n  design = dw\n)\n\nLe résultat peut être visualisé aisément avec gtsummary::tbl_regression() ou ggstats::ggcoef_model().\n\n44.4.2 avec svrepmisc::svymultinom()\n\nAlternativement, il est possible d’utiliser à ordinal::clm() en ayant recours à des poids de réplication, comme suggéré par Thomas Lumley dans son ouvrage Complex Surveys: A Guide to Analysis Using R.\nL’extension svrepmisc disponible sur GitHub fournit quelques fonctions facilitant l’utilisation des poids de réplication avec survey. Pour l’installer, on utilisera le code ci-dessous :\n\nremotes::install_github(\"carlganz/svrepmisc\")\n\nEn premier lieu, il faut définir le design de notre tableau de données puis calculer des poids de réplication.\n\nlibrary(survey)\nlibrary(srvyr)\ndw_rep &lt;- d |&gt;\n  as_survey(weights = poids) |&gt; \n  as_survey_rep(type = \"bootstrap\", replicates = 25)\n\nIl faut prévoir un nombre de replicates suffisant pour calculer ultérieurement les intervalles de confiance des coefficients. Plus ce nombre est élevé, plus précise sera l’estimation de la variance et donc des valeurs p et des intervalles de confiance. Cependant, plus ce nombre est élevé, plus le temps de calcul sera important. Pour gagner en temps de calcul, nous avons ici pris une valeur de 25, mais l’usage est de considérer au moins 1000 réplications.\nsvrepmisc fournit une fonction svrepmisc::svyclm() pour le calcul d’une régression multinomiale avec des poids de réplication.\n\nlibrary(svrepmisc)\nrego6 &lt;- svyclm(\n  trav.satisf ~ sexe + etudes + trav.imp,\n  design = dw_rep\n)\n\nsvrepmisc fournit également des méthodes svrepmisc::confint() et svrepmisc::tidy(). Nous pouvons donc calculer et afficher les odds ratio et leur intervalle de confiance.\n\nrego6\n\n                                Coefficient          SE t value Pr(&gt;|t|)   \nInsatisfaction|Equilibre        -2.03917466  0.68578624 -2.9735  0.00947 **\nEquilibre|Satisfaction           0.27271800  0.70391645  0.3874  0.70388   \nsexeHomme                       -0.13280477  0.16514615 -0.8042  0.43386   \netudesSecondaire                -0.04271403  0.29847702 -0.1431  0.88811   \netudesTechnique / Professionnel  0.00042809  0.19997661  0.0021  0.99832   \netudesSupérieur                  0.64247607  0.22827571  2.8145  0.01307 * \netudesNon documenté             -0.46945975  0.53333962 -0.8802  0.39262   \ntrav.impAussi                    0.12071087  0.58062352  0.2079  0.83810   \ntrav.impMoins                    0.05267146  0.62836491  0.0838  0.93431   \ntrav.impPeu                     -1.53039056  0.66160102 -2.3132  0.03531 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nrego6 |&gt; confint()\n\n                                     2.5 %     97.5 %\nInsatisfaction|Equilibre        -3.5008934 -0.5774559\nEquilibre|Satisfaction          -1.2276444  1.7730804\nsexeHomme                       -0.4848055  0.2191959\netudesSecondaire                -0.6789027  0.5934747\netudesTechnique / Professionnel -0.4258120  0.4266681\netudesSupérieur                  0.1559179  1.1290342\netudesNon documenté             -1.6062462  0.6673267\ntrav.impAussi                   -1.1168589  1.3582806\ntrav.impMoins                   -1.2866566  1.3919996\ntrav.impPeu                     -2.9405598 -0.1202214\n\nrego6 |&gt;\n  broom::tidy(exponentiate = TRUE, conf.int = TRUE)\n\n                              term  estimate std.error    statistic     p.value\n1           Equilibre|Satisfaction 1.3135298 0.7039165  0.387429505 0.703880188\n2              etudesNon documenté 0.6253400 0.5333396 -0.880226664 0.392621184\n3                 etudesSecondaire 0.9581854 0.2984770 -0.143106607 0.888110688\n4                  etudesSupérieur 1.9011825 0.2282757  2.814474071 0.013072196\n5  etudesTechnique / Professionnel 1.0004282 0.1999766  0.002140676 0.998320199\n6         Insatisfaction|Equilibre 0.1301361 0.6857862 -2.973484363 0.009470254\n7                        sexeHomme 0.8756360 0.1651462 -0.804165077 0.433862196\n8                    trav.impAussi 1.1282986 0.5806235  0.207898683 0.838104447\n9                    trav.impMoins 1.0540833 0.6283649  0.083823045 0.934305585\n10                     trav.impPeu 0.2164511 0.6616010 -2.313162322 0.035313682\n     conf.low conf.high\n1  0.29298191 5.8889659\n2  0.20063935 1.9490201\n3  0.50717319 1.8102676\n4  1.16873026 3.0926683\n5  0.65323915 1.5321441\n6  0.03017042 0.5613246\n7  0.61581699 1.2450752\n8  0.32730629 3.8895000\n9  0.27619265 4.0228860\n10 0.05283614 0.8867241\n\n\nPar contre, le support de gtsummary::tbl_regression() et ggstats::ggcoef_model() est plus limité. Vous pourrez afficher un tableau basique des résultats et un graphiques des coefficients, mais sans les enrichissements usuels (identification des variables, étiquettes propres, identification des niveaux, etc.).\n\n44.4.3 avec svyVGAM::svy_glm()\n\nUne alternative possible pour le calcul de la régression logistique multinomiale avec des données pondérées est svyVGAM::svy_vglm() avec family = VGAM::multinomial.\nNous allons commencer par définir le plan d’échantillonnage.\n\nlibrary(survey)\nlibrary(srvyr)\ndw &lt;- d |&gt;\n  as_survey(weights = poids)\n\nPuis, on appelle svyVGAM::svy_vglm() en précisant family = VGAM::cumulative(parallel = TRUE).\n\nrego7 &lt;- svyVGAM::svy_vglm(\n  trav.satisf ~ sexe + etudes + trav.imp,\n  family = VGAM::cumulative(parallel = TRUE),\n  design = dw\n)\nrego7 |&gt; summary()\n\nsvy_vglm.survey.design(trav.satisf ~ sexe + etudes + trav.imp, \n    family = VGAM::cumulative(parallel = TRUE), design = dw)\nIndependent Sampling design (with replacement)\nCalled via srvyr\nSampling variables:\n  - ids: `1` \n  - weights: poids \nData variables: \n  - id (int), age (int), sexe (fct), nivetud (fct), poids (dbl), occup (fct),\n    qualif (fct), freres.soeurs (int), clso (fct), relig (fct), trav.imp (fct),\n    trav.satisf (ord), hard.rock (fct), lecture.bd (fct), peche.chasse (fct),\n    cuisine (fct), bricol (fct), cinema (fct), sport (fct), heures.tv (dbl),\n    groupe_ages (fct), etudes (fct)\n                                       Coef          SE       z         p\n(Intercept):1                   -2.03917232  0.52467564 -3.8865 0.0001017\n(Intercept):2                    0.27272042  0.51315926  0.5315 0.5951044\nsexeHomme                        0.13280416  0.15421876  0.8611 0.3891602\netudesSecondaire                 0.04271296  0.28498254  0.1499 0.8808599\netudesTechnique / Professionnel -0.00043004  0.25720348 -0.0017 0.9986659\netudesSupérieur                 -0.64247750  0.26590126 -2.4162 0.0156823\netudesNon documenté              0.46945812  0.52541495  0.8935 0.3715896\ntrav.impAussi                   -0.12071140  0.48525530 -0.2488 0.8035476\ntrav.impMoins                   -0.05267211  0.47029563 -0.1120 0.9108251\ntrav.impPeu                      1.53036737  0.65156164  2.3488 0.0188356\n\n\nLà encore, le support de gtsummary::tbl_regression() et ggstats::ggcoef_model() sera limité (seulement des résultats bruts). Pour calculer les odds ratios avec leurs intervalles de confiance, on pourra avoir recours à broom.helpers::tidy_parameters().\n\nrego7 |&gt; broom.helpers::tidy_parameters(exponentiate = TRUE) \n\n                              term  estimate  std.error conf.level   conf.low\n1                    (Intercept):1 0.1301364 0.06827939       0.95 0.04653653\n2                    (Intercept):2 1.3135330 0.67405160       0.95 0.48043985\n3                        sexeHomme 1.1420263 0.17612188       0.95 0.84412131\n4                 etudesSecondaire 1.0436383 0.29741869       0.95 0.59699738\n5  etudesTechnique / Professionnel 0.9995700 0.25709290       0.95 0.60378349\n6                  etudesSupérieur 0.5259877 0.13986079       0.95 0.31234891\n7              etudesNon documenté 1.5991274 0.84020546       0.95 0.57101702\n8                    trav.impAussi 0.8862897 0.43007677       0.95 0.34239361\n9                    trav.impMoins 0.9486910 0.44616524       0.95 0.37740568\n10                     trav.impPeu 4.6198737 3.01013253       0.95 1.28830837\n    conf.high    statistic df.error      p.value\n1   0.3639179 -3.886538948      Inf 0.0001016836\n2   3.5912276  0.531453766      Inf 0.5951043720\n3   1.5450672  0.861141383      Inf 0.3891601794\n4   1.8244316  0.149879202      Inf 0.8808599211\n5   1.6547990 -0.001671995      Inf 0.9986659418\n6   0.8857499 -2.416225817      Inf 0.0156823321\n7   4.4783403  0.893499744      Inf 0.3715896094\n8   2.2941709 -0.248758549      Inf 0.8035475563\n9   2.3847407 -0.111997880      Inf 0.9108250872\n10 16.5668669  2.348768359      Inf 0.0188356206\n\n\n\n\n\nFigure 44.1: Graphique des coefficients du modèle ordinal\nFigure 44.2: Graphique et table des coefficients du modèle ordinal\nFigure 44.3: Prédictions marginales du modèle ordinal",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Régression logistique ordinale</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/modeles-comptage.html",
    "href": "analyses_avancees/modeles-comptage.html",
    "title": "45  Modèles de comptage (Poisson & apparentés)",
    "section": "",
    "text": "45.1 Modèle de Poisson\nNous allons nous intéresser à un premier exemple démographique en nous intéressant à la descendance atteinte par des femmes à l’âge de 30 ans.",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Modèles de comptage (Poisson & apparentés)</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/modeles-comptage.html#modèle-de-poisson",
    "href": "analyses_avancees/modeles-comptage.html#modèle-de-poisson",
    "title": "45  Modèles de comptage (Poisson & apparentés)",
    "section": "",
    "text": "45.1.1 Préparation des données du premier exemple\nPour cet exemple, nous allons considérer le jeu de données fecondite fourni par le package questionr. Ce jeu de données comprends trois tables de données (menages, femmes et enfants) simulant les résultats d’une enquête démographique et de santé (EDS). Chargeons les données et jetons y un œil avec labelled::look_for().\n\nlibrary(tidyverse)\nlibrary(labelled)\ndata(\"fecondite\", package = \"questionr\")\n\n\nenfants |&gt; look_for()\n\n pos variable       label                        col_type missing values      \n 1   id_enfant      Identifiant de l'enfant      dbl      0                   \n 2   id_femme       Identifiant de la mère       dbl      0                   \n 3   date_naissance Date de naissance            date     0                   \n 4   sexe           Sexe de l'enfant             dbl+lbl  0       [1] masculin\n                                                                  [2] féminin \n 5   survie         L'enfant est-il toujours en~ dbl+lbl  0       [0] non     \n                                                                  [1] oui     \n 6   age_deces      Age au décès (en mois)       dbl      1442                \n\n\nComme nous pouvons le voir, les variables catégorielles sont codées sous la forme de vecteurs numériques labellisés (cf. Chapitre 12), comme cela aurait été le cas si nous avions importé un fichier Stata ou SPSS avec haven. Première étape, nous allons convertir à la volée ces variables catégorielles en facteurs avec labelled::unlabelled().\n\nfemmes &lt;- \n  femmes |&gt; \n  unlabelled()\nenfants &lt;- \n  enfants |&gt; \n  unlabelled()\n\nPour notre analyse, nous allons devoir compter le nombre d’enfants que chaque femme a eu avant l’âge de 30 ans exacts. En premier lieu, nous devons calculer l’âge (cf. Section 34.4) de la mère à la naissance dans le tableau enfants, à l’aide de la fonction lubridate::time_length().\n\nenfants &lt;-\n  enfants |&gt;\n  left_join(\n    femmes |&gt;\n      select(id_femme, date_naissance_mere = date_naissance),\n    by = \"id_femme\"\n  ) |&gt;\n  mutate(\n    age_mere = time_length(\n      date_naissance_mere %--% date_naissance,\n      unit = \"years\"\n    )\n  )\n\nComptons maintenant, par femme, le nombre d’enfants nés avant l’âge de 30 ans et ajoutons cette valeur à la table femmes. N’oublions, après la fusion, de recoder les valeurs manquantes NA en 0 avec tidyr::replace_na().\n\nfemmes &lt;-\n  femmes |&gt; \n  left_join(\n    enfants |&gt; \n      filter(age_mere &lt; 30) |&gt; \n      group_by(id_femme) |&gt; \n      count(name = \"enfants_avt_30\"),\n    by = \"id_femme\"\n  ) |&gt; \n  tidyr::replace_na(list(enfants_avt_30 = 0L)) |&gt; \n  set_variable_labels(\n    enfants_avt_30 = \"Nombre d'enfants nés avant 30 ans exact\"\n  )\n\nIl nous reste à calculer l’âge des femmes au moment de l’enquête. Nous allons en profiter pour recoder (cf. Section 9.3) la variable éducation en regroupant les modalités secondaire et supérieur.\n\nfemmes &lt;-\n  femmes |&gt; \n  mutate(\n    age = time_length(\n      date_naissance %--% date_entretien,\n      unit = \"years\"\n    ),\n    educ2 = educ |&gt; \n      fct_recode(\n        \"secondaire/supérieur\" = \"secondaire\",\n        \"secondaire/supérieur\" = \"supérieur\"\n      )\n  )\n\nEnfin, pour l’analyse, nous n’allons garder que les femmes âgées d’au moins 30 ans au moment de l’enquête. En effet, les femmes plus jeunes n’ayant pas encore atteint 30 ans, nous ne connaissons pas leur descendance atteinte à cet âge.\n\nfemmes30p &lt;- \n  femmes |&gt; \n  filter(age &gt;= 30)\n\n\n45.1.2 Statistiques descriptives\nAvant de réaliser un modèle multivariable, il est toujours bon de réaliser au préalable des analyses bivariées. Notre outcome étant numérique, nous pouvons comparer sa moyenne selon nos différentes variables catégorielles.\nPour cela, nous aurons recours à gtsummary::tbl_continuous() (une variante de gtsummary::tbl_summary().\n\nlibrary(gtsummary)\ntheme_gtsummary_language(\n  \"fr\",\n  decimal.mark = \",\",\n  big.mark = \" \"\n)\n\nSetting theme \"language: fr\"\n\n\n\nfemmes30p |&gt; \n  tbl_continuous(\n    variable = enfants_avt_30,\n    include = c(educ2, milieu, region),\n    statistic = ~ \"{mean} ({sd})\",\n    digits = ~ 2\n  ) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 804\n1\n\n\n\n\nNiveau d'éducation\n\n\n\n    aucun\n0,25 (0,61)\n\n\n    primaire\n0,30 (0,62)\n\n\n    secondaire/supérieur\n0,11 (0,32)\n\n\nMilieu de résidence\n\n\n\n    urbain\n0,18 (0,49)\n\n\n    rural\n0,28 (0,63)\n\n\nRégion de résidence\n\n\n\n    Nord\n0,22 (0,51)\n\n\n    Est\n0,31 (0,65)\n\n\n    Sud\n0,28 (0,74)\n\n\n    Ouest\n0,20 (0,49)\n\n\n\n\n1\nNombre d’enfants nés avant 30 ans exact: Moyenne (ET)\n\n\n\n\n\n\n\n\nTable 45.1: Descendance atteinte moyenne à 30 ans\n\n\n\nLe nombre d’observations par ligne n’est pas directement accessible peut s’ajouter aisément en utilisant {length}. De même, il n’y a pas de méthode add_ci() pour les objets tbl_continuous mais nous pouvons définir nos propres fonctions pour calculer, à l’aide de t.test() (cf. Section 18.4.2). Enfin, calculons des p-valeurs avec gtsummary::add_p() et en utilisant une ANOVA à un facteur (qui permet de prendre en compte des variables explicatives à plus de deux modalités).\n\nci_low &lt;- function(x, conf.level = 0.95) {\n  t.test(x, conf.level = conf.level)$conf.int[1]\n}\nci_high &lt;- function(x, conf.level = 0.95) {\n  t.test(x, conf.level = conf.level)$conf.int[2]\n}\nfemmes30p |&gt; \n  tbl_continuous(\n    variable = enfants_avt_30,\n    include = c(educ2, milieu, region),\n    statistic = ~ \"{mean} [{ci_low} - {ci_high}] ({sd}) [n={length}]\",\n    digits = ~ c(2, 2, 2, 2, 0)\n  ) |&gt; \n  add_p(test = ~ \"aov\") |&gt; \n  bold_labels()\n\nThe following warning was returned in `add_p()` for variable \"educ2\"\n! The test \"aov\" in `add_p(test)` was deprecated in gtsummary 2.0.0. ℹ The same\n  functionality is covered with \"oneway.test\". Use the following code instead:\n  ℹ `add_p(test = list(enfants_avt_30 = 'oneway.test'), test.args =\n  list(enfants_avt_30 = list(var.equal = TRUE)))`.\nThe following warning was returned in `add_p()` for variable \"milieu\"\n! The test \"aov\" in `add_p(test)` was deprecated in gtsummary 2.0.0. ℹ The same\n  functionality is covered with \"oneway.test\". Use the following code instead:\n  ℹ `add_p(test = list(enfants_avt_30 = 'oneway.test'), test.args =\n  list(enfants_avt_30 = list(var.equal = TRUE)))`.\nThe following warning was returned in `add_p()` for variable \"region\"\n! The test \"aov\" in `add_p(test)` was deprecated in gtsummary 2.0.0. ℹ The same\n  functionality is covered with \"oneway.test\". Use the following code instead:\n  ℹ `add_p(test = list(enfants_avt_30 = 'oneway.test'), test.args =\n  list(enfants_avt_30 = list(var.equal = TRUE)))`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nN = 804\n1\n\n\np-valeur\n2\n\n\n\n\nNiveau d'éducation\n\n0,036\n\n\n    aucun\n0,25 [0,20 - 0,30] (0,61) [n=534]\n\n\n\n    primaire\n0,30 [0,20 - 0,39] (0,62) [n=171]\n\n\n\n    secondaire/supérieur\n0,11 [0,05 - 0,17] (0,32) [n=99]\n\n\n\nMilieu de résidence\n\n0,017\n\n\n    urbain\n0,18 [0,12 - 0,23] (0,49) [n=307]\n\n\n\n    rural\n0,28 [0,22 - 0,34] (0,63) [n=497]\n\n\n\nRégion de résidence\n\n0,2\n\n\n    Nord\n0,22 [0,16 - 0,28] (0,51) [n=300]\n\n\n\n    Est\n0,31 [0,20 - 0,43] (0,65) [n=118]\n\n\n\n    Sud\n0,28 [0,17 - 0,39] (0,74) [n=178]\n\n\n\n    Ouest\n0,20 [0,13 - 0,26] (0,49) [n=208]\n\n\n\n\n\n\n1\nNombre d’enfants nés avant 30 ans exact: Moyenne [ci_low - ci_high] (ET) [n=length]\n\n\n\n\n2\nOne-way analysis of means\n\n\n\n\n\n\n\n\n\nTable 45.2: Descendance atteinte moyenne à 30 ans\n\n\n\n\n45.1.3 Calcul & Interprétation du modèle de Poisson\nLes modèles de Poisson font partie de la famille des modèles linéaires généralisés (GLM en anglais) et se calculent dont avec la fonction stats::glm() en précisant family = poisson.\n\nmod1_poisson &lt;- glm(\n  enfants_avt_30 ~ educ2 + milieu + region,\n  family = poisson,\n  data = femmes30p\n)\n\nL’ensemble des fonctions et méthodes applicables aux modèles GLM, que nous avons déjà abordé dans le chapitre sur la régression logistique (cf. Chapitre 22), peuvent s’appliquer également aux modèles de Poisson. Nous pouvons par exemple réduire notre modèle par minimisation de l’AIC avec stats::step().\n\nmod1_poisson &lt;- step(mod1_poisson)\n\nStart:  AIC=1013.81\nenfants_avt_30 ~ educ2 + milieu + region\n\n         Df Deviance    AIC\n- region  3   686.46 1010.6\n&lt;none&gt;        683.62 1013.8\n- milieu  1   686.84 1015.0\n- educ2   2   691.10 1017.3\n\nStep:  AIC=1010.65\nenfants_avt_30 ~ educ2 + milieu\n\n         Df Deviance    AIC\n&lt;none&gt;        686.46 1010.6\n- milieu  1   691.30 1013.5\n- educ2   2   693.94 1014.1\n\n\nPar défaut, les modèles de Poisson utilisent une fonction de lien logarithmique (log). Dès lors, il est fréquent de ne pas présenter directement les coefficients du modèle, mais plutôt l’exponentielle de leurs valeurs qui peut s’interpréter comme des risques relatifs (relative risks ou RR)1. L’exponentielle des coefficients peut aussi être appelée incidence rate ratio (IRR) car la régression de Poisson peut également être utilisée pour des modèles d’incidence, qui seront abordés dans le prochain chapitre (cf. Chapitre 46).\n1 À ne pas confondre avec les odds ratio ou OR de la régression logistique.Pour un tableau mis en forme des coefficients, on aura tout simplement recours à gtsummary et sa fonction gtsummary::tbl_regression().\n\nmod1_poisson |&gt; \n  tbl_regression(exponentiate = TRUE) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nIRR\n1\n\n\n95% IC\n1\n\np-valeur\n\n\n\nNiveau d'éducation\n\n\n\n\n\n    aucun\n—\n—\n\n\n\n    primaire\n1,25\n0,90 – 1,72\n0,2\n\n\n    secondaire/supérieur\n0,53\n0,27 – 0,96\n0,052\n\n\nMilieu de résidence\n\n\n\n\n\n    urbain\n—\n—\n\n\n\n    rural\n1,42\n1,04 – 1,98\n0,032\n\n\n\n\n1\nIRR = rapport de taux d’incidence, IC = intervalle de confiance\n\n\n\n\n\n\n\n\nTable 45.3: Tableau des coefficients du modèle de Poisson\n\n\n\nPour une représentation graphique, on pourra avoir recours à ggstats::ggcoef_model() ou ggstats::ggcoef_table().\n\nlibrary(ggstats)\nmod1_poisson |&gt; \n  ggcoef_table(exponentiate = TRUE)\n\n\n\n\n\n\nFigure 45.1: Forest plot des coefficients du modèle de Poisson\n\n\n\n\nPour interpréter les coefficients, il faut se rappeler que ce qui est modélisé dans le modèle de Poisson est le nombre moyen d’évènements. Le RR pour la modalité secondaire/supérieur est de 0,5 : cela signifie donc que, indépendamment des autres variables du modèle, la descendance atteinte à 30 ans moyenne des femmes de niveau secondaire ou supérieure est moitié moindre que celle des femmes sans niveau d’éducation (modalité de référence).\nNous pouvons vérifier visuellement ce résultat en réalisant un graphique des prédictions marginales moyennes avec broom.helpers::plot_marginal_predictions() (cf. Section 24.3).\n\nbroom.helpers::plot_marginal_predictions(mod1_poisson) |&gt; \n  patchwork::wrap_plots() &\n  ggplot2::scale_y_continuous(limits = c(0, .4))\n\n\n\n\n\n\nFigure 45.2: Prédictions marginales du modèle de Poisson\n\n\n\n\n\n45.1.4 Évaluation de la surdispersion\nComme tous les modèles GLM, le modèle de Poisson présuppose que les observations sont indépendantes les unes des autres2. Surtout, la distribution de Poisson présuppose que la variance est égale à la moyenne. Or, il arrive fréquemment que la variance soit supérieure à la moyenne, auquel cas on parle alors de surdispersion. Si c’est le cas, le modèle de Poisson va sous-estimer la variance et produire des intervalles de confiance trop petit et des p-valeurs trop petites.\n2 Si ce n’était pas le cas, par exemple s’il y a plusieurs observations pour un même individu, il faudrait adopter un autre type de modèle, par exemple un modèle mixte ou un modèle GEE, pour lesquels il est possible d’utiliser une distribution de Poisson.En premier lieu, nous pouvons vérifier si la distribution observée des données correspond peu ou prou à la distribution théorique de Poisson pour une moyenne correspondant à la moyenne observée.\nLa fonction ci-dessous permet justement de comparer la distribution observée avec la distribution théorique d’un modèle.\n\nobserved_vs_theoretical &lt;- function(model) {\n  observed &lt;- model.response(model.frame(model))\n  theoretical &lt;- simulate(model, nsim = 1)\n  theoretical &lt;- theoretical[[1]]\n  df &lt;- dplyr::tibble(\n    status = c(\n      rep.int(\"observed\", length(observed)),\n      rep.int(\"theoretical\", length(theoretical))\n    ),\n    values = c(observed, theoretical)\n  )\n  if (is.numeric(observed) && any(observed != as.integer(observed))) {\n    ggplot2::ggplot(df) +\n    ggplot2::aes(x = values, fill = status) +\n    ggplot2::geom_density(\n      alpha = .5,\n      position = \"identity\"\n    ) +\n    ggplot2::theme_light() +\n    ggplot2::labs(fill = NULL)\n  } else {\n    ggplot2::ggplot(df) +\n    ggplot2::aes(x = values, fill = status) +\n    ggplot2::geom_bar(\n      alpha = .5,\n      position = \"identity\"\n    ) +\n    ggplot2::theme_light() +\n    ggplot2::theme(\n      panel.grid.major.x = ggplot2::element_blank(),\n      panel.grid.minor.x = ggplot2::element_blank()\n    ) +\n    ggplot2::labs(fill = NULL)\n  }\n}\n\nAppliquons cette fonction à notre modèle de Poisson.\n\nmod1_poisson |&gt; \n  observed_vs_theoretical()\n\n\n\n\n\n\nFigure 45.3: Distribution observée vs distribution théorique de la descendance atteinte à 30 ans (modèle de Poisson)\n\n\n\n\nLes deux distributions restent assez proches même si la distribution observée est légèrement décalée vers la droite.\n\n\n\n\n\n\nNote\n\n\n\nLa fonction performance::check_predictions() propose une visualisation un peu plus avancée3.\n\n\nLe chargement a nécessité le package : see\n\n\n\nmod1_poisson |&gt;\n  performance::check_predictions(type = \"discrete_both\")\n\n\n\n\n\n\n\nLes points verts correspondent au nombre d’individus observés (sur l’axe vertical) pour chaque valeur de notre variable à expliquer (sur l’axe horizontal). La fonction simule ensuite une cinquantaine de jeu de données par réplication et affiche les prédictions du modèle pour ces jeux de données (points bleus avec effet de transparence), ainsi que les prédictions médianes (point bleu sans transparence) et l’intervalle des prédictions (barres verticales).\nDans notre exemple, on voit notamment que le modèle a du mal à prédire correctement le nombre d’individus avec 0, 1 ou 2 enfants.\n\n\n3 Il est nécessaire d’installer le package see pour pouvoir afficher le graphique produit.Le paramètre φ (phi) qui correspond au ratio entre la variance observée et la variance théorique peut être estimée, en pratique, selon certains auteurs, comme le ratio de la déviance résiduelle sur le nombre de degrés de libertés du modèle. Il s’obtient ainsi :\n\nmod1_poisson$deviance / mod1_poisson$df.residual\n\n[1] 0.8580717\n\n\nSi ce ratio s’écarte de 1, alors il y a un problème de surdispersion. Cependant, en pratique, il n’y a pas de seuil précis à partir duquel nous pourrions conclure qu’il faut rejeter le modèle.\nLa package {AER} propose un test, AER::dispersiontest(), pour tester s’il y a un problème de surdispersion. Ce test ne peut s’appliquer qu’à un modèle de Poisson.\n\nmod1_poisson |&gt; AER::dispersiontest()\n\n\n    Overdispersion test\n\ndata:  mod1_poisson\nz = 3.3367, p-value = 0.0004238\nalternative hypothesis: true dispersion is greater than 1\nsample estimates:\ndispersion \n  1.361364 \n\n\nLe package performance propose, quant à lui, un test plus générale de surdispersion via la fonction performance::check_overdispersion().\n\nmod1_poisson |&gt; \n  performance::check_overdispersion()\n\n# Overdispersion test\n\n       dispersion ratio =    1.371\n  Pearson's Chi-Squared = 1096.575\n                p-value =  &lt; 0.001\n\n\nOverdispersion detected.\n\n\nDans les deux cas, nous obtenons une p-valeur inférieure à 0,001, indiquant que le modèle de Poisson n’est peut-être pas approprié ici.",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Modèles de comptage (Poisson & apparentés)</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/modeles-comptage.html#modèle-de-quasi-poisson",
    "href": "analyses_avancees/modeles-comptage.html#modèle-de-quasi-poisson",
    "title": "45  Modèles de comptage (Poisson & apparentés)",
    "section": "\n45.2 Modèle de quasi-Poisson",
    "text": "45.2 Modèle de quasi-Poisson\nLe modèle de quasi-Poisson est similaire au modèle de Poisson mais autorise plus de souplesse pour la modélisation de la variance qui est alors modélisée comme une relation linéaire de la moyenne. Il se calcule également avec stats::glm(), mais en indiquant family = quasipoisson. Comme avec le modèle de Poisson, la fonction de lien par défaut est la fonction logarithmique (log).\n\nmod1_quasi &lt;- glm(\n  enfants_avt_30 ~ educ2 + milieu,\n  family = quasipoisson,\n  data = femmes30p\n)\n\n\n\n\n\n\n\nImportant\n\n\n\nL’AIC (Akaike information criterion) n’est pas défini pour ce type de modèle. Il n’est donc pas possible d’utiliser stats::step() avec un modèle de quasi-Poisson. Si l’on veut procéder à une sélection pas à pas descendante, on procédera donc en amont avec un modèle de Poisson classique.\n\n\nRegardons les résultats obtenus :\n\nmod1_quasi |&gt; \n  tbl_regression(exponentiate = TRUE) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nIRR\n1\n\n\n95% IC\n1\n\np-valeur\n\n\n\nNiveau d'éducation\n\n\n\n\n\n    aucun\n—\n—\n\n\n\n    primaire\n1,25\n0,85 – 1,81\n0,2\n\n\n    secondaire/supérieur\n0,53\n0,23 – 1,05\n0,10\n\n\nMilieu de résidence\n\n\n\n\n\n    urbain\n—\n—\n\n\n\n    rural\n1,42\n0,99 – 2,10\n0,067\n\n\n\n\n1\nIRR = rapport de taux d’incidence, IC = intervalle de confiance\n\n\n\n\n\n\n\n\nTable 45.4: Tableau des coefficients du modèle de quasi-Poisson\n\n\n\nLes coefficients sont identiques à ceux obtenus avec le modèle de Poisson (cf. Table 45.3), mais les intervalles de confiance sont plus larges et les p-valeurs plus élevées, traduisant la prise en compte d’une variance plus importante. Cela se voit aisément si l’on compare les coefficients avec ggstats::ggcoef_compare().\n\nlist(Poisson = mod1_poisson, \"quasi-Poisson\" = mod1_quasi) |&gt;\n  ggcoef_compare(exponentiate = TRUE)\n\n\n\n\n\n\nFigure 45.4: Comparaison des coefficients du modèle de Poisson et du modèle de quasi-Poisson\n\n\n\n\nLe passage à un modèle de quasi-Poisson aura-t-il été suffisant pour régler notre problème de surdispersion ? La fonction performance::check_overdispersion() peut être appliquée à un modèle de quasi-Poisson.\n\nmod1_quasi |&gt; \n  performance::check_overdispersion()\n\n# Overdispersion test\n\n       dispersion ratio =    1.371\n  Pearson's Chi-Squared = 1096.575\n                p-value =  &lt; 0.001\n\n\nOverdispersion detected.\n\n\nIl semble que nous ayons toujours une surdispersion, insuffisamment corrigée par le modèle de quasi-Poisson.",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Modèles de comptage (Poisson & apparentés)</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/modeles-comptage.html#modèle-binomial-négatif",
    "href": "analyses_avancees/modeles-comptage.html#modèle-binomial-négatif",
    "title": "45  Modèles de comptage (Poisson & apparentés)",
    "section": "\n45.3 Modèle binomial négatif",
    "text": "45.3 Modèle binomial négatif\nLe modèle binomial négatif (negative binomial en anglais) modélise la variance selon une spécification quadratique (i.e. selon le carré de la moyenne). Il est implémenté dans le package MASS via la fonction MASS::glm.nb(). Les autres paramètres sont identiques à ceux de stats::glm().\n\nmod1_nb &lt;- MASS::glm.nb(\n  enfants_avt_30 ~ educ2 + milieu + region,\n  data = femmes30p\n)\n\nL’AIC étant défini pour pour ce type de modèle, nous pouvons procéder à une sélection pas à pas avec stats::step().\n\nmod1_nb &lt;- mod1_nb |&gt; step()\n\nStart:  AIC=979.1\nenfants_avt_30 ~ educ2 + milieu + region\n\n         Df Deviance    AIC\n- region  3   462.89 975.01\n&lt;none&gt;        460.98 979.10\n- milieu  1   463.29 979.41\n- educ2   2   466.11 980.22\n\nStep:  AIC=975\nenfants_avt_30 ~ educ2 + milieu\n\n         Df Deviance    AIC\n&lt;none&gt;        460.14 975.00\n- milieu  1   463.37 976.24\n- educ2   2   465.54 976.40\n\n\nLa fonction de lien étant toujours logarithmique, nous pouvons donc afficher plutôt l’exponentielle des coefficients qui s’interprètent comme pour un modèle de Poisson.\n\nmod1_nb |&gt; \n  tbl_regression(exponentiate = TRUE) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaractéristique\n\nIRR\n1\n\n\n95% IC\n1\n\np-valeur\n\n\n\nNiveau d'éducation\n\n\n\n\n\n    aucun\n—\n—\n\n\n\n    primaire\n1,23\n0,82 – 1,82\n0,3\n\n\n    secondaire/supérieur\n0,53\n0,25 – 1,03\n0,074\n\n\nMilieu de résidence\n\n\n\n\n\n    urbain\n—\n—\n\n\n\n    rural\n1,41\n0,97 – 2,06\n0,076\n\n\n\n\n1\nIRR = rapport de taux d’incidence, IC = intervalle de confiance\n\n\n\n\n\n\n\n\nTable 45.5: Tableau des coefficients du modèle binomial négatif\n\n\n\nCette fois-ci, les coefficients sont légèrement différents par rapport au modèle de Poisson, ce qui se voit aisément si l’on compare les trois modèles.\n\nlist(\n  Poisson = mod1_poisson,\n  \"quasi-Poisson\" = mod1_quasi,\n  \"Binomial négatif\" = mod1_nb\n) |&gt;\n  ggcoef_compare(exponentiate = TRUE)\n\n\n\n\n\n\nFigure 45.5: Comparaison des coefficients du modèle de Poisson, du modèle de quasi-Poisson et du modèle binomial négatif\n\n\n\n\nNous pouvons comparer la distribution observée et la distribution théorique et constater que les prédictions sont plus proches des données observées.\n\nmod1_nb |&gt;\n  observed_vs_theoretical()\nmod1_nb |&gt;\n  performance::check_predictions(type = \"discrete_both\")\n\n\n\n\n\n\nFigure 45.6: Distribution observée vs distribution théorique de la descendance atteinte à 30 ans (modèle négatif binomial)\n\n\n\n\n\n\n\n\n\nFigure 45.7: Distribution observée vs distribution théorique de la descendance atteinte à 30 ans (modèle négatif binomial)\n\n\n\n\nNous pouvons vérifier la surdispersion.\n\nmod1_nb |&gt; \n  performance::check_overdispersion()\n\n# Overdispersion test\n\n dispersion ratio = 0.975\n          p-value = 0.856\n\n\nNo overdispersion detected.\n\n\nOuf ! Nous n’avons plus de problème de surdispersion.\nPour celles et ceux intéressé·es, il est possible de comparer la performance des modèles avec la fonction performance::compare_performance().\n\nperformance::compare_performance(\n  mod1_poisson,\n  mod1_nb,\n  metrics = \"common\"\n)\n\n# Comparison of Model Performance Indices\n\nName         |  Model |  AIC (weights) |  BIC (weights) | Nagelkerke's R2 |  RMSE\n---------------------------------------------------------------------------------\nmod1_poisson |    glm | 1010.7 (&lt;.001) | 1029.4 (&lt;.001) |           0.033 | 0.579\nmod1_nb      | negbin |  977.0 (&gt;.999) | 1000.5 (&gt;.999) |           0.032 | 0.579",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Modèles de comptage (Poisson & apparentés)</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/modeles-comptage.html#exemple-avec-une-plus-grande-surdispersion",
    "href": "analyses_avancees/modeles-comptage.html#exemple-avec-une-plus-grande-surdispersion",
    "title": "45  Modèles de comptage (Poisson & apparentés)",
    "section": "\n45.4 Exemple avec une plus grande surdispersion",
    "text": "45.4 Exemple avec une plus grande surdispersion\nPour ce second exemple, nous allons considérer le jeu de données MASS::quine qui contient les données de 146 enfants scolarisés en Australie, notamment le nombre de jours d’absence à l’école au cours de l’année passée, le sexe l’enfant et leur vitesse d’apprentissage (dans la moyenne ou lentement).\nPréparons les données en francisant les facteurs et en ajoutant des étiquettes de variable.\n\nd &lt;- MASS::quine |&gt;\n  mutate(\n    jours = Days,\n    sexe = Sex |&gt;\n      fct_recode(\n        \"fille\" = \"F\",\n        \"garçon\" = \"M\"\n      ),\n    apprentissage = Lrn |&gt;\n      fct_recode(\n        \"dans la moyenne\" = \"AL\",\n        \"lentement\" = \"SL\"\n      )\n  ) |&gt;\n  set_variable_labels(\n    jours = \"Nombre de jours d'absence à l'école\",\n    sexe = \"Sexe de l'enfant\",\n    apprentissage = \"Vitesse d'apprentissage\"\n  )\n\nCalculons notre modèle de Poisson.\n\nmod2_poisson &lt;- glm(\n  jours ~ sexe + apprentissage,\n  data = d,\n  family = poisson\n)\n\nComparons les données observées avec les données prédites.\n\nmod2_poisson |&gt; \n  observed_vs_theoretical()\n\n\n\n\n\n\nFigure 45.8: Distribution observée vs distribution théorique du nombre de jours d’absence (modèle de Poisson)\n\n\n\n\nNous voyons très clairement un décalage des deux distributions. Notre modèle de Poisson n’arrive pas à capturer la variabilité des observations. Faisons le test de surdispersion pour vérifier4.\n4 Il est possible que l’installation du package DHARMa soit requise pour la bonne réalisation du test.\n\n\n\nmod2_poisson |&gt; \n  performance::check_overdispersion()\n\n# Overdispersion test\n\n       dispersion ratio =   15.895\n  Pearson's Chi-Squared = 2273.046\n                p-value =  &lt; 0.001\n\n\nOverdispersion detected.\n\n\nCalculons un modèle binomial négatif et voyons si cela améliore la situation.\n\nmod2_nb &lt;- MASS::glm.nb(\n  jours ~ sexe + apprentissage,\n  data = d\n)\n\n\nmod2_nb |&gt; \n  observed_vs_theoretical()\n\n\n\n\n\n\nFigure 45.9: Distribution observée vs distribution théorique du nombre de jours d’absence (modèle binomial négatif)\n\n\n\n\nLes deux distributions sont bien plus proches maintenant. Vérifions la surdispersion.\n\nmod2_nb |&gt; \n  performance::check_overdispersion()\n\n# Overdispersion test\n\n dispersion ratio = 0.978\n          p-value = 0.992\n\n\nNo overdispersion detected.\n\n\nVoilà !\nPour finir, visualisons les coefficients du modèle.\n\nmod2_nb |&gt; \n  ggcoef_table(exponentiate = TRUE)\n\n\n\n\n\n\nFigure 45.10: Facteurs associés à l’absentéisme scolaire (modèle négatif binomial)",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Modèles de comptage (Poisson & apparentés)</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/modeles-comptage.html#modèles-de-comptage-avec-une-variable-binaire",
    "href": "analyses_avancees/modeles-comptage.html#modèles-de-comptage-avec-une-variable-binaire",
    "title": "45  Modèles de comptage (Poisson & apparentés)",
    "section": "\n45.5 Modèles de comptage avec une variable binaire",
    "text": "45.5 Modèles de comptage avec une variable binaire\nPour l’analyse d’une variable binaire, les modèles de comptage représentent une alternative à la régression logistique binaire (cf. Chapitre 22). L’intérêt est de pouvoir interpréter les coefficients comme des prevalence ratio plutôt que des odds ratio.\nReprenons un exemple, que nous avons déjà utilisé à plusieurs reprises, concernant la probabilité de faire du sport, à partir de l’enquête histoires de vie 2003. Commençons par charger et recoder les données.\n\ndata(hdv2003, package = \"questionr\")\n\nd &lt;-\n  hdv2003 |&gt; \n  mutate(\n    groupe_ages = age |&gt;\n      cut(\n        c(18, 25, 45, 65, 99),\n        right = FALSE,\n        include.lowest = TRUE,\n        labels = c(\"18-24 ans\", \"25-44 ans\",\n                   \"45-64 ans\", \"65 ans et plus\")\n      )\n  ) |&gt; \n  set_variable_labels(\n    sport = \"Pratique un sport ?\",\n    sexe = \"Sexe\",\n    groupe_ages = \"Groupe d'âges\",\n    heures.tv = \"Heures de télévision / jour\"\n  )\n\nPour la variable sexe, nous allons définir la modalité Femme comme modalité de référence. Pour cela, nous allons utiliser un contraste personnalisé (cf. Chapitre 25).\n\nlevels(d$sexe)\n\n[1] \"Homme\" \"Femme\"\n\ncontrasts(d$sexe) &lt;- contr.treatment(2, base = 2)\n\nCalculons le modèle de régression logistique binaire classique.\n\nmod3_binomial &lt;- glm(\n  sport ~ sexe + groupe_ages + heures.tv,\n  family = binomial,\n  data = d\n)\n\nNous allons maintenant calculer un modèle de Poisson. Nous devons déjà ré-exprimer notre variable à expliquer sous la forme d’une variable numérique égale à 0 si l’on ne pratique pas de sport et à 1 si l’on pratique un sport.\n\nlevels(d$sport)\n\n[1] \"Non\" \"Oui\"\n\nd$sport2 &lt;- as.integer(d$sport == \"Oui\")\nmod3_poisson &lt;- glm(\n  sport2 ~ sexe + groupe_ages + heures.tv,\n  family = poisson,\n  data = d\n)\n\nVérifions si nous avons un problème de surdispersion.\n\nperformance::check_overdispersion(mod3_poisson)\n\n# Overdispersion test\n\n       dispersion ratio =    0.635\n  Pearson's Chi-Squared = 1263.552\n                p-value =        1\n\n\nNo overdispersion detected.\n\n\nRegardons maintenant les résultats de nos deux modèles.\n\nmod3_binomial |&gt; \n  ggstats::ggcoef_table(exponentiate = TRUE)\n\n\n\n\n\n\nFigure 45.11: Facteurs associés à la pratique d’un sport (régression logistique)\n\n\n\n\n\nmod3_poisson |&gt; \n  ggstats::ggcoef_table(exponentiate = TRUE)\n\n\n\n\n\n\nFigure 45.12: Facteurs associés à la pratique d’un sport (régression de Poisson)\n\n\n\n\nNous pouvons voir ici que les deux modèles fournissent des résultats assez proches. Par contre, les coefficients ne s’interprètent pas de la même manière. Dans le cadre de la régression logistique, il s’agit d’odds ratios (ou rapports des côtes) définis comme \\(OR_{A/B}=(\\frac{p_A}{1-p_A})/(\\frac{p_B}{1-p_B})\\) où \\(p_A\\) correspond à la probabilité de faire du sport pour la modalité \\(A\\). Pour la régression de Poisson, il s’agit de prevalence ratios (rapports des prévalences) définis comme \\(PR_{A/B}=p_A/p_B\\). Avec un rapport des prévalences de 1,3, nous pouvons donc dire que, selon le modèle, les hommes ont 30% de chance en plus de pratiquer un sport.\nPour mieux comparer les deux modèles, nous pouvons présenter les résultats sous la forme de contrastes marginaux moyens (cf. Section 24.4) qui, pour rappel, sont exprimés dans l’échelle de la variable d’intérêt, soit ici sous la forme d’une différence de probabilité.\n\nlist(\n  \"régression logistique\" = mod3_binomial,\n  \"régression de Poisson\" = mod3_poisson\n) |&gt; \n  ggcoef_compare(tidy_fun = broom.helpers::tidy_marginal_contrasts) +\n  scale_x_continuous(labels = scales::label_percent(suffix = \"pp\"))\n\n\n\n\n\n\nFigure 45.13: Comparaison des contrastes marginaux des deux modèles\n\n\n\n\nLes résultats sont ici très proches. Nous pouvons néanmoins constater que les intervalles de confiance pour la régression de Poisson sont un peu plus large. Nous pouvons comparer les deux modèles avec performance::compare_performance() pour constater que, dans notre exemple, la régression de Poisson est un peu moins bien ajustée aux données que la régression logistique binaire. Cependant, en pratique, cela n’est pas ici problématique : le choix entre les deux modèles peut donc se faire en fonction de la manière dont on souhaite présenter et narrer les résultats.\n\nperformance::compare_performance(\n  mod3_binomial,\n  mod3_poisson,\n  metrics = \"common\"\n)\n\nWarning: contrasts dropped from factor sexe\nWarning: contrasts dropped from factor sexe\nWarning: contrasts dropped from factor sexe\nWarning: contrasts dropped from factor sexe\n\n\n# Comparison of Model Performance Indices\n\nName          | Model |  AIC (weights) |  BIC (weights) |  RMSE | Tjur's R2 | Nagelkerke's R2\n---------------------------------------------------------------------------------------------\nmod3_binomial |   glm | 2346.3 (&gt;.999) | 2379.8 (&gt;.999) | 0.447 |     0.132 |                \nmod3_poisson  |   glm | 2748.8 (&lt;.001) | 2782.4 (&lt;.001) | 0.447 |           |           0.158\n\n\n\n\n\n\n\n\nAstuce\n\n\n\nLorsque l’on a une variable binaire à expliquer et que l’on souhaite calculer des risques relatifs (RR) ou prevalence ratio (PR), une alternative au modèle de Poisson est le modèle log-binomial. Il s’agit d’un modèle binomial avec une fonction de lien logarithme.\nIl faut noter que ce type de modèles a parfois du mal à converger.\n\nmod3_log &lt;- glm(\n  sport ~ sexe + groupe_ages + heures.tv,\n  family = binomial(link = \"log\"),\n  data = d\n)\n\nError: impossible de trouver un jeu de coefficients correct : prière de fournir des valeurs initiales\n\n\nC’est le cas ici ! Nous allons donc initier le modèle avec les coefficients du modèle de Poisson.\n\nmod3_log &lt;- glm(\n  sport ~ sexe + groupe_ages + heures.tv,\n  family = binomial(link = \"log\"),\n  start = mod3_poisson$coefficients,\n  data = d\n)\n\nRegardons les résultats.\n\nmod3_log |&gt;\n  ggstats::ggcoef_table(exponentiate = TRUE)\n\nWarning: le pas a été tronqué à cause de la divergence\nWarning: le pas a été tronqué à cause de la divergence\n\n\nWarning: glm.fit : l'algorithme n'a pas convergé\nWarning: glm.fit : l'algorithme n'a pas convergé\n\n\nWarning: le pas a été tronqué à cause de la divergence\n\n\nWarning: glm.fit : l'algorithme n'a pas convergé\n\n\n\n\n\n\n\n\nNous obtenons des résultats assez proches de ceux du modèle de Poisson. Notons cependant les différents avis affichés qui nous indiquent que le modèle a eu des difficultés à converger5.\nLe package logbin propose, via logbin::logbin(), une implémentation de la régression log-binomiale en proposant des algorithmes de convergence plus stables.\n\nmod3_logbin &lt;- logbin::logbin(\n  sport ~ sexe + groupe_ages + heures.tv,\n  data = d\n)\n\nLes résultats sont très proches.\n\nmod3_logbin |&gt;\n  ggstats::ggcoef_table(exponentiate = TRUE)\n\nWarning: The `tidy()` method for objects of class `logbin` is not maintained by the broom team, and is only supported through the `glm` tidier method. Please be cautious in interpreting and reporting broom output.\n\nThis warning is displayed once per session.\n\n\n\n\n\n\n\n\n\n\n5 Sur ce sujet, on pourra consulter l’article Log-binomial models: exploring failed convergence par Tyler Williamson, Misha Eliasziw et Gordon Hilton Fick, DOI: 10.1186/1742-7622-10-14. On pourra également consulter cet échange sur StackExchange.",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Modèles de comptage (Poisson & apparentés)</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/modeles-comptage.html#données-pondérées-et-plan-déchantillonnage",
    "href": "analyses_avancees/modeles-comptage.html#données-pondérées-et-plan-déchantillonnage",
    "title": "45  Modèles de comptage (Poisson & apparentés)",
    "section": "\n45.6 Données pondérées et plan d’échantillonnage",
    "text": "45.6 Données pondérées et plan d’échantillonnage\nLorsque l’on a des données pondérées avec prise en compte d’un plan d’échantillonnage (cf. Chapitre 28), on ne peut utiliser directement stats::glm() avec un objet survey. On aura alors recours à survey::svyglm() qui est très similaire.\n\nlibrary(srvyr)\nlibrary(survey)\ndp &lt;- d |&gt; \n  as_survey_design(weights = poids)\nmod4_poisson &lt;- svyglm(\n  sport2 ~ sexe + groupe_ages + heures.tv,\n  family = poisson,\n  design = dp\n)\nmod4_quasi &lt;- svyglm(\n  sport2 ~ sexe + groupe_ages + heures.tv,\n  family = quasipoisson,\n  design = dp\n)\n\nIl est tout à fait possible d’appliquer stats::step() à ces modèles6.\n6 Y compris, dans le cas présent, au modèle de quasi-Poisson.Concernant la régression binomiale négative, il n’y a pas d’implémentation fournie directement par survey. Cependant, le package sjstats en propose une via la fonction sjstats::svyglm.nb().\n\nmod4_nb &lt;- sjstats::svyglm.nb(\n  sport2 ~ sexe + groupe_ages + heures.tv,\n  design = dp\n)\n\nWarning in theta.ml(Y, mu, sum(w), w, limit = control$maxit, trace =\ncontrol$trace &gt; : nombre limite d'iterations atteint\nWarning in theta.ml(Y, mu, sum(w), w, limit = control$maxit, trace =\ncontrol$trace &gt; : nombre limite d'iterations atteint\n\n\n\n\n\n\n\n\nNote\n\n\n\nUne alternative possible consiste à utiliser des poids de réplication selon une approche du type bootsrap. Il faudra déjà définir des poids de réplication avec srvyr::as_survey_rep() puis avoir recours à survey::withReplicates(). Pour faciliter cette deuxième étape, on pourra se faciliter la vie avec le package svrepmisc et sa fonction svrepmisc::svynb(). Ce package n’étant pas disponible sur CRAN, on devra l’installer avec la commande remotes::install_github(\"carlganz/svrepmisc\").\nAttention : le temps de calcul du modèle avec les poids de réplication est de plusieurs minutes.\n\ndp_rep &lt;- dp |&gt; \n  as_survey_rep(type = \"bootstrap\", replicates = 100)\nmod4_nb_alt &lt;- svrepmisc::svynb(\n  sport2 ~ sexe + groupe_ages + heures.tv,\n  design = dp_rep\n)",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Modèles de comptage (Poisson & apparentés)</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/modeles-comptage.html#tutomate",
    "href": "analyses_avancees/modeles-comptage.html#tutomate",
    "title": "45  Modèles de comptage (Poisson & apparentés)",
    "section": "\n45.7 Tuto@Mate",
    "text": "45.7 Tuto@Mate\nLes modèles de comptage sont présentés sur YouTube dans le Tuto@Mate#62.",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Modèles de comptage (Poisson & apparentés)</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/modeles-comptage.html#lectures-complémentaires",
    "href": "analyses_avancees/modeles-comptage.html#lectures-complémentaires",
    "title": "45  Modèles de comptage (Poisson & apparentés)",
    "section": "\n45.8 Lectures complémentaires",
    "text": "45.8 Lectures complémentaires\n\nTutoriel : GLM sur données de comptage (régression de Poisson) avec R par Claire Della Vedova\nTutorial: Poisson Regression in R (en anglais) par Hafsa Jabeen\nQuasi-Poisson vs. negative binomial regression: how should we model overdispersed count data? par Jay M Ver Hoef et Peter L Boveng, Ecology. 2007 Nov; 88(11):2766-72. doi: 10.1890/07-0043.1. PMID: 18051645\n\n\n\n\nFigure 45.1: Forest plot des coefficients du modèle de Poisson\nFigure 45.2: Prédictions marginales du modèle de Poisson\nFigure 45.3: Distribution observée vs distribution théorique de la descendance atteinte à 30 ans (modèle de Poisson)\nFigure 45.4: Comparaison des coefficients du modèle de Poisson et du modèle de quasi-Poisson\nFigure 45.5: Comparaison des coefficients du modèle de Poisson, du modèle de quasi-Poisson et du modèle binomial négatif\nFigure 45.6: Distribution observée vs distribution théorique de la descendance atteinte à 30 ans (modèle négatif binomial)\nFigure 45.7: Distribution observée vs distribution théorique de la descendance atteinte à 30 ans (modèle négatif binomial)\nFigure 45.8: Distribution observée vs distribution théorique du nombre de jours d’absence (modèle de Poisson)\nFigure 45.9: Distribution observée vs distribution théorique du nombre de jours d’absence (modèle binomial négatif)\nFigure 45.10: Facteurs associés à l’absentéisme scolaire (modèle négatif binomial)\nFigure 45.11: Facteurs associés à la pratique d’un sport (régression logistique)\nFigure 45.12: Facteurs associés à la pratique d’un sport (régression de Poisson)\nFigure 45.13: Comparaison des contrastes marginaux des deux modèles",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Modèles de comptage (Poisson & apparentés)</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/modeles-incidence.html",
    "href": "analyses_avancees/modeles-incidence.html",
    "title": "46  Modèles d’incidence / de taux",
    "section": "",
    "text": "46.1 Premier exemple (données individuelles, évènement unique)\nPrenons un premier exemple à partir du jeux de données gtsummary::trial qui contient des informations sur 200 patients atteints d’un cancer. Il contient entre autre les variables suivantes :\nNous nous intéressons donc aux facteurs associés au taux de mortalité (death/ttdeath) : nous allons donc réaliser un modèle de Poisson sur la variable death en ajoutant un décalage (offset) correspondant à log(ttdeath).",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Modèles d'incidence / de taux</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/modeles-incidence.html#premier-exemple-données-individuelles-évènement-unique",
    "href": "analyses_avancees/modeles-incidence.html#premier-exemple-données-individuelles-évènement-unique",
    "title": "46  Modèles d’incidence / de taux",
    "section": "",
    "text": "death : variable binaire (0/1) indiquant si le patient est décédé\nttdeath : le nombre de mois d’observation jusqu’au décès (si décès) ou jusqu’à la fin de l’étude (si survie)\nstage : un facteur indiquant le stade T de la tumeur (plus la valeur est élevée, plus la tumeur est grosse)\ntrt : le traitement reçu par le patient (A ou B)\nresponse : une variable binaire (0/1) indiquant si le traitement a eu un effet sur la tumeur (diminution)\n\n\n\n46.1.1 Statistiques descriptives\nPour réaliser un tableau des incidences, nous aurons recours à gtsummary::tbl_custom_summary() qui permets de réaliser des tableaux avancés avec des statistiques personnalisées. Nous allons utiliser cette fonction en combinaison avec gtsummary::ratio_summary() qui permet de calculer le ratio de deux variables ainsi que des intervalles de confiance à 95% via la fonction poisson.test(). Nous allons exprimer les taux d’incidence pour 100 personne-mois (pm, person-months en anglais).\nN’oublions pas, en amont, de recoder la variable response en un facteur.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntrial &lt;- gtsummary::trial |&gt; \n  mutate(\n    response = response |&gt; \n      as_factor() |&gt; \n      fct_recode(no = \"0\", yes = \"1\")\n  ) |&gt; \n  labelled::set_variable_labels(response = \"Tumor Response\")\n\n\nlibrary(gtsummary)\n\n\nAttachement du package : 'gtsummary'\n\n\nL'objet suivant est masqué _par_ '.GlobalEnv':\n\n    trial\n\npercent2 &lt;- scales::label_percent(accuracy = .01, suffix = \"\")\ntrial |&gt; \n  tbl_custom_summary(\n    include = c(stage, trt, response),\n    stat_fns = ~ ratio_summary(\"death\", \"ttdeath\"),\n    statistic = ~\"{ratio}/100pm [{conf.low} - {conf.high}] ({num}/{denom})\",\n    digits = ~ c(percent2, percent2, percent2, 0, 0),\n    overall_row = TRUE,\n    overall_row_label = \"Overall\"\n  ) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nN = 200\n1\n\n\n\n\nOverall\n2.85/100pm [2.35 - 3.43] (112/3,925)\n\n\nT Stage\n\n\n\n    T1\n2.17/100pm [1.39 - 3.23] (24/1,105)\n\n\n    T2\n2.48/100pm [1.63 - 3.61] (27/1,089)\n\n\n    T3\n2.58/100pm [1.62 - 3.91] (22/852)\n\n\n    T4\n4.43/100pm [3.15 - 6.06] (39/879)\n\n\nChemotherapy Treatment\n\n\n\n    Drug A\n2.62/100pm [1.96 - 3.44] (52/1,983)\n\n\n    Drug B\n3.09/100pm [2.36 - 3.98] (60/1,942)\n\n\nTumor Response\n1.85/100pm [1.19 - 2.76] (24/1,296)\n\n\n    Unknown\n7\n\n\n\n\n1\nratio/100pm [conf.low - conf.high] (num/denom)\n\n\n\n\n\n\n\n\nTable 46.1: Taux de mortalité (pour 100 personne-mois) selon différents prédicteurs\n\n\n\nIl n’existe pas de méthode add_p() utilisable ici. Nous verrons un peu plus loin (cf. Section 46.1.3) comment réaliser des modèles univariables qui permettront de calculer la relation de chaque prédicteur avec l’outcome avant ajustement.\n\n46.1.2 Calcul et interprétation du modèle multivariable\nPour ajouter un décalage, nous avons deux syntaxes équivalentes : soit en ajoutant offset(log(ttdeath)) directement à l’équation du modèle, soit en passant à glm() l’argument offset = log(ttdeath).\n\nmod1_poisson &lt;- glm(\n  death ~ stage + trt + response + offset(log(ttdeath)),\n  family = poisson,\n  data = trial\n)\nmod1_poisson_alt &lt;- glm(\n  death ~ stage + trt + response,\n  offset = log(ttdeath),\n  family = poisson,\n  data = trial\n)\n\nLes deux écritures sont totalement équivalentes.\nVérifions la présence éventuelle de surdispersion.\n\nmod1_poisson |&gt; \n  performance::check_overdispersion()\n\n# Overdispersion test\n\n       dispersion ratio =   0.850\n  Pearson's Chi-Squared = 159.039\n                p-value =   0.932\n\n\nNo overdispersion detected.\n\n\nTout est bon. Regardons maintenant les coefficients du modèle.\n\nmod1_poisson |&gt; \n  ggstats::ggcoef_table(exponentiate = TRUE)\n\n\n\n\n\n\nFigure 46.1: Facteurs associés à la mortalité des patients atteints d’un cancer (modèle de Poisson)\n\n\n\n\nNous avons affiché ici l’exponentielle des coefficients qui s’interprètent ici comme des IRR ou incidence rate ratio : le taux de décès est deux fois moindre pour les patients pour lesquels le traitement a eu un effet sur la tumeur (variable Tumor response). Sans surprise, le taux de décès est bien plus élevé selon la taille de la tumeur : 2,1 fois plus important pour ceux avec une tumeur au stade T4 par rapport à ceux ayant une tumeur au stade T1.\n\n46.1.3 Modèles univariables\nPour tester les associations bivariées, nous pouvons avoir recours à des régressions univariables, que nous avons déjà abordé dans le chapitre sur la régression logistique binaire (cf. Section 22.9).\nPour cela, nous allons tout simplement appeler gtsummary::tbl_uvregression() avec gtsummary::add_global_p() pour obtenir des p-valeurs globales indiquant si chaque variable prédictive est associée à la mortalité (sans ajustement sur les autres variables).\n\ntrial |&gt; \n  tbl_uvregression(\n    y = death,\n    include = c(stage, trt, response),\n    method = glm,\n    method.args = list(\n      family = poisson,\n      offset = log(ttdeath)\n    ),\n    exponentiate = TRUE\n  ) |&gt; \n  add_global_p() |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN\n\nIRR\n1\n\n\n95% CI\n1\n\np-value\n\n\n\nT Stage\n200\n\n\n0.025\n\n\n    T1\n\n—\n—\n\n\n\n    T2\n\n1.14\n0.66, 1.99\n\n\n\n    T3\n\n1.19\n0.66, 2.12\n\n\n\n    T4\n\n2.04\n1.24, 3.44\n\n\n\nChemotherapy Treatment\n200\n\n\n0.4\n\n\n    Drug A\n\n—\n—\n\n\n\n    Drug B\n\n1.18\n0.81, 1.71\n\n\n\nTumor Response\n193\n\n\n0.008\n\n\n    no\n\n—\n—\n\n\n\n    yes\n\n0.56\n0.35, 0.86\n\n\n\n\n\n1\nIRR = Incidence Rate Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\nTable 46.2: Facteurs associés à la mortalité des patients atteints d’un cancer (régressions univariables)",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Modèles d'incidence / de taux</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/modeles-incidence.html#deuxième-exemple-données-agrégées",
    "href": "analyses_avancees/modeles-incidence.html#deuxième-exemple-données-agrégées",
    "title": "46  Modèles d’incidence / de taux",
    "section": "\n46.2 Deuxième exemple (données agrégées)",
    "text": "46.2 Deuxième exemple (données agrégées)\nPour ce second exemple, nous allons considérer le jeu de données MASS::Insurance qui provient d’une compagnie d’assurance américaine et porte sur le troisième trimestre 1973. Il indique le nombre de demande d’indemnisations (Claims) parmi les assurés pour leur voiture (Holders) en fonction de leur groupe d’âges (Age) et de la taille de la cylindrée de la voiture (Group). Nous cherchons à identifier les facteurs associés au taux de réclamation. Préparons rapidement les données et définissons notre modèle.\n\nd &lt;- MASS::Insurance\nd$Age &lt;- factor(d$Age, ordered = FALSE)\nd$Group &lt;- factor(d$Group, ordered = FALSE)\nmod2_poisson &lt;- glm(\n  Claims ~ Age + Group + offset(log(Holders)),\n  family = poisson,\n  data = d\n)\nmod2_poisson |&gt; \n  performance::check_overdispersion()\n\n# Overdispersion test\n\n       dispersion ratio =  1.140\n  Pearson's Chi-Squared = 65.003\n                p-value =  0.218\n\n\nNo overdispersion detected.\n\n\nRegardons les résultats.\n\nmod2_poisson |&gt; \n  ggstats::ggcoef_table(exponentiate = TRUE)\n\n\n\n\n\n\nFigure 46.2: Facteurs associés au taux de réclamation (modèle de Poisson)\n\n\n\n\nLe taux de réclamation diminue avec l’âge de l’assuré (il est 40% moindre pour les assurés de plus de 35 ans par rapport à ceux de moins de 25 ans) et augmente avec la cylindrée de la voiture (il est 80% plus élevé pour les véhicules avec une cylindrée de plus de 2 litres par rapport aux véhicules avec une cylindrée de moins d’1 litre).",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Modèles d'incidence / de taux</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/modeles-incidence.html#troisième-exemple-données-individuelles-évènement-unique",
    "href": "analyses_avancees/modeles-incidence.html#troisième-exemple-données-individuelles-évènement-unique",
    "title": "46  Modèles d’incidence / de taux",
    "section": "\n46.3 Troisième exemple (données individuelles, évènement unique)",
    "text": "46.3 Troisième exemple (données individuelles, évènement unique)\nPour notre troisième exemple, nous allons reprendre les données de fécondité présentée au chapitre précédent (cf. Chapitre 45) et venant d’une enquête transversale rétrospective menée auprès de femmes âgées de 15 à 49 ans.\nNous allons nous intéresser au taux de fécondité entre 15 et 24 ans révolus (soit entre 15 et 25 ans exacts) et intégrer à l’analyse les femmes de moins de 25 ans en tenant compte de leur durée d’exposition (différence entre l’âge à l’enquête et 15 ans). Nous allons donc calculer la durée d’exposition comme exposition = if_else(age &lt;= 25, age - 15, 10) puisque, pour les femmes de plus de 25 ans à l’enquête, la durée d’exposition entre 15 et 25 ans exacts est de 10 ans.\n\nlibrary(tidyverse)\nlibrary(labelled)\ndata(\"fecondite\", package = \"questionr\")\nfemmes &lt;-\n  femmes |&gt; \n  unlabelled() |&gt; \n  mutate(\n    age = time_length(\n      date_naissance %--% date_entretien,\n      unit = \"years\"\n    ),\n    exposition = if_else(age &lt;= 25, age - 15, 10),\n    educ2 = educ |&gt; \n      fct_recode(\n        \"secondaire/supérieur\" = \"secondaire\",\n        \"secondaire/supérieur\" = \"supérieur\"\n      )\n  ) |&gt; \n  # exclure celles qui viennent juste d'avoir 15 ans\n  filter(exposition &gt; 0)\n\nComptons maintenant le nombre de naissances entre 15 et 25 ans exacts.\n\nenfants &lt;-\n  enfants |&gt; \n  unlabelled() |&gt; \n  left_join(\n    femmes |&gt;\n      select(id_femme, date_naissance_mere = date_naissance),\n    by = \"id_femme\"\n  ) |&gt;\n  mutate(\n    age_mere = time_length(\n      date_naissance_mere %--% date_naissance,\n      unit = \"years\"\n    )\n  )\nfemmes &lt;-\n  femmes |&gt; \n  left_join(\n    enfants |&gt; \n      filter(age_mere &gt;= 15 & age_mere &lt; 25) |&gt; \n      group_by(id_femme) |&gt; \n      count(name = \"enfants_15_24\"),\n    by = \"id_femme\"\n  ) |&gt; \n  tidyr::replace_na(list(enfants_15_24 = 0L))\n\nCalculons maintenant notre modèle.\n\nmod3_poisson &lt;- glm(\n  enfants_15_24 ~ educ2 + milieu + offset(log(exposition)),\n  family = poisson,\n  data = femmes\n)\n\nVérifions la surdispersion.\n\nmod3_poisson |&gt;\n  performance::check_overdispersion()\n\n# Overdispersion test\n\n       dispersion ratio =    1.368\n  Pearson's Chi-Squared = 2723.252\n                p-value =  &lt; 0.001\n\n\nOverdispersion detected.\n\n\nLe test indique de la surdispersion. Optons donc pour un modèle négatif binomial.\n\nmod3_nb &lt;- MASS::glm.nb(\n  enfants_15_24 ~ educ2 + milieu + offset(log(exposition)),\n  data = femmes\n)\nmod3_nb |&gt;\n  performance::check_overdispersion()\n\n# Overdispersion test\n\n dispersion ratio = 0.822\n          p-value = 0.016\n\n\nUnderdispersion detected.\n\n\nNous pouvons maintenant regarder les résultats.\n\nmod3_nb |&gt; \n  ggstats::ggcoef_table(exponentiate = TRUE)\n\n\n\n\n\n\nFigure 46.3: Facteurs associés au taux de fécondité entre 15 et 25 ans (modèle négatif binomial)",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Modèles d'incidence / de taux</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/modeles-incidence.html#tutomate",
    "href": "analyses_avancees/modeles-incidence.html#tutomate",
    "title": "46  Modèles d’incidence / de taux",
    "section": "\n46.4 Tuto@Mate",
    "text": "46.4 Tuto@Mate\nLes modèles d’incidence sont présentés sur YouTube dans le Tuto@Mate#62.",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Modèles d'incidence / de taux</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/modeles-incidence.html#lectures-complémentaires",
    "href": "analyses_avancees/modeles-incidence.html#lectures-complémentaires",
    "title": "46  Modèles d’incidence / de taux",
    "section": "\n46.5 Lectures complémentaires",
    "text": "46.5 Lectures complémentaires\n\n\nTutoriel : GLM sur données de comptage (régression de Poisson) avec R par Claire Della Vedova\n\nZoom sur la Regression de Poisson et l’Incidence Risque Ratio (IRR) : exemple du vaccin anti-SarsCov2 d’Oxford par Ihsane Hmamouchi\n\n\n\n\nFigure 46.1: Facteurs associés à la mortalité des patients atteints d’un cancer (modèle de Poisson)\nFigure 46.2: Facteurs associés au taux de réclamation (modèle de Poisson)\nFigure 46.3: Facteurs associés au taux de fécondité entre 15 et 25 ans (modèle négatif binomial)",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Modèles d'incidence / de taux</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/modeles-zero-inflated.html",
    "href": "analyses_avancees/modeles-zero-inflated.html",
    "title": "47  Modèles de comptage zero-inflated et hurdle",
    "section": "",
    "text": "47.1 Données d’illustration\nDans ce chapitre, nous allons utiliser un jeu de données issu d’un article de Partha Deb et Pravin K. Trivedi (Deb et Trivedi 1997). Ce jeu de données porte sur 4406 individus âgés de 66 ans ou plus et couvert par le programme américain Medicare.\nL’analyse va porter sur la demande de soins, mesurée ici à travers le nombre de visites médicales (ofp). Pour les variables explicatives, nous allons considérer le genre du patient (gender), le fait de disposer d’une assurance privée (privins), la santé perçue (health) et le nombre de conditions chroniques de l’assuré.\nChargeons et préparons rapidement les données. Nous allons recoder les variables catégorielles en français (Section 9.3) et ajouter des étiquettes de variables (cf. Chapitre 11).\nlibrary(labelled)\nlibrary(tidyverse)\nload(url(\"https://github.com/larmarange/guide-R/raw/main/analyses_avancees/ressources/DebTrivedi.rda\"))\nd &lt;- DebTrivedi |&gt;\n  mutate(\n    gender = gender |&gt; \n      fct_recode(\"femme\" = \"female\", \"homme\" = \"male\"),\n    privins = privins |&gt;\n      fct_recode(\"non\" = \"no\", \"oui\" = \"yes\"),\n    health = health |&gt; \n      fct_recode(\n        \"pauvre\" = \"poor\",\n        \"moyenne\" = \"average\",\n        \"excellente\" = \"excellent\"\n      )\n  ) |&gt; \n  set_variable_labels(\n    ofp = \"Nombre de visites médicales\",\n    gender = \"Genre de l'assuré\",\n    privins = \"Dispose d'une assurance privée ?\",\n    health = \"Santé perçue\",\n    numchron = \"Nombre de conditions chroniques\"\n  )\ncontrasts(d$health) &lt;- contr.treatment(3, base = 2)",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Modèles de comptage *zero-inflated* et *hurdle*</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/modeles-zero-inflated.html#données-dillustration",
    "href": "analyses_avancees/modeles-zero-inflated.html#données-dillustration",
    "title": "47  Modèles de comptage zero-inflated et hurdle",
    "section": "",
    "text": "Deb, Partha, et Pravin K. Trivedi. 1997. « Demand for Medical Care by the Elderly: A Finite Mixture Approach ». Journal of Applied Econometrics 12 (3): 313‑36. https://doi.org/10.1002/(SICI)1099-1255(199705)12:3&lt;313::AID-JAE440&gt;3.0.CO;2-G.",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Modèles de comptage *zero-inflated* et *hurdle*</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/modeles-zero-inflated.html#modèles-de-comptage-classique",
    "href": "analyses_avancees/modeles-zero-inflated.html#modèles-de-comptage-classique",
    "title": "47  Modèles de comptage zero-inflated et hurdle",
    "section": "\n47.2 Modèles de comptage classique",
    "text": "47.2 Modèles de comptage classique\nCommençons tout d’abord par une approche classique (Chapitre 45) : calculons un modèle de Poisson et vérifions la surdispersion.\n\nmod_poisson &lt;- glm(\n  ofp ~ gender + privins + health + numchron,\n  family = poisson,\n  data = d\n)\nmod_poisson |&gt;\n  performance::check_overdispersion()\n\n# Overdispersion test\n\n       dispersion ratio =     7.103\n  Pearson's Chi-Squared = 31254.867\n                p-value =   &lt; 0.001\n\n\nOverdispersion detected.\n\n\nUne surdispersion étant détectée, basculons sur un modèle négatif binomial.\n\nmod_nb &lt;- MASS::glm.nb(\n  ofp ~ gender + privins + health + numchron,\n  data = d\n)\nmod_nb |&gt;\n  performance::check_overdispersion()\n\n# Overdispersion test\n\n dispersion ratio = 1.050\n          p-value =  0.36\n\n\nNo overdispersion detected.\n\n\nLe modèle négatif binomial ne règle pas notre problème de surdispersion. Comparons les valeurs observées avec les valeurs théoriques avec performance::check_predictions()1. Pour faciliter la lecture du graphique, nous allons zoomer sur les 20 premières valeurs.\n1 Nous aurions aussi pu utiliser la fonction observed_vs_theoretical() présentée dans le chapitre sur les modèles de comptage (cf. Section 45.1.4).\nmod_nb |&gt; \n  performance::check_predictions() |&gt; \n  plot() +\n  xlim(0, 20)\n\n\n\n\n\n\nFigure 47.1: Comparaison des valeurs observées et des valeurs théoriques\n\n\n\n\nComme nous pouvons le voir sur ce graphique, le nombre de 0 prédit par le modèle est inférieur à celui observé. Cela signifie que les 0 sont sur-représentés dans nos données par rapport à une distribution négative binomiale. Ces 0 ont tendance à tirer la moyenne vers le bas. Dès lors, le nombre de 1 et de 2 prédits par le modèle sont quant à eux sur-représentés par rapport aux données observées. On dit alors qu’il y a une inflation de zéros dans les données (zero-inflated en anglais).\nOn peut essayer de regarder s’il y a une sous- ou une sur-représentation de zéros avec la fonction performance::check_zeroinflation().\n\nmod_nb |&gt; \n  performance::check_zeroinflation(tolerance = 0.05)\n\n# Check for zero-inflation\n\n   Observed zeros: 683\n  Predicted zeros: 620\n            Ratio: 0.91\n\n\nModel is underfitting zeros (probable zero-inflation) (p &lt; .001).",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Modèles de comptage *zero-inflated* et *hurdle*</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/modeles-zero-inflated.html#modèles-zero-inflated",
    "href": "analyses_avancees/modeles-zero-inflated.html#modèles-zero-inflated",
    "title": "47  Modèles de comptage zero-inflated et hurdle",
    "section": "\n47.3 Modèles zero-inflated\n",
    "text": "47.3 Modèles zero-inflated\n\nLes modèles zero-inflated ont justement été prévus pour ce cas de figure. Un modèle de Poisson zero-inflated combine deux modèles : un modèle logistique binaire et un modèle de Poisson. Dans un premier temps, on applique le modèle logistique binaire. Si la valeur obtenue est 0, le résultat final est 0. Si la valeur obtenue est 1, alors on applique le modèle de Poisson.\nLes modèles de Poisson zero-inflated sont notamment implémentés dans le package pscl via la fonction pscl::zeroinfl().\nCalculons un premier modèle de Poisson zero-inflated.\n\nmod_zip &lt;- pscl::zeroinfl(\n  ofp ~ gender + privins + health + numchron,\n  data = d\n)\n\nRegardons les coefficients du modèle (en forçant l’affichage des intercepts). Comme il s’agit d’un modèle à plusieurs composantes, nous aurons recours à ggstats::ggcoef_multicomponents().\n\nmod_zip |&gt; \n  ggstats::ggcoef_multicomponents(\n    type = \"table\",\n    exponentiate = TRUE,\n    intercept = TRUE\n  )\n\nℹ &lt;zeroinfl&gt; model detected.\n\n\n✔ `tidy_zeroinfl()` used instead.\n\n\nℹ Add `tidy_fun = broom.helpers::tidy_zeroinfl` to quiet these messages.\n\n\n\n\n\n\n\nFigure 47.2: Coefficients du modèle de Poisson zero-inflated\n\n\n\n\nNous obtenons deux séries de coefficients : une série conditional correspondant au modèle de Poisson et une série zero_inflated correspondant au modèle logistique binaire. Nous avons représenter les exponentiels des coefficients, qui s’interprètent donc comme des risk ratio pour le modèle de Poisson et des odds ratio pour le modèle logistique.\nLes variables ayant un effet significatif ne sont pas les mêmes pour les deux composantes du modèle. Il est d’ailleurs possible d’utiliser des variables différentes pour chaque composante, en écrivant d’abord l’équation du modèle de Poisson, puis celle du modèle logistique et en les séparant avec le symbole |. D’ailleurs, la syntaxe ofp ~ gender + privins + health + numchron est équivalente à ofp ~ gender + privins + health + numchron | gender + privins + health + numchron. Dans la littérature, on trouve fréquemment des modèles de Poisson zero-inflated simplifiés où seul un intercept est utilisé pour la composante logistique binaire.\n\nmod_zip_simple &lt;- pscl::zeroinfl(\n  ofp ~ gender + privins + health + numchron | 1,\n  data = d\n)\n\n\nmod_zip_simple |&gt; \n  ggstats::ggcoef_multicomponents(\n    type = \"table\",\n    tidy_fun = broom.helpers::tidy_zeroinfl,\n    exponentiate = TRUE,\n    intercept = TRUE,\n    component_label = c(\n      conditional = \"Modèle de Poisson\",\n      zero_inflated = \"Modèle logistique binaire\"\n    )\n  ) +\n  patchwork::plot_layout(heights = c(6, 1))\n\n\n\n\n\n\nFigure 47.3: Coefficients du modèle de Poisson zero-inflated simple\n\n\n\n\nPour ce jeu de données, cela ne modifie que peu les coefficients de la composante modèle de comptage.\nDe même, il est possible de préférer un modèle négatif binomial plutôt que Poisson pour la composante modèle de comptage. Il suffit d’ajouter l’argument dist = \"negbin\".\n\nmod_zinb &lt;- pscl::zeroinfl(\n  ofp ~ gender + privins + health + numchron,\n  dist = \"negbin\",\n  data = d\n)\n\nNous pouvons aisément comparer l’AIC de ces différents modèles.\n\nperformance::compare_performance(\n  mod_poisson,\n  mod_zip_simple,\n  mod_zip,\n  mod_nb,\n  mod_zinb,\n  metrics = \"AIC\"\n)\n\n# Comparison of Model Performance Indices\n\nName           |    Model |   AIC (weights)\n-------------------------------------------\nmod_poisson    |      glm | 36792.1 (&lt;.001)\nmod_zip_simple | zeroinfl | 33308.5 (&lt;.001)\nmod_zip        | zeroinfl | 33014.2 (&lt;.001)\nmod_nb         |   negbin | 24505.7 (&lt;.001)\nmod_zinb       | zeroinfl | 24380.9 (&gt;.999)\n\n\nComparons les coefficients de la composante comptage du modèle négatif binomial zero-inflated avec ceux du modèle négatif binomial classique.\n\nlibrary(gtsummary)\ntbl_nb &lt;- mod_nb |&gt; \n  tbl_regression(exponentiate = TRUE)\ntbl_zinb &lt;- mod_zinb |&gt; \n  tbl_regression(\n    tidy_fun = broom.helpers::tidy_zeroinfl,\n    component = \"conditional\",\n    exponentiate = TRUE\n  )\nlist(tbl_nb, tbl_zinb) |&gt; \n  tbl_merge(c(\"**NB**\", \"**ZI-NB**\")) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\n\nNB\n\n\n\nZI-NB\n\n\n\n\nIRR\n1\n\n\n95% CI\n1\n\np-value\nexp(Beta)\n\n95% CI\n1\n\np-value\n\n\n\n\nGenre de l'assuré\n\n\n\n\n\n\n\n\n    femme\n—\n—\n\n—\n—\n\n\n\n    homme\n0.90\n0.84, 0.95\n&lt;0.001\n0.93\n0.88, 0.99\n0.031\n\n\nDispose d'une assurance privée ?\n\n\n\n\n\n\n\n\n    non\n—\n—\n\n—\n—\n\n\n\n    oui\n1.39\n1.29, 1.50\n&lt;0.001\n1.23\n1.14, 1.33\n&lt;0.001\n\n\nSanté perçue\n\n\n\n\n\n\n\n\n    pauvre\n1.39\n1.27, 1.53\n&lt;0.001\n1.38\n1.26, 1.51\n&lt;0.001\n\n\n    moyenne\n—\n—\n\n—\n—\n\n\n\n    excellente\n0.71\n0.63, 0.80\n&lt;0.001\n0.71\n0.63, 0.81\n&lt;0.001\n\n\nNombre de conditions chroniques\n1.21\n1.19, 1.25\n&lt;0.001\n1.16\n1.13, 1.19\n&lt;0.001\n\n\n\n\n1\nIRR = Incidence Rate Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\nTable 47.1: Coefficients du modèle négatif binomial et de la composante comptage du modèle négatif binomial zero-inflated\n\n\n\nComme nous pouvons le voir, les résultats sont relativement proches.\nSi l’interprétation du modèle de comptage reste classique, celle du modèle logistique binaire est parfois un peu plus complexe. En effet, il y a deux sources de 0 dans le modèle zero-inflated : si certains sont générés par la composante logistique binaire (dont c’est justement le rôle), le modèle de comptage génère lui aussi des 0. Dès lors, le modèle logistique binaire ne suffit pas à lui seul à identifier les facteurs associés de vivre au moins une fois l’évènement.\nSi l’objectif de l’analyse est avant tout d’identifier les facteurs associés avec le nombre moyen d’évènements, on pourra éventuellement se contenter d’un modèle zero-inflated simple, c’est-à-dire avec seulement un intercept pour la composante zero-inflated afin de corriger la sur-représentation des zéros dans nos données.\nAlternativement, on pourra se tourner vers un modèle avec saut qui distingue les valeurs nulles des valeurs positives : les modèles hurdle en anglais.",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Modèles de comptage *zero-inflated* et *hurdle*</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/modeles-zero-inflated.html#modèles-hurdle",
    "href": "analyses_avancees/modeles-zero-inflated.html#modèles-hurdle",
    "title": "47  Modèles de comptage zero-inflated et hurdle",
    "section": "\n47.4 Modèles hurdle\n",
    "text": "47.4 Modèles hurdle\n\nLes modèles hurdle se distinguent des modèles zero-inflated dans le sens où l’on combine un modèle logistique binomial pour déterminer si les individus ont vécu au moins une fois l’évènement et un modèle de comptage tronqué (qui n’accepte que des valeurs strictement positives) qui détermine le nombre d’évènements vécus uniquement pour ceux l’ayant vécu au moins une fois.\nLes modèles zero-inflated et hurdle diffèrent par leur conceptualisation des zéros et l’interprétation des paramètres du modèle (C. X. Feng 2021).\n\nFeng, Cindy Xin. 2021. « A comparison of zero-inflated and hurdle models for modeling zero-inflated count data ». Journal of Statistical Distributions and Applications 8 (1): 8. https://doi.org/10.1186/s40488-021-00121-4.\nUn modèle zero-inflated suppose que les comptes nuls résultent d’un mélange de deux distributions, l’une où les sujets produisent toujours des comptes nuls, souvent appelés “zéros structurels” ou “zéros excessifs”. Les sujets qui sont exposés au résultat mais qui n’ont pas ou n’ont pas rapporté l’expérience du résultat au cours de la période d’étude sont appelés “zéros d’échantillonnage”. La différenciation des zéros en deux groupes se justifie par le fait que les zéros excessifs sont souvent dus à l’existence d’une sous-population de sujets qui ne sont pas exposés à certains résultats au cours de la période d’étude. Par exemple, lors de la modélisation du nombre de comportements à haut risque, certains participants peuvent obtenir un score de zéro parce qu’ils ne sont pas exposés à un tel comportement à risque pour la santé ; il s’agit des zéros structurels puisqu’ils ne peuvent pas présenter de tels comportements à haut risque. D’autres participants à risque peuvent obtenir un score de zéro parce qu’ils n’ont pas manifesté de tels comportements à risque au cours de la période étudiée. La probabilité d’appartenir à l’une ou l’autre population est estimée à l’aide d’une composante de probabilité à inflation nulle, tandis que les effectifs de la seconde population du groupe d’utilisateurs sont modélisés par une distribution de comptage ordinaire, telle qu’une distribution de Poisson ou binomiale négative.\nEn revanche, un modèle hurdle suppose que toutes les données nulles proviennent d’une source “structurelle”, une partie du modèle étant un modèle binaire pour modéliser si la variable de réponse est nulle ou positive, et une autre partie utilisant un modèle tronqué, pour les données positives. Par exemple, dans les études sur l’utilisation des soins de santé, la partie zéro implique la décision de rechercher des soins, et la composante positive détermine la fréquence de l’utilisation au sein du groupe de l’utilisateur.\nUne autre différence importante entre les modèles hurdle et zero-inflated est leur capacité à gérer la déflation zéro (moins de zéros que prévu par le processus de génération des données). Les modèles zero-inflated ne sont pas en mesure de gérer la déflation zéro, quel que soit le niveau d’un facteur, et donneront des estimations de paramètres de l’ordre de l’infini pour la composante logistique, alors que les modèles hurdle peuvent gérer la déflation zéro (Min et Agresti 2005).\n\nMin, Yongyi, et Alan Agresti. 2005. « Random Effect Models for Repeated Measures of Zero-Inflated Count Data ». Statistical Modelling 5 (1): 1‑19. https://doi.org/10.1191/1471082X05st084oa.\nLes modèles hurdle peuvent être calculés avec la fonction pscl::hurdle() dont la syntaxe est similaire à pscl::zeroinfl().\n\nmod_hurdle_poisson &lt;- pscl::hurdle(\n  ofp ~ gender + privins + health + numchron,\n  data = d\n)\nmod_hurdle_nb &lt;- pscl::hurdle(\n  ofp ~ gender + privins + health + numchron,\n  dist = \"negbin\",\n  data = d\n)\n\nRegardons les coefficients obtenus.\n\nmod_hurdle_nb |&gt; \n  ggstats::ggcoef_multicomponents(\n    type = \"table\",\n    tidy_fun = broom.helpers::tidy_zeroinfl,\n    exponentiate = TRUE,\n    component_label = c(\n      conditional = \"Facteurs associés au nombre d'évènements\",\n      zero_inflated = \"Facteurs associés au fait d'avoir vécu l'évènement\"\n    )\n  )\n\n\n\n\n\n\nFigure 47.4: Coefficients du modèle négatif binomial hurdle\n\n\n\n\nNous pouvons également produire un tableau avec gtsummary::tbl_regression(). L’astuce consiste à générer un tableau pour chaque composante du modèle puis à les fusionner.\n\ntbl_log &lt;- mod_hurdle_nb |&gt; \n  tbl_regression(\n    tidy_fun = broom.helpers::tidy_zeroinfl,\n    component = \"zero_inflated\",\n    exponentiate = TRUE\n  )\ntbl_nb &lt;- mod_hurdle_nb |&gt; \n  tbl_regression(\n    tidy_fun = broom.helpers::tidy_zeroinfl,\n    component = \"conditional\",\n    exponentiate = TRUE\n  )\nlist(tbl_log, tbl_nb) |&gt; \n  tbl_merge(\n    c(\n      \"**OR (régression logistique)**\",\n      \"**RR (négatif binomial)**\"\n    )\n  ) |&gt; \n  bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\n\nOR (régression logistique)\n\n\n\nRR (négatif binomial)\n\n\n\nexp(Beta)\n\n95% CI\n1\n\np-value\nexp(Beta)\n\n95% CI\n1\n\np-value\n\n\n\n\nGenre de l'assuré\n\n\n\n\n\n\n\n\n    femme\n—\n—\n\n—\n—\n\n\n\n    homme\n0.67\n0.56, 0.79\n&lt;0.001\n0.95\n0.89, 1.01\n0.12\n\n\nDispose d'une assurance privée ?\n\n\n\n\n\n\n\n\n    non\n—\n—\n\n—\n—\n\n\n\n    oui\n2.48\n2.06, 2.99\n&lt;0.001\n1.21\n1.12, 1.32\n&lt;0.001\n\n\nSanté perçue\n\n\n\n\n\n\n\n\n    pauvre\n0.98\n0.72, 1.34\n0.9\n1.42\n1.29, 1.57\n&lt;0.001\n\n\n    moyenne\n—\n—\n\n—\n—\n\n\n\n    excellente\n0.77\n0.58, 1.01\n0.063\n0.71\n0.62, 0.81\n&lt;0.001\n\n\nNombre de conditions chroniques\n1.74\n1.59, 1.90\n&lt;0.001\n1.16\n1.13, 1.19\n&lt;0.001\n\n\n\n\n1\nCI = Confidence Interval\n\n\n\n\n\nCoefficients des deux composantes du modèle hurdle\n\n\nAvec un tel modèle, on cherche à répondre à deux questions :\n\nQuels sont les facteurs associés au fait d’avoir vécu l’évènement au moins une fois ?\nSi l’on a vécu l’évènement au moins une fois, quels sont les facteurs associés à la fréquence de l’évènement ?\n\nDans notre exemple, le fait d’avoir une assurance privée joue à la fois sur le fait d’aller consulter un médecin et sur le nombre de consultations. Par contre, la santé perçue n’a pas d’effet sur le fait d’aller consulter mais, si l’on va consulter, cela va influer fortement sur le nombre de consultations. À l’inverse, le sexe de l’assuré a un effet sur le fait d’aller consulter (les hommes consultent moins que les femmes) mais, si l’on consulte, ne joue pas sur le nombre de consultations.",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Modèles de comptage *zero-inflated* et *hurdle*</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/modeles-zero-inflated.html#modèles-de-taux-zero-inflated-ou-hurdle",
    "href": "analyses_avancees/modeles-zero-inflated.html#modèles-de-taux-zero-inflated-ou-hurdle",
    "title": "47  Modèles de comptage zero-inflated et hurdle",
    "section": "\n47.5 Modèles de taux zero-inflated ou hurdle\n",
    "text": "47.5 Modèles de taux zero-inflated ou hurdle\n\nIl est tout à fait possible de réaliser un modèle de taux ou d’incidence (cf. Chapitre 46) zero-inflated ou hurdle. Pour cela, on rajoutera comme avec un modèle classique un décalage (offset) correspondant au logarithme de la durée d’exposition.\nCe décalage s’ajoute a minima à la composante comptage du modèle zero-inflated ou du modèle hurdle. Toutefois, la probabilité de ne pas vivre l’évènement (donc de zéro) peut elle-même être influencée par la durée d’exposition, auquel cas il pourrait être pertinent d’ajouter également l’offset à la composante inflation des zéros du modèle. Certains auteurs suggèrent même d’inclure le logarithme de la durée d’exposition non pas sous forme d’un offset mais directement comme une variable explicative du modèle (C. Feng 2022).\n\nFeng, Cindy. 2022. « Zero-inflated models for adjusting varying exposures: a cautionary note on the pitfalls of using offset ». Journal of Applied Statistics 49 (1): 1‑23. https://doi.org/10.1080/02664763.2020.1796943.",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Modèles de comptage *zero-inflated* et *hurdle*</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/modeles-zero-inflated.html#tutomate",
    "href": "analyses_avancees/modeles-zero-inflated.html#tutomate",
    "title": "47  Modèles de comptage zero-inflated et hurdle",
    "section": "\n47.6 Tuto@Mate",
    "text": "47.6 Tuto@Mate\nLes modèles de comptage zero-inflated sont présentés sur YouTube dans le Tuto@Mate#62.",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Modèles de comptage *zero-inflated* et *hurdle*</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/modeles-zero-inflated.html#lectures-complémentaires",
    "href": "analyses_avancees/modeles-zero-inflated.html#lectures-complémentaires",
    "title": "47  Modèles de comptage zero-inflated et hurdle",
    "section": "\n47.7 Lectures complémentaires",
    "text": "47.7 Lectures complémentaires\n\nRegression Models for Count Data in R par Achim Zeileis, Christian Kleiber et Simon Jackman\nToo many zeros and/or highly skewed? A tutorial on modelling health behaviour as count data with Poisson and negative binomial regression par James A. Green. DOI : 10.1080/21642850.2021.1920416\nA comparison of zero-inflated and hurdle models for modeling zero-inflated count data par Cindy Xin Feng. DOI : 10.1186/s40488-021-00121-4\nZero-inflated models for adjusting varying exposures: a cautionary note on the pitfalls of using offset by Cindy Xin Feng. DOI : 10.1080/02664763.2020.1796943\n\n\n\n\nFigure 47.1: Comparaison des valeurs observées et des valeurs théoriques\nFigure 47.2: Coefficients du modèle de Poisson zero-inflated\nFigure 47.3: Coefficients du modèle de Poisson zero-inflated simple\nFigure 47.4: Coefficients du modèle négatif binomial hurdle",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Modèles de comptage *zero-inflated* et *hurdle*</span>"
    ]
  },
  {
    "objectID": "analyses_avancees/choix-modele.html#footnotes",
    "href": "analyses_avancees/choix-modele.html#footnotes",
    "title": "48  Quel modèle choisir ?",
    "section": "",
    "text": "Voir aussi glmtoolbox::glmgee() ou gee::gee() comme alternative à geepack::geeglm().↩︎\nIl n’y a pas de solution évidente.\nL’approche la plus simple consiste à réaliser plusieurs modèles logistiques binaires séparés à l’aide de lme4::glmer(). Si la variable à expliquer a trois niveaux (A, B et C), on pourra réaliser un modèle binaire B vs A, et un modèle binaire C vs A. Cette approche est appelée approximation de Begg et Gray. On trouvera, en anglais, plus d’explications et des références bibliographiques sur StackOverflow.\nUne approche alternative, dans un contexte bayésien et non fréquentiste, est d’avoir recours à brms::brm() qui peut gérer ce type de modèles. Cette approche, avec des exemples de code, est mentionnée sur StackOverflow.\nDans le cadre d’une approche fréquentiste, la fonction mgcv::gam() est mentionnée sur StackExchange, de même que la fonction mixcat::npmlt() (voir ce post), sachant que le package {mixcat} est faiblement documenté et ne semble plus forcément maintenu.\nEnfin, il semble possible d’avoir recours à MCMCglmm::MCMCglmm(), selon cette réponse sur StackOverflowet ce billet de blog.↩︎\nCf. https://drizopoulos.github.io/GLMMadaptive/articles/ZeroInflated_and_TwoPart_Models.html↩︎",
    "crumbs": [
      "**Analyses avancées**",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Quel modèle choisir ?</span>"
    ]
  },
  {
    "objectID": "extra/ressources-documentaires.html",
    "href": "extra/ressources-documentaires.html",
    "title": "49  Ressources documentaires",
    "section": "",
    "text": "49.1 Ressources génériques",
    "crumbs": [
      "**Pour aller plus loin**",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Ressources documentaires</span>"
    ]
  },
  {
    "objectID": "extra/ressources-documentaires.html#ressources-génériques",
    "href": "extra/ressources-documentaires.html#ressources-génériques",
    "title": "49  Ressources documentaires",
    "section": "",
    "text": "Introduction à R et au tidyverse de Julien Barnier\nAwesome R : cette liste recense des ressources sur différents domaines\nRzine : un site collaboratif et interdisciplinaire de référencement et de partage de documentation sur la pratique de R en sciences humaines et sociales\nRseek : un moteur de recherche restreignant les résultats à un corpus de sources sur R\nR for data science par Hadley Wickham, Mine Çetinkaya-Rundel et Garret Grolemund\nUtilitR, une documentation sur R née à l’INSEE\nNotes de cours de R par Ewan Gallic\nProgrammer en R, un wikibook collaboratif\nIntroduction à la programmation en R par Vincent Goulet\nHappy Git and GitHub for the useR par Jennifer Bryan\nModern Data Science with R par Benjamin S. Baumer, Daniel T. Kaplan, and Nicholas J. Horton\nThe Epidemiologist R Handbook: R for applied epidemiology and public health porté par un collectif d’auteurs\nR for Non-Programmers: A Guide for Social Scientists par Daniel Dauber",
    "crumbs": [
      "**Pour aller plus loin**",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Ressources documentaires</span>"
    ]
  },
  {
    "objectID": "extra/ressources-documentaires.html#analyse-de-réseaux",
    "href": "extra/ressources-documentaires.html#analyse-de-réseaux",
    "title": "49  Ressources documentaires",
    "section": "49.2 Analyse de réseaux",
    "text": "49.2 Analyse de réseaux\n\nL’analyse de réseau en sciences sociales. Petit guide pratique par Laurent Beauguitte, HAL : hal-04052709\nNetwork visualization with R par Katherine Ognyanova\nAwesome Network Analysis list portée par François Briatte\nCours d’introduction à l’analyse de réseaux avec R par Hugues Pecout et Laurent Beauguitte",
    "crumbs": [
      "**Pour aller plus loin**",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Ressources documentaires</span>"
    ]
  },
  {
    "objectID": "extra/ressources-documentaires.html#analyse-spatiale-cartographie",
    "href": "extra/ressources-documentaires.html#analyse-spatiale-cartographie",
    "title": "49  Ressources documentaires",
    "section": "49.3 Analyse spatiale & Cartographie",
    "text": "49.3 Analyse spatiale & Cartographie\n\nCartographie avec R et Géomatique avec R par Timothée Giraud et Hugues Pecout\nDonnées géospatiales et cartographie avec R par Nicolas Roelandt\nGeocomputation with R par Robin Lovelace, Jakub Nowosad et Jannes Muenchow\nSpatial Modelling for Data Scientists par Francisco Rowe et Dani Arribas-Bel\nSpatial Data Science with R and “terra” par Robert J. Hijmans",
    "crumbs": [
      "**Pour aller plus loin**",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Ressources documentaires</span>"
    ]
  },
  {
    "objectID": "extra/ressources-documentaires.html#analyse-textuelle",
    "href": "extra/ressources-documentaires.html#analyse-textuelle",
    "title": "49  Ressources documentaires",
    "section": "49.4 Analyse textuelle",
    "text": "49.4 Analyse textuelle\n\nLe Descriptoire : Recueil et analyse de texte avec R par Lise Vaudor\nText mining with R par Julia Silge et David Robinson",
    "crumbs": [
      "**Pour aller plus loin**",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Ressources documentaires</span>"
    ]
  }
]